<html><head></head><body>
<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2"><h1 class="chapter-number" id="_idParaDest-185"><a id="_idTextAnchor199" class="pcalibre1 pcalibre2 pcalibre"/>10</h1>

<h3 id="_idParaDest-186" class="calibre6"><a id="_idTextAnchor200" class="pcalibre1 pcalibre2 pcalibre"/>Cloud Evidence Acquisition</h3>
<p class="calibre3">Until now, we<a id="_idIndexMarker824" class="pcalibre1 pcalibre2 pcalibre"/> have looked at investigating artifacts locally within the cloud using the tools provided by the <strong class="bold">Cloud Service Provider</strong> (<strong class="bold">CSP</strong>). We looked at AWS GuardDuty CloudTrail from a logging and investigation point of view. We also looked at GCP’s Cloud Logging capability to investigate cloud logs emitted by various services, and Azure Monitor offers similar capabilities for services hosted within <span>Microsoft Azure.</span></p>
<p class="calibre3">This chapter will take a step further in our cloud investigative journey and look at methods and techniques for securely collecting artifacts or forensic images of core services for offline analysis. Investigators will recognize that not all investigations can be performed using native cloud tools. Investigators may be required to use specialized tools that they have access to in a forensic environment, and the challenge will be to collect images from the cloud in a forensically sound and legally acceptable manner. We will explore these tools in the later sections of this chapter. We will be looking at forensic collections from the three <span>significant CSPs:</span></p>

<ul class="calibre12">
<li class="calibre13">Forensic acquisition of <span>AWS instances</span></li>
<li class="calibre13">Forensic acquisition of Microsoft <span>Azure Instances</span></li>
<li class="calibre13">Forensic acquisition of <span>GCP instances</span></li>
</ul>
<p class="calibre3">Note that throughout this chapter, we will rely on some standard steps for collecting forensic images when investigators can access a Windows or a Linux operating system; these steps are standard irrespective of the underlying <span>cloud platform.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h1 id="_idParaDest-187" class="calibre5"><a id="_idTextAnchor201" class="pcalibre1 pcalibre2 pcalibre"/>Forensic acquisition of AWS instance</h1>
<p class="calibre3">Let us<a id="_idIndexMarker825" class="pcalibre1 pcalibre2 pcalibre"/> jump right into the details of collecting forensic<a id="_idIndexMarker826" class="pcalibre1 pcalibre2 pcalibre"/> artifacts in a secure and forensically sound manner. We will assume that an organization received alerts for ransomware deployment on<a id="_idIndexMarker827" class="pcalibre1 pcalibre2 pcalibre"/> an <strong class="bold">Elastic Compute Cloud</strong> (<strong class="bold">EC2</strong>) instance. As a result, this instance was stopped. Forensic investigators would need to pull forensic artifacts out of the EC2 <span>instance safely.</span></p>
<p class="calibre3">Any disks associated with an EC2 instance are referred to <a id="_idIndexMarker828" class="pcalibre1 pcalibre2 pcalibre"/>as <strong class="bold">volumes</strong> by AWS. To collect artifacts, investigators have to follow a specific sequence of steps. Firstly, investigators must record the infected <a id="_idIndexMarker829" class="pcalibre1 pcalibre2 pcalibre"/>instance’s <strong class="bold">instance ID</strong> (<span>unique identifier).</span></p>
<p class="calibre3">In this case, the<a id="_idIndexMarker830" class="pcalibre1 pcalibre2 pcalibre"/> infected instance name is <strong class="source-inline">CF2</strong> and it has the <a id="_idIndexMarker831" class="pcalibre1 pcalibre2 pcalibre"/>instance <span>ID </span><span><strong class="source-inline">i-00229ce2dd123a2e6</strong></span><span>.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h2 id="_idParaDest-188" class="calibre10"><a id="_idTextAnchor202" class="pcalibre1 pcalibre2 pcalibre"/>Step 1 – creating EC2 volume snapshots</h2>
<p class="calibre3">We will<a id="_idIndexMarker832" class="pcalibre1 pcalibre2 pcalibre"/> refer <a id="_idIndexMarker833" class="pcalibre1 pcalibre2 pcalibre"/>to these EC2 instances by their instance ID for the <span>following steps:</span></p>

<ol class="calibre14">
<li class="calibre13">Investigators must note storage volumes associated with <strong class="source-inline">i-00229ce2dd123a2e6 (CF2)</strong> and the volume IDs (a unique identifier for <span>each volume):</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer156"><img alt="Figure 10.1 – Volumes (disks) associated with 00229ce2dd123a2e (CF2)" src="../images/00021.jpeg" class="calibre158"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.1 – Volumes (disks) associated with 00229ce2dd123a2e (CF2)</p>

<ol class="calibre14">
<li value="2" class="calibre13">We see two volumes attached to <strong class="source-inline">i-00229ce2dd123a2e (CF2)</strong>. AWS will always assign the root drive (<strong class="source-inline">C:\</strong>) to <strong class="source-inline">/dev/sda1</strong>. This is an investigator’s reference point if they only want to collect forensic images of the <span>root drive.</span></li>
<li class="calibre13">We select the root drive, <strong class="source-inline">vol-061392d9abebf9433</strong>, attached to instance <strong class="source-inline">i-00229ce2dd123a2e (CF2)</strong>, which takes us to the <strong class="bold">Volumes</strong> page, identified in the <span>following screenshot:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer157"><img alt="Figure 10.2 – Selecting the volume that requires forensic imaging" src="../images/00039.jpeg" class="calibre159"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.2 – Selecting the volume that requires forensic imaging</p>

<ol class="calibre14">
<li value="4" class="calibre13">Under <a id="_idIndexMarker834" class="pcalibre1 pcalibre2 pcalibre"/>the <strong class="bold">Actions</strong> tab, select the <strong class="bold">Create snapshot</strong> option. Snapshot creates a copy of the original volume without modifying the volume. We demonstrate this in <span><em class="italic">Figure 10</em></span><em class="italic">.3</em>. Investigators must note<a id="_idIndexMarker835" class="pcalibre1 pcalibre2 pcalibre"/> that volumes associated with an EC2 instance cannot directly be downloaded or exported. It is always recommended to perform forensics on a copy or a snapshot of the original volume instead of the original volume to <span>preserve artifacts.</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer158"><img alt="Figure 10.3 – Selecting the AWS volume for the snapshot" src="../images/00056.jpeg" class="calibre160"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.3 – Selecting the AWS volume for the snapshot</p>

<ol class="calibre14">
<li value="5" class="calibre13">Depending on the size of the volume, creating a snapshot may take seconds to a few minutes. Investigators must wait until proceeding further, ensuring snapshots are successfully created. In <span><em class="italic">Figure 10</em></span><em class="italic">.4</em>, we see the successful completion of the snapshot. All the snapshots will be available under the <strong class="bold">Snapshots</strong> navigation tab within AWS EC2. Investigations must again record the unique snapshot<a id="_idIndexMarker836" class="pcalibre1 pcalibre2 pcalibre"/> ID. In this <a id="_idIndexMarker837" class="pcalibre1 pcalibre2 pcalibre"/>case, this <span>is </span><span><strong class="source-inline">snap-0857fc1efa85ae0ff</strong></span><span>.</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer159"><img alt="Figure 10.4 – Snapshot created of AWS Volume (vol-061392d9abebf9433)" src="../images/00074.jpeg" class="calibre161"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.4 – Snapshot created of AWS Volume (vol-061392d9abebf9433)</p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h2 id="_idParaDest-189" class="calibre10"><a id="_idTextAnchor203" class="pcalibre1 pcalibre2 pcalibre"/>Step 2 – acquiring OS memory images</h2>
<p class="calibre3">Let us <a id="_idIndexMarker838" class="pcalibre1 pcalibre2 pcalibre"/>now look at methods of acquiring memory images of an EC2 instance forensically. Should there be a need for taking a memory image as part of the<a id="_idIndexMarker839" class="pcalibre1 pcalibre2 pcalibre"/> investigation, DFIR teams can consider some common steps as long as the infected instance is still running. Investigators have some form of interactive access to the infected instance via the command line (AWS <strong class="bold">System Manager</strong> (<strong class="bold">SSM</strong>) or GCP’s Cloud Shell) or direct access to the <a id="_idIndexMarker840" class="pcalibre1 pcalibre2 pcalibre"/>instance via RDP or SSH. If possible, investigators must ensure that their identities are configured with the <strong class="source-inline">AmazonSSMFullAccess</strong> policy to allow complete access to the EC2 instance through <span>Amazon SSM.</span></p>
<p class="calibre3">Taking a memory image is more complicated than a disk image. One of the simplest methods would be switching the EC2 instance into hibernation mode, which forces all the memory contents to be written to the disk in the form of <strong class="source-inline">hyberfil.sys</strong> before a complete disk evidence collection can be performed, allowing investigators to utilize a snapshot of <span>the memory.</span></p>

<h3 class="calibre11">Step 2a – acquiring memory images via hibernation</h3>
<p class="calibre3">One of the <a id="_idIndexMarker841" class="pcalibre1 pcalibre2 pcalibre"/>options that AWS allows within its EC2 <a id="_idIndexMarker842" class="pcalibre1 pcalibre2 pcalibre"/>dashboard is hibernation. Select the instance, choose <strong class="bold">Instance state</strong>, and select <strong class="bold">Hibernation</strong>. However, for AWS to hibernate the EC2 instance (on Windows or Linux), it must meet the <span>following conditions:</span></p>

<ul class="calibre12">
<li class="calibre13">AWS supports the cloud native hibernation feature only on select <span>instance families.</span></li>
<li class="calibre13">When launching an EC2 instance, administrators should have enabled the <strong class="bold">Hibernation</strong> feature under <strong class="bold">Advanced settings</strong> to enable this behavior. This cannot be changed after an EC2 instance <span>is created/launched.</span></li>
<li class="calibre13">The EC2 instance must have root storage space to accommodate <span>memory contents.</span></li>
<li class="calibre13">Only specific <strong class="bold">Elastic Block Storage</strong> (<strong class="bold">EBS</strong>) volumes<a id="_idIndexMarker843" class="pcalibre1 pcalibre2 pcalibre"/> are supported, including General Purpose SSD (<strong class="source-inline">gp2</strong> and <strong class="source-inline">gp3</strong>) or Provisioned IOPS SSD (<strong class="source-inline">io1</strong> <span>and </span><span><strong class="source-inline">io2</strong></span><span>)</span></li>
</ul>
<p class="calibre3">AWS will not support cloud-native hibernation if the preceding conditions are <span>not configured.</span></p>
<p class="calibre3">Once hibernation is enabled, investigators can capture memory contents by hibernating via the cloud console and collecting disk images <span>for forensics.</span></p>

<h3 class="calibre11">Step 2b – common steps for acquiring memory images directly from OS</h3>
<p class="calibre3">The process for <a id="_idIndexMarker844" class="pcalibre1 pcalibre2 pcalibre"/>memory acquisition is quite simple, but securely acquiring a forensic image is a manual process. You will note that there are various ways this can be automated; however, it depends on the level of access the investigators have and their roles (external (one-time) investigators or in-house corporate investigators). If it’s in-house and organizations have a bigger footprint in the cloud, they can look into automating forensic collections and uploading to the cloud storage in various ways. In the <em class="italic">Further reading</em> section, we have included some ideas that leverage other cloud services. However, these steps provide you with a guide to make forensic data <span>acquisition easier.</span></p>
<p class="calibre3">The following steps will provide a high-level overview of collecting memory images from relevant operating systems. Investigators must ensure that they can connect to the instance, either through an interactive RDP session or through a command line using cloud-native <a id="_idIndexMarker845" class="pcalibre1 pcalibre2 pcalibre"/>command <span>line capabilities:</span></p>

<h4 class="calibre136">Collecting memory images from a Windows OS instance</h4>
<p class="calibre3">Once <a id="_idIndexMarker846" class="pcalibre1 pcalibre2 pcalibre"/>investigators log into the infected <a id="_idIndexMarker847" class="pcalibre1 pcalibre2 pcalibre"/>Windows instance, they can begin <span>their collections:</span></p>

<ol class="calibre14">
<li class="calibre13">Specifically in AWS, this can be achieved by either directly logging into the affected virtual machine or via <span>Amazon SSM.</span></li>
<li class="calibre13">Using <strong class="source-inline">powershell.exe</strong> with Windows Administrator privileges, create a folder to place all the memory dumps and <span>artifacts in.</span></li>
<li class="calibre13">We then download the most recent version of <strong class="source-inline">winpmem.exe</strong> (we referred to this tool in <a href="part0028_split_000.html#_idTextAnchor151" class="pcalibre1 pcalibre2 pcalibre"><span><em class="italic">Chapter 8</em></span></a>) using the <span>following command:</span>
<pre class="source-code"><strong class="bold">&gt; Invoke</strong><strong class="bold">-WebRequest -Uri https://github.com/Velocidex/WinPmem/releases/download/v4.0.rc1/winpmem_mini_x64_rc2.exe -OutFile "winpmem.exe"</strong></pre></li> <li class="calibre13">Once it's been downloaded, we run it within the same PowerShell window. We run the tool and provide a file name as a parameter to save the memory into a file. Note that we are capturing the memory in <span>RAW format:</span>
<pre class="source-code"><strong class="bold">&gt; winpmem</strong><strong class="bold">.exe memory.raw</strong></pre></li> <li class="calibre13">The following screenshots demonstrate the in-progress memory collection. Depending upon the size of the memory, this may take anything from a few seconds to a <span>few minutes:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer160"><img alt="Figure 10.5 – Memory dump using winpmem.exe" src="../images/00094.jpeg" class="calibre162"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.5 – Memory dump using winpmem.exe</p>
<p class="calibre3">Once <a id="_idIndexMarker848" class="pcalibre1 pcalibre2 pcalibre"/>memory collections are <a id="_idIndexMarker849" class="pcalibre1 pcalibre2 pcalibre"/>complete, investigators must export the memory dump to a remote server or cloud-native storage area for offline access and processing. Alternatively, depending on an investigator’s preference, you can also turn off the operating system and take a complete disk snapshot, and through forensic disk imaging, the memory images can later be exported as an artifact during the offline processing of the <span>disk images.</span></p>

<h4 class="calibre136">Acquiring memory images from a Linux OS</h4>
<p class="calibre3">Key differences <a id="_idIndexMarker850" class="pcalibre1 pcalibre2 pcalibre"/>investigators must know about are the<a id="_idIndexMarker851" class="pcalibre1 pcalibre2 pcalibre"/> different Linux and Windows operating system tools for memory acquisition. In some cases, investigators must first compile the specialized tools from the source to collect forensic images of the memory. This is because these tools make use of low-level libraries that are specific to the Linux kernel versions. For this purpose, we use <strong class="bold">LiME</strong>, which<a id="_idIndexMarker852" class="pcalibre1 pcalibre2 pcalibre"/> allows for full volatile memory acquisition <span>in Linux.</span></p>
<p class="calibre3">Here are the steps for collecting <span>memory images:</span></p>

<ol class="calibre14">
<li class="calibre13">Once relevant access is secured, investigators must ensure they can download and compile tools from the source. They will also need access to the <strong class="source-inline">sudo</strong> command. In this case, we will use the LiME tool for memory capture. We will download them from GitHub using a command compile them. It is best if all the following commands are run with <strong class="source-inline">sudo</strong> privileges (meaning <span>as </span><span><strong class="source-inline">root</strong></span><span>):</span>
<pre class="source-code"><strong class="bold"># git</strong><strong class="bold"> clone https://github.com/504ensicsLabs/LiME.git</strong>
<strong class="bold"># cd</strong><strong class="bold"> LiME/src</strong>
<strong class="bold"># make</strong></pre></li> <li class="calibre13">Once <a id="_idIndexMarker853" class="pcalibre1 pcalibre2 pcalibre"/>LiME is compiled within the virtual <a id="_idIndexMarker854" class="pcalibre1 pcalibre2 pcalibre"/>machine, you can collect memory images using the following command. Ensure you have a folder created to save your memory artifacts in. In our example, we will save the memory image within <strong class="source-inline">/home/ubuntu/ir_forensics/</strong> <span>as </span><span><strong class="source-inline">memory.dump</strong></span>
<pre class="source-code"><strong class="bold">root@ip-172-31-2-215:/home/ubuntu/ir_forensics/LiME/src# insmod lime-$(uname -r).ko "path=/home/ubuntu/ir_forensics/memory.dump format=lime"</strong></pre></li> <li class="calibre13">The following parameters are supplied for collecting the memory image. We are running LiME from the <strong class="source-inline">src</strong> folder, as the compiled version is saved in <span>this folder:</span><ul class="calibre17"><li class="calibre13"><strong class="source-inline">insmod</strong>: This command inserts a kernel module into a running <span>Linux kernel.</span></li><li class="calibre13"><strong class="source-inline">lime-$(uname -r).ko</strong>: This command part specifies the kernel module to load. It uses command substitution (<strong class="source-inline">$(uname -r)</strong>) to dynamically insert the current kernel version into the filename, loading a LiME module tailored to the currently running <span>kernel version.</span></li><li class="calibre13"><strong class="source-inline">path=/home/ubuntu/ir_foreniscs/memory.dump</strong>: This parameter specifies the path to save the <span>memory dump.</span></li><li class="calibre13"><strong class="source-inline">format=lime</strong>: This parameter specifies the format in which the memory dump should be saved, which is <strong class="source-inline">lime</strong> in <span>this case.</span></li></ul></li>
<li class="calibre13">Once the<a id="_idIndexMarker855" class="pcalibre1 pcalibre2 pcalibre"/> command executes completely and a <a id="_idIndexMarker856" class="pcalibre1 pcalibre2 pcalibre"/>memory dump is generated, investigators can export the artifacts and analyze them offline using the tool of their choice, <span>including volatility.</span></li>
</ol>
</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h2 id="_idParaDest-190" class="calibre10"><a id="_idTextAnchor204" class="pcalibre1 pcalibre2 pcalibre"/>Step 3 – creating a forensic collector instance</h2>
<p class="calibre3">Once snapshots are <a id="_idIndexMarker857" class="pcalibre1 pcalibre2 pcalibre"/>successfully created, investigators must <a id="_idIndexMarker858" class="pcalibre1 pcalibre2 pcalibre"/>prepare a forensic collector instance. Some DFIR teams may already have their instance pre-created or use a templated virtual machine created for this purpose. Any of the preceding methods is suitable for forensically collecting the artifacts. Investigators must, however, note that when creating a forensic collector instance, the storage size of the collector instance must be appropriately configured. In general, it is recommended to configure a storage space for forensic data that is at least 120% or more of the <span>original volume.</span></p>
<p class="calibre3">We are creating an <strong class="bold">Ubuntu Linux</strong> for <a id="_idIndexMarker859" class="pcalibre1 pcalibre2 pcalibre"/>our forensic collections since Ubuntu natively supports the <strong class="source-inline">dd</strong> tool and Windows and Linux filesystems. No other live forensic tools are installed on Ubuntu for this demonstration, and it’s purely used for forensic collection. Investigators must, however, consider assigning higher CPU and memory for the instance since it will be doing bulk bit-by-bit copying, which requires more <span>CPU cycles.</span></p>
<p class="calibre3">Some investigators may create vast storage space and save all their forensic images within the same storage space, treat it like a USB Drive, or create separate storage for specific volumes. Either way, as long as there’s enough space for the forensic image to be saved, that is all that matters. We created a 100 GB storage volume to capture our forensic image in our target forensic collector instance, although we know the original infected system had only 30 GB of disk size. This should be good enough for all the bit-by-bit copying into the <span>target storage.</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer161"><img alt="Figure 10.6 – Creating a new storage for forensic collections" src="../images/00115.jpeg" class="calibre163"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.6 – Creating a new storage for forensic collections</p>
<p class="calibre3">Once the <a id="_idIndexMarker860" class="pcalibre1 pcalibre2 pcalibre"/>instance is created (<strong class="source-inline">i-00747860d682ac481 (EC2_FORENSIC_CAPTURE)</strong>) and additional storage is set up, we mount the disk, as<a id="_idIndexMarker861" class="pcalibre1 pcalibre2 pcalibre"/> indicated in the following screenshot. See <strong class="source-inline">/dev/nvme1n1p1</strong>, which is mounted <span>as</span> <span><strong class="source-inline">/forensic</strong></span><span>:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer162"><img alt="Figure 10.7 – Additional storage for forensic collections (initialized and mounted)" src="../images/00138.jpeg" class="calibre164"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.7 – Additional storage for forensic collections (initialized and mounted)</p>
<p class="calibre3">Refer to the <em class="italic">Further reading</em> section for information about initializing and mounting disks in <span>Ubuntu Linux.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">Once the target EC2 instance is created (forensic collector), investigators must note the <strong class="bold">availability zone</strong> of<a id="_idIndexMarker862" class="pcalibre1 pcalibre2 pcalibre"/> this instance. We will explain the importance of this in <span><em class="italic">step 4</em></span><span>.</span></p>
<p class="calibre3">In our case, the <a id="_idIndexMarker863" class="pcalibre1 pcalibre2 pcalibre"/>forensic collector instance is hosted in <strong class="source-inline">ca-central-1d</strong>. This <a id="_idIndexMarker864" class="pcalibre1 pcalibre2 pcalibre"/>information is only made available once the EC2 instance <span>is created.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h2 id="_idParaDest-191" class="calibre10"><a id="_idTextAnchor205" class="pcalibre1 pcalibre2 pcalibre"/>Step 4 – creating and attaching infected volume from snapshots</h2>
<p class="calibre3">Specifically for <a id="_idIndexMarker865" class="pcalibre1 pcalibre2 pcalibre"/>forensic purposes, we will create a volume from the snapshot we created in <em class="italic">step 1</em> and attach it to the target volume we created in <span><em class="italic">step 2</em></span><span>:</span></p>

<ol class="calibre14">
<li class="calibre13">The first step is to initiate the volume creation process from the snapshot. As indicated in the following screenshot, we select the snapshot we created in <em class="italic">step 1</em> and then use the <strong class="bold">Actions</strong> option to <strong class="bold">Create volume </strong><span><strong class="bold">from snapshot</strong></span><span>:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer163"><img alt="Figure 10.8 – Create volume from Snapshot (created in step 1)" src="../images/00154.jpeg" class="calibre165"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.8 – Create volume from Snapshot (created in step 1)</p>

<ol class="calibre14">
<li value="2" class="calibre13">As indicated in <em class="italic">step 2</em>, the forensic collector instance is created in the <strong class="source-inline">ca-central-1d</strong> availability zone. Investigators will require this information as volumes are assigned to an availability zone. If appropriate availability zones are not selected, the created volumes will not be available to attach to the target EC2 instance. We follow on-screen instructions on creating the volume; however, ensure that you map the volume to an availability zone that we recorded in <em class="italic">step 2</em> (<strong class="source-inline">ca-central-1d</strong>). Once a volume is created, availability zones cannot be changed, so it is essential to select the correct <span>availability zone.</span></li>
<li class="calibre13">Record the volume ID upon creating the volume from the snapshot. In our case, the volume ID (as reflected in the following screenshot) <span>is </span><span><strong class="source-inline">vol-09ba3e6ad9ed12e5b</strong></span><span>:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer164"><img alt="Figure 10.9 – Successful volume creation from snapshot" src="../images/00172.jpeg" class="calibre166"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.9 – Successful volume creation from snapshot</p>

<ol class="calibre14">
<li value="4" class="calibre13">Once the<a id="_idIndexMarker866" class="pcalibre1 pcalibre2 pcalibre"/> volume is successfully created, we attach the new volume to the forensic collector EC2 instance (<strong class="source-inline">i-00747860d682ac481 (EC2_FORENSIC_CAPTURE)</strong>). We filter the new volume based on its unique identifier, select the volume, and under <strong class="bold">Actions</strong>, select <strong class="bold">Attach volume</strong>. No limitation exists on how many volumes can be attached to an <span>EC2 instance:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer165"><img alt="Figure 10.10 – Attaching a volume to the EC2 instance" src="../images/00190.jpeg" class="calibre167"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.10 – Attaching a volume to the EC2 instance</p>

<ol class="calibre14">
<li value="5" class="calibre13">As indicated in the next screenshot, we follow on-screen instructions. However, one specific area that requires investigators to pay attention is mapping the volume to the correct instance; therefore, investigators must record the unique instance ID to ensure the volumes are attached correctly. In our case, we attach the volume (<strong class="source-inline">vol-09ba3e6ad9ed12e5b</strong>) to the EC2 instance (<strong class="source-inline">i-00747860d682ac481 (EC2_FORENSIC_CAPTURE)</strong>). As you can see, key elements are highlighted in the following screenshot. This is where everything comes together: the <strong class="bold">Volume ID</strong>, which reflects the new volume (<strong class="source-inline">vol-09ba3e6ad9ed12e5b</strong>) we created from the snapshot (<strong class="source-inline">snap-0957fc1efa85ae0ff</strong>) in <em class="italic">step 1</em>, the <strong class="bold">Availability Zone</strong> (<strong class="source-inline">ca-central-1d</strong>), which we recorded in <em class="italic">step 2</em> upon creating the EC2 instance and also when volume was created, and the <strong class="bold">Instance</strong> itself, which is the EC2 instance we created for<a id="_idIndexMarker867" class="pcalibre1 pcalibre2 pcalibre"/> forensic collections (<span><strong class="source-inline">i-00747860d682ac481 (EC2_FORENSIC_CAPTURE)</strong></span><span>):</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer166"><img alt="Figure 10.11 – Attaching volumes to EC2 instance for forensics" src="../images/00009.jpeg" class="calibre168"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.11 – Attaching volumes to EC2 instance for forensics</p>

<ol class="calibre14">
<li value="6" class="calibre13">Note that AWS will reference attached volumes as mount points; in this case, for AWS, the device name mount point is <strong class="source-inline">/dev/sdf</strong>, which may not be the same when accessing the volume within the Ubuntu Linux <span>operating system.</span></li>
<li class="calibre13">Now we <a id="_idIndexMarker868" class="pcalibre1 pcalibre2 pcalibre"/>switch to the Ubuntu Linux, our forensic collector system (<span><strong class="source-inline">i-00747860d682ac481 (EC2_FORENSIC_CAPTURE)</strong></span><span>).</span></li>
</ol>
<h3 class="calibre11">Step 4a – common steps for acquiring instance disk images</h3>
<p class="calibre3">Irrespective of the cloud<a id="_idIndexMarker869" class="pcalibre1 pcalibre2 pcalibre"/> service provider, the following steps are common steps that would be followed for collecting operating system forensic data. Before we start the forensic collection, ensure that pre-requisites are completed, which includes taking a snapshot, creating a forensic collector instance, and <span>so on:</span></p>

<ol class="calibre14">
<li class="calibre13">Once infected volume snapshots are created within the cloud console, investigators can perform full disk forensic data collections. We will leverage the <strong class="source-inline">dd</strong> command natively available on Linux Ubuntu to <span>do this.</span></li>
<li class="calibre13">We will create a forensic collector instance on the same cloud platform to attach snapshots to the forensic collector instance as <span>disk volumes.</span></li>
<li class="calibre13">We validate whether the new volume was correctly attached; see the following screenshot. We do this by running the <strong class="source-inline">lsblk</strong> command along with validating the filesystem information for the identified disk by running <strong class="source-inline">sudo file -</strong><span><strong class="source-inline">s /dev/nvme2n1p1</strong></span><span>:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer167"><img alt="Figure 10.12 – Validating volumes attached to the EC2 instance" src="../images/00028.jpeg" class="calibre169"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.12 – Validating volumes attached to the EC2 instance</p>

<ol class="calibre14">
<li value="4" class="calibre13">For entire disk <a id="_idIndexMarker870" class="pcalibre1 pcalibre2 pcalibre"/>forensic imaging, mounting disks to the instance (within the OS) is unnecessary; <strong class="source-inline">dd</strong> will image the whole volume directly. However, if investigations prefer to pull down specific artifacts (as outlined in <a href="part0028_split_000.html#_idTextAnchor151" class="pcalibre1 pcalibre2 pcalibre"><span><em class="italic">Chapter 8</em></span></a>), they can manually mount the disk to a mount point and extract <span>relevant artifacts.</span></li>
<li class="calibre13">Before initiating the <strong class="source-inline">dd</strong> command, investigators must also ensure the target storage where the forensic images will be saved is created and mounted with read-write privileges. We run the following command to initiate forensic data collection. Ensure you have access to the <strong class="source-inline">sudo</strong> command, as this will be a low-level <span>forensic collection:</span>
<pre class="source-code"><strong class="bold">$ sudo</strong><strong class="bold"> dd if=/dev/nvme2n1p1 of=/forensic/cf2.raw bs=4M status=progress</strong></pre>
<p class="calibre3">Here are the details of the parameters supplied for the <span><strong class="source-inline">dd</strong></span><span> command:</span></p>
<ul class="calibre17"><li class="calibre13"><strong class="source-inline">if=/dev/nvme2n1p1</strong>: This is the source disk that you need a <span>copy of.</span></li><li class="calibre13"><strong class="source-inline">of=/forensic/cf2.raw</strong>: We dump the forensic image in raw format at <strong class="source-inline">/forensic</strong> mount point. You can dump the forensic image in any format if the tool supports it. The forensic image is saved as <strong class="source-inline">cf2.raw</strong> (similar to the hostname of the infected EC2 instance) and is stored under the <span>folder </span><span><strong class="source-inline">/forensic/</strong></span><span>.</span></li><li class="calibre13"><strong class="source-inline">bs=4M</strong>: This sets the block size to 4 MB; you can adjust the value based on <span>the needs.</span></li></ul>
<p class="calibre3">The following screenshot reflects the completion of forensic acquisition via the <span><strong class="source-inline">dd</strong></span><span> command:</span></p>
</li> </ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer168"><img alt="Figure 10.13 – Outputs from the dd command" src="../images/00046.jpeg" class="calibre170"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.13 – Outputs from the dd command</p>

<ol class="calibre14">
<li value="6" class="calibre13">Optionally, once<a id="_idIndexMarker871" class="pcalibre1 pcalibre2 pcalibre"/> forensic imaging is completed, investigators can validate the accuracy by hashing both the source and destination points. For example, in the following snippet, we validate the hashes by running the <strong class="source-inline">md5sum</strong> command and confirming that the acquisition <span>is accurate:</span>
<pre class="source-code"><strong class="bold">ubuntu@ip-172-31-45-98:~$ sudo md5sum /forensic/cf2_image.raw</strong>
<strong class="bold">e24806611c969189ec53a013e143f883  /forensic/cf2_image.raw</strong>
<strong class="bold">ubuntu@ip-172-31-45-98:~$ sudo md5sum /dev/nvme2n1p1</strong>
<strong class="bold">e24806611c969189ec53a013e143f883  /dev/nvme2n1p1</strong></pre></li> </ol>
<p class="calibre3">Once these steps are completed, investigators must determine their export options. Simply put, investigators can either upload these artifacts to the cloud-hosted storage (AWS S3, Azure Blob Storage, GCP Cloud Storage) or upload them to a remote server controlled by the investigator for <span>offline analysis.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h2 id="_idParaDest-192" class="calibre10"><a id="_idTextAnchor206" class="pcalibre1 pcalibre2 pcalibre"/>Step 5 – exporting collected images to AWS S3 for offline processing</h2>
<p class="calibre3">Now that we have <a id="_idIndexMarker872" class="pcalibre1 pcalibre2 pcalibre"/>completed <em class="italic">steps 1–4</em>, our forensic image can be processed offline or offsite. However, before offline processing, you will have to export it. One of the most common methods investigators use is exporting via an <span>S3 bucket:</span></p>

<ol class="calibre14">
<li class="calibre13">Investigators must ensure that an S3 bucket is created and their account is configured with an AWS access key and secret key to access S3 buckets via the command line within EC2. Default configurations will not allow access to <span>S3 buckets.</span></li>
<li class="calibre13">Once a bucket is created and access to AWS S3 is configured, you are all set to export. You can export by running the <span>following command:</span>
<pre class="source-code"><strong class="bold">aws s3 cp /forensic/ s3://forensicbucket1/ --recursive</strong></pre>
<p class="calibre3">The following parameters are typically supplied with the <strong class="source-inline">aws </strong><span><strong class="source-inline">s3</strong></span><span> command:</span></p>
<ul class="calibre17"><li class="calibre13"><strong class="source-inline">cp</strong>: Initiates the copy function, similar to the command available in most <span>Linux variants</span></li><li class="calibre13"><strong class="source-inline">/forensic/</strong>: The source folder name you would like <span>to export</span></li><li class="calibre13"><strong class="source-inline">S3://foreniscbucket1/</strong>: The destination S3 bucket where the files must be uploaded; command line parameters require using the <span><strong class="source-inline">s3://</strong></span><span> nomenclature</span></li><li class="calibre13"><strong class="source-inline">--recursive</strong>: Copy everything within the source folder, including sub-folders, to the <span>destination bucket</span></li></ul>
<p class="calibre3">The following screenshot reflects the <span>copy process:</span></p>
</li> </ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer169"><img alt="Figure 10.14 – Exporting files to AWS S3 from the command-line interface (CLI)" src="../images/00062.jpeg" class="calibre171"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.14 – Exporting files to AWS S3 from the command-line interface (CLI)</p>

<ol class="calibre14">
<li value="3" class="calibre13">If the <strong class="source-inline">aws s3</strong> command<a id="_idIndexMarker873" class="pcalibre1 pcalibre2 pcalibre"/> is unavailable, run <strong class="source-inline">sudo apt install aws-cli</strong>, followed by the <strong class="source-inline">aws configure</strong> command, and follow on-screen instructions to configure the AWS access key and <span>secret key.</span></li>
<li class="calibre13">Once uploads are completed, you can validate them via the S3 dashboard online. Investigators can download the file directly on the forensic workstations for further analysis. The next screenshot confirms successful uploads to the S3 bucket from the <span>EC2 instance:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer170"><img alt="Figure 10.15 – Uploading forensic images to AWS S3" src="../images/00081.jpeg" class="calibre172"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.15 – Uploading forensic images to AWS S3</p>

<ol class="calibre14">
<li value="5" class="calibre13">Most<a id="_idIndexMarker874" class="pcalibre1 pcalibre2 pcalibre"/> forensic tools can access RAW files; investigators can add this forensic image to their forensic case library and begin their <span>offline processing.</span></li>
</ol>
<p class="calibre3">As we can see here, there are steps within AWS Console that you are required to perform to ensure access to the operating systems and memory to capture images. However, complications are added when you export the artifacts or full disk images of these AWS instances, which requires specific steps to <span>be followed.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h1 id="_idParaDest-193" class="calibre5"><a id="_idTextAnchor207" class="pcalibre1 pcalibre2 pcalibre"/>Forensic acquisition of Microsoft Azure Instances</h1>
<p class="calibre3">Like AWS, Microsoft<a id="_idIndexMarker875" class="pcalibre1 pcalibre2 pcalibre"/> Azure offers a similar approach <a id="_idIndexMarker876" class="pcalibre1 pcalibre2 pcalibre"/>when collecting the full disk image of an <strong class="bold">Azure Virtual Machine</strong> (<strong class="bold">VM</strong>) instance. You <a id="_idIndexMarker877" class="pcalibre1 pcalibre2 pcalibre"/>will have to specifically create a snapshot and then look to export the snapshot. Let us look at these specific steps <span>in detail.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h2 id="_idParaDest-194" class="calibre10"><a id="_idTextAnchor208" class="pcalibre1 pcalibre2 pcalibre"/>Step 1 – creating an Azure VM Snapshot</h2>
<p class="calibre3">As indicated earlier, each<a id="_idIndexMarker878" class="pcalibre1 pcalibre2 pcalibre"/> cloud platform will have slight variations in terms of the steps to achieve an entire disk and memory imaging; familiarity with these<a id="_idIndexMarker879" class="pcalibre1 pcalibre2 pcalibre"/> variations will help investigators greatly to the point where they can automate basic tasks if the number of VMs for forensic acquisition <span>is significant:</span></p>

<ol class="calibre14">
<li class="calibre13">The first step is ensuring investigators have information about the infected Azure VM. This includes the VM name and <span>operating system.</span></li>
<li class="calibre13">Investigators can create a full disk snapshot of this infected Azure VM. Investigators may prefer to turn off the VM entirely before taking the snapshot. Snapshots are accessible via the navigation page of the VM. Once on the snapshot page, we will select the <strong class="bold">Create snapshot </strong>option, as indicated in the <span>following screenshot:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer171"><img alt="Figure 10.16 – Creating an Azure VM snapshot" src="../images/00100.jpeg" class="calibre173"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.16 – Creating an Azure VM snapshot</p>

<ol class="calibre14">
<li value="3" class="calibre13">Follow the on-screen instructions to create the snapshot of the infected Azure VM. As indicated in the next screenshot, ensure that you select the right resource group in which the infected VM resides and the specific <strong class="bold">Instance details</strong> (which we <span>collected earlier):</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer172"><img alt="Figure 10.17 – Creating an Azure VM snapshot (details)" src="../images/00122.jpeg" class="calibre174"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.17 – Creating an Azure VM snapshot (details)</p>

<ol class="calibre14">
<li value="4" class="calibre13">In the same screen, select <strong class="bold">Full</strong> (<span><em class="italic">Figure 10</em></span><em class="italic">.18</em>). Microsoft Azure also offers incremental snapshots that will only take a snapshot of the changes made within the<a id="_idIndexMarker880" class="pcalibre1 pcalibre2 pcalibre"/> filesystem. Since we intend to capture the disk image fully, we will select <strong class="bold">Full</strong> snapshot<a id="_idIndexMarker881" class="pcalibre1 pcalibre2 pcalibre"/> for a <span>complete copy:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer173"><img alt="Figure 10.18 – Azure VM snapshot options" src="../images/00143.jpeg" class="calibre175"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.18 – Azure VM snapshot options</p>

<ol class="calibre14">
<li value="5" class="calibre13">You will subsequently be asked to select the <strong class="bold">Source disk</strong> for which the snapshot will be created. As indicated in the following screenshot, ensure you select the correct disk. Typically, investigators will snapshot the root drive of the operating system; however, in some cases, investigators may want to take a snapshot of all the disks attached to the VM. Each disk attached to the infected VM will require a separate snapshot operation in <span>these cases.</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer174"><img alt="Figure 10.19 – Azure VM snapshot disk" src="../images/00160.jpeg" class="calibre176"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.19 – Azure VM snapshot disk</p>

<ol class="calibre14">
<li value="6" class="calibre13">Once you have filled in all the required details, you can let Azure create the disk snapshot. Once completed, the snapshots will be available within the Azure subscription hosting the infected VM. You will notice the snapshot details within the snapshot<a id="_idIndexMarker882" class="pcalibre1 pcalibre2 pcalibre"/> dashboard, as <a id="_idIndexMarker883" class="pcalibre1 pcalibre2 pcalibre"/>indicated in the <span>following screenshot:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer175"><img alt="Figure 10.20 – Successful completion of Azure VM snapshot" src="../images/00179.jpeg" class="calibre177"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.20 – Successful completion of Azure VM snapshot</p>
<p class="calibre3">Next, we look at exporting the newly <span>created snapshot.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h2 id="_idParaDest-195" class="calibre10"><a id="_idTextAnchor209" class="pcalibre1 pcalibre2 pcalibre"/>Step 2 – exporting an Azure VM snapshot directly</h2>
<p class="calibre3">Once we<a id="_idIndexMarker884" class="pcalibre1 pcalibre2 pcalibre"/> complete <em class="italic">step 1</em>, investigators can attach this <a id="_idIndexMarker885" class="pcalibre1 pcalibre2 pcalibre"/>snapshot by creating a new disk, connecting to a VM to run a <strong class="source-inline">dd</strong> command, or using any of the commonly available tools discussed in <a href="part0028_split_000.html#_idTextAnchor151" class="pcalibre1 pcalibre2 pcalibre"><span><em class="italic">Chapter 8</em></span></a>. However, Microsoft Azure offers an option to download the snapshot directly once it's <span>been created:</span></p>

<ol class="calibre14">
<li class="calibre13">Within the navigation menu, on the <strong class="bold">Settings</strong> tab, click on <strong class="bold">Export snapshot</strong>; this section offers the ability to export any snapshot directly via <span>the browser:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer176"><img alt="Figure 10.21 – Exporting Azure snapshots directly" src="../images/00198.jpeg" class="calibre178"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.21 – Exporting Azure snapshots directly</p>

<ol class="calibre14">
<li value="2" class="calibre13">Depending<a id="_idIndexMarker886" class="pcalibre1 pcalibre2 pcalibre"/> on the size of the infected volume, investigators<a id="_idIndexMarker887" class="pcalibre1 pcalibre2 pcalibre"/> may have to select the amount of time required for exporting snapshots, after which the secure URL will expire. They will not be available to resume or download any further. The maximum time that Microsoft Azure allows is 10 hours (36,000 seconds). In our example, we are downloading a 30 GB file, which takes less than one hour; therefore, we left it with the default value of 3,600 seconds. The Azure administrator may also configure specific authentication requirements instead of allowing the secure and unique URL to be publicly available online. Investigators must note URLs, which are displayed only once, before navigating away from the page. Even though they are publicly available, they are not widely available through search engines and require the investigators to know the full URL to access <span>these artifacts.</span></li>
<li class="calibre13">Microsoft <a id="_idIndexMarker888" class="pcalibre1 pcalibre2 pcalibre"/>Azure typically generates two URLs, one with the <strong class="bold">virtual hard disk </strong>(<strong class="bold">VHD</strong>) file export and another with <strong class="bold">VM guest state VHD</strong> Export. These two<a id="_idIndexMarker889" class="pcalibre1 pcalibre2 pcalibre"/> links provide<a id="_idIndexMarker890" class="pcalibre1 pcalibre2 pcalibre"/> different files; however, investigators <a id="_idIndexMarker891" class="pcalibre1 pcalibre2 pcalibre"/>should download VHD files for <span>investigative purposes.</span></li>
</ol>
</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h2 id="_idParaDest-196" class="calibre10"><a id="_idTextAnchor210" class="pcalibre1 pcalibre2 pcalibre"/>Step 3 – connecting to an Azure VM for memory imaging</h2>
<p class="calibre3">Microsoft Azure <a id="_idIndexMarker892" class="pcalibre1 pcalibre2 pcalibre"/>offers a couple of options to access the VMs; one of the most common is accessing the Azure VM via RDP or SSH. Alternatively, Azure offers a service called <strong class="bold">Bastion</strong>, which<a id="_idIndexMarker893" class="pcalibre1 pcalibre2 pcalibre"/> provides in-browser capabilities to access the Azure VM safely. See the next screenshot, which shows the options that are typically available. The choice on the left offers Bastion, which proxies RDP connection to the Azure VM through a browser session. The option on the right is the traditional approach to connecting with the Azure VM. To collect memory images, we will access the Azure VM <span>via Bastion:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer177"><img alt="Figure 10.22 – Connection Option to Azure VM" src="../images/00015.jpeg" class="calibre179"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.22 – Connection Option to Azure VM</p>
<p class="calibre3">After selecting <strong class="bold">Go To Bastion</strong>, Azure will automatically create a proxy tunnel service that allows connection to Azure VM. Investigators must supply a username and password to Bastion<a id="_idIndexMarker894" class="pcalibre1 pcalibre2 pcalibre"/> service to connect to the Azure VM, as indicated in the following screenshot. This service is similar to what Amazon calls its SSM service, which offers command-line access to the <span>virtual machine:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer178"><img alt="Figure 10.23 – Connecting to Azure VM via the Bastion service" src="../images/00034.jpeg" class="calibre180"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.23 – Connecting to Azure VM via the Bastion service</p>
<p class="calibre3">Once connected to the Azure VM, investigators can follow the steps outlined in <em class="italic">step 2b</em> and <em class="italic">step 4a</em> <span>for AWS.</span></p>
<p class="calibre3">Once all the relevant artifacts are collected, investigators can use their choice of export mechanism to export memory images or operating system artifacts using a third-party file-sharing <a id="_idIndexMarker895" class="pcalibre1 pcalibre2 pcalibre"/>service or through Azure <span>Blob storage.</span></p>
<p class="calibre3">In the next section, we will review GCP’s approach to allowing investigators to acquire and collect snapshots and memory images for offline <span>forensic analysis.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h1 id="_idParaDest-197" class="calibre5"><a id="_idTextAnchor211" class="pcalibre1 pcalibre2 pcalibre"/>Forensic acquisition of GCP instances</h1>
<p class="calibre3">Like the steps we saw for <a id="_idIndexMarker896" class="pcalibre1 pcalibre2 pcalibre"/>AWS and Microsoft Azure, forensic acquisition<a id="_idIndexMarker897" class="pcalibre1 pcalibre2 pcalibre"/> of a GCP compute follows the same steps. We will first take a snapshot<a id="_idIndexMarker898" class="pcalibre1 pcalibre2 pcalibre"/> of the <strong class="bold">compute engine</strong> instance and then attach the snapshot as a separate drive to another forensic collector compute instance so we can do a bit-by-bit copy before exporting the disk image via cloud storage or any other data <span>transfer means.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h2 id="_idParaDest-198" class="calibre10"><a id="_idTextAnchor212" class="pcalibre1 pcalibre2 pcalibre"/>Step 1 – creating a snapshot of the compute engine instance</h2>
<p class="calibre3">So, let us<a id="_idIndexMarker899" class="pcalibre1 pcalibre2 pcalibre"/> look at the <a id="_idIndexMarker900" class="pcalibre1 pcalibre2 pcalibre"/>pre-requisite steps to acquire <a id="_idIndexMarker901" class="pcalibre1 pcalibre2 pcalibre"/>a forensic image of a <span>compute instance:</span></p>

<ol class="calibre14">
<li class="calibre13">The first step is to create a disk snapshot of the compute engine instance; this can be done by accessing the navigation menu under <strong class="bold">Storage</strong> and selecting <strong class="bold">Snapshots</strong>. GCP offers two forms of snapshots. The first is regular snapshots, which include a complete disk snapshot of the compute engine instance, while the second is instant snapshots, which are more like an in-place backup of the disk used to create new disk volumes quickly. Instant snapshots are incremental, meaning after the first full snapshots, only the changes to the disk are recorded in instant snapshots. This is used for a more straightforward restoration of files. We will require a complete snapshot to copy everything from the operating system level <span>for forensics.</span></li>
<li class="calibre13">When creating a snapshot, we must select the correct disk associated with the original infected instance, as indicated in the following screenshot. Similar to AWS and Microsoft Azure, each snapshot will associate with each disk, and therefore, when snapshotting a compute engine with multiple attached disks, investigators must note the number of disks attached to the instance and consider snapshotting them if all other disks are required. However, at minimum, the instance’s root drive (<strong class="source-inline">C:\</strong>) must be selected <span>for snapshots:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer179"><img alt="Figure 10.24 – Selecting a disk for a snapshot" src="../images/00051.jpeg" class="calibre181"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.24 – Selecting a disk for a snapshot</p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h2 id="_idParaDest-199" class="calibre10"><a id="_idTextAnchor213" class="pcalibre1 pcalibre2 pcalibre"/>Step 2 – attaching a snapshot disk for forensic acquisition</h2>
<p class="calibre3">Once a snapshot is <a id="_idIndexMarker902" class="pcalibre1 pcalibre2 pcalibre"/>completed, investigators <a id="_idIndexMarker903" class="pcalibre1 pcalibre2 pcalibre"/>can create a new forensic instance within the same GCP tenant and attach this snapshot as a disk source. The following are some of the critical steps that investigators must take <span>note of:</span></p>

<ol class="calibre14">
<li class="calibre13">When creating a new instance, investigators must select the additional disk and choose the recently saved snapshot. As indicated in the following screenshot, investigators must ensure they attach the correct snapshots if multiple disk snapshots <span>are taken:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer180"><img alt="Figure 10.25 – Attaching a disk and restoring from a snapshot in GCP" src="../images/00069.jpeg" class="calibre182"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.25 – Attaching a disk and restoring from a snapshot in GCP</p>

<ol class="calibre14">
<li value="2" class="calibre13">Once a disk is attached, similar to the steps listed earlier for AWS, investigators can validate whether the disk is attached correctly by running the <strong class="source-inline">lsblk -a</strong> command, as illustrated in the <span>following screenshot:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer181"><img alt="Figure 10.26 – Snapshot attached as a disk to the GCP compute instance" src="../images/00088.jpeg" class="calibre183"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.26 – Snapshot attached as a disk to the GCP compute instance</p>

<ol class="calibre14">
<li value="3" class="calibre13">Once the<a id="_idIndexMarker904" class="pcalibre1 pcalibre2 pcalibre"/> disk is successfully <a id="_idIndexMarker905" class="pcalibre1 pcalibre2 pcalibre"/>attached, we follow the steps outlined in <em class="italic">step 4a</em> for AWS through the <span><strong class="source-inline">dd</strong></span><span> command.</span></li>
</ol>
</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h2 id="_idParaDest-200" class="calibre10"><a id="_idTextAnchor214" class="pcalibre1 pcalibre2 pcalibre"/>Step 3 – connecting to the GCP compute engine instance for memory acquisition</h2>
<p class="calibre3">Since all the <a id="_idIndexMarker906" class="pcalibre1 pcalibre2 pcalibre"/>cloud service providers operate in the same way, each cloud service provider offers a remote connection tool such as Cloud Shell or direct connection via IP. This section will utilize GCP Cloud Shell to connect to the infected host machine for <span>memory acquisition:</span></p>

<ol class="calibre14">
<li class="calibre13">Upon connecting to GCP’s cloud shell, it will request an interactive logon to pass authentication tokens to the Cloud Shell session. Alternatively, administrators may create appropriate service accounts for investigators to handle the authentication process at the command line level without passing <span>credentials interactively.</span></li>
<li class="calibre13">When creating a service account, investigators must ensure that appropriate privileges are configured to the service account, specifically <strong class="bold">Compute Admin</strong> and <strong class="bold">Storage Object Admin</strong> privileges. <strong class="bold">Compute Admin</strong> privileges will allow investigators to access and modify the instance as required for forensic collections. In contrast, <strong class="bold">Storage Object Admin</strong> will allow the service account with privileges to upload artifacts to GCPs’ cloud storage buckets. To create a service account, the following steps must <span>be taken:</span><ol class="calibre142"><li class="upper-roman">Within the GCP’s console, navigate to the <strong class="bold">IAM &amp; </strong><span><strong class="bold">Admin</strong></span><span> section.</span></li><li class="upper-roman">Click on <strong class="bold">Service accounts</strong> and then click on the <strong class="bold">Create service </strong><span><strong class="bold">account</strong></span><span> button.</span></li><li class="upper-roman">Give the service account a name description and select the role(s) that grant it the <span>necessary permissions.</span></li><li class="upper-roman">Click <strong class="bold">Create</strong> to create the <span>service account.</span></li></ol>
<p class="calibre3">For forensic <a id="_idIndexMarker907" class="pcalibre1 pcalibre2 pcalibre"/>collections, we created a service account, as indicated in the following screenshot, that will be used to interact with compute <span>engine instances:</span></p>
</li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer182"><img alt="Figure 10.27 – Creating a service account for forensic acquisition" src="../images/00108.jpeg" class="calibre184"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 10.27 – Creating a service account for forensic acquisition</p>

<ol class="calibre14">
<li value="3" class="calibre13">Next, we<a id="_idIndexMarker908" class="pcalibre1 pcalibre2 pcalibre"/> generate keys to access the compute engine instance using the <span>service account:</span><ol class="calibre142"><li class="upper-roman">Within the GCP’s console, navigate to the <strong class="bold">IAM &amp; </strong><span><strong class="bold">Admin</strong></span><span> section.</span></li><li class="upper-roman">Click on <strong class="bold">Service accounts</strong> and then click on the service account name that requires keys to <span>be generated.</span></li><li class="upper-roman">On the <strong class="bold">KEYS</strong> tab, select <strong class="bold">ADD KEY</strong> and then <strong class="bold">Create </strong><span><strong class="bold">new key</strong></span><span>.</span></li><li class="upper-roman">Select <strong class="bold">JSON</strong> as the option for the key file to be created. You will be presented with details once, with the option to download and save it on <span>your computer.</span></li></ol></li>
<li class="calibre13">Investigators <a id="_idIndexMarker909" class="pcalibre1 pcalibre2 pcalibre"/>can use this service account or their interactive accounts when connecting to a compute engine instance via Cloud Shell. Essentially, a service account offers a containerized set of roles that investigators can use to access the compute <span>instance securely.</span></li>
<li class="calibre13">Once we have access to the compute instance via Cloud Shell or directly via RDP, we will follow the same steps as in <em class="italic">step 2b</em> for AWS for <span>memory acquisition.</span></li>
<li class="calibre13">To export a memory image, investigators can upload the file to a remote server hosted by the DFIR team or to GCP’s cloud storage bucket. To do this, you can use the service account that was created. We will take an example of exporting the memory image in a Windows device using PowerShell. We will first download the JSON file or copy the contents into a JSON file we generated in <span><em class="italic">step 3</em></span><span>.</span></li>
<li class="calibre13">Using PowerShell, we will run the following commands; you must ensure <strong class="bold">gcloud</strong> is installed <a id="_idIndexMarker910" class="pcalibre1 pcalibre2 pcalibre"/>on the Windows compute engine instance. The first thing is to activate the service account <span>with </span><span><strong class="source-inline">gcloud</strong></span><span>:</span>
<pre class="source-code"><strong class="bold">gcloud auth activate-service-account forensic-collector@vaulted-timing-390314.iam.gserviceaccount.com --key-file=./KEY.json --project=vaulted-timing-390314</strong></pre>
<p class="calibre3"><strong class="source-inline">gcloud</strong> is the command we invoke to connect to the GCP console. The following parameters are utilized to establish a connection to <span>GCP successfully:</span></p>
<ul class="calibre17"><li class="calibre13"><strong class="source-inline">gcloud auth activate-service-account</strong>: This command is used to activate a service account <span>for authentication.</span></li><li class="calibre13"><strong class="source-inline">forensic-collector@vaulted-timing-390314.iam.gserviceaccount.com</strong>: This is the full email address of the service account (created under Google IAM) that <span>requires activation.</span></li><li class="calibre13"><strong class="source-inline">key-file=./KEY.json</strong>: This parameter specifies the path to the JSON key file associated with the service account. Ensure the JSON file <span>path exists.</span></li><li class="calibre13"><strong class="source-inline">--project=vaulted-timing-390314</strong>: This represents the project name assigned by GCP under which the service account <span>is associated.</span></li></ul>
<p class="calibre3">Once the <a id="_idIndexMarker911" class="pcalibre1 pcalibre2 pcalibre"/>service account is authenticated, investigators can upload memory images and other artifacts to the <strong class="bold">GCP Cloud Storage</strong> (<strong class="bold">GCS</strong>) bucket<a id="_idIndexMarker912" class="pcalibre1 pcalibre2 pcalibre"/> using the <span>following command:</span></p>
<pre class="source-code"><strong class="bold">gsutil cp &lt;memory.img&gt; gs://&lt;bucket_name&gt;</strong></pre>
<p class="calibre3">The following are the parameters that are utilized for exporting the memory image to the <span>storage area:</span></p>
<ul class="calibre17"><li class="calibre13"><strong class="source-inline">cp</strong>: The sub-command of <strong class="source-inline">gsutil</strong> used for copying files and objects to and from <span>GCS buckets</span></li><li class="calibre13"><strong class="source-inline">&lt;memory.img&gt;</strong>: The filename and full path of the memory image stored on the <span>host instance</span></li><li class="calibre13"><strong class="source-inline">gs://&lt;bucket_name&gt;</strong>: The destination GCS bucket where the file will <span>be exported</span></li></ul></li> </ol>
<p class="calibre3">Once the<a id="_idIndexMarker913" class="pcalibre1 pcalibre2 pcalibre"/> memory image or any other artifacts are exported through <strong class="source-inline">gsutil</strong>, investigators can then proceed to acquire these artifacts from storage for their offline analysis. They can continue to retain these images in the storage area as long as it’s not publicly accessible and access controls are <span>strictly defined.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h1 id="_idParaDest-201" class="calibre5"><a id="_idTextAnchor215" class="pcalibre1 pcalibre2 pcalibre"/>Summary</h1>
<p class="calibre3">To summarize, the basic principles for collecting forensic artifacts, disk images, and memory dumps are similar when investigators have access to the operating system. The process is very similar if they have access to a computer or a device as part of the investigation. What is more important to learn are the steps to gain safe access to an operating system during an incident <span>response situation.</span></p>
<p class="calibre3">Debunking cloud forensic acquisition is key; however, investigators must familiarize themselves with getting access to the full disk without making significant modifications to the instance, such as adding a new empty disk or installing tools only to create a full disk image and jumping through the challenges of exporting. Most cloud services have the option to snapshot your entire disk; this allows for more accessible collections. As for memory dump, unfortunately, there is no better option than jumping on the infected machine and running tools to dump memory. It is important for investigators to minimize their forensic footprint in <span>volatile memory.</span></p>
<p class="calibre3">The next chapter will go over containerized instances, such as dockers and Kubernetes. In the forensic world, containerized instances offer different challenges, exacerbated when hosted on the cloud, and investigators are required to analyze them. The next chapter will look into demystifying container forensics on <span>the cloud.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer183" class="calibre2">
<h1 id="_idParaDest-202" class="calibre5"><a id="_idTextAnchor216" class="pcalibre1 pcalibre2 pcalibre"/>Further reading</h1>
<ul class="calibre12">
<li class="calibre13">Make an Amazon EBS volume available for use on <span>Linux: </span><a href="https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-using-volumes.xhtml" class="pcalibre1 pcalibre2 pcalibre"><span>https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ebs-using-volumes.xhtml</span></a></li>
<li class="calibre13">How To Use LVM To Manage Storage Devices on Ubuntu <span>18.04: </span><a href="https://www.digitalocean.com/community/tutorials/how-to-use-lvm-to-manage-storage-devices-on-ubuntu-18-04" class="pcalibre1 pcalibre2 pcalibre"><span>https://www.digitalocean.com/community/tutorials/how-to-use-lvm-to-manage-storage-devices-on-ubuntu-18-04</span></a></li>
<li class="calibre13">Creating an IAM role with permissions for Session Manager and Amazon S3 and CloudWatch Logs (<span>console): </span><a href="https://docs.aws.amazon.com/systems-manager/latest/userguide/getting-started-create-iam-instance-profile.xhtml#create-iam-instance-profile-ssn-logging" class="pcalibre1 pcalibre2 pcalibre"><span>https://docs.aws.amazon.com/systems-manager/latest/userguide/getting-started-create-iam-instance-profile.xhtml#create-iam-instance-profile-ssn-logging</span></a></li>
<li class="calibre13">Create a Partition in Linux – A Step-by-Step <span>Guide: </span><a href="https://www.digitalocean.com/community/tutorials/create-a-partition-in-linux" class="pcalibre1 pcalibre2 pcalibre"><span>https://www.digitalocean.com/community/tutorials/create-a-partition-in-linux</span></a></li>
<li class="calibre13">Download a Windows VHD from <span>Azure: </span><a href="https://learn.microsoft.com/en-us/azure/virtual-machines/windows/download-vhd?tabs=azure-portal" class="pcalibre1 pcalibre2 pcalibre"><span>https://learn.microsoft.com/en-us/azure/virtual-machines/windows/download-vhd?tabs=azure-portal</span></a></li>
<li class="calibre13">Google Cloud (GCP) Forensics Best Practices and <span>Tools: </span><a href="mailto:https://medium.com/@cloud_tips/google-cloud-gcp-forensics-best-practices-and-tools-a99ed21e5ae5" class="pcalibre1 pcalibre2 pcalibre"><span>https://medium.com/@cloud_tips/google-cloud-gcp-forensics-best-practices-and-tools-a99ed21e5ae5</span></a></li>
<li class="calibre13">How to automate forensic disk collection in <span>AWS: </span><a href="https://aws.amazon.com/blogs/security/how-to-automate-forensic-disk-collection-in-aws/" class="pcalibre1 pcalibre2 pcalibre"><span>https://aws.amazon.com/blogs/security/how-to-automate-forensic-disk-collection-in-aws/</span></a></li>
<li class="calibre13">Computer forensics chain of custody in <span>Azure: </span><a href="https://learn.microsoft.com/en-us/azure/architecture/example-scenario/forensics/" class="pcalibre1 pcalibre2 pcalibre"><span>https://learn.microsoft.com/en-us/azure/architecture/example-scenario/forensics/</span></a></li>
</ul></div>
</div>
</body></html>