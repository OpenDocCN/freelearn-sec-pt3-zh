["```\n s3client = boto3.client(\n      service_name='s3',\n      region_name='us-east-1',\n      aws_access_key_id=ACCESS_KEY,\n      aws_secret_access_key=SECRET_KEY\n  )\n  response = s3.list_buckets()\n  for bucket in response['Buckets']:\n      print(f'Bucket Name: {bucket[\"Name\"]}')\n```", "```\n  from azure.storage.blob import BlobServiceClient\n  # Connect to the Azure Blob service\n  connection_string = \"<your_connection_string>\"\n  blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n  # List containers in the storage account\n  containers = blob_service_client.list_containers()\n  for container in containers:\n     print(f'Container Name: {container.name}')\n```", "```\n  import openai\n  import argparse\n  # Function to check for AWS or Azure keys in the provided text\n  def check_for_keys(text):\n      # Use the OpenAI GPT-3 API to analyze the content\n      response = openai.Completion.create(\n          engine=\"davinci-codex\",\n          prompt=text,\n         max_tokens=100\n     )\n     generated_text = response['choices'][0]['text']\n     # Check the generated text for AWS or Azure keys\n     if 'AWS_ACCESS_KEY_ID' in generated_text and 'AWS_SECRET_ACCESS_KEY' in generated_text:\n         print(\"Potential AWS keys found.\")\n     elif 'AZURE_CLIENT_ID' in generated_text and 'AZURE_CLIENT_SECRET' in generated_text:\n         print(\"Potential Azure keys found.\")\n     else:\n         print(\"No potential AWS or Azure keys found.\")\n # Create argument parser\n parser = argparse.ArgumentParser(description='Check for AWS or Azure keys in a JavaScript file.')\n parser.add_argument('file_path', type=str, help='Path to the JavaScript file')\n # Parse command line arguments\n args = parser.parse_args()\n # Read the JavaScript file content\n file_path = args.file_path\n try:\n     with open(file_path, 'r') as file:\n         javascript_content = file.read()\n         check_for_keys(javascript_content) except FileNotFoundError:\n     print(f\"File '{file_path}' not found.\")\n```", "```\n  import boto3\n  # Initialize an AWS session\n  session = boto3.Session(region_name='us-west-1')  # Replace with your desired region\n  # Create clients for different AWS services\n  ec2_client = session.client('ec2')\n  s3_client = session.client('s3')\n  iam_client = session.client('iam')\n # Enumerate EC2 instances\n response = ec2_client.describe_instances()\n for reservation in response['Reservations']:\n     for instance in reservation['Instances']:\n         print(f»EC2 Instance ID: {instance['InstanceId']}, State: {instance['State']['Name']}»)\n # Enumerate S3 buckets\n buckets = s3_client.list_buckets() for bucket in buckets['Buckets']:\n     print(f\"S3 Bucket Name: {bucket['Name']}\")\n # Enumerate IAM users\n users = iam_client.list_users()\n for user in users['Users']:\n     print(f\"IAM User Name: {user[‚UserName']}\")\n```", "```\n    { \"Version\": \"2012-10-17\", \"Statement\": [ { \"Effect\": \"Allow\", \"Action\": \"ec2:DescribeInstances\", \"Resource\": \"*\" } ] }\n    ```", "```\n  import boto3\n  # Initialize an AWS session\n  session = boto3.Session(region_name='us-west-1')  # Replace with your desired region\n  # Create an EC2 client\n  ec2_client = session.client('ec2')\n  # Enumerate EC2 instances\n response = ec2_client.describe_instances()\n # Process response to extract instance details\n for reservation in response['Reservations']:\n     for instance in reservation['Instances']:\n         instance_id = instance['InstanceId']\n         instance_state = instance['State']['Name']\n         instance_type = instance['InstanceType']\n         public_ip = instance.get('PublicIpAddress', 'N/A')  # Retrieves Public IP if available\n         print(f»EC2 Instance ID: {instance_id}»)\n         print(f\"Instance State: {instance_state}\")\n         print(f\"Instance Type: {instance_type}\")\n         print(f\"Public IP: {public_ip}\")\n         print(\"-\" * 30)  # Separator for better readability\n```", "```\npip install prowler\nprowler -v\n```", "```\nprowler aws\n```", "```\n    prowler <provider> -M csv json json-asff html\n    ```", "```\n    prowler <provider> --list-checks\n    prowler <provider> --list-services\n    ```", "```\n    prowler azure --checks storage_blob_public_access_level_is_disabled\n    prowler aws --services s3 ec2\n    prowler aws --services s3 command:\n    ```", "```\n  import sys\n  import json\n  import requests\n  def send_to_webhook(finding):\n      webhook_url = \"YOUR_WEBHOOK_URL_HERE\"  # Replace this with your actual webhook URL\n      headers = {\n         \"Content-Type\": \"application/json\"\n     }\n     payload = {\n         \"finding_id\": finding[\"FindingUniqueId\"],\n         \"severity\": finding[\"Severity\"],\n         \"description\": finding[\"Description\"],\n         # Include any other relevant data from the finding\n     }\n     try:\n         response = requests.post(webhook_url, json=payload, headers=headers)\n         response.raise_for_status()\n         print(f\"Webhook sent for finding: {finding['FindingUniqueId']}\")\n     except requests.RequestException as e:\n         print(f\"Failed to send webhook for finding {finding['FindingUniqueId']}: {e}\")\n if __name__ == \"__main__\":\n     if len(sys.argv) != 2:\n         print(\"Usage: python script.py <json_file_path>\")\n         sys.exit(1)\n     json_file_path = sys.argv[1]\n     try:\n         with open(json_file_path, \"r\") as file:\n             data = json.load(file)\n     except FileNotFoundError:\n         print(f\"File not found: {json_file_path}\")\n         sys.exit(1)\n     except json.JSONDecodeError as e:\n         print(f\"Error loading JSON: {e}\")\n         sys.exit(1)\n     # Send data to webhook for critical findings\n     for finding in data:\n         if finding.get(\"Severity\", \"\").lower() == \"critical\":\n             send_to_webhook(finding)\n```", "```\n    python script.py path/to/your/json_file.json\n    ```", "```\n      import boto3\n      # Get CloudWatch logs for a Lambda function\n      def get_lambda_logs(lambda_name):\n          client = boto3.client('logs')\n          response = client.describe_log_streams(logGroupName=f'/aws/lambda/{lambda_name}')\n          log_stream_name = response['logStreams'][0]['logStreamName']\n          logs = client.get_log_events(logGroupName=f'/aws/lambda/{lambda_name}', logStreamName=log_stream_name)\n          return logs['events']\n    ```", "```\n      import boto3\n      # Check Lambda function's permissions\n      def check_lambda_permissions(lambda_name):\n          client = boto3.client('lambda')\n          response = client.get_policy(FunctionName=lambda_name)\n          permissions = response['Policy']\n          # Analyze permissions and enforce least privilege\n          # Example: Validate permissions against predefined access levels\n         # Implement corrective actions\n    ```", "```\n     from cryptography.fernet import Fernet\n     # Encrypt data in a Lambda function using Fernet encryption\n     def encrypt_data(data):\n         key = Fernet.generate_key()\n         cipher_suite = Fernet(key)\n         encrypted_data = cipher_suite.encrypt(data.encode())\n         return encrypted_data\n    ```", "```\n     import subprocess\n     # Use Terraform to apply consistent configurations\n     def apply_terraform():\n         subprocess.run([\"terraform\", \"init\"])\n         subprocess.run([\"terraform\", \"apply\"])\n         # Ensure consistent configurations across environments\n    ```", "```\n     import boto3\n     # Access AWS Secrets Manager to retrieve secrets\n     def retrieve_secret(secret_name):\n         client = boto3.client('secretsmanager')\n         response = client.get_secret_value(SecretId=secret_name)\n         secret = response['SecretString']\n         return secret\n    ```", "```\n     import subprocess\n     # Use CloudFormation validate-template to check for misconfigurations\n     def validate_cf_template(template_file):\n         subprocess.run([\"aws\", \"cloudformation\", \"validate-template\", \"--template-body\", f\"file://{template_file}\"])\n         # Validate CloudFormation template for misconfigurations\n    ```"]