- en: '6'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: DFIR Investigations – Logs in GCP
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: You must have noticed each cloud service provider’s common resources and elements
    by now. In this chapter, we will dive straight into the security capabilities
    of **Google Cloud Platform** (**GCP**), what log sources are available, and how
    we can conduct our investigation. Note that cloud providers may use common terminologies.
    However, the applications and availability of logs may differ for each cloud service
    provider. Therefore, it is essential to understand which logs will be available
    during an incident investigation.
  prefs: []
  type: TYPE_NORMAL
- en: In [*Chapter 3*](part0021_split_000.html#_idTextAnchor042), we briefly introduced
    specific cloud service offerings within GCP; in this chapter, we will dig deep
    into some of its core components and digital forensics. This chapter outlines
    the logs available for some of the critical GCP services and products discussed
    in [*Chapter 3*](part0021_split_000.html#_idTextAnchor042) and looks at utilizing
    these sources in the context of an investigation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Specifically, we will discuss the following topics in this chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: GCP core services
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GCP identity and access management
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Policy Analyzer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GCP Logs Explorer
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: VPC Flow Logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Packet Mirroring
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Compute Engine logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Logging Dataflow pipelines
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GCP storage logs
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud Security Command Center
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GCP Cloud Shell
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will discuss Google Workspace in [*Chapter 7*](part0026_split_000.html#_idTextAnchor137),
    along with Microsoft 365 (M365), as these relate to email and cloud-hosted collaboration
    services.
  prefs: []
  type: TYPE_NORMAL
- en: GCP core services
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GCP is a suite of cloud computing services provided by Google. It offers a wide
    range of tools and services to build, deploy, and manage applications and infrastructure
    in the cloud. It provides services similar to cloud providers, such as AWS and
    Microsoft Azure.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are some of the critical service offerings from GCP:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Compute services**: GCP offers several compute options, including **Google
    Compute Engine** (**GCE**) (**virtual** **machines** [**VM**s]), **Google Kubernetes
    Engine** (**GKE**) (managed Kubernetes), and **App Engine** (managed platform
    for applications)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Storage services**: GCP provides various storage options such as **Google
    Cloud Storage** (**GCS**) (object storage), **Cloud SQL** (relational database
    service), **Cloud Bigtable** (NoSQL database), and **Cloud Firestore** (document
    database)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Networking**: GCP offers networking services such as **Virtual Private Cloud**
    (**VPC**) for creating private networks, **Cloud Load Balancing** for distributing
    traffic, and **Cloud CDN** for content delivery'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Big data and machine learning**: GCP includes services such as **BigQuery**
    (serverless data warehouse), **Cloud Dataflow** (data processing), **Cloud Pub/Sub**
    (messaging and event streaming), and **Cloud Machine Learning Engine** (managed
    machine learning)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Identity and access management** (**IAM**): IAM allows you to manage access
    to GCP resources and services, defining roles and permissions for users and groups'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Management and monitoring**: GCP provides tools for managing and monitoring
    your resources, such as **Cloud Console** (web-based management interface), **Cloud
    Logging** (centralized log management), **Cloud Monitoring** (performance and
    health monitoring), and **Cloud Trace** (request latency analysis)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security and compliance**: GCP incorporates various security features, including
    encryption at rest and in transit, IAM roles and policies, VPC Service Controls,
    and compliance certifications to meet industry standards'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Developer tools**: GCP offers developer tools such as **Cloud SDK** (command-line
    tools), **Cloud Build** (continuous integration and delivery), and **Cloud Source
    Repositories** (version control system)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**AI and ML services**: GCP provides pre-trained AI models and APIs through
    services such as **Cloud Vision API**, **Cloud Natural Language API**, and **Cloud
    Translation API**, enabling developers to integrate AI capabilities into their
    applications'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Serverless computing**: GCP offers serverless services such as **Cloud Functions**
    (event-driven functions), **Cloud Run** (serverless containers), and **Cloud Scheduler**
    (cron job scheduler)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have looked at the core services GCP offers, we can dive deeper
    into specific services that investigators would be interested in. The focus will
    be on specific GCP services that form the backbone of any investigations, including
    identities, logs from the Compute Engine, and so on. We will start with GCP’s
    IAM console that is core to allowing users access to the GCP resources.
  prefs: []
  type: TYPE_NORMAL
- en: GCP IAM
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: IAM provides a framework for controlling resource access within the GCP realm
    by defining the relationships between identities, roles, and the corresponding
    resources. Within this system, the concept of resources extends to include a wide
    array of entities, such as GCE VM instances, GKE clusters, **Cloud Storage buckets**,
    and the organizational structure consisting of organizations, folders, and projects.
  prefs: []
  type: TYPE_NORMAL
- en: IAM operates on the principle that direct access permissions are not granted
    to end users; instead, permissions are organized into roles, which are subsequently
    assigned to authenticated principals or members (Google account, service account,
    Google group, authenticated users, cloud identity domain, etc.).
  prefs: []
  type: TYPE_NORMAL
- en: Central to IAM’s functioning is the **allow policy**, or **IAM policy**, which
    serves as the mechanism for specifying and enforcing the assignment of roles to
    principals. Each allow policy is linked to a specific resource. When an authenticated
    principal attempts to access a resource, IAM examines the associated allow policy,
    thereby ascertaining the permissibility of the intended action based on its stipulations.
    While the allow policy lets you set guidelines to allow access to specific resources,
    GCP will also enable you to set up a **deny policy** that specifies what users
    or roles do not have access to. A deny policy lets you set up a deny rule based
    on specific conditions that determine the permissibility of the resource. Deny
    policy examples include setting restrictions on defining new API keys or deleting
    or editing GCE resources or configurations.
  prefs: []
  type: TYPE_NORMAL
- en: By embracing IAM within the GCP ecosystem, organizations can establish granular
    control over access privileges, ensuring that identities are assigned only the
    necessary roles to interact with designated resources. This approach to access
    management enables increased security and effective governance over the GCP environment.
  prefs: []
  type: TYPE_NORMAL
- en: GCP’s IAM roles and identities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: From the perspective of incident response and forensics, it is essential to
    understand how cloud service providers organize and provision identities and privileges
    to these identities. Note that handling identities is generally different for
    each cloud service provider.
  prefs: []
  type: TYPE_NORMAL
- en: In the case of GCP, end users do not directly get assigned privileges. Instead,
    privileges are assigned to **roles**. You can imagine roles as a group or a collection
    of privileges that grant access to various services within GCP’s environment.
    Users or API services needing to access these resources are termed **principals**
    by GCP. Therefore, privileges are assigned to roles, and roles are attached to
    principals. A policy is a collection of roles that can be attached to one or more
    principals.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure summarizes how IAM policies are defined, assigned, enforced,
    and ultimately managed through GCP’s IAM module:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.1 – GCP‘s IAM enforcement architecture](img/00013.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.1 – GCP‘s IAM enforcement architecture
  prefs: []
  type: TYPE_NORMAL
- en: While the preceding figure just illustrates a generic version of how permissions
    can be assigned to each GCP resource, GCP also offers federated integration to
    active directories to manage access to GCP resources. This, however, uses a similar
    concept to enforce IAM policies. You can create granular allow and deny policies
    to enforce specific resource elements. For example, you can allow access to an
    instance within GCE while restricting access to other instances.
  prefs: []
  type: TYPE_NORMAL
- en: Policy Analyzer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Given that IAM assignments occur over roles where principals are assigned access
    permissions to a resource using roles, GCP offers additional tools for troubleshooting
    and investigating IAM policy configurations. Policy Analyzer allows DFIR teams
    to analyze excess privileges assigned to users or roles that may have resulted
    in abuse. Policy Analyzer can also determine whether a user has the necessary
    permissions to perform specific actions, such as deleting a table, a GCE resource,
    and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following is an example of Policy Analyzer’s output. We can see in the
    query result what roles and permissions were configured for a user under a GCP
    resource. Note that resources are allocated toward a project, and GCP tags them
    as resources:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.2 – Policy Analyzer query results and list of permissions per role](img/00032.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.2 – Policy Analyzer query results and list of permissions per role
  prefs: []
  type: TYPE_NORMAL
- en: DFIR use cases for Policy Analyzer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Using a policy analyzer in the context of DFIR within GCP enables organizations
    to evaluate compliance and security across various GCP resources. Here are some
    use cases for GCP Policy Analyzer:'
  prefs: []
  type: TYPE_NORMAL
- en: '**IAM policies**: Analyzing IAM policies includes assessing roles assigned
    to users, service accounts, and groups, as well as identifying potential misconfigurations
    or overly permissive access.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network security policies**: Review firewalls, network configurations, and
    routing policies to ensure proper network segmentation and secure connectivity
    and protection against unauthorized access.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data encryption and key management policies**: Verify that data encryption
    policies are enforced for sensitive information at rest and in transit. This involves
    assessing the usage of encryption keys, key rotation practices, and compliance
    with encryption standards.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logging and monitoring policies**: Assess logging configurations and monitoring
    practices to ensure that appropriate logs are generated and retained and that
    log analysis tools are properly configured to detect security incidents and abnormal
    activities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Service account and API access policies**: Verify the security of service
    accounts and API access configurations. This includes assessing permissions granted
    to service accounts, auditing the usage of service accounts, and ensuring proper
    management and revocation of API access credentials.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As you can see, GCP Policy Analyzer helps identify policy violations and non-compliant
    resources. However, it does not provide information on the activity performed
    due to policy deviations; we need Logs Explorer to identify specific actions performed.
    We will look at GCP Logs Explorer, which ingests and hosts detailed logs and has
    advanced filtering options and real-time log streaming capabilities, making it
    essential for any investigator to use.
  prefs: []
  type: TYPE_NORMAL
- en: GCP Logs Explorer
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'GCP designed **Logs Explorer** to troubleshoot performance issues with applications
    and systems by reviewing the logs. The user interface for Logs Explorer features
    a histogram that displays log rates and associated spikes. Nevertheless, where
    there are logs, you can always use them to investigate their incident. Google
    also offers the Logs Explorer API, which allows automation or query logs via a
    Python program or any other medium through an API key. The following screenshot
    is an example of GCP’s histogram on Logs Explorer that highlights activities by
    time:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.3 – GCP’s Logs Explorer histogram](img/00050.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.3 – GCP’s Logs Explorer histogram
  prefs: []
  type: TYPE_NORMAL
- en: However, Logs Explorer only displays logs per period; it does not quantify or
    correlate the logs against other activities within the system. You can set the
    time range for which you want to see the logs, with a default log retention of
    30 days. For this, GCP offers **Log Analytics**, a separate service that allows
    real-time analytics on the roles to allow log aggregation and quantification of
    the logs collected. This is a separate service and requires you to explicitly
    upgrade your log bucket to allow GCP to perform log analytics. GCP Log Analytics
    enables users to use **BigQuery** on the logs. BigQuery is a data warehouse where
    users can perform queries on massive datasets and perform analytics on them. GCP
    offers BigQuery as a separate service, which is not available by default. For
    example, you can run BigQuery to query your logs against known malicious domains
    from a threat intelligence source.
  prefs: []
  type: TYPE_NORMAL
- en: 'For DFIR teams to access Logs Explorer, teams must be assigned the following
    roles:'
  prefs: []
  type: TYPE_NORMAL
- en: '`roles/logging.viewer`: For viewing all logs under the`_Required` and `_Default`
    buckets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/logging.privateLogViewer`: For viewing all logs, including data access
    logs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/logging.viewAccessor`: Condition-based log view that grants access to
    user-defined logs. This role grants access to logs within a user-defined bucket
    if no condition is specified.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Roles/logging.fieldAccessor`: For viewing restricted fields within a log entry
    bucket. You will need to configure field-level access.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Overview of log buckets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every log a resource generates is ingested by a Cloud Logging infrastructure
    that determines the conditions and criteria for the bucket assignments for log
    storage, known as log **sinks**. Log sinks are part of GCP’s logging infrastructure
    that determines how logs are routed to relevant log buckets. GCP also allows you
    to export these logs to a third-party log aggregation tool through a Pub/Sub topic
    that helps third-party log aggregation tools subscribe to Pub/Sub to authorize
    and import the logs.
  prefs: []
  type: TYPE_NORMAL
- en: GCP offers two pre-defined log buckets, `_Required` and `_Default`. Buckets
    are independent of each other and serve as a default destination per GCP account
    for logging required logs. Users/administrators can also create their sinks/buckets,
    which are classified as user-defined buckets. As log entries are passed to logging
    infrastructure, log routing is initiated, in which, based upon the configured
    filters for inclusion and exclusion of the log entry, logs are routed to appropriate
    sinks or redirected to Pub/Sub topics for external consumption, or the logs are
    dropped altogether. Logs can also be redirected to the BigQuery dataset, allowing
    users to run Log Analytics for correlation and further analysis.
  prefs: []
  type: TYPE_NORMAL
- en: 'As indicated previously, cloud log entries are, by default, routed to one of
    these log buckets:'
  prefs: []
  type: TYPE_NORMAL
- en: '`_Required`: The `_Required` log buckets collect the following types of logs:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Admin Activity logs**: These contain log entries for API calls for reading
    resource metadata or configuration. For example, an API call to read GCE configurations
    is recorded under this sub-category.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**System Event logs**: Any changes to a cloud resource, for example, GCE, are
    recorded under this sub-category. Users/administrators cannot turn off logging
    this type of log by creating an exclusion filter; it is always recorded.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Access Transparency logs**: Any actions performed by Google Cloud members
    within a GCP account are recorded under this log. This allows a transparent view
    into any actions the cloud service provider performs – in this case, Google.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`_Default`: Any logs that do not satisfy the conditions of the `_Required`
    bucket are routed to `_Default` buckets. The following types of logs are automatically
    redirected:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data Access logs**: These are log entries that include what API calls were
    made to access metadata or configuration information about a GCP resource. Data
    Access logs are typically voluminous and are disabled by default. If you run BigQuery,
    then Data Access logs are enabled. Therefore, it is essential to understand the
    operating resources and whether the logs are enabled.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Policy Denied logs**: As the name suggests, log entries are categorized as
    Policy Denied logs when GCP denies access to a resource based on a defined set
    of conditions or policies. Policy Denied logs are enabled by default and cannot
    be disabled. However, you can configure an exclusion filter not to record these
    logs.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User-defined bucket**: These are log buckets created by users to collect
    a subset of logs produced by GCP resources. You can create your user-defined bucket
    in any cloud project. When you create a log bucket, you do have to specify the
    region in which the log bucket will be stored.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: DFIR use cases for using Logs Explorer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The following are some of the DFIR use cases for utilizing GCP’s native Logs
    Explorer:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Incident investigation**: During an incident, Logs Explorer enables you to
    search and analyze logs across various GCP services. You can correlate events
    from different logs to reconstruct the timeline of an incident, identify the root
    cause, and determine the extent of the impact.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Threat hunting**: Logs Explorer allows you to query and filter logs based
    on specific criteria or patterns related to known threats or **indicators of compromise**
    (**IOCs**). By analyzing logs from GCP services such as Cloud Storage, Cloud Functions,
    or Cloud Pub/Sub, you can proactively search for suspicious activities or abnormal
    behavior.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User activity monitoring**: Logs Explorer provides visibility into user activities
    within GCP services. You can track user logins, administrative actions, API calls,
    and resource access to identify unauthorized or suspicious actions. This information
    can help detect insider threats or compromised user accounts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data leak and exposure detection**: Logs Explorer can be employed to identify
    potential data leaks or exfiltration attempts. By analyzing logs from relevant
    services, such as Cloud Storage or BigQuery, you can search for patterns indicative
    of unauthorized data access, large data transfers, or unusual data egress.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Forensic analysis**: Logs Explorer can serve as a valuable source of evidence
    during forensic investigations. By querying and analyzing logs, you can reconstruct
    events, identify the actions taken by an attacker, or track the movement of an
    adversary within your GCP environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Familiarizing with Logs Explorer
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll look at an example of querying Logs Explorer. Logs Explorer has handy
    features allowing investigators to click and filter relevant artifacts. Let’s
    familiarize ourselves with multiple areas of Logs Explorer:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4 – Logs Explorer overview](img/00067.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 – Logs Explorer overview
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see in the Logs Explorer dashboard, a few key elements will be helpful
    to security teams. We have numbered them for your easier reference:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Date/time filter**: This allows the teams to nail down specific events and
    activities that may have occurred within a time range.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Query pane**: This text bar allows the team to search queries manually. Note
    that this search query term will automatically be updated when you click and update
    the filter.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Query filter fields**: This enables the teams to filter specific GCP resources,
    objects or logs, and types of logs. Note that we have filtered records associated
    with a VM instance, with severity as an error in this example.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Log fields pane**: This view gives the user a more granular view into the
    number of events per type of logs filter or severity rating. As indicated earlier,
    every record is categorized before it is routed to relevant log storage destinations.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Query results pane**: This view lets the user look into the logs more thoroughly.
    Each entry allows the user to expand and view all the fields within a log entry
    and perform additional filtering based on investigative leads.'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Our next section will look into a sample investigation using Logs Explorer,
    but first, let us look at VPC Flow Logs.
  prefs: []
  type: TYPE_NORMAL
- en: VPC Flow Logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like AWS, VPC Flow Logs are not enabled for GCE by default. Turning on VPC Flow
    Logs is relatively easy and requires minimal effort. It’s important to note that
    VPC Flow Logs are aggregated by time in minutes and summarized in a dashboard
    that includes relevant information. VPC Flow Logs are enabled at the subnet level,
    meaning every flow log is associated with a subnet that your GCE is part of. This
    typically refers to GCP’s internal subnet architecture. Turning on VPC Flow Logs
    for a noisy server may generate many logs, ultimately impacting costs.
  prefs: []
  type: TYPE_NORMAL
- en: Enabling VPC Flow Logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: To analyze traffic, you must first enable VPC Flow Logs within GCE. As GCEs
    are created by default, a regional VPC acts as the network gateway for the virtual
    server to access the internet or other GCP resources. Alternatively, if a custom
    VPC node is created, you must ensure that the VPC Flow Log option is turned on
    for the GCE to send logs to Logs Explorer. We’ll look at an example for one of
    the GCEs under network details.
  prefs: []
  type: TYPE_NORMAL
- en: 'Like AWS, VPC Flow Logs are not automatically enabled and require manual activation.
    GCP provides a range of customizable network settings, including the ability to
    create subnets, establish firewall rules, and set up VPC connections. The following
    figure displays the VPC network configured for one of the regions with a custom
    VPC network called `test-lab1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.5 – Network subnet details for a GCE](img/00085.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.5 – Network subnet details for a GCE
  prefs: []
  type: TYPE_NORMAL
- en: 'VPC Flow Logs are subnet-specific; therefore, it is essential to note that
    when enabling VPC Flow Logs, you must make changes to the VPC subnet and allow
    the flow logs to be collected. If the GCE has more than one VPC connected to the
    instance, you must verify and enable each VPC subnet to collect flow logs. In
    the following figure, we look at the sample customized VPC we created named `test-lab1`
    with a VPC subnet named `subnet-lab1`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.6 – VPC subnet information](img/00104.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.6 – VPC subnet information
  prefs: []
  type: TYPE_NORMAL
- en: Click and edit the subnet name and select the option for turning **FLOW LOGS**
    on or off. Once enabled, specify the frequency of aggregation of network packets.
    Remember that VPC Flow Logs only collect header information, not full packet details.
    As a result, it is essential to weigh the aggregation frequency and identify the
    most suitable time interval for aggregation. Packet aggregation can occur at 5-second,
    30-second, 1-minute, 5-minute, 10-minute, and 15-minute intervals.
  prefs: []
  type: TYPE_NORMAL
- en: 'Suppose GCP resources produce a lot of network traffic throughout the day;
    in that case, a higher frequency flow log aggregation can be set to allow granular
    network traffic visibility. Low-frequency flow log aggregation is suitable for
    those who do not have a lot of network traffic activity. The following figure
    demonstrates the option for setting flow logs:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – Enabling VPC Flow Logs under a VPC subnet](img/00127.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 – Enabling VPC Flow Logs under a VPC subnet
  prefs: []
  type: TYPE_NORMAL
- en: 'While setting up the flow logs, select the sample rate of the packets that
    will be aggregated into the flow logs and reported to Logs Explorer, ideally at
    100%. This means that 100% of observed traffic is sent to Logs Explorer and not
    downsized to a specific percentage of traffic activity. The following figure demonstrates
    the subnet configuration with a sample rate of 100% of the observed network traffic
    with an aggregation interval of 5 seconds:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – Flow log network aggregation configuration](img/00147.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 – Flow log network aggregation configuration
  prefs: []
  type: TYPE_NORMAL
- en: Once the VPC is configured, flow logs are automatically sent to Logs Explorer,
    where investigators can begin threat hunting. The following section will demonstrate
    an example use case for using Logs Explorer and hunting VPC Flow Logs for malicious
    activities.
  prefs: []
  type: TYPE_NORMAL
- en: Hunting VPC Flow Logs for malicious activities
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this scenario, we have a GCP Cloud Storage bucket named `app-data1` with
    a few backups critical for the organization. The infrastructure setup is such
    that any internal GCP resource or application can access GCP Cloud Storage but
    is not publicly available to users or on the internet. The following figure indicates
    a list of Cloud Storage objects stored within the `app-data1` bucket:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9 – Cloud Storage view](img/00164.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.9 – Cloud Storage view
  prefs: []
  type: TYPE_NORMAL
- en: We have a threat actor who is using a GCE VM, `cf1-ta-vm,` (with an internal
    IP address of `10.0.0.15` and an external IP of `34.152.3.1`) to grab these files
    from Cloud Storage and ultimately exfiltrate the data to a threat actor-controlled
    remote server at `3.98.136.11`.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now look into using Logs Explorer to hunt for threat actor activity
    concerning this GCE resource:'
  prefs: []
  type: TYPE_NORMAL
- en: As a first step, we begin by selecting appropriate event times within the Logs
    Explorer dashboard to capture the most relevant events.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We then look for the associated log entry when this file was uploaded to the
    GCS bucket. Investigators must pay attention to the `methodName` attribute with
    the `storage.objects.create` value, indicating that the object was created within
    a specific bucket. The following figure illustrates the log record created when
    uploaded to the bucket and the full file path identified within the `resourceName`
    attribute:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.10 – Log entry for object uploaded to GCS bucket](img/00183.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.10 – Log entry for object uploaded to GCS bucket
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is to look for any GCE VMs accessing this resource. Using the
    log fields pane (as described in *Figure 6**.4*), we will filter the logs relevant
    to the purpose of the investigation. As logs are filtered, the `src_ip` (source
    IP), `dest_ip` (destination IP), and `bytes_sent` (bytes sent) to be visualized
    within the log entry summaries. Right-click and access these options for tagging
    fields. Notice that the following figure demonstrates tagging key fields for easier
    visualization and investigation:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.11 – Logs Explorer field filters](img/00002.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.11 – Logs Explorer field filters
  prefs: []
  type: TYPE_NORMAL
- en: 'Once relevant filters are applied to support the investigation, we can review
    the log entries within Logs Explorer and identify threat actor activities. From
    the Logs Explorer view, we can see that the threat actor first copied the files
    from GCS to the GCE VM with the `cf1-ta-vm` hostname and associated IP address
    (`10.0.0.15`) as the destination IP. Given that the transfer is within GCP’s infrastructure,
    the transfers occur through GCP’s backend network infrastructure. Notice the bytes
    sent size within the following snippet with the order of tags as `src_ip` followed
    by `dest_ip` and `bytes_sent`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.12 – Query result for GCS data transfer to GCE](img/00019.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.12 – Query result for GCS data transfer to GCE
  prefs: []
  type: TYPE_NORMAL
- en: Putting the pieces together, we have determined that GCS storage objects were
    copied to a local GCE host. We now flip the destination IP and identify whether
    that GCE host was responsible for outbound connections. We apply filters on the
    source IP address as `10.0.0.15` and immediately see the outbound connection to
    a remote server along with the `bytes_sent` values, which we attribute to a threat
    actor-controlled server.
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.13 – Logs Explorer hunting for outbound connections](img/00037.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.13 – Logs Explorer hunting for outbound connections
  prefs: []
  type: TYPE_NORMAL
- en: As we can see through the sequence of steps illustrated, investigators can extract
    relevant event logs attributed to threat actor activities through interactive
    filtering capabilities and click-through filters to the log fields. There is always
    the option of extracting all the logs, performing an offline analysis, and slicing-and-dicing
    them further to determine specific actions the threat actor performs. There are
    various ways, however, for command-line entries to be extracted. Investigation
    teams can use this information to obtain a complete snapshot of the GCE. We will
    explore this mechanism in [*Chapter 10*](part0030_split_000.html#_idTextAnchor199).
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Logs Explorer has limitations on recording commands entered within the GCE;
    any commands entered by the user or the threat actor are not recorded within Logs
    Explorer.
  prefs: []
  type: TYPE_NORMAL
- en: Expanding on network monitoring capabilities, let us delve into GCP’s Packet
    Mirroring feature, which complements the insights provided by VPC Flow Logs.
  prefs: []
  type: TYPE_NORMAL
- en: Packet Mirroring
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GCP’s Packet Mirroring feature allows security teams to collect network packets
    from VMs and identify security threats or activities associated with the VMs.
    GCP’s Packet Mirroring only mirrors traffic between VMs and external interfaces
    and does not mirror traffic between cluster nodes such as GKE. We will learn more
    about containers, including **Docker** and **Kubernetes**, in [*Chapter 11*](part0031_split_000.html#_idTextAnchor217).
  prefs: []
  type: TYPE_NORMAL
- en: To mirror packets, ensure the principals are attached with the `compute.packetMirrorUser`
    and `compute.packetMirroringAdmin` roles.
  prefs: []
  type: TYPE_NORMAL
- en: An internal load balancer must be deployed with **network passthrough** capabilities
    that pass the traffic to the **collector** instances to enable packet mirroring.
    The load balancer must be pointed to a **managed instance group** in the backend
    with pre-configured instance templates, allowing GCP to create collector instances
    automatically. The collector instance can be a VM with tools for capturing and
    receiving network packets via the internal load balancer.
  prefs: []
  type: TYPE_NORMAL
- en: When setting up an internal load balancer, ensure that it is created within
    the same region as the instance being mirrored, `,` and **backend subsetting**
    is not enabled. Also, ensure that packet forwarding rules are created on the load
    balancers to forward all the mirrored packets while configuring the load balancer.
    This setting cannot be changed once configured.
  prefs: []
  type: TYPE_NORMAL
- en: When creating an internal load balancer, a managed instance group must be created
    and assigned VMs within that group. GCP will then determine this VM as part of
    the collector instance for packet mirroring and capture.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure demonstrates a simple configuration for an internal network
    load balancer. We created a sample load balancer, `lb2`, and configured it on
    `subnet-lab1` under the `test-lab1` VPC. We also created a managed instance group,
    `instance-group1`, that automatically makes the collector VMs for receiving network
    packets:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.14 – Internal load balancer configuration](img/00054.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.14 – Internal load balancer configuration
  prefs: []
  type: TYPE_NORMAL
- en: Once a load balancer is created, configure the **packet mirroring policy** and
    specify the target VPC and subnet for the source of packet capture. Alternatively,
    select a suspect GCE from where the network packets will be collected. Note that
    the target VPC and collector instance must be created within the same network
    region for successfully mirroring packets.
  prefs: []
  type: TYPE_NORMAL
- en: In the following screenshot, we configure the packet mirroring policy (`pkt-mirror1`)
    that defines the collector VM or VPC network (in this case, `test-lab1`) and the
    load balancers (specified in the form of a forwarding rule, `lb2-forwarding-rule`)
    the policy will be attached to. **Policy enforcement** must be turned on to enable
    packet mirroring.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.15 – Packet mirroring policy](img/00072.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.15 – Packet mirroring policy
  prefs: []
  type: TYPE_NORMAL
- en: The packet mirroring policy is also configured to forward and mirror packets
    associated with the `test-lab1` VPC, with the suspect VM attached to `subnet-lab1`.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, in the collector VM, we begin collecting network packets by running `tcpdump`.
    Note the IP address of the suspect VM before initiating network packet capture:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: 'The following parameters are supplied when running `tcpdump`:'
  prefs: []
  type: TYPE_NORMAL
- en: '`-i INTERFACE_NAME`: Collector instance network interface name that will listen
    to network packets (`ens33`, `enp03`, etc.)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-f "IP_ADDRESS"`: Filter flag to apply a packet capture based on a specific
    IP address of the suspect VM'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Outputs from `tcpdump` can also be written to a file. In the example, we dump
    the packets using the `-w` flag and provide the file location.
  prefs: []
  type: TYPE_NORMAL
- en: Investigators prefer to capture full packets recording all threat actor activities
    across multiple VMs via the VPC network before focusing on specific GCP services
    for investigation.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the packets are written to the disk, the following GCP command-line options
    can be used to access GCP storage and upload artifacts:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: It is assumed that the investigation team will have its own identities and associated
    roles attached to those identities (principals). First, you must log in by entering
    the preceding command and following the on-screen instructions.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once completed, you can access Google Cloud Storage and copy the artifacts
    using the following command:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The following are the key parameters that are required to upload artifacts
    successfully:'
  prefs: []
  type: TYPE_NORMAL
- en: '`SOURCE_FILE`: The source artifacts that the team would like to investigate'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BUCKET_NAME`: The Google Cloud Storage bucket name'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DESTINATION_PATH`: The destination folder path within the storage bucket'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we can see, the VPC Flow Logs offered by GCP present substantial data related
    to network traffic patterns, which can significantly enhance security and troubleshooting
    efforts. Packet mirroring amplifies the potential for monitoring and analyzing
    network traffic but also enables the identification of potential security threats
    in real time.
  prefs: []
  type: TYPE_NORMAL
- en: The following section will examine more granular GCE logs, offering profound
    insights into activities and enabling correlation capabilities via Logs Explorer.
  prefs: []
  type: TYPE_NORMAL
- en: Compute Engine logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GCE is a service offered by GCP that allows users to create VMs within GCP’s
    infrastructure. These VMs can be hosted across any part of the world where GCP
    operates. It provides flexibility and scalability options, making various preconfigured
    VM instances available. It can create on demand or resize a VM based on requirements.
    Users can create a VM instance or a group of VMs through **GCE Instance Group
    Manager**, which manages the deployment and configuration of VMs.
  prefs: []
  type: TYPE_NORMAL
- en: GCP’s logging platform
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'GCP’s Cloud Logging platform automatically collects and aggregates logs from
    various GCP resources via Logs Explorer. It offers a single-pane view of all the
    logs and filters, allowing investigators to hunt for specific alerts or threats
    and use them for monitoring. Some of the types of logs it collects are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Platform logs**: Generated through GCP’s services, these logs are used for
    debugging and troubleshooting. Examples of platform logs include VPC Flow Logs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Component logs**: Similar to platform logs, these are generated by GCP’s
    software-based components, such as Kubernetes clusters. GKE logs are classified
    as component logs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security logs**: Two forms of security logs are collected within GCP; the
    first is **Cloud Audit logs**, which provide administrative information and activities
    performed by the administrator, supporting cloud audit and compliance requirements.
    Secondly, **Access Transparency logs** log any actions performed by Google’s staff
    directly on a Google Cloud tenant to allow for transparency and compliance.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User-written logs**: As the name suggests, they log any custom application
    logging, which can be sent to Cloud Logging through the OpsAgent, Logging Agent,
    Cloud Logging API, and other libraries. We will learn about the OpsAgent in a
    later part of this chapter.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multi-cloud and hybrid logs**: These include logs from other cloud providers
    such as Microsoft Azure and on-premises infrastructure. They can be collected
    alongside GCP logs; however, there may be cost implications based on the number
    of logs.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GCP’s default logging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every VM within GCP is preconfigured to send default logs to the **Cloud Logging
    platform**. These include CPU utilization, memory utilization, network bandwidth
    consumption, and so on. While the telemetry collected is rudimentary, it is vital
    in determining whether any abnormal activities are detected within the monitoring
    console for deep-dive investigation.
  prefs: []
  type: TYPE_NORMAL
- en: Specifically speaking of logging agents, Google primarily relies on the **OpsAgent**,
    legacy agents, and custom logging packages.
  prefs: []
  type: TYPE_NORMAL
- en: OpsAgent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GCP uses OpsAgent as the primary source for monitoring and collecting telemetric
    data from Windows and Linux-based systems. The OpsAgent is based on FluentBit,
    a third-party but lightweight logging and telemetry data provider that allows
    metrics collection in the **Prometheus** format. FluentBit (**fluentd**) handles
    automatic tagging and metrics parsing before sending it to the logging platform.
  prefs: []
  type: TYPE_NORMAL
- en: Google also relies on **OpenTelemetry Collector**, another open source service,
    for specific metrics.
  prefs: []
  type: TYPE_NORMAL
- en: GCP users can also configure their fluentd configuration for specific application-level
    logging that will be automatically sent to Google’s Cloud Logging platform.
  prefs: []
  type: TYPE_NORMAL
- en: By using the OpsAgent and deploying custom configuration files (fluentd configurations),
    investigators can collect metrics and logs from various third-party applications
    such as Microsoft Active Directory, Apache Tomcat, **Internet Information Services**
    (**IIS**), MySQL, MariaDB, and many more. The OpsAgent also allows log collections
    from GKE.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some of the log sources that the OpsAgent collects by default:'
  prefs: []
  type: TYPE_NORMAL
- en: '`/var/log/syslog` and `/var/log/messages` in Linux'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Journald** daemon and **Systemd** logs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TCP port**: Listen to a TCP port and collect logs'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Windows event logs**: Logs from Windows operating systems'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fluentd Forward**: Logs collected via Fluentd Forward over TCP'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following metrics are reported by the OpsAgent by default without any additional
    configuration on the host VM. These metrics help identify deviations from the
    baseline and, if a breach occurs, allow the security team to respond immediately:'
  prefs: []
  type: TYPE_NORMAL
- en: '**CPU metrics**: CPU states (idle, interrupt, system, and user), CPU load,
    CPU usage time, and CPU utilization'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Disk metrics**: Disk used (bytes), disk I/O time, disk operations, disk pending
    operations, disk utilization (percent), disk bytes read, and disk bytes written'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**IIS metrics (Windows)**: IIS open connections, IIS transferred bytes, IIS
    connections, and IIS requests'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network interface metrics**: Network errors, packets, and traffic (bytes)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Memory metrics**: Memory usage, memory states (buffered, cached, free, slab,
    and used), and memory utilization (percent)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MSSQL metrics**: SQL server open connections, SQL server transaction rate,
    and SQL server write transaction rate'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Swap metrics (Linux only)**: Swap usage, swap I/O operations, and swap utilization
    (percent)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network metrics**: TCP connections'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Process metrics**: Process count by states (running, sleeping, and zombie),
    process CPU time, process disk read I/O, process disk writes I/O, fork count,
    process resident memory (allocations), and process virtual memory (usage)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Agent self metrics**: Agent API request count, agent log entry count, agent
    memory usage, agent metric point count, agent enabled receiver count, and agent
    uptime'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Legacy logging agent
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Google has currently deprecated the legacy logging agent. However, there are
    still VMs that require legacy agents, so they continue to be supported by Google.
    While fluentd is still being used here, the application utilizes older methodologies
    for collecting the metrics and routing them to Logs Explorer.
  prefs: []
  type: TYPE_NORMAL
- en: Logging Dataflow pipelines
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Dataflow pipelines provide a stream of data or batch processing capabilities
    at scale. GCP’s Dataflow pipeline is based on **Apache Beam**. Logs can be streamed
    at variable volumes in near real time using Dataflow applications.
  prefs: []
  type: TYPE_NORMAL
- en: Any actions performed on GCP Dataflow are recorded by default in Logs Explorer.
    Through Logs Explorer, investigators can detect any changes to the Dataflow parameters
    or whether unauthorized users altered the pipeline.
  prefs: []
  type: TYPE_NORMAL
- en: Note that a Docker instance forms the base of any Dataflow pipeline’s operations.
    Therefore, investigators must also investigate the logs emitted by the GKE cluster
    and GCE Instance Group Manager. GCP relies on Instance Group Manager to create
    multiple managed VMs that run the containers (GKE) to handle instance resourcing
    and deploying VMs automatically.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure outlines some sample resources required for successful
    Dataflow pipeline execution. Like **Syslog**, Dataflow events are tagged with
    a severity rating; it also generates the exact name of the job that emitted the
    log entry. Using the filters within Logs Explorer, relevant logs can be specifically
    targeted and investigated in a Dataflow job or pipeline:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.16 – Resource types for Dataflow pipeline execution](img/00092.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.16 – Resource types for Dataflow pipeline execution
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: '![Figure 6.17 – Log streams emitted by GCP Dataflow](img/00112.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.17 – Log streams emitted by GCP Dataflow
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, monitoring and investigating Dataflow logs is no different from
    analyzing any other activity logs emitted by relevant GCP resources. It is essential
    to understand that when a resource is accessed, GCP in the backend may access
    other associated resources or dependencies to deliver the service, impacting the
    number of logs or the logs emitted by relevant dependent services.
  prefs: []
  type: TYPE_NORMAL
- en: GCP storage logs
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like AWS’s S3 buckets, GCP Storage also refers to storage containers as buckets.
    Each bucket can contain any file format, referred to as an **object**. Principals
    can be assigned granular permissions and access to each bucket or object. Storage
    buckets can also be made publicly accessible on the internet, depending on the
    use case. Storage metadata is recorded in the key/value pair format at the bucket
    level to manage the object life cycle. Values assigned to keys can be a bucket
    name string or an array of object life cycle management configurations.
  prefs: []
  type: TYPE_NORMAL
- en: Once a storage bucket is created, you cannot change the bucket name, the location
    (where the bucket is hosted), the project associated with the storage bucket,
    or the metadata generation number, uniquely identifying the bucket state.
  prefs: []
  type: TYPE_NORMAL
- en: Storage permissions
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to IAM permissions, specific permissions are required for accessing
    objects by a resource or a principal. In GCP’s IAM realm, permissions are assigned
    to roles and roles are attached to principals.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table outlines the list of permissions required for accessing
    storage objects:'
  prefs: []
  type: TYPE_NORMAL
- en: '| **Permission name** | **Description** |'
  prefs: []
  type: TYPE_TB
- en: '| `storage.buckets.create` | Creates a storage bucket within a project |'
  prefs: []
  type: TYPE_TB
- en: '| `storage.buckets.delete` | Deletes a storage bucket from a project |'
  prefs: []
  type: TYPE_TB
- en: '| `storage.buckets.get` | Reads metadata associated with the bucket, including
    bucket configurations |'
  prefs: []
  type: TYPE_TB
- en: '| `storage.buckets.list` | Lists buckets in a project |'
  prefs: []
  type: TYPE_TB
- en: '| `storage.buckets.update` | Updates metadata associated with the bucket and
    configuration of the bucket |'
  prefs: []
  type: TYPE_TB
- en: '| `storage.buckets.getObjectInsights` | Reads metadata associated with the
    object within the bucket |'
  prefs: []
  type: TYPE_TB
- en: Table 6.1 – Minimum IAM permissions required to create and manage buckets
  prefs: []
  type: TYPE_NORMAL
- en: Storage object logging
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Like all the resources within GCP, activities on storage buckets emit logs and
    are recorded within Logs Explorer; storage logs or access logs associated with
    the objects are also recorded within Logs Explorer. Investigators should, therefore,
    consider reviewing storage-related logs to determine evidence of data exfiltration
    and any threats against GCP’s storage buckets.
  prefs: []
  type: TYPE_NORMAL
- en: Investigating GCP Cloud storage logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When setting up GCP Cloud Storage, ensure that it has appropriate permissions
    set. This also includes public access prevention policies that must be turned
    on or off, depending on the use case.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example will examine the logs to determine privilege escalation
    attempts to GCP’s Cloud Storage. For this purpose, we created a temporary storage
    folder, `test_cf1_test1`, and set it for non-public access to the folder; we have
    not enabled any fine-grained access control for this purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.18 – GCP Cloud Storage configuration summary example](img/00027.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.18 – GCP Cloud Storage configuration summary example
  prefs: []
  type: TYPE_NORMAL
- en: 'We will examine the storage logs within Logs Explorer. We evaluate the IAM
    policies configured using GCP’s `gsutil iam get gs://test_cf1_test1` command and
    requesting IAM policies configured for this bucket. This is equivalent to making
    a `GET` request to `https://storage.googleapis.com/storage/v1/b/<bucket>/iam`,
    but as an authenticated user:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.19 – IAM policies on a Cloud Storage folder example](img/00170.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.19 – IAM policies on a Cloud Storage folder example
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the following primary roles are configured for the storage folder.
    GCP automatically applies legacy roles to buckets when owners create a **uniform
    bucket-level access** (meaning all objects within the bucket have similar access
    permissions enabled):'
  prefs: []
  type: TYPE_NORMAL
- en: '`roles/storage.legacyBucketOwner`: Principals with `roles/editor` or `roles/owner`
    are granted this access'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/storage.legacyBucketReader`: Principals with `roles/viewer` are granted
    this access'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/storage.legacyObjectOwner`: Principals with `roles/editor` or `roles/owner`
    are granted this access'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/storage.legacyObjectReader`: Principals with `roles/viewer` are granted
    this access'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we know that access to this folder is only limited to those users or principals
    with `roles/editor` access or `roles/owner` access. In summary, any other principals
    or general public access are not allowed for this folder.
  prefs: []
  type: TYPE_NORMAL
- en: We will review Logs Explorer to determine the access requests made when an authenticated
    user or principal attempts to access the bucket using non-standard methods, such
    as accessing Cloud Storage buckets through a Python program.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will look at a log entry for an authenticated user attempting to access
    the bucket. Within the `authorizationInfo` section, we look specifically at the
    highlighted areas: `CallerIP`, which refers to the user’s IP address that is trying
    to access the bucket, and `callerSuppliedUserAgent` (**user-agent** string), which
    is reflective of the browser and operating system variant that the user is using
    to attempt to access the storage. Finally, we also look at what resource is being
    requested along with the assigned permission tagged to this bucket and object,
    and whether IAM granted this access:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: 'Let us look at a situation where an unauthenticated user tries to gain access
    to GCP’s Cloud Storage buckets and objects outside of GCP’s Cloud console. Similar
    to the previous example, we’ll look at a similar form of log entry and look for
    the `authorizationInfo` section. The request is for accessing the `test_cf1_test1`
    bucket. In this case, note the user-agent string and IP address. Given that the
    user attempted to authenticate as the owner/principal, and since the access attempt
    was via a Python command-line application instead of a browser accessing the bucket,
    this permission was denied as there is no public access to the folder outside
    of the GCP console, GCP CLI, or GCP API:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'The following figure outlines the series of attempts while allowing access
    to GCP API tools:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.20 – Multiple denied access attempts to non-GCP applications while
    only allowing API access](img/00068.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.20 – Multiple denied access attempts to non-GCP applications while
    only allowing API access
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, Logs Explorer forms the basis of most of the investigative insights
    into activities performed by the user or external resources.
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will look into some of GCP’s dashboards that offer insight into the
    security status of the resources configured within GCP.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Security Command Center (Cloud SCC)
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloud SCC is like a dashboard for notifying organizations and security teams
    about possible threats or vulnerabilities. Cloud SCC is only available when a
    GCP account is set up as an organization. Individual GCP users do not have access
    to Cloud SCC. When an anomaly is identified, it creates a report of a particular
    threat or misconfiguration in GCP’s realm, called a **finding**. Cloud SCC provides
    a consolidated view of all the findings and anomalies detected within a cloud
    service, such as a GCE.
  prefs: []
  type: TYPE_NORMAL
- en: Note that there are two activation levels; by default, organizations, when they
    sign up, are assigned the **Standard service tier**, which has limited functionality
    and includes looking at the general security health of GCEs and their configurations.
    It also includes features such as error reporting, continuous exports to Pub/Sub,
    and access to other integration points, including Cloud Data Loss Prevention,
    Cloud Armor, and so on.
  prefs: []
  type: TYPE_NORMAL
- en: 'Google also offers a **Premium service tier**, which comes at a price that
    includes additional capabilities, as outlined in the following screenshot, such
    as **Event Threat Detection**, **Web Security Scanner**, **Container Threat Detection**,
    **Virtual Machine Threat Detection**, **Security Health Analytics**, and **Rapid**
    **vulnerability detection**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.21 – Cloud SCC Premium subscriptions](img/00113.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.21 – Cloud SCC Premium subscriptions
  prefs: []
  type: TYPE_NORMAL
- en: The following sections will examine some of the Cloud SCC capabilities in more
    depth.
  prefs: []
  type: TYPE_NORMAL
- en: IAM roles
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we know GCP uses IAM roles to assign access to principals, it is vital
    to understand the various access privileges required for teams to have access
    to Cloud SCC dashboards and other details.
  prefs: []
  type: TYPE_NORMAL
- en: 'From a DFIR perspective, the following roles are required for accessing the
    Cloud SCC console:'
  prefs: []
  type: TYPE_NORMAL
- en: '`roles/resourcemanager.organizationAdmin`: Provides admin access at the organization
    level. An organization can have multiple projects.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/securitycenter.admin`: Administrative or superuser access to Cloud SCC
    and other resources within Cloud SCC. It provides access to project-level detections.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/securitycenter.adminViewer`: Admin read-only access to the security
    center. Users can view scan results and see threat detections. No changes are
    allowed. It provides access to project-level detections.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/securitycenter.findingsViewer`: Provides restrictive access to view
    only the findings generated within Cloud SCC for a specific project.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/cloudsecurityscanner.editor`: Provides project-level access, with administrative
    controls (read-write controls) to run cloud web scanning. Access to all the resources
    within the web scanner module is provided.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Threats and Findings dashboards
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The GCP **Threats** and **Findings** dashboards provide visibility into potential
    threats and security incidents, allowing organizations to manage security threats
    and findings within their GCP environment. They are a central hub for monitoring
    and analyzing security events and proactively detecting and responding to threats
    by aggregating data from various services and tools within GCP.
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Threats** dashboard displays threats per VM instance and threats identified
    within the overall GCP environment. This includes any potential misconfigurations
    and features that, as a result, introduced a vulnerability within the GCP environment.
    The following figure is a sample dashboard with identified threats:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.22 – Threats dashboard](img/00135.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.22 – Threats dashboard
  prefs: []
  type: TYPE_NORMAL
- en: 'Details of identified threats are documented on the **Findings** page. Findings
    provide detailed information on the threat, severity, event detection time (event
    time), event reporting time (create time), GCP resource, GCP project, and resource
    type. Findings also allow investigators to utilize filters to investigate the
    identified findings further and gain an understanding of the threat. The following
    is the drill-down screenshot of an identified threat within the **Findings** section:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.23 – Findings dashboard](img/00086.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.23 – Findings dashboard
  prefs: []
  type: TYPE_NORMAL
- en: Note that findings are classified into **Threat**, **Misconfiguration**, or
    **Vulnerability**. By default, if investigators navigate to the **Findings** page,
    it will display all the findings that are not muted and have been active for the
    previous seven days.
  prefs: []
  type: TYPE_NORMAL
- en: 'On the **Findings** page, within the **Quick filters** pane, investigators
    can quickly filter down the types of findings that they are interested in and
    are relevant to the investigation:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.24 – Findings quick filters](img/00105.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.24 – Findings quick filters
  prefs: []
  type: TYPE_NORMAL
- en: 'Once filters are applied, the findings are available for review and investigators
    can determine more information. In the following screenshot, we have filtered
    down **Open RDP port** and identified two findings concerning the exposed RDP
    port. GCP has classified this detection as a high-severity finding:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.25 – Findings based on quick filters](img/00196.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.25 – Findings based on quick filters
  prefs: []
  type: TYPE_NORMAL
- en: Each finding provides a link to get more details about the results that indicate
    what was detected, including **Artificial Intelligence (AI) Generated Summary**,
    **Description**, **Affected Resource**, **Security Marks**, suggested next steps,
    and related links to various standards and detection services. It also allows
    investigators to mute this detection to ensure that findings do not report on
    similar exposures.
  prefs: []
  type: TYPE_NORMAL
- en: As we delve into the intricacies of Cloud SCC Assets, we will explore how this
    feature empowers investigators and security teams with a detailed inventory of
    GCP resources, identifying vulnerabilities, misconfigurations, and potential threats.
    This visibility lays the foundation for practical risk assessment and proactive
    security measures, ultimately fostering a more resilient and secure cloud infrastructure.
    Let us now navigate the key functionalities that Cloud SCC Assets brings to the
    cloud security journey.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud SCC Assets
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Investigators always appreciate seeing all the assets and knowing what is configured
    within an environment. Similarly, GCP’s Cloud SCC offers something called Cloud
    SCC Assets that provides a high-level view of all the categories of assets, their
    details, and the configurational information set for these assets. Getting the
    lay of the land is vital when investigating a complex case. Investigators can
    use this asset management page to obtain relevant information and potentially
    identify the next steps in their investigation.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure outlines the asset summary configured within our sample
    GCP instance and the relevant resource types:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.26 – Cloud SCC Assets view](img/00184.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.26 – Cloud SCC Assets view
  prefs: []
  type: TYPE_NORMAL
- en: 'Only assets associated with the current project or resources are visible in
    the asset view. More information is presented within each asset under the `resourceProperties.name`
    field. For example, we can select the `compute`. `Instance` resource type in the
    filters, then click on the first item. The following figure summarizes what kind
    of resource is configured and its various configurational elements (or attributes).
    It also presents resource properties in the JSON format and includes any additional
    metadata for this asset. Finally, this page also provides any findings about this
    particular asset:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.27 – Asset detail view](img/00121.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.27 – Asset detail view
  prefs: []
  type: TYPE_NORMAL
- en: Configurational vulnerabilities
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Platform configurational vulnerabilities** is a GCP feature that natively
    scans the configurations of various GCP services and GCP VMs and identifies vulnerabilities
    within the infrastructure. Although very simplistic, this dashboard provides detailed
    findings for each configurational vulnerability. GCP deems something a vulnerability
    or a threat if it sees a deviation from acceptable standards. Since each organization
    differs, some variations would be permissible for the business.'
  prefs: []
  type: TYPE_NORMAL
- en: From an investigation point of view, the vulnerability findings feature offers
    historical insights into when GCP observed the vulnerability or the deviation,
    the severity of the associated findings, and the number of services or endpoints
    impacted, and provides a mapping to various commonly accepted security standards.
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: GCP’s vulnerability findings can be used to determine potential root causes
    and, through digital forensics, confirm whether the threat actor exploited any
    of these vulnerabilities.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure illustrates the list of vulnerabilities, including third-party
    application vulnerabilities. Each finding will also provide detailed descriptions
    of where this deviation was identified:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.28 – List of vulnerabilities](img/00106.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.28 – List of vulnerabilities
  prefs: []
  type: TYPE_NORMAL
- en: From a digital forensics standpoint, configurational vulnerabilities can provide
    investigators with clues about potential gaps within an infrastructure and indicate
    whether any of the gaps could have been the root cause of an incident.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we venture into the command-line environment, which allows
    access to various GCP resources. GCP Cloud Shell is helpful for incident responders
    who are very comfortable with command-line tools. It can be useful for quick access
    and investigative insights into a GCP resource.
  prefs: []
  type: TYPE_NORMAL
- en: GCP Cloud Shell
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Cloud Shell** is GCP’s native command-line tool that allows access to various
    GCP services over a command-line interface. GCP Cloud Shell, a browser-based shell
    environment, can be used to investigate and identify potential security incidents
    for threat-hunting activities. Investigators can also use Cloud Shell to turn
    a service such as packet mirroring on or off. It also has an interactive code
    editor for users or investigators who want to import custom code, enabling Cloud
    Shell to perform certain activities. GCP’s Cloud Shell can also be accessed locally
    through the Google Cloud SDK or an in-browser session.'
  prefs: []
  type: TYPE_NORMAL
- en: GCP offers essential command-line tools, specifically `gcloud` and `gsutil`.
    `gcloud` provides access to general GCP services such as `gsutil` is a specific
    utility tool to access storage buckets.
  prefs: []
  type: TYPE_NORMAL
- en: 'Through `gcloud`, investigators can access Logs Explorer and collect all the
    associated logs for offline analysis. Investigators can also list the services
    a user has subscribed to or all VPC policies:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.29 – GCP Cloud Shell](img/00080.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 6.29 – GCP Cloud Shell
  prefs: []
  type: TYPE_NORMAL
- en: GCP Cloud Shell offers investigators a browser-based command-line interface
    for investigating incidents. It allows access to GCP resources for tasks such
    as log analysis, memory examination, and malware assessment. Cloud Shell aids
    in artifact preservation, collaboration, and automation, enabling efficient, scalable,
    and secure digital forensics and incident response operations.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After diving deep into GCP, we know the GCP infrastructure is very similar to
    other popular cloud providers. We highlighted the importance of understanding
    the varying verbosity of logs emitted by GCP services, emphasizing the need for
    investigators to seek corroborating evidence to confirm events. GCP’s centralized
    logging system, which flows into Logs Explorer, is a powerful tool for administrators
    to troubleshoot routine issues and for investigators to delve into event correlations
    across the GCP ecosystem.
  prefs: []
  type: TYPE_NORMAL
- en: We learned about similarities between how GCP organizes its buckets and objects,
    which is conceptually similar to AWS. Cloud SCC offers a dashboard or a security
    scorecard on infrastructure for administrators. At the same time, for investigators,
    it is a goldmine of findings, with detailed information on where to look when
    kicking off an investigation. Cloud SCC offers unique insights into vulnerabilities
    without deploying specific agents within the hosts. Finally, we looked at Cloud
    Shell, which provides more freedom for investigators to perform investigative
    activities from the command line.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will dive deep into email workspaces, especially Microsoft
    365 and Google Workspaces, and identify methodologies for investigating cloud
    email workspaces.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Google Access Transparency policy: [https://cloud.google.com/privacy](https://cloud.google.com/privacy)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cloud Audit Logs overview: [https://cloud.google.com/logging/docs/audit#system-event](https://cloud.google.com/logging/docs/audit#system-event)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Enabling logging: [https://cloud.google.com/logging/docs/audit/configure-data-access](https://cloud.google.com/logging/docs/audit/configure-data-access)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cloud SCC IAM, access control with IAM: [https://cloud.google.com/security-command-center/docs/access-control](https://cloud.google.com/security-command-center/docs/access-control)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'IAM for organization-level activations: [https://cloud.google.com/security-command-center/docs/access-control-org](https://cloud.google.com/security-command-center/docs/access-control-org)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Exporting Security Command Center data: [https://cloud.google.com/security-command-center/docs/how-to-export-data?authuser=2](https://cloud.google.com/security-command-center/docs/how-to-export-data?authuser=2)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Investigating and responding to threats: [https://cloud.google.com/security-command-center/docs/how-to-investigate-threats#defense_evasion_breakglass_workload_deployment](https://cloud.google.com/security-command-center/docs/how-to-investigate-threats#defense_evasion_breakglass_workload_deployment)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using event threat detection: [https://cloud.google.com/security-command-center/docs/how-to-use-event-threat-detection](https://cloud.google.com/security-command-center/docs/how-to-use-event-threat-detection)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'How Security Command Center helps you detect and stop cyber attacks: [https://cloud.google.com/security-command-center/docs/concepts-how-scc-determines-env-under-attack](https://cloud.google.com/security-command-center/docs/concepts-how-scc-determines-env-under-attack)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Compute Engine IAM roles and permissions: [https://cloud.google.com/compute/docs/access/iam](https://cloud.google.com/compute/docs/access/iam)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FluentBit: [https://github.com/fluent/fluent-bit](https://github.com/fluent/fluent-bit)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Install Google CLI: [https://cloud.google.com/sdk/docs/install#linux](https://cloud.google.com/sdk/docs/install#linux)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Live forensics to analyze a cyber-attack: [https://cloud.google.com/blog/products/identity-security/how-to-use-live-forensics-to-analyze-a-cyberattack](https://cloud.google.com/blog/products/identity-security/how-to-use-live-forensics-to-analyze-a-cyberattack)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
