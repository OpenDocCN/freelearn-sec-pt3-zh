- en: '6'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '6'
- en: DFIR Investigations – Logs in GCP
  id: totrans-1
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: DFIR调查 – GCP中的日志
- en: You must have noticed each cloud service provider’s common resources and elements
    by now. In this chapter, we will dive straight into the security capabilities
    of **Google Cloud Platform** (**GCP**), what log sources are available, and how
    we can conduct our investigation. Note that cloud providers may use common terminologies.
    However, the applications and availability of logs may differ for each cloud service
    provider. Therefore, it is essential to understand which logs will be available
    during an incident investigation.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 你一定已经注意到每个云服务提供商的常见资源和元素了。在本章中，我们将深入探讨**Google Cloud Platform**（**GCP**）的安全功能、可用的日志来源以及如何进行调查。请注意，云服务提供商可能使用相似的术语，但日志的应用和可用性在每个云服务提供商之间可能有所不同。因此，了解在事件调查过程中哪些日志是可用的是至关重要的。
- en: In [*Chapter 3*](part0021_split_000.html#_idTextAnchor042), we briefly introduced
    specific cloud service offerings within GCP; in this chapter, we will dig deep
    into some of its core components and digital forensics. This chapter outlines
    the logs available for some of the critical GCP services and products discussed
    in [*Chapter 3*](part0021_split_000.html#_idTextAnchor042) and looks at utilizing
    these sources in the context of an investigation.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 在[*第3章*](part0021_split_000.html#_idTextAnchor042)中，我们简要介绍了GCP中的一些特定云服务；在本章中，我们将深入探讨其一些核心组件和数字取证。本章概述了[*第3章*](part0021_split_000.html#_idTextAnchor042)中讨论的部分关键GCP服务和产品的日志，并探讨在调查过程中如何利用这些日志来源。
- en: 'Specifically, we will discuss the following topics in this chapter:'
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章我们将讨论以下主题：
- en: GCP core services
  id: totrans-5
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GCP核心服务
- en: GCP identity and access management
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GCP身份与访问管理
- en: Policy Analyzer
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 策略分析器
- en: GCP Logs Explorer
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GCP日志资源浏览器
- en: VPC Flow Logs
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: VPC流日志
- en: Packet Mirroring
  id: totrans-10
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据包镜像
- en: Compute Engine logs
  id: totrans-11
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 计算引擎日志
- en: Logging Dataflow pipelines
  id: totrans-12
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 日志数据流管道
- en: GCP storage logs
  id: totrans-13
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GCP存储日志
- en: Cloud Security Command Center
  id: totrans-14
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 云安全指挥中心
- en: GCP Cloud Shell
  id: totrans-15
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: GCP Cloud Shell
- en: We will discuss Google Workspace in [*Chapter 7*](part0026_split_000.html#_idTextAnchor137),
    along with Microsoft 365 (M365), as these relate to email and cloud-hosted collaboration
    services.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们将在[*第7章*](part0026_split_000.html#_idTextAnchor137)中讨论Google Workspace，以及Microsoft
    365（M365），因为它们与电子邮件和云托管的协作服务相关。
- en: GCP core services
  id: totrans-17
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GCP核心服务
- en: GCP is a suite of cloud computing services provided by Google. It offers a wide
    range of tools and services to build, deploy, and manage applications and infrastructure
    in the cloud. It provides services similar to cloud providers, such as AWS and
    Microsoft Azure.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: GCP是Google提供的一套云计算服务，提供一系列工具和服务，用于在云端构建、部署和管理应用程序和基础设施。它提供类似于其他云服务提供商（如AWS和Microsoft
    Azure）的服务。
- en: 'Here are some of the critical service offerings from GCP:'
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 这里是GCP的一些关键服务：
- en: '**Compute services**: GCP offers several compute options, including **Google
    Compute Engine** (**GCE**) (**virtual** **machines** [**VM**s]), **Google Kubernetes
    Engine** (**GKE**) (managed Kubernetes), and **App Engine** (managed platform
    for applications)'
  id: totrans-20
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**计算服务**：GCP提供几种计算选项，包括**Google Compute Engine**（**GCE**）（**虚拟机**[**VM**]）、**Google
    Kubernetes Engine**（**GKE**）（托管Kubernetes）和**App Engine**（应用程序的托管平台）'
- en: '**Storage services**: GCP provides various storage options such as **Google
    Cloud Storage** (**GCS**) (object storage), **Cloud SQL** (relational database
    service), **Cloud Bigtable** (NoSQL database), and **Cloud Firestore** (document
    database)'
  id: totrans-21
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**存储服务**：GCP提供多种存储选项，如**Google Cloud Storage**（**GCS**）（对象存储）、**Cloud SQL**（关系型数据库服务）、**Cloud
    Bigtable**（NoSQL数据库）和**Cloud Firestore**（文档数据库）'
- en: '**Networking**: GCP offers networking services such as **Virtual Private Cloud**
    (**VPC**) for creating private networks, **Cloud Load Balancing** for distributing
    traffic, and **Cloud CDN** for content delivery'
  id: totrans-22
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络**：GCP提供网络服务，如用于创建私有网络的**虚拟私有云**（**VPC**）、用于分配流量的**Cloud Load Balancing**和用于内容传输的**Cloud
    CDN**'
- en: '**Big data and machine learning**: GCP includes services such as **BigQuery**
    (serverless data warehouse), **Cloud Dataflow** (data processing), **Cloud Pub/Sub**
    (messaging and event streaming), and **Cloud Machine Learning Engine** (managed
    machine learning)'
  id: totrans-23
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**大数据和机器学习**：GCP包括诸如**BigQuery**（无服务器数据仓库）、**Cloud Dataflow**（数据处理）、**Cloud
    Pub/Sub**（消息传递与事件流）和**Cloud Machine Learning Engine**（托管机器学习）等服务'
- en: '**Identity and access management** (**IAM**): IAM allows you to manage access
    to GCP resources and services, defining roles and permissions for users and groups'
  id: totrans-24
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**身份与访问管理**（**IAM**）：IAM允许你管理对GCP资源和服务的访问，定义用户和组的角色与权限'
- en: '**Management and monitoring**: GCP provides tools for managing and monitoring
    your resources, such as **Cloud Console** (web-based management interface), **Cloud
    Logging** (centralized log management), **Cloud Monitoring** (performance and
    health monitoring), and **Cloud Trace** (request latency analysis)'
  id: totrans-25
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管理和监控**：GCP 提供管理和监控资源的工具，如 **Cloud Console**（基于 web 的管理界面）、**Cloud Logging**（集中式日志管理）、**Cloud
    Monitoring**（性能和健康监控）和 **Cloud Trace**（请求延迟分析）。'
- en: '**Security and compliance**: GCP incorporates various security features, including
    encryption at rest and in transit, IAM roles and policies, VPC Service Controls,
    and compliance certifications to meet industry standards'
  id: totrans-26
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**安全与合规性**：GCP 融入了各种安全特性，包括静态和传输加密、IAM 角色和政策、VPC 服务控制以及合规认证，以满足行业标准。'
- en: '**Developer tools**: GCP offers developer tools such as **Cloud SDK** (command-line
    tools), **Cloud Build** (continuous integration and delivery), and **Cloud Source
    Repositories** (version control system)'
  id: totrans-27
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**开发者工具**：GCP 提供如 **Cloud SDK**（命令行工具）、**Cloud Build**（持续集成和交付）和 **Cloud Source
    Repositories**（版本控制系统）等开发者工具。'
- en: '**AI and ML services**: GCP provides pre-trained AI models and APIs through
    services such as **Cloud Vision API**, **Cloud Natural Language API**, and **Cloud
    Translation API**, enabling developers to integrate AI capabilities into their
    applications'
  id: totrans-28
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**AI 和 ML 服务**：GCP 提供通过如 **Cloud Vision API**、**Cloud Natural Language API**
    和 **Cloud Translation API** 等服务预训练的 AI 模型和 API，使开发者能够将 AI 功能集成到他们的应用程序中。'
- en: '**Serverless computing**: GCP offers serverless services such as **Cloud Functions**
    (event-driven functions), **Cloud Run** (serverless containers), and **Cloud Scheduler**
    (cron job scheduler)'
  id: totrans-29
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**无服务器计算**：GCP 提供无服务器服务，如 **Cloud Functions**（事件驱动函数）、**Cloud Run**（无服务器容器）和
    **Cloud Scheduler**（定时任务调度器）。'
- en: Now that we have looked at the core services GCP offers, we can dive deeper
    into specific services that investigators would be interested in. The focus will
    be on specific GCP services that form the backbone of any investigations, including
    identities, logs from the Compute Engine, and so on. We will start with GCP’s
    IAM console that is core to allowing users access to the GCP resources.
  id: totrans-30
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经了解了 GCP 提供的核心服务，可以深入探讨一些调查人员可能感兴趣的特定服务。重点将放在 GCP 的特定服务上，这些服务构成了任何调查的基础，包括身份、来自计算引擎的日志等。我们将从
    GCP 的 IAM 控制台开始，它是让用户访问 GCP 资源的核心。
- en: GCP IAM
  id: totrans-31
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GCP IAM
- en: IAM provides a framework for controlling resource access within the GCP realm
    by defining the relationships between identities, roles, and the corresponding
    resources. Within this system, the concept of resources extends to include a wide
    array of entities, such as GCE VM instances, GKE clusters, **Cloud Storage buckets**,
    and the organizational structure consisting of organizations, folders, and projects.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: IAM 提供了一个框架，通过定义身份、角色和相应资源之间的关系来控制 GCP 范围内的资源访问。在这个系统中，资源的概念扩展到包括广泛的实体，如 GCE
    虚拟机实例、GKE 集群、**Cloud Storage 存储桶**，以及由组织、文件夹和项目组成的组织结构。
- en: IAM operates on the principle that direct access permissions are not granted
    to end users; instead, permissions are organized into roles, which are subsequently
    assigned to authenticated principals or members (Google account, service account,
    Google group, authenticated users, cloud identity domain, etc.).
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: IAM 基于一个原则：不直接授予最终用户访问权限；相反，权限被组织成角色，并将这些角色分配给经过身份验证的主体或成员（如 Google 帐号、服务帐号、Google
    群组、经过身份验证的用户、云身份域等）。
- en: Central to IAM’s functioning is the **allow policy**, or **IAM policy**, which
    serves as the mechanism for specifying and enforcing the assignment of roles to
    principals. Each allow policy is linked to a specific resource. When an authenticated
    principal attempts to access a resource, IAM examines the associated allow policy,
    thereby ascertaining the permissibility of the intended action based on its stipulations.
    While the allow policy lets you set guidelines to allow access to specific resources,
    GCP will also enable you to set up a **deny policy** that specifies what users
    or roles do not have access to. A deny policy lets you set up a deny rule based
    on specific conditions that determine the permissibility of the resource. Deny
    policy examples include setting restrictions on defining new API keys or deleting
    or editing GCE resources or configurations.
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: IAM 功能的核心是**允许策略**，或称**IAM 策略**，它作为指定和强制分配角色给主体的机制。每个允许策略都与特定资源关联。当经过身份验证的主体尝试访问某个资源时，IAM
    会检查关联的允许策略，从而根据其规定确定预定操作的可行性。虽然允许策略让你设置准则以允许访问特定资源，GCP 还允许你设置**拒绝策略**，指定哪些用户或角色无法访问。拒绝策略让你根据特定条件设置拒绝规则，来决定资源的可行性。拒绝策略的示例包括限制定义新
    API 密钥或删除或编辑 GCE 资源或配置的权限。
- en: By embracing IAM within the GCP ecosystem, organizations can establish granular
    control over access privileges, ensuring that identities are assigned only the
    necessary roles to interact with designated resources. This approach to access
    management enables increased security and effective governance over the GCP environment.
  id: totrans-35
  prefs: []
  type: TYPE_NORMAL
  zh: 通过在 GCP 生态系统中采用 IAM，组织可以对访问权限进行精细控制，确保身份只被分配与指定资源交互所需的角色。这种访问管理方法可以增强安全性，并有效地管理
    GCP 环境的治理。
- en: GCP’s IAM roles and identities
  id: totrans-36
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: GCP 的 IAM 角色和身份
- en: From the perspective of incident response and forensics, it is essential to
    understand how cloud service providers organize and provision identities and privileges
    to these identities. Note that handling identities is generally different for
    each cloud service provider.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 从事件响应和取证的角度来看，了解云服务提供商如何组织和分配身份及其权限是至关重要的。需要注意的是，每个云服务提供商处理身份的方式通常不同。
- en: In the case of GCP, end users do not directly get assigned privileges. Instead,
    privileges are assigned to **roles**. You can imagine roles as a group or a collection
    of privileges that grant access to various services within GCP’s environment.
    Users or API services needing to access these resources are termed **principals**
    by GCP. Therefore, privileges are assigned to roles, and roles are attached to
    principals. A policy is a collection of roles that can be attached to one or more
    principals.
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 对于 GCP，最终用户不会直接获得权限。相反，权限会被分配给**角色**。你可以把角色想象成一组权限，授予对 GCP 环境中各种服务的访问权限。需要访问这些资源的用户或
    API 服务被 GCP 称为**主体**。因此，权限被分配给角色，角色附加到主体。策略是角色的集合，可以附加到一个或多个主体。
- en: 'The following figure summarizes how IAM policies are defined, assigned, enforced,
    and ultimately managed through GCP’s IAM module:'
  id: totrans-39
  prefs: []
  type: TYPE_NORMAL
  zh: 以下图示总结了如何通过 GCP 的 IAM 模块定义、分配、强制执行并最终管理 IAM 策略：
- en: '![Figure 6.1 – GCP‘s IAM enforcement architecture](img/00013.jpeg)'
  id: totrans-40
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.1 – GCP 的 IAM 强制执行架构](img/00013.jpeg)'
- en: Figure 6.1 – GCP‘s IAM enforcement architecture
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.1 – GCP 的 IAM 强制执行架构
- en: While the preceding figure just illustrates a generic version of how permissions
    can be assigned to each GCP resource, GCP also offers federated integration to
    active directories to manage access to GCP resources. This, however, uses a similar
    concept to enforce IAM policies. You can create granular allow and deny policies
    to enforce specific resource elements. For example, you can allow access to an
    instance within GCE while restricting access to other instances.
  id: totrans-42
  prefs: []
  type: TYPE_NORMAL
  zh: 前面的图示仅展示了如何将权限分配给每个 GCP 资源的通用版本，GCP 还提供了与活动目录的联合集成功能来管理对 GCP 资源的访问。然而，这使用了类似的概念来强制执行
    IAM 策略。你可以创建精细的允许和拒绝策略来强制执行特定的资源元素。例如，你可以允许访问 GCE 中的某个实例，同时限制对其他实例的访问。
- en: Policy Analyzer
  id: totrans-43
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 策略分析器
- en: Given that IAM assignments occur over roles where principals are assigned access
    permissions to a resource using roles, GCP offers additional tools for troubleshooting
    and investigating IAM policy configurations. Policy Analyzer allows DFIR teams
    to analyze excess privileges assigned to users or roles that may have resulted
    in abuse. Policy Analyzer can also determine whether a user has the necessary
    permissions to perform specific actions, such as deleting a table, a GCE resource,
    and so on.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 考虑到 IAM 分配是通过角色实现的，其中主体通过角色将访问权限分配给资源，GCP 提供了额外的工具来排查和调查 IAM 策略配置。策略分析器允许 DFIR
    团队分析分配给用户或角色的过度权限，这些权限可能导致滥用。策略分析器还可以确定用户是否具有执行特定操作所需的权限，例如删除表、GCE 资源等。
- en: 'The following is an example of Policy Analyzer’s output. We can see in the
    query result what roles and permissions were configured for a user under a GCP
    resource. Note that resources are allocated toward a project, and GCP tags them
    as resources:'
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是策略分析器输出的示例。我们可以在查询结果中看到为某个用户配置的 GCP 资源的角色和权限。请注意，资源分配给项目，且 GCP 将其标记为资源：
- en: '![Figure 6.2 – Policy Analyzer query results and list of permissions per role](img/00032.jpeg)'
  id: totrans-46
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.2 – 策略分析器查询结果及每个角色的权限列表](img/00032.jpeg)'
- en: Figure 6.2 – Policy Analyzer query results and list of permissions per role
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.2 – 策略分析器查询结果及每个角色的权限列表
- en: DFIR use cases for Policy Analyzer
  id: totrans-48
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DFIR 使用案例：策略分析器
- en: 'Using a policy analyzer in the context of DFIR within GCP enables organizations
    to evaluate compliance and security across various GCP resources. Here are some
    use cases for GCP Policy Analyzer:'
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 在 GCP 的 DFIR 环境中使用策略分析器可以帮助组织评估各种 GCP 资源的合规性和安全性。以下是 GCP 策略分析器的一些使用案例：
- en: '**IAM policies**: Analyzing IAM policies includes assessing roles assigned
    to users, service accounts, and groups, as well as identifying potential misconfigurations
    or overly permissive access.'
  id: totrans-50
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**IAM 策略**：分析 IAM 策略包括评估分配给用户、服务账户和组的角色，识别潜在的配置错误或权限过度的访问。'
- en: '**Network security policies**: Review firewalls, network configurations, and
    routing policies to ensure proper network segmentation and secure connectivity
    and protection against unauthorized access.'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**网络安全策略**：审查防火墙、网络配置和路由策略，以确保适当的网络分段、可靠的连接性，并保护防止未经授权的访问。'
- en: '**Data encryption and key management policies**: Verify that data encryption
    policies are enforced for sensitive information at rest and in transit. This involves
    assessing the usage of encryption keys, key rotation practices, and compliance
    with encryption standards.'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据加密和密钥管理策略**：验证是否对静态和传输中的敏感信息实施数据加密策略。这包括评估加密密钥的使用、密钥轮换实践及加密标准的合规性。'
- en: '**Logging and monitoring policies**: Assess logging configurations and monitoring
    practices to ensure that appropriate logs are generated and retained and that
    log analysis tools are properly configured to detect security incidents and abnormal
    activities.'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**日志记录和监控策略**：评估日志配置和监控实践，确保生成并保留适当的日志，并确保日志分析工具正确配置，以检测安全事件和异常活动。'
- en: '**Service account and API access policies**: Verify the security of service
    accounts and API access configurations. This includes assessing permissions granted
    to service accounts, auditing the usage of service accounts, and ensuring proper
    management and revocation of API access credentials.'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**服务账户和 API 访问策略**：验证服务账户和 API 访问配置的安全性。这包括评估授予服务账户的权限，审计服务账户的使用，并确保适当管理和撤销
    API 访问凭证。'
- en: As you can see, GCP Policy Analyzer helps identify policy violations and non-compliant
    resources. However, it does not provide information on the activity performed
    due to policy deviations; we need Logs Explorer to identify specific actions performed.
    We will look at GCP Logs Explorer, which ingests and hosts detailed logs and has
    advanced filtering options and real-time log streaming capabilities, making it
    essential for any investigator to use.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: 如您所见，GCP 策略分析器有助于识别策略违规和不合规资源。然而，它并不提供因策略偏差而执行的活动信息；我们需要日志浏览器来识别具体的执行动作。我们将查看
    GCP 日志浏览器，它采集并托管详细日志，具有高级过滤选项和实时日志流功能，使其成为任何调查人员必备的工具。
- en: GCP Logs Explorer
  id: totrans-56
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: GCP 日志浏览器
- en: 'GCP designed **Logs Explorer** to troubleshoot performance issues with applications
    and systems by reviewing the logs. The user interface for Logs Explorer features
    a histogram that displays log rates and associated spikes. Nevertheless, where
    there are logs, you can always use them to investigate their incident. Google
    also offers the Logs Explorer API, which allows automation or query logs via a
    Python program or any other medium through an API key. The following screenshot
    is an example of GCP’s histogram on Logs Explorer that highlights activities by
    time:'
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: GCP 设计了**日志浏览器**，通过查看日志来排查应用程序和系统的性能问题。日志浏览器的用户界面包含一个直方图，显示日志速率及相关的峰值。然而，只要有日志，你总是可以利用它们来调查事件。Google
    还提供了日志浏览器 API，允许通过 Python 程序或其他方式通过 API 密钥进行自动化或查询日志。以下截图展示了 GCP 日志浏览器中的直方图，突出显示了按时间划分的活动：
- en: '![Figure 6.3 – GCP’s Logs Explorer histogram](img/00050.jpeg)'
  id: totrans-58
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.3 – GCP 日志浏览器直方图](img/00050.jpeg)'
- en: Figure 6.3 – GCP’s Logs Explorer histogram
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.3 – GCP 日志浏览器直方图
- en: However, Logs Explorer only displays logs per period; it does not quantify or
    correlate the logs against other activities within the system. You can set the
    time range for which you want to see the logs, with a default log retention of
    30 days. For this, GCP offers **Log Analytics**, a separate service that allows
    real-time analytics on the roles to allow log aggregation and quantification of
    the logs collected. This is a separate service and requires you to explicitly
    upgrade your log bucket to allow GCP to perform log analytics. GCP Log Analytics
    enables users to use **BigQuery** on the logs. BigQuery is a data warehouse where
    users can perform queries on massive datasets and perform analytics on them. GCP
    offers BigQuery as a separate service, which is not available by default. For
    example, you can run BigQuery to query your logs against known malicious domains
    from a threat intelligence source.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: 然而，日志浏览器仅按时间段显示日志；它不会量化或将日志与系统内的其他活动相关联。你可以设置你希望查看日志的时间范围，默认的日志保留期限为 30 天。为此，GCP
    提供了**日志分析**，这是一项独立的服务，允许对日志进行实时分析，以便进行日志聚合和日志量化。这是一项独立的服务，需要显式地升级你的日志存储桶，以便 GCP
    执行日志分析。GCP 日志分析使用户能够在日志上使用**BigQuery**。BigQuery 是一个数据仓库，用户可以在其上对大规模数据集进行查询并执行分析。GCP
    将 BigQuery 作为一项独立的服务提供，默认情况下不可用。例如，你可以运行 BigQuery 来查询你的日志，查找已知的恶意域名，来源于威胁情报源。
- en: 'For DFIR teams to access Logs Explorer, teams must be assigned the following
    roles:'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: 为了让 DFIR 团队访问日志浏览器，团队必须被分配以下角色：
- en: '`roles/logging.viewer`: For viewing all logs under the`_Required` and `_Default`
    buckets.'
  id: totrans-62
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roles/logging.viewer`：用于查看`_Required` 和 `_Default` 存储桶下的所有日志。'
- en: '`roles/logging.privateLogViewer`: For viewing all logs, including data access
    logs.'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roles/logging.privateLogViewer`：用于查看所有日志，包括数据访问日志。'
- en: '`roles/logging.viewAccessor`: Condition-based log view that grants access to
    user-defined logs. This role grants access to logs within a user-defined bucket
    if no condition is specified.'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`roles/logging.viewAccessor`：基于条件的日志查看权限，允许访问用户定义的日志。如果没有指定条件，则此角色允许访问用户定义的存储桶中的日志。'
- en: '`Roles/logging.fieldAccessor`: For viewing restricted fields within a log entry
    bucket. You will need to configure field-level access.'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`Roles/logging.fieldAccessor`：用于查看日志条目存储桶中的受限字段。你需要配置字段级访问。'
- en: Overview of log buckets
  id: totrans-66
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 日志存储桶概览
- en: Every log a resource generates is ingested by a Cloud Logging infrastructure
    that determines the conditions and criteria for the bucket assignments for log
    storage, known as log **sinks**. Log sinks are part of GCP’s logging infrastructure
    that determines how logs are routed to relevant log buckets. GCP also allows you
    to export these logs to a third-party log aggregation tool through a Pub/Sub topic
    that helps third-party log aggregation tools subscribe to Pub/Sub to authorize
    and import the logs.
  id: totrans-67
  prefs: []
  type: TYPE_NORMAL
  zh: 每当资源生成日志时，它都会被云日志基础设施所接收，该基础设施确定日志存储的条件和准则，称为日志**接收器**。日志接收器是 GCP 日志基础设施的一部分，负责确定如何将日志路由到相关的日志存储桶。GCP
    还允许你通过 Pub/Sub 主题将这些日志导出到第三方日志聚合工具，帮助第三方日志聚合工具订阅 Pub/Sub 来授权和导入日志。
- en: GCP offers two pre-defined log buckets, `_Required` and `_Default`. Buckets
    are independent of each other and serve as a default destination per GCP account
    for logging required logs. Users/administrators can also create their sinks/buckets,
    which are classified as user-defined buckets. As log entries are passed to logging
    infrastructure, log routing is initiated, in which, based upon the configured
    filters for inclusion and exclusion of the log entry, logs are routed to appropriate
    sinks or redirected to Pub/Sub topics for external consumption, or the logs are
    dropped altogether. Logs can also be redirected to the BigQuery dataset, allowing
    users to run Log Analytics for correlation and further analysis.
  id: totrans-68
  prefs: []
  type: TYPE_NORMAL
  zh: GCP 提供了两个预定义的日志存储桶，分别是`_Required`和`_Default`。这些存储桶相互独立，并作为每个 GCP 账户的默认日志存储目标。用户/管理员还可以创建自己的日志存储桶，这些存储桶被归类为用户定义的存储桶。当日志条目被传送到日志基础设施时，日志路由开始执行。在此过程中，根据配置的包含和排除过滤器，日志会被路由到相应的存储桶，或者被重定向到
    Pub/Sub 主题供外部使用，或者完全丢弃。日志还可以被重定向到 BigQuery 数据集，以便用户执行日志分析，进行相关性分析和进一步的分析。
- en: 'As indicated previously, cloud log entries are, by default, routed to one of
    these log buckets:'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: 如前所述，云日志条目默认会被路由到以下其中一个日志存储桶：
- en: '`_Required`: The `_Required` log buckets collect the following types of logs:'
  id: totrans-70
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_Required`：`_Required` 日志存储桶会收集以下类型的日志：'
- en: '**Admin Activity logs**: These contain log entries for API calls for reading
    resource metadata or configuration. For example, an API call to read GCE configurations
    is recorded under this sub-category.'
  id: totrans-71
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**管理员活动日志**：这些日志包含用于读取资源元数据或配置的 API 调用日志条目。例如，读取 GCE 配置的 API 调用会记录在这个子类别下。'
- en: '**System Event logs**: Any changes to a cloud resource, for example, GCE, are
    recorded under this sub-category. Users/administrators cannot turn off logging
    this type of log by creating an exclusion filter; it is always recorded.'
  id: totrans-72
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**系统事件日志**：任何对云资源的更改，例如 GCE，都会记录在此子类别下。用户/管理员不能通过创建排除过滤器关闭此类型日志的记录；它始终会被记录。'
- en: '**Access Transparency logs**: Any actions performed by Google Cloud members
    within a GCP account are recorded under this log. This allows a transparent view
    into any actions the cloud service provider performs – in this case, Google.'
  id: totrans-73
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**访问透明度日志**：任何 Google Cloud 成员在 GCP 账户内执行的操作都会记录在此日志中。这使得可以透明地查看云服务提供商执行的任何操作——在本案例中是
    Google。'
- en: '`_Default`: Any logs that do not satisfy the conditions of the `_Required`
    bucket are routed to `_Default` buckets. The following types of logs are automatically
    redirected:'
  id: totrans-74
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`_Default`：任何不符合 `_Required` 存储桶条件的日志会被路由到 `_Default` 存储桶。以下类型的日志会自动被重定向：'
- en: '**Data Access logs**: These are log entries that include what API calls were
    made to access metadata or configuration information about a GCP resource. Data
    Access logs are typically voluminous and are disabled by default. If you run BigQuery,
    then Data Access logs are enabled. Therefore, it is essential to understand the
    operating resources and whether the logs are enabled.'
  id: totrans-75
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**数据访问日志**：这些日志条目包括对 GCP 资源的元数据或配置信息的 API 调用。数据访问日志通常数量庞大，默认情况下是禁用的。如果您运行 BigQuery，则会启用数据访问日志。因此，理解操作资源和是否启用日志至关重要。'
- en: '**Policy Denied logs**: As the name suggests, log entries are categorized as
    Policy Denied logs when GCP denies access to a resource based on a defined set
    of conditions or policies. Policy Denied logs are enabled by default and cannot
    be disabled. However, you can configure an exclusion filter not to record these
    logs.'
  id: totrans-76
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**策略拒绝日志**：顾名思义，当 GCP 根据定义的条件或策略拒绝访问某个资源时，日志条目会被归类为策略拒绝日志。策略拒绝日志默认启用，且无法禁用。不过，您可以配置排除过滤器来避免记录这些日志。'
- en: '**User-defined bucket**: These are log buckets created by users to collect
    a subset of logs produced by GCP resources. You can create your user-defined bucket
    in any cloud project. When you create a log bucket, you do have to specify the
    region in which the log bucket will be stored.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '**用户定义的存储桶**：这些是用户创建的日志存储桶，用于收集 GCP 资源生成的日志子集。您可以在任何云项目中创建用户定义的存储桶。当您创建日志存储桶时，必须指定日志存储桶将存储的区域。'
- en: DFIR use cases for using Logs Explorer
  id: totrans-78
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: DFIR 使用案例，使用日志资源管理器
- en: 'The following are some of the DFIR use cases for utilizing GCP’s native Logs
    Explorer:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些 DFIR 使用案例，利用 GCP 的本地日志资源管理器：
- en: '**Incident investigation**: During an incident, Logs Explorer enables you to
    search and analyze logs across various GCP services. You can correlate events
    from different logs to reconstruct the timeline of an incident, identify the root
    cause, and determine the extent of the impact.'
  id: totrans-80
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Threat hunting**: Logs Explorer allows you to query and filter logs based
    on specific criteria or patterns related to known threats or **indicators of compromise**
    (**IOCs**). By analyzing logs from GCP services such as Cloud Storage, Cloud Functions,
    or Cloud Pub/Sub, you can proactively search for suspicious activities or abnormal
    behavior.'
  id: totrans-81
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User activity monitoring**: Logs Explorer provides visibility into user activities
    within GCP services. You can track user logins, administrative actions, API calls,
    and resource access to identify unauthorized or suspicious actions. This information
    can help detect insider threats or compromised user accounts.'
  id: totrans-82
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data leak and exposure detection**: Logs Explorer can be employed to identify
    potential data leaks or exfiltration attempts. By analyzing logs from relevant
    services, such as Cloud Storage or BigQuery, you can search for patterns indicative
    of unauthorized data access, large data transfers, or unusual data egress.'
  id: totrans-83
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Forensic analysis**: Logs Explorer can serve as a valuable source of evidence
    during forensic investigations. By querying and analyzing logs, you can reconstruct
    events, identify the actions taken by an attacker, or track the movement of an
    adversary within your GCP environment.'
  id: totrans-84
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Familiarizing with Logs Explorer
  id: totrans-85
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We’ll look at an example of querying Logs Explorer. Logs Explorer has handy
    features allowing investigators to click and filter relevant artifacts. Let’s
    familiarize ourselves with multiple areas of Logs Explorer:'
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.4 – Logs Explorer overview](img/00067.jpeg)'
  id: totrans-87
  prefs: []
  type: TYPE_IMG
- en: Figure 6.4 – Logs Explorer overview
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
- en: 'As we can see in the Logs Explorer dashboard, a few key elements will be helpful
    to security teams. We have numbered them for your easier reference:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
- en: '**Date/time filter**: This allows the teams to nail down specific events and
    activities that may have occurred within a time range.'
  id: totrans-90
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Query pane**: This text bar allows the team to search queries manually. Note
    that this search query term will automatically be updated when you click and update
    the filter.'
  id: totrans-91
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Query filter fields**: This enables the teams to filter specific GCP resources,
    objects or logs, and types of logs. Note that we have filtered records associated
    with a VM instance, with severity as an error in this example.'
  id: totrans-92
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Log fields pane**: This view gives the user a more granular view into the
    number of events per type of logs filter or severity rating. As indicated earlier,
    every record is categorized before it is routed to relevant log storage destinations.'
  id: totrans-93
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Query results pane**: This view lets the user look into the logs more thoroughly.
    Each entry allows the user to expand and view all the fields within a log entry
    and perform additional filtering based on investigative leads.'
  id: totrans-94
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
  zh: '**查询结果窗格**：此视图允许用户更深入地查看日志。每个条目都允许用户展开并查看日志条目中的所有字段，并根据调查线索进行额外的过滤。'
- en: Our next section will look into a sample investigation using Logs Explorer,
    but first, let us look at VPC Flow Logs.
  id: totrans-95
  prefs: []
  type: TYPE_NORMAL
  zh: 我们接下来的部分将通过 Logs Explorer 进行一个示例调查，但首先，让我们先看一下 VPC 流量日志。
- en: VPC Flow Logs
  id: totrans-96
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: VPC 流量日志
- en: Like AWS, VPC Flow Logs are not enabled for GCE by default. Turning on VPC Flow
    Logs is relatively easy and requires minimal effort. It’s important to note that
    VPC Flow Logs are aggregated by time in minutes and summarized in a dashboard
    that includes relevant information. VPC Flow Logs are enabled at the subnet level,
    meaning every flow log is associated with a subnet that your GCE is part of. This
    typically refers to GCP’s internal subnet architecture. Turning on VPC Flow Logs
    for a noisy server may generate many logs, ultimately impacting costs.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 与 AWS 类似，GCE 默认没有启用 VPC 流量日志。启用 VPC 流量日志相对简单，所需的工作量也很小。需要注意的是，VPC 流量日志按分钟汇总，并在一个包含相关信息的仪表盘中显示。VPC
    流量日志在子网级别启用，这意味着每个流量日志都与 GCE 所在的子网相关联。这通常指的是 GCP 的内部子网架构。为一个繁忙的服务器启用 VPC 流量日志可能会生成大量日志，从而影响成本。
- en: Enabling VPC Flow Logs
  id: totrans-98
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: 启用 VPC 流量日志
- en: To analyze traffic, you must first enable VPC Flow Logs within GCE. As GCEs
    are created by default, a regional VPC acts as the network gateway for the virtual
    server to access the internet or other GCP resources. Alternatively, if a custom
    VPC node is created, you must ensure that the VPC Flow Log option is turned on
    for the GCE to send logs to Logs Explorer. We’ll look at an example for one of
    the GCEs under network details.
  id: totrans-99
  prefs: []
  type: TYPE_NORMAL
  zh: 要分析流量，首先必须在 GCE 中启用 VPC 流量日志。由于 GCE 默认创建时，区域 VPC 作为虚拟服务器访问互联网或其他 GCP 资源的网络网关。如果创建了自定义
    VPC 节点，必须确保启用 VPC 流量日志选项，才能将日志发送到 Logs Explorer。我们将查看其中一个 GCE 的网络详情示例。
- en: 'Like AWS, VPC Flow Logs are not automatically enabled and require manual activation.
    GCP provides a range of customizable network settings, including the ability to
    create subnets, establish firewall rules, and set up VPC connections. The following
    figure displays the VPC network configured for one of the regions with a custom
    VPC network called `test-lab1`:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: 与 AWS 类似，VPC 流量日志并不会自动启用，需要手动激活。GCP 提供了一系列可定制的网络设置，包括创建子网、设定防火墙规则和设置 VPC 连接的功能。下图显示了为某个区域配置的
    VPC 网络，其中包含名为 `test-lab1` 的自定义 VPC 网络：
- en: '![Figure 6.5 – Network subnet details for a GCE](img/00085.jpeg)'
  id: totrans-101
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.5 – GCE 的网络子网详情](img/00085.jpeg)'
- en: Figure 6.5 – Network subnet details for a GCE
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.5 – GCE 的网络子网详情
- en: 'VPC Flow Logs are subnet-specific; therefore, it is essential to note that
    when enabling VPC Flow Logs, you must make changes to the VPC subnet and allow
    the flow logs to be collected. If the GCE has more than one VPC connected to the
    instance, you must verify and enable each VPC subnet to collect flow logs. In
    the following figure, we look at the sample customized VPC we created named `test-lab1`
    with a VPC subnet named `subnet-lab1`:'
  id: totrans-103
  prefs: []
  type: TYPE_NORMAL
  zh: VPC 流量日志是子网特定的；因此，启用 VPC 流量日志时，必须对 VPC 子网进行更改，并允许收集流量日志。如果 GCE 实例连接了多个 VPC，你必须逐一验证并启用每个
    VPC 子网，以便收集流量日志。在下图中，我们查看了名为 `test-lab1` 的自定义 VPC 和名为 `subnet-lab1` 的 VPC 子网：
- en: '![Figure 6.6 – VPC subnet information](img/00104.jpeg)'
  id: totrans-104
  prefs: []
  type: TYPE_IMG
  zh: '![图 6.6 – VPC 子网信息](img/00104.jpeg)'
- en: Figure 6.6 – VPC subnet information
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 图 6.6 – VPC 子网信息
- en: Click and edit the subnet name and select the option for turning **FLOW LOGS**
    on or off. Once enabled, specify the frequency of aggregation of network packets.
    Remember that VPC Flow Logs only collect header information, not full packet details.
    As a result, it is essential to weigh the aggregation frequency and identify the
    most suitable time interval for aggregation. Packet aggregation can occur at 5-second,
    30-second, 1-minute, 5-minute, 10-minute, and 15-minute intervals.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 点击并编辑子网名称，选择开启或关闭 **FLOW LOGS** 的选项。启用后，指定网络数据包的聚合频率。请记住，VPC 流量日志只收集头信息，而不包括完整的数据包详情。因此，必须权衡聚合频率，并确定最合适的聚合时间间隔。数据包聚合可以在
    5 秒、30 秒、1 分钟、5 分钟、10 分钟和 15 分钟的间隔内进行。
- en: 'Suppose GCP resources produce a lot of network traffic throughout the day;
    in that case, a higher frequency flow log aggregation can be set to allow granular
    network traffic visibility. Low-frequency flow log aggregation is suitable for
    those who do not have a lot of network traffic activity. The following figure
    demonstrates the option for setting flow logs:'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.7 – Enabling VPC Flow Logs under a VPC subnet](img/00127.jpeg)'
  id: totrans-108
  prefs: []
  type: TYPE_IMG
- en: Figure 6.7 – Enabling VPC Flow Logs under a VPC subnet
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
- en: 'While setting up the flow logs, select the sample rate of the packets that
    will be aggregated into the flow logs and reported to Logs Explorer, ideally at
    100%. This means that 100% of observed traffic is sent to Logs Explorer and not
    downsized to a specific percentage of traffic activity. The following figure demonstrates
    the subnet configuration with a sample rate of 100% of the observed network traffic
    with an aggregation interval of 5 seconds:'
  id: totrans-110
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.8 – Flow log network aggregation configuration](img/00147.jpeg)'
  id: totrans-111
  prefs: []
  type: TYPE_IMG
- en: Figure 6.8 – Flow log network aggregation configuration
  id: totrans-112
  prefs: []
  type: TYPE_NORMAL
- en: Once the VPC is configured, flow logs are automatically sent to Logs Explorer,
    where investigators can begin threat hunting. The following section will demonstrate
    an example use case for using Logs Explorer and hunting VPC Flow Logs for malicious
    activities.
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
- en: Hunting VPC Flow Logs for malicious activities
  id: totrans-114
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In this scenario, we have a GCP Cloud Storage bucket named `app-data1` with
    a few backups critical for the organization. The infrastructure setup is such
    that any internal GCP resource or application can access GCP Cloud Storage but
    is not publicly available to users or on the internet. The following figure indicates
    a list of Cloud Storage objects stored within the `app-data1` bucket:'
  id: totrans-115
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.9 – Cloud Storage view](img/00164.jpeg)'
  id: totrans-116
  prefs: []
  type: TYPE_IMG
- en: Figure 6.9 – Cloud Storage view
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
- en: We have a threat actor who is using a GCE VM, `cf1-ta-vm,` (with an internal
    IP address of `10.0.0.15` and an external IP of `34.152.3.1`) to grab these files
    from Cloud Storage and ultimately exfiltrate the data to a threat actor-controlled
    remote server at `3.98.136.11`.
  id: totrans-118
  prefs: []
  type: TYPE_NORMAL
- en: 'We will now look into using Logs Explorer to hunt for threat actor activity
    concerning this GCE resource:'
  id: totrans-119
  prefs: []
  type: TYPE_NORMAL
- en: As a first step, we begin by selecting appropriate event times within the Logs
    Explorer dashboard to capture the most relevant events.
  id: totrans-120
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'We then look for the associated log entry when this file was uploaded to the
    GCS bucket. Investigators must pay attention to the `methodName` attribute with
    the `storage.objects.create` value, indicating that the object was created within
    a specific bucket. The following figure illustrates the log record created when
    uploaded to the bucket and the full file path identified within the `resourceName`
    attribute:'
  id: totrans-121
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.10 – Log entry for object uploaded to GCS bucket](img/00183.jpeg)'
  id: totrans-122
  prefs: []
  type: TYPE_IMG
- en: Figure 6.10 – Log entry for object uploaded to GCS bucket
  id: totrans-123
  prefs: []
  type: TYPE_NORMAL
- en: 'The next step is to look for any GCE VMs accessing this resource. Using the
    log fields pane (as described in *Figure 6**.4*), we will filter the logs relevant
    to the purpose of the investigation. As logs are filtered, the `src_ip` (source
    IP), `dest_ip` (destination IP), and `bytes_sent` (bytes sent) to be visualized
    within the log entry summaries. Right-click and access these options for tagging
    fields. Notice that the following figure demonstrates tagging key fields for easier
    visualization and investigation:'
  id: totrans-124
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.11 – Logs Explorer field filters](img/00002.jpeg)'
  id: totrans-125
  prefs: []
  type: TYPE_IMG
- en: Figure 6.11 – Logs Explorer field filters
  id: totrans-126
  prefs: []
  type: TYPE_NORMAL
- en: 'Once relevant filters are applied to support the investigation, we can review
    the log entries within Logs Explorer and identify threat actor activities. From
    the Logs Explorer view, we can see that the threat actor first copied the files
    from GCS to the GCE VM with the `cf1-ta-vm` hostname and associated IP address
    (`10.0.0.15`) as the destination IP. Given that the transfer is within GCP’s infrastructure,
    the transfers occur through GCP’s backend network infrastructure. Notice the bytes
    sent size within the following snippet with the order of tags as `src_ip` followed
    by `dest_ip` and `bytes_sent`:'
  id: totrans-127
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.12 – Query result for GCS data transfer to GCE](img/00019.jpeg)'
  id: totrans-128
  prefs: []
  type: TYPE_IMG
- en: Figure 6.12 – Query result for GCS data transfer to GCE
  id: totrans-129
  prefs: []
  type: TYPE_NORMAL
- en: Putting the pieces together, we have determined that GCS storage objects were
    copied to a local GCE host. We now flip the destination IP and identify whether
    that GCE host was responsible for outbound connections. We apply filters on the
    source IP address as `10.0.0.15` and immediately see the outbound connection to
    a remote server along with the `bytes_sent` values, which we attribute to a threat
    actor-controlled server.
  id: totrans-130
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 6.13 – Logs Explorer hunting for outbound connections](img/00037.jpeg)'
  id: totrans-131
  prefs: []
  type: TYPE_IMG
- en: Figure 6.13 – Logs Explorer hunting for outbound connections
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
- en: As we can see through the sequence of steps illustrated, investigators can extract
    relevant event logs attributed to threat actor activities through interactive
    filtering capabilities and click-through filters to the log fields. There is always
    the option of extracting all the logs, performing an offline analysis, and slicing-and-dicing
    them further to determine specific actions the threat actor performs. There are
    various ways, however, for command-line entries to be extracted. Investigation
    teams can use this information to obtain a complete snapshot of the GCE. We will
    explore this mechanism in [*Chapter 10*](part0030_split_000.html#_idTextAnchor199).
  id: totrans-133
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
- en: Logs Explorer has limitations on recording commands entered within the GCE;
    any commands entered by the user or the threat actor are not recorded within Logs
    Explorer.
  id: totrans-135
  prefs: []
  type: TYPE_NORMAL
- en: Expanding on network monitoring capabilities, let us delve into GCP’s Packet
    Mirroring feature, which complements the insights provided by VPC Flow Logs.
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
- en: Packet Mirroring
  id: totrans-137
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GCP’s Packet Mirroring feature allows security teams to collect network packets
    from VMs and identify security threats or activities associated with the VMs.
    GCP’s Packet Mirroring only mirrors traffic between VMs and external interfaces
    and does not mirror traffic between cluster nodes such as GKE. We will learn more
    about containers, including **Docker** and **Kubernetes**, in [*Chapter 11*](part0031_split_000.html#_idTextAnchor217).
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
- en: To mirror packets, ensure the principals are attached with the `compute.packetMirrorUser`
    and `compute.packetMirroringAdmin` roles.
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
- en: An internal load balancer must be deployed with **network passthrough** capabilities
    that pass the traffic to the **collector** instances to enable packet mirroring.
    The load balancer must be pointed to a **managed instance group** in the backend
    with pre-configured instance templates, allowing GCP to create collector instances
    automatically. The collector instance can be a VM with tools for capturing and
    receiving network packets via the internal load balancer.
  id: totrans-140
  prefs: []
  type: TYPE_NORMAL
- en: When setting up an internal load balancer, ensure that it is created within
    the same region as the instance being mirrored, `,` and **backend subsetting**
    is not enabled. Also, ensure that packet forwarding rules are created on the load
    balancers to forward all the mirrored packets while configuring the load balancer.
    This setting cannot be changed once configured.
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
- en: When creating an internal load balancer, a managed instance group must be created
    and assigned VMs within that group. GCP will then determine this VM as part of
    the collector instance for packet mirroring and capture.
  id: totrans-142
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure demonstrates a simple configuration for an internal network
    load balancer. We created a sample load balancer, `lb2`, and configured it on
    `subnet-lab1` under the `test-lab1` VPC. We also created a managed instance group,
    `instance-group1`, that automatically makes the collector VMs for receiving network
    packets:'
  id: totrans-143
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.14 – Internal load balancer configuration](img/00054.jpeg)'
  id: totrans-144
  prefs: []
  type: TYPE_IMG
- en: Figure 6.14 – Internal load balancer configuration
  id: totrans-145
  prefs: []
  type: TYPE_NORMAL
- en: Once a load balancer is created, configure the **packet mirroring policy** and
    specify the target VPC and subnet for the source of packet capture. Alternatively,
    select a suspect GCE from where the network packets will be collected. Note that
    the target VPC and collector instance must be created within the same network
    region for successfully mirroring packets.
  id: totrans-146
  prefs: []
  type: TYPE_NORMAL
- en: In the following screenshot, we configure the packet mirroring policy (`pkt-mirror1`)
    that defines the collector VM or VPC network (in this case, `test-lab1`) and the
    load balancers (specified in the form of a forwarding rule, `lb2-forwarding-rule`)
    the policy will be attached to. **Policy enforcement** must be turned on to enable
    packet mirroring.
  id: totrans-147
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.15 – Packet mirroring policy](img/00072.jpeg)'
  id: totrans-148
  prefs: []
  type: TYPE_IMG
- en: Figure 6.15 – Packet mirroring policy
  id: totrans-149
  prefs: []
  type: TYPE_NORMAL
- en: The packet mirroring policy is also configured to forward and mirror packets
    associated with the `test-lab1` VPC, with the suspect VM attached to `subnet-lab1`.
  id: totrans-150
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, in the collector VM, we begin collecting network packets by running `tcpdump`.
    Note the IP address of the suspect VM before initiating network packet capture:'
  id: totrans-151
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  id: totrans-152
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'The following parameters are supplied when running `tcpdump`:'
  id: totrans-153
  prefs: []
  type: TYPE_NORMAL
- en: '`-i INTERFACE_NAME`: Collector instance network interface name that will listen
    to network packets (`ens33`, `enp03`, etc.)'
  id: totrans-154
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`-f "IP_ADDRESS"`: Filter flag to apply a packet capture based on a specific
    IP address of the suspect VM'
  id: totrans-155
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Outputs from `tcpdump` can also be written to a file. In the example, we dump
    the packets using the `-w` flag and provide the file location.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
- en: Investigators prefer to capture full packets recording all threat actor activities
    across multiple VMs via the VPC network before focusing on specific GCP services
    for investigation.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the packets are written to the disk, the following GCP command-line options
    can be used to access GCP storage and upload artifacts:'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  id: totrans-159
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: It is assumed that the investigation team will have its own identities and associated
    roles attached to those identities (principals). First, you must log in by entering
    the preceding command and following the on-screen instructions.
  id: totrans-160
  prefs: []
  type: TYPE_NORMAL
- en: 'Once completed, you can access Google Cloud Storage and copy the artifacts
    using the following command:'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  id: totrans-162
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'The following are the key parameters that are required to upload artifacts
    successfully:'
  id: totrans-163
  prefs: []
  type: TYPE_NORMAL
- en: '`SOURCE_FILE`: The source artifacts that the team would like to investigate'
  id: totrans-164
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`BUCKET_NAME`: The Google Cloud Storage bucket name'
  id: totrans-165
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`DESTINATION_PATH`: The destination folder path within the storage bucket'
  id: totrans-166
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we can see, the VPC Flow Logs offered by GCP present substantial data related
    to network traffic patterns, which can significantly enhance security and troubleshooting
    efforts. Packet mirroring amplifies the potential for monitoring and analyzing
    network traffic but also enables the identification of potential security threats
    in real time.
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
- en: The following section will examine more granular GCE logs, offering profound
    insights into activities and enabling correlation capabilities via Logs Explorer.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
- en: Compute Engine logs
  id: totrans-169
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: GCE is a service offered by GCP that allows users to create VMs within GCP’s
    infrastructure. These VMs can be hosted across any part of the world where GCP
    operates. It provides flexibility and scalability options, making various preconfigured
    VM instances available. It can create on demand or resize a VM based on requirements.
    Users can create a VM instance or a group of VMs through **GCE Instance Group
    Manager**, which manages the deployment and configuration of VMs.
  id: totrans-170
  prefs: []
  type: TYPE_NORMAL
- en: GCP’s logging platform
  id: totrans-171
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'GCP’s Cloud Logging platform automatically collects and aggregates logs from
    various GCP resources via Logs Explorer. It offers a single-pane view of all the
    logs and filters, allowing investigators to hunt for specific alerts or threats
    and use them for monitoring. Some of the types of logs it collects are as follows:'
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
- en: '**Platform logs**: Generated through GCP’s services, these logs are used for
    debugging and troubleshooting. Examples of platform logs include VPC Flow Logs.'
  id: totrans-173
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Component logs**: Similar to platform logs, these are generated by GCP’s
    software-based components, such as Kubernetes clusters. GKE logs are classified
    as component logs.'
  id: totrans-174
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Security logs**: Two forms of security logs are collected within GCP; the
    first is **Cloud Audit logs**, which provide administrative information and activities
    performed by the administrator, supporting cloud audit and compliance requirements.
    Secondly, **Access Transparency logs** log any actions performed by Google’s staff
    directly on a Google Cloud tenant to allow for transparency and compliance.'
  id: totrans-175
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**User-written logs**: As the name suggests, they log any custom application
    logging, which can be sent to Cloud Logging through the OpsAgent, Logging Agent,
    Cloud Logging API, and other libraries. We will learn about the OpsAgent in a
    later part of this chapter.'
  id: totrans-176
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Multi-cloud and hybrid logs**: These include logs from other cloud providers
    such as Microsoft Azure and on-premises infrastructure. They can be collected
    alongside GCP logs; however, there may be cost implications based on the number
    of logs.'
  id: totrans-177
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GCP’s default logging
  id: totrans-178
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Every VM within GCP is preconfigured to send default logs to the **Cloud Logging
    platform**. These include CPU utilization, memory utilization, network bandwidth
    consumption, and so on. While the telemetry collected is rudimentary, it is vital
    in determining whether any abnormal activities are detected within the monitoring
    console for deep-dive investigation.
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
- en: Specifically speaking of logging agents, Google primarily relies on the **OpsAgent**,
    legacy agents, and custom logging packages.
  id: totrans-180
  prefs: []
  type: TYPE_NORMAL
- en: OpsAgent
  id: totrans-181
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: GCP uses OpsAgent as the primary source for monitoring and collecting telemetric
    data from Windows and Linux-based systems. The OpsAgent is based on FluentBit,
    a third-party but lightweight logging and telemetry data provider that allows
    metrics collection in the **Prometheus** format. FluentBit (**fluentd**) handles
    automatic tagging and metrics parsing before sending it to the logging platform.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
- en: Google also relies on **OpenTelemetry Collector**, another open source service,
    for specific metrics.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
- en: GCP users can also configure their fluentd configuration for specific application-level
    logging that will be automatically sent to Google’s Cloud Logging platform.
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
- en: By using the OpsAgent and deploying custom configuration files (fluentd configurations),
    investigators can collect metrics and logs from various third-party applications
    such as Microsoft Active Directory, Apache Tomcat, **Internet Information Services**
    (**IIS**), MySQL, MariaDB, and many more. The OpsAgent also allows log collections
    from GKE.
  id: totrans-185
  prefs: []
  type: TYPE_NORMAL
- en: 'The following are some of the log sources that the OpsAgent collects by default:'
  id: totrans-186
  prefs: []
  type: TYPE_NORMAL
- en: '`/var/log/syslog` and `/var/log/messages` in Linux'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Journald** daemon and **Systemd** logs'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TCP port**: Listen to a TCP port and collect logs'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Windows event logs**: Logs from Windows operating systems'
  id: totrans-190
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fluentd Forward**: Logs collected via Fluentd Forward over TCP'
  id: totrans-191
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following metrics are reported by the OpsAgent by default without any additional
    configuration on the host VM. These metrics help identify deviations from the
    baseline and, if a breach occurs, allow the security team to respond immediately:'
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: '**CPU metrics**: CPU states (idle, interrupt, system, and user), CPU load,
    CPU usage time, and CPU utilization'
  id: totrans-193
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Disk metrics**: Disk used (bytes), disk I/O time, disk operations, disk pending
    operations, disk utilization (percent), disk bytes read, and disk bytes written'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**IIS metrics (Windows)**: IIS open connections, IIS transferred bytes, IIS
    connections, and IIS requests'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network interface metrics**: Network errors, packets, and traffic (bytes)'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Memory metrics**: Memory usage, memory states (buffered, cached, free, slab,
    and used), and memory utilization (percent)'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**MSSQL metrics**: SQL server open connections, SQL server transaction rate,
    and SQL server write transaction rate'
  id: totrans-198
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Swap metrics (Linux only)**: Swap usage, swap I/O operations, and swap utilization
    (percent)'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network metrics**: TCP connections'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Process metrics**: Process count by states (running, sleeping, and zombie),
    process CPU time, process disk read I/O, process disk writes I/O, fork count,
    process resident memory (allocations), and process virtual memory (usage)'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Agent self metrics**: Agent API request count, agent log entry count, agent
    memory usage, agent metric point count, agent enabled receiver count, and agent
    uptime'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Legacy logging agent
  id: totrans-203
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Google has currently deprecated the legacy logging agent. However, there are
    still VMs that require legacy agents, so they continue to be supported by Google.
    While fluentd is still being used here, the application utilizes older methodologies
    for collecting the metrics and routing them to Logs Explorer.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: Logging Dataflow pipelines
  id: totrans-205
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Dataflow pipelines provide a stream of data or batch processing capabilities
    at scale. GCP’s Dataflow pipeline is based on **Apache Beam**. Logs can be streamed
    at variable volumes in near real time using Dataflow applications.
  id: totrans-206
  prefs: []
  type: TYPE_NORMAL
- en: Any actions performed on GCP Dataflow are recorded by default in Logs Explorer.
    Through Logs Explorer, investigators can detect any changes to the Dataflow parameters
    or whether unauthorized users altered the pipeline.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: Note that a Docker instance forms the base of any Dataflow pipeline’s operations.
    Therefore, investigators must also investigate the logs emitted by the GKE cluster
    and GCE Instance Group Manager. GCP relies on Instance Group Manager to create
    multiple managed VMs that run the containers (GKE) to handle instance resourcing
    and deploying VMs automatically.
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure outlines some sample resources required for successful
    Dataflow pipeline execution. Like **Syslog**, Dataflow events are tagged with
    a severity rating; it also generates the exact name of the job that emitted the
    log entry. Using the filters within Logs Explorer, relevant logs can be specifically
    targeted and investigated in a Dataflow job or pipeline:'
  id: totrans-209
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.16 – Resource types for Dataflow pipeline execution](img/00092.jpeg)'
  id: totrans-210
  prefs: []
  type: TYPE_IMG
- en: Figure 6.16 – Resource types for Dataflow pipeline execution
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  id: totrans-212
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: '![Figure 6.17 – Log streams emitted by GCP Dataflow](img/00112.jpeg)'
  id: totrans-213
  prefs: []
  type: TYPE_IMG
- en: Figure 6.17 – Log streams emitted by GCP Dataflow
  id: totrans-214
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, monitoring and investigating Dataflow logs is no different from
    analyzing any other activity logs emitted by relevant GCP resources. It is essential
    to understand that when a resource is accessed, GCP in the backend may access
    other associated resources or dependencies to deliver the service, impacting the
    number of logs or the logs emitted by relevant dependent services.
  id: totrans-215
  prefs: []
  type: TYPE_NORMAL
- en: GCP storage logs
  id: totrans-216
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Like AWS’s S3 buckets, GCP Storage also refers to storage containers as buckets.
    Each bucket can contain any file format, referred to as an **object**. Principals
    can be assigned granular permissions and access to each bucket or object. Storage
    buckets can also be made publicly accessible on the internet, depending on the
    use case. Storage metadata is recorded in the key/value pair format at the bucket
    level to manage the object life cycle. Values assigned to keys can be a bucket
    name string or an array of object life cycle management configurations.
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: Once a storage bucket is created, you cannot change the bucket name, the location
    (where the bucket is hosted), the project associated with the storage bucket,
    or the metadata generation number, uniquely identifying the bucket state.
  id: totrans-218
  prefs: []
  type: TYPE_NORMAL
- en: Storage permissions
  id: totrans-219
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Similar to IAM permissions, specific permissions are required for accessing
    objects by a resource or a principal. In GCP’s IAM realm, permissions are assigned
    to roles and roles are attached to principals.
  id: totrans-220
  prefs: []
  type: TYPE_NORMAL
- en: 'The following table outlines the list of permissions required for accessing
    storage objects:'
  id: totrans-221
  prefs: []
  type: TYPE_NORMAL
- en: '| **Permission name** | **Description** |'
  id: totrans-222
  prefs: []
  type: TYPE_TB
- en: '| `storage.buckets.create` | Creates a storage bucket within a project |'
  id: totrans-223
  prefs: []
  type: TYPE_TB
- en: '| `storage.buckets.delete` | Deletes a storage bucket from a project |'
  id: totrans-224
  prefs: []
  type: TYPE_TB
- en: '| `storage.buckets.get` | Reads metadata associated with the bucket, including
    bucket configurations |'
  id: totrans-225
  prefs: []
  type: TYPE_TB
- en: '| `storage.buckets.list` | Lists buckets in a project |'
  id: totrans-226
  prefs: []
  type: TYPE_TB
- en: '| `storage.buckets.update` | Updates metadata associated with the bucket and
    configuration of the bucket |'
  id: totrans-227
  prefs: []
  type: TYPE_TB
- en: '| `storage.buckets.getObjectInsights` | Reads metadata associated with the
    object within the bucket |'
  id: totrans-228
  prefs: []
  type: TYPE_TB
- en: Table 6.1 – Minimum IAM permissions required to create and manage buckets
  id: totrans-229
  prefs: []
  type: TYPE_NORMAL
- en: Storage object logging
  id: totrans-230
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Like all the resources within GCP, activities on storage buckets emit logs and
    are recorded within Logs Explorer; storage logs or access logs associated with
    the objects are also recorded within Logs Explorer. Investigators should, therefore,
    consider reviewing storage-related logs to determine evidence of data exfiltration
    and any threats against GCP’s storage buckets.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: Investigating GCP Cloud storage logs
  id: totrans-232
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: When setting up GCP Cloud Storage, ensure that it has appropriate permissions
    set. This also includes public access prevention policies that must be turned
    on or off, depending on the use case.
  id: totrans-233
  prefs: []
  type: TYPE_NORMAL
- en: 'The following example will examine the logs to determine privilege escalation
    attempts to GCP’s Cloud Storage. For this purpose, we created a temporary storage
    folder, `test_cf1_test1`, and set it for non-public access to the folder; we have
    not enabled any fine-grained access control for this purpose:'
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.18 – GCP Cloud Storage configuration summary example](img/00027.jpeg)'
  id: totrans-235
  prefs: []
  type: TYPE_IMG
- en: Figure 6.18 – GCP Cloud Storage configuration summary example
  id: totrans-236
  prefs: []
  type: TYPE_NORMAL
- en: 'We will examine the storage logs within Logs Explorer. We evaluate the IAM
    policies configured using GCP’s `gsutil iam get gs://test_cf1_test1` command and
    requesting IAM policies configured for this bucket. This is equivalent to making
    a `GET` request to `https://storage.googleapis.com/storage/v1/b/<bucket>/iam`,
    but as an authenticated user:'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.19 – IAM policies on a Cloud Storage folder example](img/00170.jpeg)'
  id: totrans-238
  prefs: []
  type: TYPE_IMG
- en: Figure 6.19 – IAM policies on a Cloud Storage folder example
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: 'Note that the following primary roles are configured for the storage folder.
    GCP automatically applies legacy roles to buckets when owners create a **uniform
    bucket-level access** (meaning all objects within the bucket have similar access
    permissions enabled):'
  id: totrans-240
  prefs: []
  type: TYPE_NORMAL
- en: '`roles/storage.legacyBucketOwner`: Principals with `roles/editor` or `roles/owner`
    are granted this access'
  id: totrans-241
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/storage.legacyBucketReader`: Principals with `roles/viewer` are granted
    this access'
  id: totrans-242
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/storage.legacyObjectOwner`: Principals with `roles/editor` or `roles/owner`
    are granted this access'
  id: totrans-243
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/storage.legacyObjectReader`: Principals with `roles/viewer` are granted
    this access'
  id: totrans-244
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now we know that access to this folder is only limited to those users or principals
    with `roles/editor` access or `roles/owner` access. In summary, any other principals
    or general public access are not allowed for this folder.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: We will review Logs Explorer to determine the access requests made when an authenticated
    user or principal attempts to access the bucket using non-standard methods, such
    as accessing Cloud Storage buckets through a Python program.
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: 'We will look at a log entry for an authenticated user attempting to access
    the bucket. Within the `authorizationInfo` section, we look specifically at the
    highlighted areas: `CallerIP`, which refers to the user’s IP address that is trying
    to access the bucket, and `callerSuppliedUserAgent` (**user-agent** string), which
    is reflective of the browser and operating system variant that the user is using
    to attempt to access the storage. Finally, we also look at what resource is being
    requested along with the assigned permission tagged to this bucket and object,
    and whether IAM granted this access:'
  id: totrans-247
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  id: totrans-248
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'Let us look at a situation where an unauthenticated user tries to gain access
    to GCP’s Cloud Storage buckets and objects outside of GCP’s Cloud console. Similar
    to the previous example, we’ll look at a similar form of log entry and look for
    the `authorizationInfo` section. The request is for accessing the `test_cf1_test1`
    bucket. In this case, note the user-agent string and IP address. Given that the
    user attempted to authenticate as the owner/principal, and since the access attempt
    was via a Python command-line application instead of a browser accessing the bucket,
    this permission was denied as there is no public access to the folder outside
    of the GCP console, GCP CLI, or GCP API:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  id: totrans-250
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: 'The following figure outlines the series of attempts while allowing access
    to GCP API tools:'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.20 – Multiple denied access attempts to non-GCP applications while
    only allowing API access](img/00068.jpeg)'
  id: totrans-252
  prefs: []
  type: TYPE_IMG
- en: Figure 6.20 – Multiple denied access attempts to non-GCP applications while
    only allowing API access
  id: totrans-253
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, Logs Explorer forms the basis of most of the investigative insights
    into activities performed by the user or external resources.
  id: totrans-254
  prefs: []
  type: TYPE_NORMAL
- en: Next, we will look into some of GCP’s dashboards that offer insight into the
    security status of the resources configured within GCP.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: Cloud Security Command Center (Cloud SCC)
  id: totrans-256
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Cloud SCC is like a dashboard for notifying organizations and security teams
    about possible threats or vulnerabilities. Cloud SCC is only available when a
    GCP account is set up as an organization. Individual GCP users do not have access
    to Cloud SCC. When an anomaly is identified, it creates a report of a particular
    threat or misconfiguration in GCP’s realm, called a **finding**. Cloud SCC provides
    a consolidated view of all the findings and anomalies detected within a cloud
    service, such as a GCE.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: Note that there are two activation levels; by default, organizations, when they
    sign up, are assigned the **Standard service tier**, which has limited functionality
    and includes looking at the general security health of GCEs and their configurations.
    It also includes features such as error reporting, continuous exports to Pub/Sub,
    and access to other integration points, including Cloud Data Loss Prevention,
    Cloud Armor, and so on.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: 'Google also offers a **Premium service tier**, which comes at a price that
    includes additional capabilities, as outlined in the following screenshot, such
    as **Event Threat Detection**, **Web Security Scanner**, **Container Threat Detection**,
    **Virtual Machine Threat Detection**, **Security Health Analytics**, and **Rapid**
    **vulnerability detection**:'
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.21 – Cloud SCC Premium subscriptions](img/00113.jpeg)'
  id: totrans-260
  prefs: []
  type: TYPE_IMG
- en: Figure 6.21 – Cloud SCC Premium subscriptions
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: The following sections will examine some of the Cloud SCC capabilities in more
    depth.
  id: totrans-262
  prefs: []
  type: TYPE_NORMAL
- en: IAM roles
  id: totrans-263
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Now that we know GCP uses IAM roles to assign access to principals, it is vital
    to understand the various access privileges required for teams to have access
    to Cloud SCC dashboards and other details.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: 'From a DFIR perspective, the following roles are required for accessing the
    Cloud SCC console:'
  id: totrans-265
  prefs: []
  type: TYPE_NORMAL
- en: '`roles/resourcemanager.organizationAdmin`: Provides admin access at the organization
    level. An organization can have multiple projects.'
  id: totrans-266
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/securitycenter.admin`: Administrative or superuser access to Cloud SCC
    and other resources within Cloud SCC. It provides access to project-level detections.'
  id: totrans-267
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/securitycenter.adminViewer`: Admin read-only access to the security
    center. Users can view scan results and see threat detections. No changes are
    allowed. It provides access to project-level detections.'
  id: totrans-268
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/securitycenter.findingsViewer`: Provides restrictive access to view
    only the findings generated within Cloud SCC for a specific project.'
  id: totrans-269
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`roles/cloudsecurityscanner.editor`: Provides project-level access, with administrative
    controls (read-write controls) to run cloud web scanning. Access to all the resources
    within the web scanner module is provided.'
  id: totrans-270
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Threats and Findings dashboards
  id: totrans-271
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The GCP **Threats** and **Findings** dashboards provide visibility into potential
    threats and security incidents, allowing organizations to manage security threats
    and findings within their GCP environment. They are a central hub for monitoring
    and analyzing security events and proactively detecting and responding to threats
    by aggregating data from various services and tools within GCP.
  id: totrans-272
  prefs: []
  type: TYPE_NORMAL
- en: 'The **Threats** dashboard displays threats per VM instance and threats identified
    within the overall GCP environment. This includes any potential misconfigurations
    and features that, as a result, introduced a vulnerability within the GCP environment.
    The following figure is a sample dashboard with identified threats:'
  id: totrans-273
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.22 – Threats dashboard](img/00135.jpeg)'
  id: totrans-274
  prefs: []
  type: TYPE_IMG
- en: Figure 6.22 – Threats dashboard
  id: totrans-275
  prefs: []
  type: TYPE_NORMAL
- en: 'Details of identified threats are documented on the **Findings** page. Findings
    provide detailed information on the threat, severity, event detection time (event
    time), event reporting time (create time), GCP resource, GCP project, and resource
    type. Findings also allow investigators to utilize filters to investigate the
    identified findings further and gain an understanding of the threat. The following
    is the drill-down screenshot of an identified threat within the **Findings** section:'
  id: totrans-276
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.23 – Findings dashboard](img/00086.jpeg)'
  id: totrans-277
  prefs: []
  type: TYPE_IMG
- en: Figure 6.23 – Findings dashboard
  id: totrans-278
  prefs: []
  type: TYPE_NORMAL
- en: Note that findings are classified into **Threat**, **Misconfiguration**, or
    **Vulnerability**. By default, if investigators navigate to the **Findings** page,
    it will display all the findings that are not muted and have been active for the
    previous seven days.
  id: totrans-279
  prefs: []
  type: TYPE_NORMAL
- en: 'On the **Findings** page, within the **Quick filters** pane, investigators
    can quickly filter down the types of findings that they are interested in and
    are relevant to the investigation:'
  id: totrans-280
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.24 – Findings quick filters](img/00105.jpeg)'
  id: totrans-281
  prefs: []
  type: TYPE_IMG
- en: Figure 6.24 – Findings quick filters
  id: totrans-282
  prefs: []
  type: TYPE_NORMAL
- en: 'Once filters are applied, the findings are available for review and investigators
    can determine more information. In the following screenshot, we have filtered
    down **Open RDP port** and identified two findings concerning the exposed RDP
    port. GCP has classified this detection as a high-severity finding:'
  id: totrans-283
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.25 – Findings based on quick filters](img/00196.jpeg)'
  id: totrans-284
  prefs: []
  type: TYPE_IMG
- en: Figure 6.25 – Findings based on quick filters
  id: totrans-285
  prefs: []
  type: TYPE_NORMAL
- en: Each finding provides a link to get more details about the results that indicate
    what was detected, including **Artificial Intelligence (AI) Generated Summary**,
    **Description**, **Affected Resource**, **Security Marks**, suggested next steps,
    and related links to various standards and detection services. It also allows
    investigators to mute this detection to ensure that findings do not report on
    similar exposures.
  id: totrans-286
  prefs: []
  type: TYPE_NORMAL
- en: As we delve into the intricacies of Cloud SCC Assets, we will explore how this
    feature empowers investigators and security teams with a detailed inventory of
    GCP resources, identifying vulnerabilities, misconfigurations, and potential threats.
    This visibility lays the foundation for practical risk assessment and proactive
    security measures, ultimately fostering a more resilient and secure cloud infrastructure.
    Let us now navigate the key functionalities that Cloud SCC Assets brings to the
    cloud security journey.
  id: totrans-287
  prefs: []
  type: TYPE_NORMAL
- en: Cloud SCC Assets
  id: totrans-288
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Investigators always appreciate seeing all the assets and knowing what is configured
    within an environment. Similarly, GCP’s Cloud SCC offers something called Cloud
    SCC Assets that provides a high-level view of all the categories of assets, their
    details, and the configurational information set for these assets. Getting the
    lay of the land is vital when investigating a complex case. Investigators can
    use this asset management page to obtain relevant information and potentially
    identify the next steps in their investigation.
  id: totrans-289
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure outlines the asset summary configured within our sample
    GCP instance and the relevant resource types:'
  id: totrans-290
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.26 – Cloud SCC Assets view](img/00184.jpeg)'
  id: totrans-291
  prefs: []
  type: TYPE_IMG
- en: Figure 6.26 – Cloud SCC Assets view
  id: totrans-292
  prefs: []
  type: TYPE_NORMAL
- en: 'Only assets associated with the current project or resources are visible in
    the asset view. More information is presented within each asset under the `resourceProperties.name`
    field. For example, we can select the `compute`. `Instance` resource type in the
    filters, then click on the first item. The following figure summarizes what kind
    of resource is configured and its various configurational elements (or attributes).
    It also presents resource properties in the JSON format and includes any additional
    metadata for this asset. Finally, this page also provides any findings about this
    particular asset:'
  id: totrans-293
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.27 – Asset detail view](img/00121.jpeg)'
  id: totrans-294
  prefs: []
  type: TYPE_IMG
- en: Figure 6.27 – Asset detail view
  id: totrans-295
  prefs: []
  type: TYPE_NORMAL
- en: Configurational vulnerabilities
  id: totrans-296
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**Platform configurational vulnerabilities** is a GCP feature that natively
    scans the configurations of various GCP services and GCP VMs and identifies vulnerabilities
    within the infrastructure. Although very simplistic, this dashboard provides detailed
    findings for each configurational vulnerability. GCP deems something a vulnerability
    or a threat if it sees a deviation from acceptable standards. Since each organization
    differs, some variations would be permissible for the business.'
  id: totrans-297
  prefs: []
  type: TYPE_NORMAL
- en: From an investigation point of view, the vulnerability findings feature offers
    historical insights into when GCP observed the vulnerability or the deviation,
    the severity of the associated findings, and the number of services or endpoints
    impacted, and provides a mapping to various commonly accepted security standards.
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: Note
  id: totrans-299
  prefs: []
  type: TYPE_NORMAL
- en: GCP’s vulnerability findings can be used to determine potential root causes
    and, through digital forensics, confirm whether the threat actor exploited any
    of these vulnerabilities.
  id: totrans-300
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure illustrates the list of vulnerabilities, including third-party
    application vulnerabilities. Each finding will also provide detailed descriptions
    of where this deviation was identified:'
  id: totrans-301
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.28 – List of vulnerabilities](img/00106.jpeg)'
  id: totrans-302
  prefs: []
  type: TYPE_IMG
- en: Figure 6.28 – List of vulnerabilities
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: From a digital forensics standpoint, configurational vulnerabilities can provide
    investigators with clues about potential gaps within an infrastructure and indicate
    whether any of the gaps could have been the root cause of an incident.
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we venture into the command-line environment, which allows
    access to various GCP resources. GCP Cloud Shell is helpful for incident responders
    who are very comfortable with command-line tools. It can be useful for quick access
    and investigative insights into a GCP resource.
  id: totrans-305
  prefs: []
  type: TYPE_NORMAL
- en: GCP Cloud Shell
  id: totrans-306
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '**Cloud Shell** is GCP’s native command-line tool that allows access to various
    GCP services over a command-line interface. GCP Cloud Shell, a browser-based shell
    environment, can be used to investigate and identify potential security incidents
    for threat-hunting activities. Investigators can also use Cloud Shell to turn
    a service such as packet mirroring on or off. It also has an interactive code
    editor for users or investigators who want to import custom code, enabling Cloud
    Shell to perform certain activities. GCP’s Cloud Shell can also be accessed locally
    through the Google Cloud SDK or an in-browser session.'
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: GCP offers essential command-line tools, specifically `gcloud` and `gsutil`.
    `gcloud` provides access to general GCP services such as `gsutil` is a specific
    utility tool to access storage buckets.
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: 'Through `gcloud`, investigators can access Logs Explorer and collect all the
    associated logs for offline analysis. Investigators can also list the services
    a user has subscribed to or all VPC policies:'
  id: totrans-309
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 6.29 – GCP Cloud Shell](img/00080.jpeg)'
  id: totrans-310
  prefs: []
  type: TYPE_IMG
- en: Figure 6.29 – GCP Cloud Shell
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: GCP Cloud Shell offers investigators a browser-based command-line interface
    for investigating incidents. It allows access to GCP resources for tasks such
    as log analysis, memory examination, and malware assessment. Cloud Shell aids
    in artifact preservation, collaboration, and automation, enabling efficient, scalable,
    and secure digital forensics and incident response operations.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-313
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: After diving deep into GCP, we know the GCP infrastructure is very similar to
    other popular cloud providers. We highlighted the importance of understanding
    the varying verbosity of logs emitted by GCP services, emphasizing the need for
    investigators to seek corroborating evidence to confirm events. GCP’s centralized
    logging system, which flows into Logs Explorer, is a powerful tool for administrators
    to troubleshoot routine issues and for investigators to delve into event correlations
    across the GCP ecosystem.
  id: totrans-314
  prefs: []
  type: TYPE_NORMAL
- en: We learned about similarities between how GCP organizes its buckets and objects,
    which is conceptually similar to AWS. Cloud SCC offers a dashboard or a security
    scorecard on infrastructure for administrators. At the same time, for investigators,
    it is a goldmine of findings, with detailed information on where to look when
    kicking off an investigation. Cloud SCC offers unique insights into vulnerabilities
    without deploying specific agents within the hosts. Finally, we looked at Cloud
    Shell, which provides more freedom for investigators to perform investigative
    activities from the command line.
  id: totrans-315
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will dive deep into email workspaces, especially Microsoft
    365 and Google Workspaces, and identify methodologies for investigating cloud
    email workspaces.
  id: totrans-316
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-317
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Google Access Transparency policy: [https://cloud.google.com/privacy](https://cloud.google.com/privacy)'
  id: totrans-318
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cloud Audit Logs overview: [https://cloud.google.com/logging/docs/audit#system-event](https://cloud.google.com/logging/docs/audit#system-event)'
  id: totrans-319
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Enabling logging: [https://cloud.google.com/logging/docs/audit/configure-data-access](https://cloud.google.com/logging/docs/audit/configure-data-access)'
  id: totrans-320
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Cloud SCC IAM, access control with IAM: [https://cloud.google.com/security-command-center/docs/access-control](https://cloud.google.com/security-command-center/docs/access-control)'
  id: totrans-321
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'IAM for organization-level activations: [https://cloud.google.com/security-command-center/docs/access-control-org](https://cloud.google.com/security-command-center/docs/access-control-org)'
  id: totrans-322
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Exporting Security Command Center data: [https://cloud.google.com/security-command-center/docs/how-to-export-data?authuser=2](https://cloud.google.com/security-command-center/docs/how-to-export-data?authuser=2)'
  id: totrans-323
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Investigating and responding to threats: [https://cloud.google.com/security-command-center/docs/how-to-investigate-threats#defense_evasion_breakglass_workload_deployment](https://cloud.google.com/security-command-center/docs/how-to-investigate-threats#defense_evasion_breakglass_workload_deployment)'
  id: totrans-324
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Using event threat detection: [https://cloud.google.com/security-command-center/docs/how-to-use-event-threat-detection](https://cloud.google.com/security-command-center/docs/how-to-use-event-threat-detection)'
  id: totrans-325
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'How Security Command Center helps you detect and stop cyber attacks: [https://cloud.google.com/security-command-center/docs/concepts-how-scc-determines-env-under-attack](https://cloud.google.com/security-command-center/docs/concepts-how-scc-determines-env-under-attack)'
  id: totrans-326
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Compute Engine IAM roles and permissions: [https://cloud.google.com/compute/docs/access/iam](https://cloud.google.com/compute/docs/access/iam)'
  id: totrans-327
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'FluentBit: [https://github.com/fluent/fluent-bit](https://github.com/fluent/fluent-bit)'
  id: totrans-328
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Install Google CLI: [https://cloud.google.com/sdk/docs/install#linux](https://cloud.google.com/sdk/docs/install#linux)'
  id: totrans-329
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Live forensics to analyze a cyber-attack: [https://cloud.google.com/blog/products/identity-security/how-to-use-live-forensics-to-analyze-a-cyberattack](https://cloud.google.com/blog/products/identity-security/how-to-use-live-forensics-to-analyze-a-cyberattack)'
  id: totrans-330
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
