- en: '5'
  id: totrans-0
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: '5'
- en: Computer Investigation Process
  id: totrans-1
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 计算机调查流程
- en: Being a digital forensic examiner requires you to have a plan to conduct the
    investigation. For instance, there is the kitchen sink approach – where the person
    requesting the examination states, *I want it all*. However, this is not practical
    when the smallest drive might contain hundreds of thousands of pages or events.
    So while the kitchen sink approach is a plan, it may not be the most efficient.
  id: totrans-2
  prefs: []
  type: TYPE_NORMAL
  zh: 成为数字取证检查员需要你有一个调查计划。例如，有一种所谓的“厨房水槽方法”——即请求检查的人说，*我要所有的信息*。然而，这种方法并不实际，因为最小的驱动器可能包含数十万页或事件。因此，尽管“厨房水槽方法”是一个计划，但它可能不是最有效的。
- en: In reality, your search method will depend on the crime you are investigating
    and whether there are limitations to the scope of the search. For example, in
    some investigations, the judicial authority may restrict an investigator’s access
    to digital evidence to only email messages, or you may be limited to a specific
    date and time within the forensic image.
  id: totrans-3
  prefs: []
  type: TYPE_NORMAL
  zh: 实际上，你的搜索方法将取决于你正在调查的犯罪类型，以及搜索范围是否有限制。例如，在某些调查中，司法机关可能会限制调查员访问数字证据，只能查看电子邮件信息，或者你可能仅限于在法医镜像中查找特定日期和时间。
- en: This chapter will first go through timeline analysis, where a user’s activity
    is analyzed *temporally*. Then, we will examine the storage containers used by
    the user. You will also learn about string search, in which you search a dataset
    using matching strings of characters. Finally, in the last section, we will analyze
    data that has been deleted from the filesystem.
  id: totrans-4
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将首先讲解时间轴分析，分析用户活动的*时间性*。接下来，我们将检查用户使用的存储容器。你还将了解字符串搜索，即通过匹配字符字符串在数据集中进行搜索。最后，在最后一节中，我们将分析从文件系统中删除的数据。
- en: 'In this chapter, we will learn about the following topics:'
  id: totrans-5
  prefs: []
  type: TYPE_NORMAL
  zh: 本章将介绍以下内容：
- en: Timeline analysis
  id: totrans-6
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 时间轴分析
- en: Media analysis
  id: totrans-7
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 媒体分析
- en: String search
  id: totrans-8
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 字符串搜索
- en: Recovering deleted data
  id: totrans-9
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 恢复删除的数据
- en: Timeline analysis
  id: totrans-10
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
  zh: 时间轴分析
- en: During the investigation, you may find artifacts that appear to show the accused’s
    guilt or innocence. However, we cannot construe the mere presence of the artifact
    as a sign of the suspect’s guilt or innocence. Instead, the artifact needs to
    be placed within the user and system activity context.
  id: totrans-11
  prefs: []
  type: TYPE_NORMAL
  zh: 在调查过程中，你可能会发现看似显示被告有罪或无罪的遗留物。然而，我们不能仅凭遗留物的存在就推断嫌疑人有罪或无罪。相反，这些遗留物需要放在用户和系统活动的背景下进行分析。
- en: For example, I was brought in as a consultant on a case; they accused the suspect
    of physically abusing their child. One piece of evidence that was considered against
    the suspect was the high number of Google searches about how to treat an injury.
    They attributed the searches to the accused, who was the father. The most challenging
    piece of evidence is to prove the user’s identity behind the keyboard when the
    contested actions occurred. Since the items were present in the internet history
    (we will go into much greater detail in *Chapter 9*, *Internet Artifacts*), I
    wanted to check the context of when the searches were made. The wife was the primary
    owner of the laptop, but the husband was also a frequent user of the laptop. So,
    how do you attribute the searches to a specific user, especially when you have
    multiple people using the same laptop with the same user account?
  id: totrans-12
  prefs: []
  type: TYPE_NORMAL
  zh: 例如，我被聘为一个案件的顾问；他们指控嫌疑人身体虐待自己的孩子。作为反对嫌疑人的证据之一是关于如何处理伤害的 Google 搜索次数过多。他们将这些搜索归咎于被告，即父亲。最具挑战性的证据是，在争议行为发生时，如何证明键盘背后的用户身份。由于这些项目出现在互联网历史记录中（我们将在*第九章*，*互联网遗留物*中深入讨论），我想检查搜索发生的时间背景。妻子是这台笔记本电脑的主要拥有者，但丈夫也是这台笔记本的常用用户。那么，如何将这些搜索归因于特定用户，尤其是在有多个用户使用同一台笔记本并且使用相同账户的情况下？
- en: A person’s internet viewing habits can almost be as distinctive as a fingerprint.
    As I reviewed the one million-plus lines of internet history, I could differentiate
    the two different users on the laptop. I could correlate social media use with
    each user and attribute the Google searches to the child’s mother. When she was
    confronted with the findings, the mother admitted that she searched for how to
    treat her child’s injuries. After being presented with the evidence and testimony
    of the mother, the jury found the client not guilty of child abuse.
  id: totrans-13
  prefs: []
  type: TYPE_NORMAL
  zh: 一个人的互联网浏览习惯几乎可以像指纹一样具有独特性。当我查看超过一百万行的互联网历史记录时，我能够区分笔记本电脑上的两个不同用户。我能够将社交媒体的使用与每个用户相关联，并将Google搜索归因于孩子的母亲。当她面对这些发现时，母亲承认她曾搜索如何处理孩子的伤势。在出示了证据和母亲的证词后，陪审团判定客户无罪，不构成虐待儿童罪。
- en: Suppose they had done a timeline analysis before making the charging decision.
    In that case, I believe the father would not have been charged, as the only evidence
    against him was the digital evidence found on the wife’s laptop.
  id: totrans-14
  prefs: []
  type: TYPE_NORMAL
  zh: 假设在做出起诉决定之前他们进行了时间线分析，我相信父亲不会被起诉，因为唯一针对他的证据是从妻子的笔记本电脑中发现的数字证据。
- en: Your ability to create a timeline to analyze the system and actions of the user
    allows you to develop a much deeper and more thorough understanding of digital
    evidence. When I first started in the field, timelines were rudimentary and were
    typically based on the MAC times of the filesystem. **MAC** times refer to the
    **Modified, Accessed, and Created** times that are records created by the filesystem
    as created, edited, or accessed. The downside to only using MAC times for timeline
    analysis is that the recorded times may not be accurate. For example, this can
    happen when files are moved from one volume to another or if a user uses a third-party
    tool to change the timestamps and the timestamps are dependent on the system time.
  id: totrans-15
  prefs: []
  type: TYPE_NORMAL
  zh: 你创建时间线以分析系统和用户行为的能力，让你能够对数字证据有更深入、更全面的理解。当我刚开始从事这个领域时，时间线是初步的，通常基于文件系统的MAC时间。**MAC**时间指的是**修改时间、访问时间和创建时间**，这些记录由文件系统在文件创建、编辑或访问时生成。仅使用MAC时间进行时间线分析的缺点是记录的时间可能不准确。例如，当文件从一个卷移动到另一个卷，或者用户使用第三方工具更改时间戳，并且时间戳依赖于系统时间时，就可能发生这种情况。
- en: We will now use multiple sources to help us to determine the context of what
    is happening on a system regarding a specific artifact. These additional sources
    may not be as easily manipulated as the MAC times and can determine any irregularities
    in the timestamps. For example, using multiple resources found within the forensic
    image, we can see when the user logs in, launches an executable, and accesses
    a file associated with the executable. This method of accessing multiple sources
    helps us confirm and validate the information provided by the MAC times.
  id: totrans-16
  prefs: []
  type: TYPE_NORMAL
  zh: 我们现在将使用多个来源来帮助我们确定系统中与特定证据相关的事件上下文。这些附加来源可能不像MAC时间那样容易被篡改，并且能够确定时间戳中的任何异常。例如，使用法医镜像中的多个资源，我们可以看到用户登录、启动可执行文件，并访问与可执行文件相关联的文件。这种访问多个来源的方法有助于我们确认并验证MAC时间提供的信息。
- en: Applying multiple frames of reference to the event being investigated allows
    us to support our hypothesis about the event. For example, can we determine whether
    the investigated incident results from user activity or is it a system process?
    In addition, using all of the available sources such as event logs, filesystem
    logs, or internet history captured by the system allows us to get into the small
    details to see the context of the event.
  id: totrans-17
  prefs: []
  type: TYPE_NORMAL
  zh: 将多个参考框架应用于正在调查的事件，能帮助我们支持对事件的假设。例如，我们是否能够判断调查事件是由用户活动引起的，还是系统进程的结果？此外，使用所有可用的资源，如事件日志、文件系统日志或系统捕获的互联网历史记录，可以帮助我们深入细节，了解事件的上下文。
- en: By gathering data points from multiple sources, you can create what Rob Lee
    from the SANS Institute calls a super timeline because of the sheer amount of
    data points you will have to sort through.
  id: totrans-18
  prefs: []
  type: TYPE_NORMAL
  zh: 通过从多个来源收集数据点，你可以创建出罗布·李（Rob Lee）在SANS研究所所称的超级时间线，因为你需要筛选的大量数据点会使得这一过程更加复杂。
- en: Hard drive capacity is not getting smaller. Instead, it is increasing at a phenomenal
    rate. Users and developers use this increased capacity to store more data and
    increase the number of logs that can track what occurs in a system. In some investigations,
    you may not need to examine the content of the files; for example, in an investigation
    dealing with illicit images, I need not see the visual depiction of the file.
    Instead, to answer whether a user knew about the existence of a specific file,
    I can use timeline analysis to make that determination.
  id: totrans-19
  prefs: []
  type: TYPE_NORMAL
  zh: 硬盘容量并没有变小，反而以惊人的速度在增长。用户和开发人员利用这种增加的容量来存储更多的数据，并增加可以追踪系统中发生事件的日志数量。在某些调查中，你可能不需要检查文件的内容；例如，在涉及非法图片的调查中，我无需查看文件的视觉内容。相反，为了回答一个用户是否知道某个特定文件的存在，我可以使用时间线分析来做出这个判断。
- en: Commercial forensic (and open-source) tools have made many advances when it
    comes to creating timelines. For example, at one time, you had to use many tools
    to extract data to create a timeline. Now you can use just a single tool to create
    a timeline.
  id: totrans-20
  prefs: []
  type: TYPE_NORMAL
  zh: 商业取证工具（以及开源工具）在创建时间线方面取得了许多进展。例如，曾经你需要使用多个工具来提取数据以创建时间线。现在，你只需使用一个工具就可以创建时间线。
- en: '**Note**'
  id: totrans-21
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: In this chapter, we will be discussing date-times, which will be converted into
    UTC/GMT. Always be aware of which time zone your dataset is operating in and the
    time zone it is stored. I use GMT/UTC as a standard when conducting an examination.
  id: totrans-22
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我们将讨论日期和时间，这些将被转换为UTC/GMT。始终注意你的数据集操作的时区以及它存储的时区。我在进行审查时使用GMT/UTC作为标准。
- en: In this chapter, I will demonstrate the use of several tools for you to see
    the difference in the outputs and discuss where the tools pull the information
    from.
  id: totrans-23
  prefs: []
  type: TYPE_NORMAL
  zh: 在本章中，我将演示使用几种工具，让你了解它们输出的区别，并讨论这些工具从哪里获取信息。
- en: X-Ways
  id: totrans-24
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
  zh: X-Ways
- en: X-Ways Forensics has a very robust timeline-creation utility built in, called
    an **event list**. X-Ways compiles multiple sources such as timestamps at the
    filesystem level, internal timestamps, browser histories, event logs, registry
    hives, emails, and many other sources. When you start an event list, the data
    will be presented chronologically, creating a timeline. The event list is a very
    detailed timeline with copious amounts of information, which allows you to see
    the sequence of events of the incident you are investigating.
  id: totrans-25
  prefs: []
  type: TYPE_NORMAL
  zh: X-Ways Forensics内置了一个非常强大的时间线创建工具，叫做**事件列表**。X-Ways整合了多个来源的数据，如文件系统级别的时间戳、内部时间戳、浏览器历史记录、事件日志、注册表配置单元、电子邮件等。当你启动事件列表时，数据将按时间顺序呈现，形成时间线。事件列表是一条非常详细的时间线，包含大量信息，允许你看到你正在调查的事件的时间顺序。
- en: '**Note**'
  id: totrans-26
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: As you explore the features of a new tool, remember to validate the tool against
    a known dataset. We will use a forensic image offered by Digital Corpora for this
    lab. You can visit [https://digitalcorpora.org/](https://digitalcorpora.org/)
    and go to the 2008 M–57 Jean scenario for more information.
  id: totrans-27
  prefs: []
  type: TYPE_NORMAL
  zh: 在你探索新工具的功能时，记得用已知的数据集来验证工具。我们将在本实验中使用Digital Corpora提供的取证镜像。你可以访问[https://digitalcorpora.org/](https://digitalcorpora.org/)并查看2008年M–57
    Jean案例，获取更多信息。
- en: In this scenario, you are investigating a data leak. Someone has posted a spreadsheet
    containing an organization’s confidential information onto a competitor’s website,
    and the spreadsheet came from the computer of the CFO, Jean. During her interview,
    Jean stated that she emailed the spreadsheet to the president, Allison, at her
    request. The spreadsheet is `m57plan.xls` and can be found on the desktop of Jean’s
    account. It has an MD5 hash value of `e23a4eb7f2562f53e88c9dca8b26a153` and a
    modified time of **2008-JUL-20 01:28:03 GMT** that also corresponds to Jean’s
    statement regarding when she emailed the spreadsheet.
  id: totrans-28
  prefs: []
  type: TYPE_NORMAL
  zh: 在这种情况下，你正在调查一起数据泄露事件。有人将一份包含某组织机密信息的电子表格发布到竞争对手的网站上，而这份电子表格来自首席财务官（CFO）Jean的计算机。在她的面谈中，Jean表示她根据总裁Allison的要求，将这份电子表格通过邮件发送给了她。电子表格名为`m57plan.xls`，可以在Jean账户的桌面上找到。该文件的MD5哈希值为`e23a4eb7f2562f53e88c9dca8b26a153`，修改时间为**2008-JUL-20
    01:28:03 GMT**，这与Jean关于她何时发送电子表格的陈述相符。
- en: 'The filename and time frame give us a starting point for conducting the timeline
    analysis. When you are in the user environment of X-Ways Forensics, select the
    icon for the event list:'
  id: totrans-29
  prefs: []
  type: TYPE_NORMAL
  zh: 文件名和时间范围为我们提供了进行时间线分析的起点。当你进入X-Ways Forensics的用户环境时，选择事件列表图标：
- en: '![](img/B18329_05_01.png)'
  id: totrans-30
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_01.png)'
- en: 'Figure 5.1: X-Ways'
  id: totrans-31
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.1：X-Ways
- en: As you can see in the preceding screenshot, when you select the **Calendar**
    option, it will show you the calendar interface so that you can drill down to
    a specific day. If I do not filter any of the results on the event list, I have
    over one million entries that I will need to parse through. My preferred workflow
    method is to start big and then filter the results to meet the needs of my investigation.
  id: totrans-32
  prefs: []
  type: TYPE_NORMAL
  zh: 如前图所示，当你选择**日历**选项时，它会显示日历界面，方便你深入查看特定日期。如果我不对事件列表中的结果进行筛选，那么会有超过一百万条记录需要我逐一解析。我的首选工作流程是从大的数据集开始，然后逐步筛选结果，以满足调查的需求。
- en: When I filter down to July 20, I have reduced my results to a much more manageable
    4,052 events.
  id: totrans-33
  prefs: []
  type: TYPE_NORMAL
  zh: 当我将筛选范围缩小到 7 月 20 日时，我将结果减少到了 4,052 个事件，更加易于管理。
- en: 'Once we filter the results, let’s search for the filename and see what activity
    has occurred. One of the first results shows that at 01:27:42, the system created
    a link file for the spreadsheet. In the following screenshot, you can see the
    user activity from 01:27 to 01:28\. A pre-fetch file (`EXCEL.EXE-1C75F8D6.pf`)
    was created for Excel at 01:27, which shows the user starting the Excel program
    and then opening the spreadsheet, which corresponds to the creation of a link
    file:'
  id: totrans-34
  prefs: []
  type: TYPE_NORMAL
  zh: 一旦筛选了结果，我们可以搜索文件名，看看发生了什么活动。第一个结果显示，在 01:27:42，系统为电子表格创建了一个链接文件。在接下来的截图中，你可以看到从
    01:27 到 01:28 的用户活动。在 01:27 时，创建了一个预取文件（`EXCEL.EXE-1C75F8D6.pf`），这表示用户启动了 Excel
    程序并打开了电子表格，正好对应了链接文件的创建。
- en: '![](img/B18329_05_02.png)'
  id: totrans-35
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_02.png)'
- en: 'Figure 5.2: Filter results'
  id: totrans-36
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.2：筛选结果
- en: When you view the event list, you can see where the forensic tool is getting
    the information that is being displayed. The creation of the pre-fetch file starts
    with a change in the NT `user.dat` file. The tool follows along from gathering
    information from the internal file metadata to the operating system artifact.
    We can follow along and observe what occurs at the user and system levels as the
    user activity is being recorded.
  id: totrans-37
  prefs: []
  type: TYPE_NORMAL
  zh: 查看事件列表时，你可以看到法医工具获取并展示信息的来源。预取文件的创建始于 NT `user.dat` 文件的变更。工具会跟踪从内部文件元数据到操作系统工件的整个过程。我们可以跟踪并观察用户和系统层面的活动，记录下用户操作的全过程。
- en: 'If you look at timestamp 01:28:00, you can see that Jean sent a message out.
    In the **Name** column, we can see the subject of the email, and when we double-click
    on it, we can view the email itself:'
  id: totrans-38
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你查看时间戳 01:28:00，可以看到 Jean 发送了一条消息。在**名称**列中，我们可以看到邮件的主题，双击后可以查看邮件内容：
- en: '![](img/B18329_05_03.png)'
  id: totrans-39
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_03.png)'
- en: 'Figure 5.3: Jean’s email'
  id: totrans-40
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.3：Jean 的邮件
- en: 'We can see that Jean has emailed what appears to be `allison@M57.biz`, but,
    in reality, it is going to `tuckgorge@gmail.com`. We can then filter by file type,
    in this case, the `.eml` files, and you can see the results as follows:'
  id: totrans-41
  prefs: []
  type: TYPE_NORMAL
  zh: 我们可以看到 Jean 发出了邮件，收件人看似是 `allison@M57.biz`，但实际上是发送到了 `tuckgorge@gmail.com`。然后，我们可以根据文件类型进行筛选，在这种情况下是
    `.eml` 文件，筛选结果如下：
- en: '![Graphical user interface, text, application, email  Description automatically
    generated](img/B18329_05_04.png)'
  id: totrans-42
  prefs: []
  type: TYPE_IMG
  zh: '![图形用户界面，文本，应用程序，电子邮件 说明自动生成](img/B18329_05_04.png)'
- en: 'Figure 5.4: Jean’s email header'
  id: totrans-43
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.4：Jean 的邮件头
- en: When you look at the **Sender** and **Recipients** columns, and when the data
    is sorted chronologically, you can get a good idea about the email communication
    between the attacker and Jean. It appears they have compromised Allison’s account,
    as we can see the name “Alex” and the email account `tuckgorge@gmail.com` associated
    with the account.
  id: totrans-44
  prefs: []
  type: TYPE_NORMAL
  zh: 查看**发件人**和**收件人**列，并按时间顺序排列数据，你可以大致了解攻击者与 Jean 之间的邮件通讯。看起来他们已经入侵了 Allison 的账户，因为我们可以看到“Alex”这个名字和与该账户关联的邮件地址
    `tuckgorge@gmail.com`。
- en: Using the event list feature of X-Ways Forensics allows us to pinpoint when
    the file was compromised and from what vector. Now we can direct our investigation
    to Allison’s computer to determine whether the attacker compromised her system.
    Based on these initial results, I believe the attacker targeted Jean in a phishing
    attack.
  id: totrans-45
  prefs: []
  type: TYPE_NORMAL
  zh: 使用 X-Ways Forensics 的事件列表功能可以帮助我们准确定位文件何时被篡改以及通过什么途径。现在我们可以将调查方向指向 Allsion 的计算机，以确定攻击者是否侵入了她的系统。根据这些初步结果，我认为攻击者通过网络钓鱼攻击瞄准了
    Jean。
- en: What I like about X-Ways Forensics is its ability to gather the dates and times
    from traditional sources and combine them with the actual artifacts, in this case,
    the emails. This gives you another level of granularity and context for your investigation.
  id: totrans-46
  prefs: []
  type: TYPE_NORMAL
  zh: 我喜欢X-Ways Forensics的一点是，它能够从传统来源收集日期和时间，并将这些信息与实际的证据（在本例中为电子邮件）结合起来。这为你的调查提供了更高的细节层次和背景。
- en: 'The X-Ways Forensics documentation lists the following as sources of information
    for the event list feature:'
  id: totrans-47
  prefs: []
  type: TYPE_NORMAL
  zh: X-Ways Forensics文档列出了以下内容作为事件列表功能的信息来源：
- en: '![Table  Description automatically generated](img/B18329_05_05.png)'
  id: totrans-48
  prefs: []
  type: TYPE_IMG
  zh: '![图表 描述自动生成](img/B18329_05_05.png)'
- en: As you can see, this shows a very diverse list of sources. However, when used
    for analysis, it can give the investigator the confidence to rely on the date
    timestamps they are reporting in their investigation.
  id: totrans-49
  prefs: []
  type: TYPE_NORMAL
  zh: 如你所见，这展示了一个非常多样化的信息来源列表。然而，在用于分析时，它可以使调查员更加信赖他们在调查中报告的日期时间戳。
- en: 'I have found that forensic suites also include timeline analysis with their
    products. I have discussed X-Ways Forensics and its ability to create a timeline
    for analysis with its event list feature. I have included a list of some additional
    forensic suites that you may use to analyze timeline data. The following list
    is not inclusive of all the forensic suites that are available:'
  id: totrans-50
  prefs: []
  type: TYPE_NORMAL
  zh: 我发现法医套件也包含了时间线分析功能。我曾讨论过X-Ways Forensics及其通过事件列表功能创建时间线进行分析的能力。我列出了你可以用来分析时间线数据的一些其他法医套件。以下列表并不包含所有可用的法医套件：
- en: 'Belkasoft Evidence Center: [belkasoft.com/ec](https://belkasoft.com/ec)'
  id: totrans-51
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Belkasoft Evidence Center: [belkasoft.com/ec](https://belkasoft.com/ec)'
- en: 'Autopsy: [www.sleuthkit.org/autopsy](https://www.sleuthkit.org/autopsy)'
  id: totrans-52
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Autopsy: [www.sleuthkit.org/autopsy](https://www.sleuthkit.org/autopsy)'
- en: 'Recon Lab: [sumuri.com/software/recon-lab](https://sumuri.com/software/recon-lab)'
  id: totrans-53
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'Recon Lab: [sumuri.com/software/recon-lab](https://sumuri.com/software/recon-lab)'
- en: 'PALADIN: [sumuri.com/software/paladin](https://sumuri.com/software/paladin)'
  id: totrans-54
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 'PALADIN: [sumuri.com/software/paladin](https://sumuri.com/software/paladin)'
- en: X-Ways is not the only tool you can use to create timelines; there are also
    several open-source tools that you can utilize. One of the most common is **Plaso/log2timeline**,
    which we will discuss next.
  id: totrans-55
  prefs: []
  type: TYPE_NORMAL
  zh: X-Ways并不是唯一可以用来创建时间线的工具；你还可以使用一些开源工具。最常见的工具之一是**Plaso/log2timeline**，我们接下来将讨论它。
- en: Plaso (Plaso Langar Að Safna Öllu)
  id: totrans-56
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
  zh: Plaso（Plaso Langar Að Safna Öllu）
- en: Plaso (Plaso Langar Að Safna Öllu) is a Python backend and framework for the
    `log2timeline` tool. `log2timeline` is a forensic tool that pulls out timestamps
    from a system and creates a database of all the events, also known as a super
    timeline.
  id: totrans-57
  prefs: []
  type: TYPE_NORMAL
  zh: Plaso（Plaso Langar Að Safna Öllu）是一个Python后端和`log2timeline`工具的框架。`log2timeline`是一个法医工具，它从系统中提取时间戳并创建一个所有事件的数据库，也叫超级时间线。
- en: '**Note**'
  id: totrans-58
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: You can download Plaso at [https://github.com/log2timeline/plaso](https://github.com/log2timeline/plaso).
  id: totrans-59
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以从[https://github.com/log2timeline/plaso](https://github.com/log2timeline/plaso)下载Plaso。
- en: Plaso will work on most operating systems and was initially designed to replace
    the Perl version of `log2timeline`. However, the development has now shifted to
    modules, and they have created several CLI tools supported by the Plaso backend.
  id: totrans-60
  prefs: []
  type: TYPE_NORMAL
  zh: Plaso适用于大多数操作系统，最初设计用于替代Perl版本的`log2timeline`。然而，开发现在已经转向模块化，并且他们创建了多个由Plaso后台支持的CLI工具。
- en: 'The tools supported by Plaso are activated by the **command-line interface**
    (**CLI**). While the CLI can intimidate the user, if you take your time and proceed
    slowly, you will take the mystique out of the CLI. Many open-source tools use
    the CLI instead of the **graphical user interface** (**GUI**). The very core of
    the CLI consists of two parts: the executable and the modifiers. Once you learn
    the specific modifiers for the CLI command, you will see that it all falls into
    place.'
  id: totrans-61
  prefs: []
  type: TYPE_NORMAL
  zh: Plaso支持的工具是通过**命令行界面**（**CLI**）激活的。尽管CLI可能会让用户感到害怕，但如果你慢慢来，逐步进行操作，你会发现CLI并不神秘。许多开源工具使用CLI而不是**图形用户界面**（**GUI**）。CLI的核心由两部分组成：可执行文件和修饰符。一旦你掌握了CLI命令的特定修饰符，你会发现一切都能井然有序地运作。
- en: 'Let’s talk about the tools included with Plaso:'
  id: totrans-62
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们来谈谈Plaso中包含的工具：
- en: '`image_export`'
  id: totrans-63
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`image_export`'
- en: '`log2timeline`'
  id: totrans-64
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`log2timeline`'
- en: '`pinfo`'
  id: totrans-65
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`pinfo`'
- en: '`psort`'
  id: totrans-66
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`psort`'
- en: '`psteal`'
  id: totrans-67
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`psteal`'
- en: image_export
  id: totrans-68
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: image_export
- en: '`image_export` will export file content from a device, media image, or forensic
    image. There are several parameters that you can use to define the information
    you wish to extract.'
  id: totrans-69
  prefs: []
  type: TYPE_NORMAL
  zh: '`image_export` 将从设备、媒体镜像或法医镜像中导出文件内容。你可以使用多个参数来定义你希望提取的信息。'
- en: In the Windows version of the executable, the executable will end with `.exe`.
    With macOS, you may see it end in `.sh`.
  id: totrans-70
  prefs: []
  type: TYPE_NORMAL
  zh: 在Windows版本的可执行文件中，可执行文件以`.exe`结尾。而在macOS中，可能会看到它以`.sh`结尾。
- en: 'Using `–h` or `--help` will give you the full list of parameters:'
  id: totrans-71
  prefs: []
  type: TYPE_NORMAL
  zh: 使用`–h`或`--help`将给出完整的参数列表：
- en: '![](img/B18329_05_06.png)'
  id: totrans-72
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_06.png)'
- en: 'Figure 5.5: image_export'
  id: totrans-73
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.5：image_export
- en: 'Further down the screen, you will see detailed explanations for the modifiers.
    Note that I will only cover the most used options; there is additional documentation
    that we will not discuss here:'
  id: totrans-74
  prefs: []
  type: TYPE_NORMAL
  zh: 在屏幕下方，你将看到修饰符的详细解释。请注意，我只会涵盖最常用的选项；这里有更多的文档，我们将不再讨论：
- en: '`--names NAMES`: The filter on filenames. This option accepts a comma-separated
    string denoting all filenames, for example, `x NTUSER.DAT,UsrClass.dat`.'
  id: totrans-75
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--names NAMES`：对文件名的过滤。此选项接受一个用逗号分隔的字符串，表示所有文件名，例如，`x NTUSER.DAT, UsrClass.dat`。'
- en: '`-w PATH`, `--write PATH`: The directory in which extracted files should be
    stored.'
  id: totrans-76
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-w PATH`, `--write PATH`：提取的文件应存储的目录。'
- en: '`--data PATH`: The path to a directory containing the data files.'
  id: totrans-77
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`--data PATH`：包含数据文件的目录路径。'
- en: '`-x EXTENSIONS`, `--extensions EXTENSIONS`: The filter on filename extensions.
    This option accepts multiple comma-separated values, for example, `csv`, `docx`,
    and `pst`.'
  id: totrans-78
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: '`-x EXTENSIONS`, `--extensions EXTENSIONS`：对文件名扩展名的过滤。此选项接受多个用逗号分隔的值，例如，`csv`，`docx`，和`pst`。'
- en: 'If you use the following command, it will export the `.xls` file to the `files`
    folder:'
  id: totrans-79
  prefs: []
  type: TYPE_NORMAL
  zh: 如果使用以下命令，它将把`.xls`文件导出到`files`文件夹中：
- en: '[PRE0]'
  id: totrans-80
  prefs: []
  type: TYPE_PRE
  zh: '[PRE0]'
- en: 'You can see the breakdown of the preceding command as follows:'
  id: totrans-81
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以看到前面命令的分解如下：
- en: '![](img/B18329_05_07.png)'
  id: totrans-82
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_07.png)'
- en: 'Figure 5.6: CLI map'
  id: totrans-83
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.6：CLI 映射
- en: Here, with the `image_export` command, we are using the `names` modifier to
    look for a specific file. In this case, it is `M57plan.xls`.
  id: totrans-84
  prefs: []
  type: TYPE_NORMAL
  zh: 在这里，使用`image_export`命令，我们使用`names`修饰符来查找特定文件。在此情况下，它是`M57plan.xls`。
- en: Now, you can tell the executable where to search; in this command, we are searching
    in the forensic image, `jean.001` (make sure that you include the full path to
    where the forensic image is located). Next, you can indicate where you want the
    exported files to be sent. The `-w` modifier will specify the write location.
  id: totrans-85
  prefs: []
  type: TYPE_NORMAL
  zh: 现在，你可以告诉可执行文件在哪里进行搜索；在此命令中，我们在取证镜像`jean.001`中进行搜索（确保包含取证镜像所在位置的完整路径）。接下来，你可以指定将导出的文件发送到哪里。`-w`修饰符将指定写入位置。
- en: You will find that the modifiers have some commonality with the commands within
    the Plaso framework.
  id: totrans-86
  prefs: []
  type: TYPE_NORMAL
  zh: 你会发现，这些修饰符与Plaso框架中的命令有一些共通之处。
- en: log2timeline
  id: totrans-87
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: log2timeline
- en: '`log2timeline` is a CLI tool that is designed to extract chronological-based
    events from files, directories, forensic images, and devices. It will create a
    database file (`.plaso`) that can then be analyzed by a variety of tools.'
  id: totrans-88
  prefs: []
  type: TYPE_NORMAL
  zh: '`log2timeline`是一个命令行工具，旨在从文件、目录、取证镜像和设备中提取基于时间的事件。它将创建一个数据库文件（`.plaso`），然后可以通过各种工具进行分析。'
- en: 'As you can see in the following screenshot, the `-h` modifier (help) will display
    the options for the command. As before, there are detailed explanations not displayed
    that will give you additional context for these commands. You should be able to
    recognize some of them from the previous command we looked at:'
  id: totrans-89
  prefs: []
  type: TYPE_NORMAL
  zh: 如下图所示，`-h`修饰符（帮助）将显示命令的选项。与之前一样，虽然有些详细解释没有显示，但它们能为这些命令提供额外的上下文。你应该能够从我们之前看的命令中识别出一些：
- en: '![](img/B18329_05_08.png)'
  id: totrans-90
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_08.png)'
- en: 'Figure 5.7: log2timeline'
  id: totrans-91
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.7：log2timeline
- en: 'Try using the `info` modifier, as follows:'
  id: totrans-92
  prefs: []
  type: TYPE_NORMAL
  zh: 尝试使用`info`修饰符，如下所示：
- en: '[PRE1]'
  id: totrans-93
  prefs: []
  type: TYPE_PRE
  zh: '[PRE1]'
- en: 'You will get a list of all of the supported plugins, parsers, and output modules:'
  id: totrans-94
  prefs: []
  type: TYPE_NORMAL
  zh: 你将看到所有支持的插件、解析器和输出模块的列表：
- en: '![](img/B18329_05_09.png)'
  id: totrans-95
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_09.png)'
- en: 'Figure 5.8: Results of the info modifier'
  id: totrans-96
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.8：info修饰符的结果
- en: From the preceding output, you can see that some of the presets include collecting
    artifacts from many filesystems.
  id: totrans-97
  prefs: []
  type: TYPE_NORMAL
  zh: 从前面的输出中，你可以看到一些预设包括从多个文件系统中收集工件。
- en: 'At a very basic level, you can use the following command structure:'
  id: totrans-98
  prefs: []
  type: TYPE_NORMAL
  zh: 在一个非常基础的层面上，你可以使用以下命令结构：
- en: '[PRE2]'
  id: totrans-99
  prefs: []
  type: TYPE_PRE
  zh: '[PRE2]'
- en: 'One idiosyncrasy of `log2timeline` is that the output file is the first modifier
    to the executable and then you specify the input:'
  id: totrans-100
  prefs: []
  type: TYPE_NORMAL
  zh: '`log2timeline`的一个特点是，输出文件是可执行文件的第一个修饰符，然后你再指定输入：'
- en: '[PRE3]'
  id: totrans-101
  prefs: []
  type: TYPE_PRE
  zh: '[PRE3]'
- en: 'When the command executes, you should see the following output on the screen:'
  id: totrans-102
  prefs: []
  type: TYPE_NORMAL
  zh: 当命令执行时，你应该在屏幕上看到以下输出：
- en: '![](img/B18329_05_10.png)'
  id: totrans-103
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_10.png)'
- en: 'Figure 5.9: Output'
  id: totrans-104
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.9：输出
- en: As the command executes, it locates the data folder that contains the dependencies
    for the executable, and then it searches for the files that contain the information
    about the artifacts that may be stored within the system. This is a default folder
    and is installed when you install `plaso`.
  id: totrans-105
  prefs: []
  type: TYPE_NORMAL
  zh: 当命令执行时，它会定位包含可执行文件依赖项的数据文件夹，然后搜索包含可能存储在系统中的工件信息的文件。这是一个默认文件夹，在你安装 `plaso` 时会自动安装。
- en: We now have a `.plaso` file that we can find in the `files` folder. In some
    cases, you might not want to create the database file with every option, that
    is, the kitchen sink. Rather, you may wish to do a targeted examination of the
    timeline, in which case you would need to employ filters. Using the `-f` modifier
    will allow you to do that.
  id: totrans-106
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们有了一个 `.plaso` 文件，可以在 `files` 文件夹中找到它。在某些情况下，你可能不希望为每个选项都创建数据库文件，即不想“厨房水槽式”地处理所有内容。相反，你可能希望对时间线进行有针对性的检查，这时你需要使用过滤器。使用
    `-f` 修饰符可以实现这一点。
- en: '**Note**'
  id: totrans-107
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: If you want to download some premade filters, you can do so at [https://github.com/mark-hallman/plaso_filters](https://github.com/mark-hallman/plaso_filters).
  id: totrans-108
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你想下载一些预制的过滤器，可以访问 [https://github.com/mark-hallman/plaso_filters](https://github.com/mark-hallman/plaso_filters)。
- en: 'I downloaded the premade filters and created a folder, named `filter`, within
    the path of the `plaso` installation. As you see from the following screenshot,
    I have installed `plaso` in a folder called `tools` at the root of my `C` drive:'
  id: totrans-109
  prefs: []
  type: TYPE_NORMAL
  zh: 我下载了预制的过滤器，并在 `plaso` 安装路径下创建了一个名为 `filter` 的文件夹。如以下截图所示，我将 `plaso` 安装在了 `C`
    盘根目录下的一个名为 `tools` 的文件夹中：
- en: '[PRE4]'
  id: totrans-110
  prefs: []
  type: TYPE_PRE
  zh: '[PRE4]'
- en: 'And, as you can see in the following screenshot, the tool was able to locate
    my filter within the `artifacts` folder and created a new Plaso database file:'
  id: totrans-111
  prefs: []
  type: TYPE_NORMAL
  zh: 如以下截图所示，工具能够在 `artifacts` 文件夹中找到我的过滤器，并创建了一个新的 Plaso 数据库文件：
- en: '![](img/B18329_05_11.png)'
  id: totrans-112
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_11.png)'
- en: 'Figure 5.10: Filter'
  id: totrans-113
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.10：过滤器
- en: So far, we have covered several commands; however, we still have more to cover.
    The next command in the framework is `pinfo`.
  id: totrans-114
  prefs: []
  type: TYPE_NORMAL
  zh: 到目前为止，我们已经介绍了几个命令；然而，我们还有更多内容要讲解。框架中的下一个命令是 `pinfo`。
- en: pinfo
  id: totrans-115
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: pinfo
- en: '`pinfo` is a command line that is used to display information about the Plaso
    database file (`.plaso`).'
  id: totrans-116
  prefs: []
  type: TYPE_NORMAL
  zh: '`pinfo` 是一个命令行，用于显示关于 Plaso 数据库文件（`.plaso`）的信息。'
- en: 'The `plaso` database file will contain the following information:'
  id: totrans-117
  prefs: []
  type: TYPE_NORMAL
  zh: '`plaso` 数据库文件将包含以下信息：'
- en: When the user executed the tool
  id: totrans-118
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 用户执行工具时
- en: What options were used when the tool was run
  id: totrans-119
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 执行工具时使用的选项
- en: What information was obtained by the tool during the pre-processing stage
  id: totrans-120
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 工具在预处理阶段获取的信息
- en: The database metadata
  id: totrans-121
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 数据库元数据
- en: What was parsed and the parameters that were used
  id: totrans-122
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 解析了什么内容以及使用的参数
- en: The number of events extracted
  id: totrans-123
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 提取的事件数量
- en: Tagged events
  id: totrans-124
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
  zh: 标记事件
- en: 'To learn more about the preceding options, execute the command with the `-h`
    modifier. While the options are similar, you will have a far smaller selection
    than with the other tools, as shown in the following screenshot:'
  id: totrans-125
  prefs: []
  type: TYPE_NORMAL
  zh: 要了解更多关于前述选项的信息，请使用 `-h` 修饰符执行命令。虽然这些选项相似，但与其他工具相比，你的选择会少得多，正如下图所示：
- en: '![](img/B18329_05_12.png)'
  id: totrans-126
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_12.png)'
- en: 'Figure 5.11: pinfo'
  id: totrans-127
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.11：pinfo
- en: 'When you use the `pinfo` command in its simplest form, you will get the following
    results:'
  id: totrans-128
  prefs: []
  type: TYPE_NORMAL
  zh: 当你以最简单的形式使用 `pinfo` 命令时，将获得以下结果：
- en: '[PRE5]'
  id: totrans-129
  prefs: []
  type: TYPE_PRE
  zh: '[PRE5]'
- en: As you can see in the preceding output, you get the storage information about
    the file and how many sessions were used to create it.
  id: totrans-130
  prefs: []
  type: TYPE_NORMAL
  zh: 如前面的输出所示，你可以查看文件的存储信息以及创建该文件所用的会话数量。
- en: You can send the results to the standard output, that is, the monitor, or you
    can use the `-w` modifier to create a text file with the results. The use of the
    additional tools on the `.plaso` file will create the GUID and the date timestamp
    of when the analysis was conducted.
  id: totrans-131
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以将结果发送到标准输出，也就是显示器，或者使用 `-w` 修饰符将结果保存到一个文本文件中。对 `.plaso` 文件使用额外工具将生成 GUID
    以及分析进行时的日期时间戳。
- en: 'The tool can also provide system information about the source system you are
    now examining:'
  id: totrans-132
  prefs: []
  type: TYPE_NORMAL
  zh: 该工具还可以提供你正在检查的源系统的系统信息：
- en: '[PRE6]'
  id: totrans-133
  prefs: []
  type: TYPE_PRE
  zh: '[PRE6]'
- en: After verifying the information in the database file, you can move on to the
    next command.
  id: totrans-134
  prefs: []
  type: TYPE_NORMAL
  zh: 在验证数据库文件中的信息后，你可以继续执行下一个命令。
- en: psort
  id: totrans-135
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: psort
- en: '`psort` is a CLI tool that allows you to filter, sort, and conduct analysis
    on the contents of the `plaso` database file. Just like with the previous commands,
    the `-h` modifier will show you all the options for the command. In the following
    `psort` screenshot, you can see the available options, and you should be able
    to recognize the commonality of the options between all of the commands in the
    `plaso` architecture:'
  id: totrans-136
  prefs: []
  type: TYPE_NORMAL
  zh: '`psort` 是一个命令行工具，允许你筛选、排序并分析 `plaso` 数据库文件的内容。就像其他命令一样，`-h` 修饰符将显示该命令的所有选项。在下面的
    `psort` 截图中，你可以看到可用选项，并且你应该能识别出所有 `plaso` 架构中命令选项的共性：'
- en: '![](img/B18329_05_13.png)'
  id: totrans-137
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_13.png)'
- en: 'Figure 5.12: psort'
  id: totrans-138
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.12：psort
- en: 'Let’s discuss some of the new options:'
  id: totrans-139
  prefs: []
  type: TYPE_NORMAL
  zh: 让我们讨论一些新的选项：
- en: '[PRE7]'
  id: totrans-140
  prefs: []
  type: TYPE_PRE
  zh: '[PRE7]'
- en: 'Below is a list of the available output formats:'
  id: totrans-141
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是可用的输出格式列表：
- en: '| **Name** | **Description** |'
  id: totrans-142
  prefs: []
  type: TYPE_TB
  zh: '| **名称** | **描述** |'
- en: '| --- | --- |'
  id: totrans-143
  prefs: []
  type: TYPE_TB
  zh: '| --- | --- |'
- en: '| `dynamic` | Output events to a delimiter (comma by default) separated value
    output format, that supports a dynamic selection of fields. |'
  id: totrans-144
  prefs: []
  type: TYPE_TB
  zh: '| `dynamic` | 将事件输出为分隔符（默认是逗号）分隔的值格式，支持动态选择字段。 |'
- en: '| `elastic` | Output events to an ElasticSearch database.Requires elasticsearch-py.
    |'
  id: totrans-145
  prefs: []
  type: TYPE_TB
  zh: '| `elastic` | 将事件输出到 ElasticSearch 数据库。需要 elasticsearch-py。 |'
- en: '| `elastic_ts` | Output events to an ElasticSearch database for use with Timesketch.
    Requires elasticsearch-py.Solely intended to be used by the Timesketch backend.
    |'
  id: totrans-146
  prefs: []
  type: TYPE_TB
  zh: '| `elastic_ts` | 将事件输出到 ElasticSearch 数据库，以供 Timesketch 使用。需要 elasticsearch-py。仅供
    Timesketch 后端使用。 |'
- en: '| `json` | Output events to JSON format. |'
  id: totrans-147
  prefs: []
  type: TYPE_TB
  zh: '| `json` | 将事件输出为 JSON 格式。 |'
- en: '| `json_line` | Output events to JSON line format. |'
  id: totrans-148
  prefs: []
  type: TYPE_TB
  zh: '| `json_line` | 将事件输出为 JSON 行格式。 |'
- en: '| `kml` | Output events with geography data into a KML format. |'
  id: totrans-149
  prefs: []
  type: TYPE_TB
  zh: '| `kml` | 将含有地理数据的事件输出为 KML 格式。 |'
- en: '| `l2tcsv` | Output events to `log2timeline.pl` legacy CSV format, with 17
    fixed fields. |'
  id: totrans-150
  prefs: []
  type: TYPE_TB
  zh: '| `l2tcsv` | 将事件输出为 `log2timeline.pl` 的传统 CSV 格式，包含 17 个固定字段。 |'
- en: '| `l2ttln` | Output events to `log2timeline.pl` extended TLN format, with 7
    fixed fields. |'
  id: totrans-151
  prefs: []
  type: TYPE_TB
  zh: '| `l2ttln` | 将事件输出为 `log2timeline.pl` 的扩展 TLN 格式，包含 7 个固定字段。 |'
- en: '| `null` | Do not output events. |'
  id: totrans-152
  prefs: []
  type: TYPE_TB
  zh: '| `null` | 不输出事件。 |'
- en: '| `rawpy` | Output events in “raw” (or native) Python format. |'
  id: totrans-153
  prefs: []
  type: TYPE_TB
  zh: '| `rawpy` | 以“原始”（或本地）Python 格式输出事件。 |'
- en: '| `tln` | Output events to TLN format, with 5 fixed fields. |'
  id: totrans-154
  prefs: []
  type: TYPE_TB
  zh: '| `tln` | 将事件输出为 TLN 格式，包含 5 个固定字段。 |'
- en: '| `xlsx` | Output events to an Excel spreadsheet (XLSX). |'
  id: totrans-155
  prefs: []
  type: TYPE_TB
  zh: '| `xlsx` | 将事件输出为 Excel 电子表格（XLSX）。 |'
- en: As you are processing with `psort`, you can export your findings outside of
    the `plaso` database. There are a wide variety of options that you can use to
    export the data for analysis. One of the more common formats for exporting is
    `l2tcsv`, which is the legacy format for `log2timeline` and is a `.csv` worksheet.
  id: totrans-156
  prefs: []
  type: TYPE_NORMAL
  zh: 当你使用 `psort` 进行处理时，可以将结果导出到 `plaso` 数据库之外。你可以使用多种选项导出数据以便分析。一个常见的导出格式是 `l2tcsv`，它是
    `log2timeline` 的传统格式，采用 `.csv` 工作表格式。
- en: A potential issue you may run into when creating the `.csv` worksheet is that
    if the file you create is too large, some tools may not analyze it, nor will you
    be able to open it with your favorite spreadsheet program.
  id: totrans-157
  prefs: []
  type: TYPE_NORMAL
  zh: 在创建 `.csv` 工作表时，你可能会遇到一个潜在问题，即如果你创建的文件太大，一些工具可能无法分析它，或者你无法用你喜欢的电子表格程序打开它。
- en: '`--analysis list`: `psort` comes with analysis plugins installed by default
    (you can still create your own custom plugins) to allow you to go through the
    database file and extract and analyze the contents.'
  id: totrans-158
  prefs: []
  type: TYPE_NORMAL
  zh: '`--analysis list`：`psort` 默认安装了分析插件（你仍然可以创建自定义插件），允许你浏览数据库文件并提取和分析内容。'
- en: 'You can use the `--analysis` `list` modifier to view the complete list of plugins:'
  id: totrans-159
  prefs: []
  type: TYPE_NORMAL
  zh: 你可以使用 `--analysis` `list` 修饰符查看完整的插件列表：
- en: '![](img/B18329_05_14.png)'
  id: totrans-160
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_14.png)'
- en: 'Figure 5.13: List of analysis plugins'
  id: totrans-161
  prefs: []
  type: TYPE_NORMAL
  zh: 图 5.13：分析插件列表
- en: 'If we run the command, it will go through the `plaso` database file, tagging
    the specific events that have been identified in the `tag_windows.txt` file (which
    is part of the default installation and can be found in the `data` directory):'
  id: totrans-162
  prefs: []
  type: TYPE_NORMAL
  zh: 如果我们运行该命令，它会遍历 `plaso` 数据库文件，标记在 `tag_windows.txt` 文件中已识别的特定事件（该文件是默认安装的一部分，可以在
    `data` 目录中找到）：
- en: '[PRE8]'
  id: totrans-163
  prefs: []
  type: TYPE_PRE
  zh: '[PRE8]'
- en: 'On completion of the process, it will show you how many tags were applied to
    the database:'
  id: totrans-164
  prefs: []
  type: TYPE_NORMAL
  zh: 处理完成后，它会显示已应用于数据库的标签数量：
- en: '[PRE9]'
  id: totrans-165
  prefs: []
  type: TYPE_PRE
  zh: '[PRE9]'
- en: Additionally, you can filter out extraneous data using the `--slice` modifier.
  id: totrans-166
  prefs: []
  type: TYPE_NORMAL
  zh: 此外，你还可以使用 `--slice` 修饰符过滤掉多余的数据。
- en: '**Note**'
  id: totrans-167
  prefs: []
  type: TYPE_NORMAL
  zh: '**注意**'
- en: 5 minutes is the default value. If you want a longer or shorter time slice,
    you can add the amount after `DATE TIME` with `--slice_size <VALUE>`.
  id: totrans-168
  prefs: []
  type: TYPE_NORMAL
  zh: 5分钟是默认值。如果你想要更长或更短的时间切片，可以在`DATE TIME`后添加`--slice_size <VALUE>`来指定。
- en: 'If you find the `GET` event, you may want to place that event into context
    by observing what occurred before and afterward:'
  id: totrans-169
  prefs: []
  type: TYPE_NORMAL
  zh: 如果你发现了`GET`事件，你可能希望通过观察发生在之前和之后的事件来为其提供上下文：
- en: '[PRE10]'
  id: totrans-170
  prefs: []
  type: TYPE_PRE
  zh: '[PRE10]'
- en: The command will create a `csv` file, which contains events 5 minutes before
    and 5 minutes after the timestamp placed in the CLI.
  id: totrans-171
  prefs: []
  type: TYPE_NORMAL
  zh: 该命令将创建一个`csv`文件，包含时间戳前后各5分钟的事件。
- en: The final tool in the framework is `psteal`, which we will discuss next.
  id: totrans-172
  prefs: []
  type: TYPE_NORMAL
  zh: 框架中的最后一个工具是`psteal`，我们接下来会讨论它。
- en: psteal
  id: totrans-173
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
  zh: psteal
- en: '`psteal` is the final CLI command in the plaso framework. It combines the `log2timeline`
    and `psort` commands to extract and process events in a single step. It is very
    much the kitchen sink approach, otherwise known as “I want it ALLLLLL”, and it
    has a limited selection of modifiers when compared to the other CLI commands within
    the framework.'
  id: totrans-174
  prefs: []
  type: TYPE_NORMAL
  zh: '`psteal`是plaso框架中的最终CLI命令。它将`log2timeline`和`psort`命令结合在一起，通过一步操作提取和处理事件。这是一种典型的“万金油”方法，也可以称为“我想要所有的”，与框架中其他CLI命令相比，它有一个有限的修饰符选择。'
- en: 'Once again, `-h` will provide you with a list of options for the command, which
    are displayed in the following screenshot:'
  id: totrans-175
  prefs: []
  type: TYPE_NORMAL
  zh: 再次提醒，`-h`会为你提供命令的选项列表，具体内容如下截图所示：
- en: '![](img/B18329_05_15.png)'
  id: totrans-176
  prefs: []
  type: TYPE_IMG
  zh: '![](img/B18329_05_15.png)'
- en: 'Figure 5.14: psteal'
  id: totrans-177
  prefs: []
  type: TYPE_NORMAL
  zh: 图5.14：psteal
- en: At a minimum, specify the source and the output. The process will create the
    plaso database file and place it in the root of the plaso installation. This location
    allows you to perform additional tagging, filtering, or analysis after the command
    completes. The naming convention for the database file created is `<timestamp>-<source>.plaso`.
  id: totrans-178
  prefs: []
  type: TYPE_NORMAL
  zh: 至少需要指定源和输出。该过程将创建plaso数据库文件，并将其放置在plaso安装目录的根目录中。此位置允许你在命令完成后执行额外的标记、筛选或分析。创建的数据库文件的命名约定为`<timestamp>-<source>.plaso`。
- en: 'Here’s the command. It creates a `.csv` file that is almost 1 GB in size. However,
    if I change the output to `.xlsx`, it reduces the size to 35 MB. So, keep in mind
    that you are processing and analyzing your datasets:'
  id: totrans-179
  prefs: []
  type: TYPE_NORMAL
  zh: 这是命令。它创建了一个几乎1GB大小的`.csv`文件。然而，如果我将输出更改为`.xlsx`，文件大小会减少到35MB。所以，请记住，你正在处理和分析你的数据集：
- en: '[PRE11]'
  id: totrans-180
  prefs: []
  type: TYPE_PRE
  zh: '[PRE11]'
- en: I am using a relatively small forensic image of a 20 GB hard drive. Just imagine
    if you were using a 500 GB or a 1 TB hard drive and it had been active for an
    extended period.
  id: totrans-181
  prefs: []
  type: TYPE_NORMAL
  zh: 我正在使用一个相对较小的20GB硬盘的法医镜像。试想一下，如果你使用的是500GB或1TB的硬盘，并且该硬盘已经使用了较长时间，会是什么情况。
- en: Now that we have created our database file and have exported the datasets we
    find relevant to the investigation, what do we do now? It is time to analyze the
    datasets to find the evidence that will either prove or disprove the allegation.
    The tools you use for analysis can simply be the spreadsheet reader of your favorite
    Office suite or a commercial open-source tool designed for that specific purpose.
  id: totrans-182
  prefs: []
  type: TYPE_NORMAL
  zh: 现在我们已经创建了数据库文件并导出了与调查相关的数据集，接下来该做什么呢？是时候分析数据集，找出能够证明或反驳指控的证据了。你用来分析的工具可以是你喜欢的Office套件中的电子表格阅读器，也可以是专门为此目的设计的商业开源工具。
- en: It is not possible to cover all the tool options that are available to an examiner
    in this book. I will highlight several options that are available and summarize
    the tools for you. Ultimately, the analysis of the data is where the examiner
    eyeballs the dataset and reviews the findings. Once again, it comes back to the
    verification/validation of your forensic tools to ensure they are providing accurate
    results.
  id: totrans-183
  prefs: []
  type: TYPE_NORMAL
  zh: 本书无法涵盖所有可供检查员使用的工具选项。我将突出显示一些可用的选项并为你总结这些工具。最终，数据的分析是检查员通过查看数据集并审查结果来完成的。再次强调，这都归结于对法医工具的验证/确认，确保它们提供准确的结果。
- en: 'Here are a few tools:'
  id: totrans-184
  prefs: []
  type: TYPE_NORMAL
  zh: 以下是一些工具：
- en: '**ELK stack**: This can be found at [https://www.elastic.co](https://www.elastic.co).
    It is an acronym for three open-source projects: Elasticsearch, Logstash, and
    Kibana. Elasticsearch is the search and analytical engine. Logstash is the data
    processor and ingest engine, while Kibana is the visualizer. You have the option
    to download the three engines and install them in the operating system of your
    choice. You have options for macOS, Windows, and Linux. There is also the option
    to pay for the cloud environment if you do not wish to host the systems within
    your environment.'
  id: totrans-185
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TimelineMaker Pro**: This can be found at [www.timelinemaker.com](https://www.timelinemaker.com).
    It is a commercial product specifically designed for creating timeline charts.
    With this tool, you can import the CSV files created with the plaso framework.'
  id: totrans-186
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**TimeSketch**: This can be found at [https://github.com/google/timesketch](https://github.com/google/timesketch).
    It is an open-source forensic timeline-analysis tool. It is Linux-based. I have
    installed it in a virtual environment so that I can use it as needed. It can also
    be worked on collaboratively by different members of your team. You can also import
    from a variety of plaso framework output options.'
  id: totrans-187
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Aeon Timeline**: This can be found at [www.aeontimeline.com](https://www.aeontimeline.com).
    It is a commercial product specifically designed for creating visual timelines.
    It will allow you to view relationships among events. It was initially designed
    for authors, but it can also be used to analyze super timelines. You can import
    the CSV files created using the plaso framework.'
  id: totrans-188
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Timeline Explorer**: This can be found at [ericzimmerman.github.io/#!index.md](https://ericzimmerman.github.io#%252521index.md).
    Timeline Explorer is an open-source platform created by Eric Zimmerman, who wanted
    a tool to read MAC time and plaso-generated CSV files without the need to use
    Microsoft Excel. It is not designed to examine very large CSV files; in fact,
    Zimmerman recommends explicitly that it is best to open smaller, targeted timelines
    than one giant one.'
  id: totrans-189
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Media analysis
  id: totrans-190
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can use timeline analysis on several vectors, such as network analysis,
    media analysis, software analysis, and hardware analysis. Network analysis is
    where you analyze log files, trace files, and the communication content between
    users and their devices. Media analysis is analyzing physical storage devices
    such as hard drives, SSD drives, thumb drives, or optical storage disks. You will
    examine the content, allocated space, and slack space. Finally, when performing
    software analysis, you reverse-engineer malicious code and analyze the protection
    code for potential exports.
  id: totrans-191
  prefs: []
  type: TYPE_NORMAL
- en: So, let’s look at media analysis. The primary source for your digital investigation
    will be the forensic images of storage devices such as hard drives, SSDs, USB
    devices, optical disks, and mobile devices such as smartphones. Depending on your
    organization, you may be the person responsible for creating the forensic image,
    or the forensic image may be provided to you from another part of the organization.
    Remember, the forensic image is a bit-for-bit copy of the source device. In most
    cases, you do not want to use a backup as the source of your digital forensic
    investigation because a backup will not contain all of the information on the
    storage device.
  id: totrans-192
  prefs: []
  type: TYPE_NORMAL
- en: 'The storage device may contain four different data types that you want to examine:'
  id: totrans-193
  prefs: []
  type: TYPE_NORMAL
- en: '**Allocated space**: This is the space on the storage device that a file occupies.
    The filesystem recognizes the storage space as being used.'
  id: totrans-194
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unallocated space**: This is the space on the storage device that is not
    occupied by a file. The filesystem recognizes the storage space as being available
    for use.'
  id: totrans-195
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Slack space**: When the data is stored in a cluster, if the file does not
    completely fill a cluster, the remaining space not used by the file is referred
    to as slack space.'
  id: totrans-196
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Bad blocks/sectors/clusters**: This is the space on the disk that has been
    marked bad by the filesystem because of a defect. It can also be used by a user
    to hide data from a casual inspection.'
  id: totrans-197
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Brian Carrier describes the progression of media analysis in his paper “Defining
    Digital Forensic Examination and Analysis Tools” as follows:'
  id: totrans-198
  prefs: []
  type: TYPE_NORMAL
- en: '**Disk**: Physical storage devices such as a hard disk drive, SSD, or flash
    media.'
  id: totrans-199
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Volume**: A container comprising a single disk or multiple disks. You may
    find numerous volumes on a single disk or a volume may span across multiple discs.
    You may see the term “volume” used interchangeably with the term “partition.”
    Brian Carrier defines a partition as being restricted to a single physical disk,
    whereas a volume is a collection of one or more partitions.'
  id: totrans-200
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Filesystem**: This is used within the boundaries of a volume and tracks file
    allocation and cluster use.'
  id: totrans-201
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data unit**: The smallest allocation unit available to the filesystem. In
    most cases, this will be clusters, or, in a UNIX-based system, it will be blocks.'
  id: totrans-202
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metadata**: This is the data about data. This includes the modified, accessed,
    and created date-time stamps, as well as any other information about the file
    that the filesystem and some applications track.'
  id: totrans-203
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The goal of media analysis in your digital forensic investigation is to find
    relevant artifacts that will either prove or disprove the allegations you are
    investigating. In addition, as you conduct the digital forensic investigation,
    you may find artifacts that will direct your focus to other locations.
  id: totrans-204
  prefs: []
  type: TYPE_NORMAL
- en: We will now discuss some different analysis techniques that you might use during
    your digital forensic investigation.
  id: totrans-205
  prefs: []
  type: TYPE_NORMAL
- en: String search
  id: totrans-206
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: A search method you might use during your digital forensic investigation is
    a string or byte search. This search technique is utilized when you have a keyword
    list of specific terms that you wish to search for. Most commercial and open-source
    forensic tools allow for string searches and will search the allocated, unallocated,
    and file slack spaces. You can use specific words, symbols, or strings of letters
    as the search criteria. Generally, you will want to have some predefined keyword
    lists before you start your digital forensic investigation.
  id: totrans-207
  prefs: []
  type: TYPE_NORMAL
- en: 'Your keyword lists will fall into one of the following categories:'
  id: totrans-208
  prefs: []
  type: TYPE_NORMAL
- en: '**Generic keyword list**: This is a keyword list that you will use in every
    case. This list can also be further categorized by the subject of the investigation.
    For example, you may have one keyword list for digital forensic investigations
    into fraudulent activity and a different keyword list for digital forensic investigations
    into illicit images.'
  id: totrans-209
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Case-specific keyword list**: This is a keyword list that you will use for
    a specific digital forensic investigation. As you prepare to conduct your digital
    forensic investigation, you will identify keywords based on the participants,
    locations, and, sometimes, the slang used by the participants. For example, you
    could have keywords based on usernames, email addresses, physical addresses, phone
    numbers, credit card numbers, and more.'
  id: totrans-210
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Note**'
  id: totrans-211
  prefs: []
  type: TYPE_NORMAL
- en: You should avoid keyword terms that are generic or have additional meanings.
    For example, if you were investigating a homicide, the word “kill” seems to be
    a valid term to search for. Unfortunately, “kill” is also a term used in the programming
    language(s) you will find in a computer system. This will leave you with a large
    number of false positives. Ideally, the goal is to have the keyword list to help
    filter out non-pertinent data so that you can focus your efforts efficiently.
  id: totrans-212
  prefs: []
  type: TYPE_NORMAL
- en: 'You may encounter different encoding schemes as you are conducting your searches
    on forensic images, such as the following:'
  id: totrans-213
  prefs: []
  type: TYPE_NORMAL
- en: '**American Standard Code for Information Interchange** (**ASCII**) is a character-encoding
    scheme based initially on U.S. English and is limited to 256-character codes.'
  id: totrans-214
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Unicode** was developed to overcome the limitations of ASCII. Each character
    has a unique 2-byte value resulting in the ability to define over 65,000 characters.'
  id: totrans-215
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While keyword searching can be very powerful, there is a downside to this, as
    it is very literal when searching for content based on the keyword. For example,
    if you search for a word, it will not find an alternative spelling; that is, if
    you are searching for `ally`, the filter will not find `alley`. Luckily, there
    is an alternative search methodology known as pattern matching/regular expressions.
  id: totrans-216
  prefs: []
  type: TYPE_NORMAL
- en: 'A regular expression uses character strings to create a search pattern, and
    it will find all instances that match the pattern. Here are some common symbols
    and their meanings when used to create a regular expression:'
  id: totrans-217
  prefs: []
  type: TYPE_NORMAL
- en: '**The asterisk symbol (**`*`**)**: Match the preceding character(s) for `X`
    amount of times. For example, `ca*t` will cause positive hits for `ct`, `cat`,
    `caat`, and `caaat`.'
  id: totrans-218
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The pound sign (**`#`**)**: This will match a number (0-9).'
  id: totrans-219
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The backslash (**`\`**)**: The following character will be interpreted literally.
    `\.` will be construed as a period.'
  id: totrans-220
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Caret (**`^`**)**: Match the start of the text. For example, `^123` will
    cause the positive hits to start with `123`.'
  id: totrans-221
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**The dollar sign (**`$`**)**: Match the end of the text. For example, `123$`
    will cause positive hits to end with `123`.'
  id: totrans-222
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Plus symbol (**`+`**)**: Repeat the preceding character(s) for one or more
    times. For example, `ca+t` will cause positive hits for `cat`, `caat`, and `caaat`.'
  id: totrans-223
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Curly brackets** `{…}`: Repeat the preceding character(s) for `X` times (depending
    on the value in the bracket).'
  id: totrans-224
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Brackets** `[...]`: This will match a single character in the brackets. For
    example, `[b,c,d]` will match on b, c, or d.'
  id: totrans-225
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Brackets w/ ^ [^...]**: This will match any single character not in the brackets.
    For example, `[^b,c,d]` will match any character other than b, c, or d.'
  id: totrans-226
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Brackets (range) [..-..]**: This will match any character within the given
    range. `[0-9]` will match any character from 0 to 9.'
  id: totrans-227
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Dot** (`.`): The dot can take the place of any character.'
  id: totrans-228
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Question mark (**`?`**)**: The preceding character may/may not be present.
    For example, `.e01?` will return `.e0(x)` values. `x` shows it may find any value
    after`.e0`.'
  id: totrans-229
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Pipe (**`|`**)**: This matches any one-character set separated by the pipe
    (`|`) character. For example, `br(ead|ake|east)` will return matches for bread
    or brake or breast.'
  id: totrans-230
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The following are some common examples of pattern matching that you may find
    helpful.
  id: totrans-231
  prefs: []
  type: TYPE_NORMAL
- en: 'To search for an IP address, you can use the following regular expression:'
  id: totrans-232
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  id: totrans-233
  prefs: []
  type: TYPE_PRE
  zh: '[PRE12]'
- en: The `\d` specifies that the following will match on a digit (number). The curly
    brackets, `{1,3}`, indicate the number can be from one to three digits. `\.` specifies
    a search for the `.` character. The `\d{1,3}` pattern then repeats an additional
    three times until it has the value for an IPv4 address.
  id: totrans-234
  prefs: []
  type: TYPE_NORMAL
- en: 'To search for a US phone number, you can use the following expression:'
  id: totrans-235
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  id: totrans-236
  prefs: []
  type: TYPE_PRE
  zh: '[PRE13]'
- en: 'The `\(` will match the open bracket. `\d{3}` will match on a three-digit number.
    `\)` will match on the closed bracket. This pattern will give you the area code,
    `(###)`, in this format. The remaining regular expression will give you the first
    three digits, `\d{3}`, the dash, `-`, and the final four digits, `\d{4}`, of the
    US phone number. If the phone number is not formatted as `(###) ###-####` or `###-###-####`,
    you will not get a hit.'
  id: totrans-237
  prefs: []
  type: TYPE_NORMAL
- en: Regular expressions are a powerful tool, but they can also be very complicated
    to craft. I like to use the regular expression library (which can be found at
    [http://regexlib.com/Default.aspx](http://regexlib.com/Default.aspx)) to help
    me with my regular expression skills.
  id: totrans-238
  prefs: []
  type: TYPE_NORMAL
- en: So, what happens when the user deletes a file or folder from the media? Let’s
    discuss what happens when a file or folder is deleted next.
  id: totrans-239
  prefs: []
  type: TYPE_NORMAL
- en: Recovering deleted data
  id: totrans-240
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When a file is deleted in the FAT filesystem, the data itself does not get changed.
    The first character of the directory entry will have it changed to a `xE5` and
    the file allocation table entries are reset to `x00`. When the filesystem reads
    the directory entries, and it encounters the `xE5`, it will skip that entry and
    start reading from the subsequent entries.
  id: totrans-241
  prefs: []
  type: TYPE_NORMAL
- en: 'To recover deleted files, we need to reverse the process the filesystem used
    to delete the files. Remember, it has not changed the file contents; they still
    physically reside in their assigned clusters. We now need to reverse-engineer
    the deletion and recreate the file entry and the entries in the file allocation
    table. To do this, we need to find the first cluster of the file, the size of
    the file, and the size of the clusters in the volume:'
  id: totrans-242
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18329_05_16.png)'
  id: totrans-243
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.15: Deleted entry'
  id: totrans-244
  prefs: []
  type: TYPE_NORMAL
- en: In the preceding screenshot, we have a directory entry showing that a file has
    been deleted. We see the `xE5` at the start of the directory entry. (This will
    require the use of a hex editor to make the changes.) Then, we have to determine
    the starting cluster, `x00 x08` (which is shown as `x08 x00`), which is cluster
    number `8`. To determine the file size, look at the last four bytes (remember
    that the FAT filesystem stores data in little-endian format, which means that
    the least-significant byte is on the left, so we would read that value as `x00
    x00 x00 x27`, not as it is displayed, `x27 x00 x00 x00`), and when we convert
    the hexadecimal value to a decimal, we get the value of 39 bytes for the file
    size.
  id: totrans-245
  prefs: []
  type: TYPE_NORMAL
- en: 'Now we have to determine how many sectors make up a cluster and what the sector
    size is. You will need to go to the boot record to get that information. The boot
    record shows that there are 512 bytes per sector, and there are 8 sectors per
    cluster, which gives us a cluster size of 4,096 bytes:'
  id: totrans-246
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18329_05_17.png)'
  id: totrans-247
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.16: Boot record'
  id: totrans-248
  prefs: []
  type: TYPE_NORMAL
- en: 'This means that our file will only occupy a single cluster. We then go to the
    file allocation table and look at the entry for cluster 8 and see that it is zeroed
    out:'
  id: totrans-249
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/B18329_05_18.png)'
  id: totrans-250
  prefs: []
  type: TYPE_IMG
- en: 'Figure 5.17: Deleted FAT'
  id: totrans-251
  prefs: []
  type: TYPE_NORMAL
- en: 'To recover the deleted file, perform the following steps:'
  id: totrans-252
  prefs: []
  type: TYPE_NORMAL
- en: You need to change the entry in the file allocation table from `x0000 x0000`
    to `xFFFF FFF8` or `xFFFF FF0F`. If this were a larger file, you would need to
    change the file allocation table entry to point to the next cluster until you
    reach the cluster that contains the end of the file. Should you find an entry
    marked as allocated before you reach the end of the file, you may be dealing with
    a fragmented file. Another possibility is when the clusters were made available
    for use when the file was deleted, the data from a new file was placed in the
    available space. This would cause the old data to be overwritten with the data
    from the new file.
  id: totrans-253
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: The next step is to go back to the directory entry and replace `xE5` with another
    character. When replacing the `xE5` character of the filename in the directory
    entry, be careful not to guess what the character is. If you select an incorrect
    character, you could change the meaning or create a bias with the new filename,
    and that would be improper.
  id: totrans-254
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: I recommend that when you recover a deleted file, you replace that first character
    with an underscore or a dash so there is no misunderstanding about the filename.
  id: totrans-255
  prefs: []
  type: TYPE_NORMAL
- en: When recovering a file with a long filename, it is important to relink the long
    filename to the short filename. This is because when the additional directories
    are created to accommodate the long filename, the system creates a checksum based
    on the data of the short filename. When you changed the `xE5` value on the short
    filename entry, you also want to use the same replacement character for the subsequent
    `xE5` entries for the long filename directory entries. The reason for linking
    the long filename to the short filename is that the short filename directory entry
    contains information such as the date and times, the starting cluster, and the
    file size.
  id: totrans-256
  prefs: []
  type: TYPE_NORMAL
- en: As we discussed in *Chapter 4*, *Computer Systems**,* when a file/directory
    is created on an NTFS volume, the system creates an entry in the `$MFT` file.
    The MFT record will contain the metadata about the file/directory; if the contents
    of the file are non-resident, then the `$Bitmap` file will be updated to show
    the clusters occupied by the file are allocated.
  id: totrans-257
  prefs: []
  type: TYPE_NORMAL
- en: When a file/directory is deleted, then the sequence count in the MFT file record’s
    header is incremented by one digit. The allocation status for the record will
    change from allocated to unallocated. If the file data is non-resident, the system
    will update the `$Bitmap` file to show the clusters occupied by the file are now
    unallocated.
  id: totrans-258
  prefs: []
  type: TYPE_NORMAL
- en: Every MFT file entry will start with the file signature of the file, which you
    can use as a search term to locate MFT file entries in unallocated space. Until
    the clusters containing the data on the disk are overwritten, we can recover the
    data.
  id: totrans-259
  prefs: []
  type: TYPE_NORMAL
- en: If the MFT file record is unused, then you can reverse the steps and recover
    the file. You can decipher the file record, as we discussed in *Chapter 4*, *Computer
    Systems*. If the file is resident within the file record, you will recover the
    data when you retrieve the MFT file record. If the data is non-resident, then
    you will have to decipher the MFT file record to determine whether the data runs
    and identify the occupied clusters.
  id: totrans-260
  prefs: []
  type: TYPE_NORMAL
- en: If the system has overwritten the MFT file record, then you cannot recover the
    deleted MFT file record data or any resident data. You may recover the non-resident
    data, but that will depend on the size of the files and the fragmentation. Once
    the MFT record has been overwritten, you will lose any information regarding the
    data runs and which clusters contain the data.
  id: totrans-261
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  id: totrans-262
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this chapter, we discussed, in detail, timeline creation and timeline analysis
    with open-source and commercial forensic tools. We took an in-depth look at utilizing
    the commercial forensic tool, X-Ways Forensics, and the open-source plaso framework
    for `log2timeline`. We also touched upon using the kitchen sink approach or a
    targeted examination of the dataset. Remember, we are not analyzing the contents
    of files, just the timelines associated with the files and other events within
    the operating system and filesystems.
  id: totrans-263
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will discuss the contents of files, specifically, Windows
    artifacts.
  id: totrans-264
  prefs: []
  type: TYPE_NORMAL
- en: Questions
  id: totrans-265
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: It is important for the examiner to know the time zone in which the evidence
    was collected.
  id: totrans-266
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  id: totrans-267
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  id: totrans-268
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You can do timeline analysis with X-Way Forensics when you create a(n) ______
    list.
  id: totrans-269
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Timeline
  id: totrans-270
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Date/time
  id: totrans-271
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Event
  id: totrans-272
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Party
  id: totrans-273
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Plaso is a framework for how many tools?
  id: totrans-274
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: One
  id: totrans-275
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Three
  id: totrans-276
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Five
  id: totrans-277
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Seven
  id: totrans-278
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`pinfo` will give you what information?'
  id: totrans-279
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Information about the examiner
  id: totrans-280
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Information about the database file
  id: totrans-281
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Information about the forensic machine
  id: totrans-282
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Information about the suspect
  id: totrans-283
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`log2timeline` is a ___________ -based tool.'
  id: totrans-284
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: CLI
  id: totrans-285
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: GUI
  id: totrans-286
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: VFD
  id: totrans-287
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: XYZ
  id: totrans-288
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '`psort` will give you the ___________.'
  id: totrans-289
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Ability to sort
  id: totrans-290
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Ability to filter
  id: totrans-291
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Ability to connect
  id: totrans-292
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: All of the above
  id: totrans-293
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: You can do a timeline analysis with an Excel spreadsheet.
  id: totrans-294
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'True'
  id: totrans-295
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'False'
  id: totrans-296
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: Further reading
  id: totrans-297
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'You can refer to the following links for more information on the topics covered
    in this chapter:'
  id: totrans-298
  prefs: []
  type: TYPE_NORMAL
- en: '*T. P. P. A. (2019, July 8). Plaso Documentation. Retrieved from The Plaso
    Project*: [https://buildmedia.readthedocs.org/media/pdf/plaso/latest/plaso.pdf](https://buildmedia.readthedocs.org/media/pdf/plaso/latest/plaso.pdf)'
  id: totrans-299
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Carvey, H. (2014). Windows forensic analysis toolkit: Advanced analysis techniques
    for Windows 8; Waltham, MA: Syngress*. Available at: [https://www.abebooks.com/servlet/SearchResults?sts=t&cm_sp=SearchF-_-home-_-Results&an=&tn=Windows+forensic+analysis+toolkit&kn=&isbn=](https://www.abebooks.com/servlet/SearchResults?sts=t&cm_sp=SearchF-_-home-_-Results&an=&tn=Windows+forensic+analysis+toolkit&kn=&isbn=
    )'
  id: totrans-300
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Exercise
  id: totrans-301
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Data set
  id: totrans-302
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: '`Chapter 5 Emails.xlsx`'
  id: totrans-303
  prefs: []
  type: TYPE_NORMAL
- en: '`Chapter 5 Carving.dd`'
  id: totrans-304
  prefs: []
  type: TYPE_NORMAL
- en: Software needed
  id: totrans-305
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Timeline Explorer - [https://ericzimmerman.github.io/#!index.md](https://ericzimmerman.github.io/#!index.md)
  id: totrans-306
  prefs: []
  type: TYPE_NORMAL
- en: Microsoft .NET 6 or newer is required. You will get errors without at least
    .NET 6\. When in doubt, install it! Make sure you get the **Desktop** runtime
    if you plan on running any of the GUI programs.
  id: totrans-307
  prefs: []
  type: TYPE_NORMAL
- en: Autopsy - [https://www.autopsy.com/](https://www.autopsy.com/)
  id: totrans-308
  prefs: []
  type: TYPE_NORMAL
- en: Email exercise
  id: totrans-309
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: An individual outside of m57.biz purchased a laptop from Craigslist. The laptop
    the individual purchased contained child pornography and they decided to inform
    the police about it.
  id: totrans-310
  prefs: []
  type: TYPE_NORMAL
- en: Investigators were able to trace the laptop back to m57.biz. When the police
    contacted the CEO of m57.biz, the CEO reported that the laptop, as well as other
    items, had been stolen from the m57 inventory.
  id: totrans-311
  prefs: []
  type: TYPE_NORMAL
- en: The m57 CEO gave consent for the police investigators to search m57.biz and
    image all of the m57.biz computers, company phones, as well as USB drives.
  id: totrans-312
  prefs: []
  type: TYPE_NORMAL
- en: Analyze the emails found in the `Chapter 5 emails.xlsx` spreadsheet and identify
    potential suspects and a timeline of their activity.
  id: totrans-313
  prefs: []
  type: TYPE_NORMAL
- en: Data carving exercise
  id: totrans-314
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Load Autopsy and start a new case.
  id: totrans-315
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Select **Disk Image** or **VM file** for the data source.
  id: totrans-316
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Navigate to the folder where you stored the image `Chapter 5 Carving.dd`. Select
    only the following Ingest Modules:'
  id: totrans-317
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: PhotoRec Carver Embedded File Extractor
  id: totrans-318
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: From the drop-down menu, select **All files**, **Directory**, and **Unallocated
    Space**.
  id: totrans-319
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: Analyze the results.
  id: totrans-320
  prefs: []
  type: TYPE_NORMAL
- en: Join our community on Discord
  id: totrans-321
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Join our community’s Discord space for discussions with the author and other
    readers:'
  id: totrans-322
  prefs: []
  type: TYPE_NORMAL
- en: '[https://packt.link/CyberSec](https://packt.link/CyberSec)'
  id: totrans-323
  prefs: []
  type: TYPE_NORMAL
- en: '![](img/QR_Code3852467292877112093.png)'
  id: totrans-324
  prefs: []
  type: TYPE_IMG
