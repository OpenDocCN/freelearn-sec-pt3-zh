<html><head></head><body>
<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2"><h1 class="chapter-number" id="_idParaDest-97"><a id="_idTextAnchor108" class="pcalibre1 pcalibre2 pcalibre"/>6</h1>

<h3 id="_idParaDest-98" class="calibre6"><a id="_idTextAnchor109" class="pcalibre1 pcalibre2 pcalibre"/>DFIR Investigations – Logs in GCP</h3>
<p class="calibre3">You must have noticed each cloud service provider’s common resources and elements by now. In this chapter, we will dive straight into the security capabilities of <strong class="bold">Google Cloud Platform</strong> (<strong class="bold">GCP</strong>), what log sources are available, and how we can conduct our investigation. Note that cloud providers may use common terminologies. However, the applications and availability of logs may differ for each cloud service provider. Therefore, it is essential to understand which logs will be available during an <span>incident investigation.</span></p>
<p class="calibre3">In <a href="part0021_split_000.html#_idTextAnchor042" class="pcalibre1 pcalibre2 pcalibre"><span><em class="italic">Chapter 3</em></span></a>, we briefly introduced specific cloud service offerings within GCP; in this chapter, we will dig deep into some of its core components and digital forensics. This chapter outlines the logs available for some of the critical GCP services and products discussed in <a href="part0021_split_000.html#_idTextAnchor042" class="pcalibre1 pcalibre2 pcalibre"><span><em class="italic">Chapter 3</em></span></a> and looks at utilizing these sources in the context of <span>an investigation.</span></p>
<p class="calibre3">Specifically, we will discuss the following topics in <span>this chapter:</span></p>

<ul class="calibre12">
<li class="calibre13">GCP <span>core services</span></li>
<li class="calibre13">GCP identity and <span>access management</span></li>
<li class="calibre13"><span>Policy Analyzer</span></li>
<li class="calibre13">GCP <span>Logs Explorer</span></li>
<li class="calibre13">VPC <span>Flow Logs</span></li>
<li class="calibre13"><span>Packet Mirroring</span></li>
<li class="calibre13">Compute <span>Engine logs</span></li>
<li class="calibre13">Logging <span>Dataflow pipelines</span></li>
<li class="calibre13">GCP <span>storage logs</span></li>
<li class="calibre13">Cloud Security <span>Command Center</span></li>
<li class="calibre13">GCP <span>Cloud Shell</span></li>
</ul>
<p class="calibre3">We will discuss Google Workspace in <a href="part0026_split_000.html#_idTextAnchor137" class="pcalibre1 pcalibre2 pcalibre"><span><em class="italic">Chapter 7</em></span></a>, along with Microsoft 365 (M365), as these relate to email and cloud-hosted <span>collaboration services.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h1 id="_idParaDest-99" class="calibre5"><a id="_idTextAnchor110" class="pcalibre1 pcalibre2 pcalibre"/>GCP core services</h1>
<p class="calibre3">GCP is a suite of cloud computing services provided by Google. It offers a wide range of tools and services to build, deploy, and manage applications and infrastructure in the cloud. It provides services similar to <a id="_idIndexMarker386" class="pcalibre1 pcalibre2 pcalibre"/>cloud providers, such as AWS and <span>Microsoft Azure.</span></p>
<p class="calibre3">Here are some of the critical service offerings <span>from GCP:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Compute services</strong>: GCP offers <a id="_idIndexMarker387" class="pcalibre1 pcalibre2 pcalibre"/>several compute options, including <strong class="bold">Google Compute Engine</strong> (<strong class="bold">GCE</strong>) (<strong class="bold">virtual </strong><strong class="bold"><a id="_idIndexMarker388" class="pcalibre1 pcalibre2 pcalibre"/></strong><strong class="bold">machines</strong> [<strong class="bold">VM</strong>s]), <strong class="bold">Google Kubernetes Engine</strong> (<strong class="bold">GKE</strong>) (managed Kubernetes), and <strong class="bold">App Engine</strong> (managed platform <span>for applications)</span></li>
<li class="calibre13"><strong class="bold">Storage services</strong>: GCP provides <a id="_idIndexMarker389" class="pcalibre1 pcalibre2 pcalibre"/>various storage options<a id="_idIndexMarker390" class="pcalibre1 pcalibre2 pcalibre"/> such as <strong class="bold">Google Cloud Storage</strong> (<strong class="bold">GCS</strong>) (object storage), <strong class="bold">Cloud SQL</strong> (relational database <a id="_idIndexMarker391" class="pcalibre1 pcalibre2 pcalibre"/>service), <strong class="bold">Cloud Bigtable</strong> (NoSQL<a id="_idIndexMarker392" class="pcalibre1 pcalibre2 pcalibre"/> database), and <strong class="bold">Cloud Firestore</strong> (<span>document </span><span><a id="_idIndexMarker393" class="pcalibre1 pcalibre2 pcalibre"/></span><span>database)</span></li>
<li class="calibre13"><strong class="bold">Networking</strong>: GCP offers networking services such as <strong class="bold">Virtual Private Cloud </strong>(<strong class="bold">VPC</strong>) for<a id="_idIndexMarker394" class="pcalibre1 pcalibre2 pcalibre"/> creating <a id="_idIndexMarker395" class="pcalibre1 pcalibre2 pcalibre"/>private networks, <strong class="bold">Cloud Load Balancing</strong> for distributing traffic, and <strong class="bold">Cloud CDN</strong> for <span>content</span><span><a id="_idIndexMarker396" class="pcalibre1 pcalibre2 pcalibre"/></span><span> delivery</span></li>
<li class="calibre13"><strong class="bold">Big data and machine learning</strong>: GCP includes<a id="_idIndexMarker397" class="pcalibre1 pcalibre2 pcalibre"/> services such<a id="_idIndexMarker398" class="pcalibre1 pcalibre2 pcalibre"/> as <strong class="bold">BigQuery</strong> (serverless data warehouse), <strong class="bold">Cloud Dataflow</strong> (data processing), <strong class="bold">Cloud Pub/Sub</strong> (messaging and event<a id="_idIndexMarker399" class="pcalibre1 pcalibre2 pcalibre"/> streaming), and <strong class="bold">Cloud Machine Learning Engine</strong> (managed <a id="_idIndexMarker400" class="pcalibre1 pcalibre2 pcalibre"/><span>machine learning)</span></li>
<li class="calibre13"><strong class="bold">Identity and access management</strong> (<strong class="bold">IAM</strong>): IAM <a id="_idIndexMarker401" class="pcalibre1 pcalibre2 pcalibre"/>allows you to manage access to GCP resources and services, defining roles and permissions for users <span>and groups</span></li>
<li class="calibre13"><strong class="bold">Management and monitoring</strong>: GCP provides tools for managing and monitoring your resources, such as <strong class="bold">Cloud Console</strong> (web-based management interface), <strong class="bold">Cloud Logging</strong> (centralized <a id="_idIndexMarker402" class="pcalibre1 pcalibre2 pcalibre"/>log management), <strong class="bold">Cloud Monitoring </strong>(performance <a id="_idIndexMarker403" class="pcalibre1 pcalibre2 pcalibre"/>and health monitoring), and <strong class="bold">Cloud Trace</strong> (request <span>latency analysis)</span></li>
<li class="calibre13"><strong class="bold">Security and compliance</strong>: GCP incorporates various security features, including encryption at rest and in<a id="_idIndexMarker404" class="pcalibre1 pcalibre2 pcalibre"/> transit, IAM roles and policies, VPC Service Controls, and compliance certifications to meet <span>industry standards</span></li>
<li class="calibre13"><strong class="bold">Developer tools</strong>: GCP offers developer<a id="_idIndexMarker405" class="pcalibre1 pcalibre2 pcalibre"/> tools such as <strong class="bold">Cloud SDK</strong> (command-line tools), <strong class="bold">Cloud Build</strong> (continuous integration and delivery), and <strong class="bold">Cloud Source Repositories</strong> (version <span>control system)</span></li>
<li class="calibre13"><strong class="bold">AI and ML services</strong>: GCP provides pre-trained AI models and APIs through services such as <strong class="bold">Cloud Vision API</strong>, <strong class="bold">Cloud Natural Language API</strong>, and <strong class="bold">Cloud Translation API</strong>, enabling <a id="_idIndexMarker406" class="pcalibre1 pcalibre2 pcalibre"/>developers to integrate AI capabilities into <span>their applications</span></li>
<li class="calibre13"><strong class="bold">Serverless computing</strong>: GCP offers serverless services such as <strong class="bold">Cloud Functions</strong> (event-driven functions), <strong class="bold">Cloud Run</strong> (serverless containers), and <strong class="bold">Cloud Scheduler</strong> (cron <span>job </span><span><a id="_idIndexMarker407" class="pcalibre1 pcalibre2 pcalibre"/></span><span>scheduler)</span></li>
</ul>
<p class="calibre3">Now that we have looked at the core services GCP offers, we can dive deeper into specific services that investigators would be interested in. The focus will be on specific GCP services that form the backbone of any investigations, including identities, logs from the Compute Engine, and so on. We will start with GCP’s IAM console that is core to allowing users access to the <span>GCP resources.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h1 id="_idParaDest-100" class="calibre5"><a id="_idTextAnchor111" class="pcalibre1 pcalibre2 pcalibre"/>GCP IAM</h1>
<p class="calibre3">IAM provides a framework for <a id="_idIndexMarker408" class="pcalibre1 pcalibre2 pcalibre"/>controlling resource access within the GCP realm by defining the relationships between identities, roles, and the corresponding resources. Within this system, the concept of resources extends to include a wide array of entities, such as GCE VM<a id="_idIndexMarker409" class="pcalibre1 pcalibre2 pcalibre"/> instances, GKE clusters, <strong class="bold">Cloud Storage buckets</strong>, and the organizational structure consisting of organizations, folders, <span>and projects.</span></p>
<p class="calibre3">IAM operates on the principle that direct access permissions are not granted to end users; instead, permissions are organized into roles, which are subsequently assigned to authenticated principals or members (Google account, service account, Google group, authenticated users, cloud identity <span>domain, etc.).</span></p>
<p class="calibre3">Central to IAM’s<a id="_idIndexMarker410" class="pcalibre1 pcalibre2 pcalibre"/> functioning is the <strong class="bold">allow policy</strong>, or <strong class="bold">IAM policy</strong>, which serves as the mechanism for specifying and enforcing <a id="_idIndexMarker411" class="pcalibre1 pcalibre2 pcalibre"/>the assignment of roles to principals. Each allow policy is linked to a specific resource. When an authenticated principal attempts to access a resource, IAM examines the associated allow policy, thereby ascertaining the permissibility of the intended action based on its stipulations. While the allow policy lets you set guidelines to allow access to specific resources, GCP will also enable you <a id="_idIndexMarker412" class="pcalibre1 pcalibre2 pcalibre"/>to set up a <strong class="bold">deny policy</strong> that specifies what users or roles do not have access to. A deny policy lets you set up a deny rule based on specific conditions that determine the permissibility of the resource. Deny policy examples include setting restrictions on defining new API keys or deleting or editing GCE resources <span>or configurations.</span></p>
<p class="calibre3">By embracing IAM within the GCP ecosystem, organizations can establish granular control over access privileges, ensuring that identities are assigned only the necessary roles to interact with designated resources. This approach to access management enables increased security and effective governance over the <span>GCP environment.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h2 id="_idParaDest-101" class="calibre10"><a id="_idTextAnchor112" class="pcalibre1 pcalibre2 pcalibre"/>GCP’s IAM roles and identities</h2>
<p class="calibre3">From the perspective of incident response and forensics, it is essential to understand how cloud service providers <a id="_idIndexMarker413" class="pcalibre1 pcalibre2 pcalibre"/>organize and provision identities and privileges to these identities. Note that handling identities is generally different for each cloud <span>service provider.</span></p>
<p class="calibre3">In the case of GCP, end users do not directly get assigned privileges. Instead, privileges are assigned to <strong class="bold">roles</strong>. You can imagine roles as a group or a collection of privileges that grant access to various services within GCP’s environment. Users or API services needing to access these resources are termed <strong class="bold">principals</strong> by GCP. Therefore, privileges are assigned to roles, and roles are attached to principals. A policy is a collection of roles that can be attached to one or <span>more principals.</span></p>
<p class="calibre3">The following figure<a id="_idIndexMarker414" class="pcalibre1 pcalibre2 pcalibre"/> summarizes how IAM policies are defined, assigned, enforced, and ultimately managed through GCP’s <span>IAM module:</span></p>
<p class="calibre3"> </p>
<div class="calibre2">
<div class="img---figure" id="_idContainer095"><img alt="Figure 6.1 – GCP‘s IAM enforcement architecture" src="../images/00013.jpeg" class="calibre101"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.1 – GCP‘s IAM enforcement architecture</p>
<p class="calibre3">While the preceding figure just illustrates a generic version of how permissions can be assigned to each GCP resource, GCP also offers federated integration to active directories to manage access to GCP resources. This, however, uses a similar concept to enforce IAM policies. You can create granular allow and deny policies to enforce specific resource elements. For example, you can allow access to an instance within GCE while restricting access to <span>other instances.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h1 id="_idParaDest-102" class="calibre5"><a id="_idTextAnchor113" class="pcalibre1 pcalibre2 pcalibre"/>Policy Analyzer</h1>
<p class="calibre3">Given that IAM assignments occur over roles where principals are assigned access permissions to a resource using roles, GCP<a id="_idIndexMarker415" class="pcalibre1 pcalibre2 pcalibre"/> offers additional tools for troubleshooting and investigating IAM policy configurations. Policy Analyzer allows DFIR teams to analyze excess privileges assigned to users or roles that may have resulted in abuse. Policy Analyzer can also determine whether a user has the necessary permissions to perform specific actions, such as deleting a table, a GCE resource, and <span>so on.</span></p>
<p class="calibre3">The following is an example of Policy Analyzer’s output. We can see in the query result what roles and permissions were configured for a user under a GCP resource. Note that resources are allocated toward a project, and GCP tags them <span>as resources:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer096"><img alt="Figure 6.2 – Policy Analyzer query results and list of permissions per role" src="../images/00032.jpeg" class="calibre102"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.2 – Policy Analyzer query results and list of permissions per role</p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h2 id="_idParaDest-103" class="calibre10"><a id="_idTextAnchor114" class="pcalibre1 pcalibre2 pcalibre"/>DFIR use cases for Policy Analyzer</h2>
<p class="calibre3">Using a policy analyzer in the context of DFIR within GCP enables organizations to evaluate compliance and security <a id="_idIndexMarker416" class="pcalibre1 pcalibre2 pcalibre"/>across various GCP resources. Here are some use cases for GCP <span>Policy Analyzer:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">IAM policies</strong>: Analyzing IAM policies includes assessing roles assigned to users, service accounts, and groups, as well as identifying potential misconfigurations or overly <span>permissive access.</span></li>
<li class="calibre13"><strong class="bold">Network security policies</strong>: Review firewalls, network configurations, and routing policies to ensure proper network segmentation and secure connectivity and protection against <span>unauthorized access.</span></li>
<li class="calibre13"><strong class="bold">Data encryption and key management policies</strong>: Verify that data encryption policies are enforced for sensitive information at rest and in transit. This involves assessing the usage of encryption keys, key rotation practices, and compliance with <span>encryption standards.</span></li>
<li class="calibre13"><strong class="bold">Logging and monitoring policies</strong>: Assess logging configurations and monitoring practices to ensure that appropriate logs are generated and retained and that log analysis tools are properly configured to detect security incidents and <span>abnormal activities.</span></li>
<li class="calibre13"><strong class="bold">Service account and API access policies</strong>: Verify the security of service accounts and API access configurations. This includes assessing permissions granted to service accounts, auditing the usage of service accounts, and ensuring proper management and revocation of API <span>access credentials.</span></li>
</ul>
<p class="calibre3">As you can see, GCP Policy<a id="_idIndexMarker417" class="pcalibre1 pcalibre2 pcalibre"/> Analyzer helps identify policy violations and non-compliant resources. However, it does not provide information on the activity performed due to policy deviations; we need Logs Explorer to identify specific actions performed. We will look at GCP Logs Explorer, which ingests and hosts detailed logs and has advanced filtering options and real-time log streaming capabilities, making it essential for any investigator <span>to use.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h1 id="_idParaDest-104" class="calibre5"><a id="_idTextAnchor115" class="pcalibre1 pcalibre2 pcalibre"/>GCP Logs Explorer</h1>
<p class="calibre3">GCP designed <strong class="bold">Logs Explorer</strong> to troubleshoot performance issues with applications and systems by reviewing the logs. The user interface for Logs Explorer features a histogram that displays log rates <a id="_idIndexMarker418" class="pcalibre1 pcalibre2 pcalibre"/>and associated spikes. Nevertheless, where there are logs, you can always use them to investigate their incident. Google also offers the Logs Explorer API, which allows automation or query logs via a Python program or any other medium through an API key. The following screenshot is an example of GCP’s histogram on Logs Explorer that highlights activities <span>by time:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer097"><img alt="Figure 6.3 – GCP’s Logs Explorer histogram" src="../images/00050.jpeg" class="calibre103"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.3 – GCP’s Logs Explorer histogram</p>
<p class="calibre3">However, Logs Explorer only displays logs per period; it does not quantify or correlate the logs against other activities within the system. You can set the time range for which you want to see the logs, with a default log retention of 30 days. For this, GCP offers <strong class="bold">Log Analytics</strong>, a separate service that <a id="_idIndexMarker419" class="pcalibre1 pcalibre2 pcalibre"/>allows real-time analytics on the roles to allow log aggregation and quantification of the logs collected. This is a separate service and requires you to explicitly upgrade your log bucket to allow GCP to perform log analytics. GCP Log Analytics enables <a id="_idIndexMarker420" class="pcalibre1 pcalibre2 pcalibre"/>users to use <strong class="bold">BigQuery</strong> on the logs. BigQuery is a data warehouse where users can perform queries on massive datasets and perform analytics on them. GCP offers BigQuery as a separate service, which is not available by default. For example, you can run BigQuery to query your logs against known malicious domains from a threat <span>intelligence </span><span><a id="_idIndexMarker421" class="pcalibre1 pcalibre2 pcalibre"/></span><span>source.</span></p>
<p class="calibre3">For DFIR teams to access Logs Explorer, teams must be assigned the <span>following roles:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="source-inline">roles/logging.viewer</strong>: For viewing all logs under the<strong class="source-inline">_Required</strong> and <span><strong class="source-inline">_Default</strong></span><span> buckets.</span></li>
<li class="calibre13"><strong class="source-inline">roles/logging.privateLogViewer</strong>: For viewing all logs, including data <span>access logs.</span></li>
<li class="calibre13"><strong class="source-inline">roles/logging.viewAccessor</strong>: Condition-based log view that grants access to user-defined logs. This role grants access to logs within a user-defined bucket if no condition <span>is specified.</span></li>
<li class="calibre13"><strong class="source-inline">Roles/logging.fieldAccessor</strong>: For viewing restricted fields within a log entry bucket. You will need to configure <span>field-level access.</span></li>
</ul>
</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h2 id="_idParaDest-105" class="calibre10"><a id="_idTextAnchor116" class="pcalibre1 pcalibre2 pcalibre"/>Overview of log buckets</h2>
<p class="calibre3">Every log a resource generates is ingested by a Cloud Logging infrastructure that determines the conditions and criteria for the bucket assignments for log storage, known as log <strong class="bold">sinks</strong>. Log sinks <a id="_idIndexMarker422" class="pcalibre1 pcalibre2 pcalibre"/>are part of GCP’s logging infrastructure that <a id="_idIndexMarker423" class="pcalibre1 pcalibre2 pcalibre"/>determines how logs are routed to relevant log buckets. GCP also allows you to export these logs to a third-party log aggregation tool through a Pub/Sub topic that helps third-party log aggregation tools subscribe to Pub/Sub to authorize and import <span>the logs.</span></p>
<p class="calibre3">GCP offers two pre-defined log buckets, <strong class="source-inline">_Required</strong> and <strong class="source-inline">_Default</strong>. Buckets are independent of each other and serve as a default destination per GCP account for logging required logs. Users/administrators can also create their sinks/buckets, which are classified as user-defined buckets. As log entries are passed to logging infrastructure, log routing is initiated, in which, based upon the configured filters for inclusion and exclusion of the log entry, logs are routed to appropriate sinks or redirected to Pub/Sub topics for external consumption, or the logs are dropped altogether. Logs can also be redirected to the BigQuery dataset, allowing users to run Log Analytics for correlation and <span>further analysis.</span></p>
<p class="calibre3">As indicated previously, cloud log entries are, by default, routed to one of these <span>log buckets:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="source-inline">_Required</strong>: The <strong class="source-inline">_Required</strong> log buckets collect the following types <span>of logs:</span><ul class="calibre17"><li class="calibre13"><strong class="bold">Admin Activity logs</strong>: These contain log entries for API calls for reading resource metadata or configuration. For <a id="_idIndexMarker424" class="pcalibre1 pcalibre2 pcalibre"/>example, an API call to read GCE configurations is recorded under <span>this sub-category.</span></li><li class="calibre13"><strong class="bold">System Event logs</strong>: Any changes to a cloud resource, for example, GCE, are recorded under this sub-category. Users/administrators cannot turn off logging this type of log by creating an exclusion filter; it is <span>always recorded.</span></li><li class="calibre13"><strong class="bold">Access Transparency logs</strong>: Any actions performed by Google Cloud members within a GCP account are recorded under this log. This allows a transparent view into any actions the cloud service provider performs – in this <span>case, Google.</span></li></ul></li>
<li class="calibre13"><strong class="source-inline">_Default</strong>: Any logs that do not satisfy the conditions of the <strong class="source-inline">_Required</strong> bucket are routed to <strong class="source-inline">_Default</strong> buckets. The following types of logs are <span>automatically redirected:</span><ul class="calibre17"><li class="calibre13"><strong class="bold">Data Access logs</strong>: These are log entries that include what API calls were made to access metadata or configuration information about a GCP resource. Data Access logs are typically voluminous and are disabled by default. If you run BigQuery, then Data Access logs are enabled. Therefore, it is essential to understand the operating resources and whether the logs <span>are enabled.</span></li><li class="calibre13"><strong class="bold">Policy Denied logs</strong>: As the name suggests, log entries are categorized as Policy Denied logs when GCP denies access to a resource based on a defined set of conditions or policies. Policy Denied logs are enabled by default and cannot be disabled. However, you can configure an exclusion filter not to record <span>these logs.</span></li></ul></li>
<li class="calibre13"><strong class="bold">User-defined bucket</strong>: These are log buckets created by users to collect a subset of logs produced by GCP resources. You can create your user-defined bucket in any cloud project. When you create a log bucket, you do have to specify the region in <a id="_idIndexMarker425" class="pcalibre1 pcalibre2 pcalibre"/>which the log bucket will <span>be stored.</span></li>
</ul>
</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h2 id="_idParaDest-106" class="calibre10"><a id="_idTextAnchor117" class="pcalibre1 pcalibre2 pcalibre"/>DFIR use cases for using Logs Explorer</h2>
<p class="calibre3">The following are some of the DFIR use<a id="_idIndexMarker426" class="pcalibre1 pcalibre2 pcalibre"/> cases for utilizing GCP’s native <span>Logs Explorer:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Incident investigation</strong>: During an incident, Logs Explorer enables you to search and analyze logs across various GCP services. You can correlate events from different logs to reconstruct the timeline of an incident, identify the root cause, and determine the extent of <span>the impact.</span></li>
<li class="calibre13"><strong class="bold">Threat hunting</strong>: Logs Explorer allows you to query and filter logs based on specific criteria or patterns related to known threats or <strong class="bold">indicators of compromise</strong> (<strong class="bold">IOCs</strong>). By analyzing logs from<a id="_idIndexMarker427" class="pcalibre1 pcalibre2 pcalibre"/> GCP services such as Cloud Storage, Cloud Functions, or Cloud Pub/Sub, you can proactively search for suspicious activities or <span>abnormal behavior.</span></li>
<li class="calibre13"><strong class="bold">User activity monitoring</strong>: Logs Explorer provides visibility into user activities within GCP services. You can track user logins, administrative actions, API calls, and resource access to identify unauthorized or suspicious actions. This information can help detect insider threats or compromised <span>user accounts.</span></li>
<li class="calibre13"><strong class="bold">Data leak and exposure detection</strong>: Logs Explorer can be employed to identify potential data leaks or exfiltration attempts. By analyzing logs from relevant services, such as Cloud Storage or BigQuery, you can search for patterns indicative of unauthorized data access, large data transfers, or unusual <span>data egress.</span></li>
<li class="calibre13"><strong class="bold">Forensic analysis</strong>: Logs Explorer can serve as a valuable source of evidence during forensic investigations. By querying and analyzing logs, you can reconstruct events, identify the actions taken by an attacker, or track the movement of an <a id="_idIndexMarker428" class="pcalibre1 pcalibre2 pcalibre"/>adversary within your <span>GCP environment.</span></li>
</ul>
</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h2 id="_idParaDest-107" class="calibre10"><a id="_idTextAnchor118" class="pcalibre1 pcalibre2 pcalibre"/>Familiarizing with Logs Explorer</h2>
<p class="calibre3">We’ll look at an example of querying Logs <a id="_idIndexMarker429" class="pcalibre1 pcalibre2 pcalibre"/>Explorer. Logs Explorer has handy features allowing investigators to click and filter relevant artifacts. Let’s familiarize ourselves with multiple areas of <span>Logs Explorer:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer098"><img alt="Figure 6.4 – Logs Explorer overview" src="../images/00067.jpeg" class="calibre104"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.4 – Logs Explorer overview</p>
<p class="calibre3">As we can see in the Logs Explorer dashboard, a few key elements will be helpful to security teams. We have numbered them for your <span>easier reference:</span></p>

<ol class="calibre14">
<li class="calibre13"><strong class="bold">Date/time filter</strong>: This allows the teams to nail down specific events and activities that may have occurred within a <span>time range.</span></li>
<li class="calibre13"><strong class="bold">Query pane</strong>: This text bar allows the team to search queries manually. Note that this search query term will automatically be updated when you click and update <span>the filter.</span></li>
<li class="calibre13"><strong class="bold">Query filter fields</strong>: This enables the teams to filter specific GCP resources, objects or logs, and types of logs. Note that we have filtered records associated with a VM instance, with severity as an error in <span>this example.</span></li>
<li class="calibre13"><strong class="bold">Log fields pane</strong>: This view gives the user a more granular view into the number of events per type of logs filter or severity rating. As indicated earlier, every record is categorized before it is routed to relevant log <span>storage destinations.</span></li>
<li class="calibre13"><strong class="bold">Query results pane</strong>: This <a id="_idIndexMarker430" class="pcalibre1 pcalibre2 pcalibre"/>view lets the user look into the logs more thoroughly. Each entry allows the user to expand and view all the fields within a log entry and perform additional filtering based on <span>investigative leads.</span></li>
</ol>
<p class="calibre3">Our next section will look into a sample investigation using Logs Explorer, but first, let us look at VPC <span>Flow Logs.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h1 id="_idParaDest-108" class="calibre5"><a id="_idTextAnchor119" class="pcalibre1 pcalibre2 pcalibre"/>VPC Flow Logs</h1>
<p class="calibre3">Like AWS, VPC Flow Logs are not enabled for GCE by default. Turning on VPC Flow Logs is relatively easy and requires minimal effort. It’s important to note that VPC Flow Logs are aggregated by time in minutes and summarized in a dashboard that includes relevant information. VPC Flow Logs are enabled at the subnet level, meaning every flow log is associated with a subnet<a id="_idIndexMarker431" class="pcalibre1 pcalibre2 pcalibre"/> that your GCE is part of. This typically refers to GCP’s internal subnet architecture. Turning on VPC Flow Logs for a noisy server may generate many logs, ultimately <span>impacting costs.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h2 id="_idParaDest-109" class="calibre10"><a id="_idTextAnchor120" class="pcalibre1 pcalibre2 pcalibre"/>Enabling VPC Flow Logs</h2>
<p class="calibre3">To analyze traffic, you must first enable VPC Flow Logs within GCE. As GCEs are created by default, a regional VPC acts as the <a id="_idIndexMarker432" class="pcalibre1 pcalibre2 pcalibre"/>network gateway for the virtual server to access the internet or other GCP resources. Alternatively, if a custom VPC node is created, you must ensure that the VPC Flow Log option is turned on for the GCE to send logs to Logs Explorer. We’ll look at an example for one of the GCEs under <span>network details.</span></p>
<p class="calibre3">Like AWS, VPC Flow Logs are not automatically enabled and require manual activation. GCP provides a range of customizable network settings, including the ability to create subnets, establish firewall rules, and set up VPC connections. The following figure displays the VPC network configured for one of the regions with a custom VPC network <span>called </span><span><strong class="source-inline">test-lab1</strong></span><span>:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer099"><img alt="Figure 6.5 – Network subnet details for a GCE" src="../images/00085.jpeg" class="calibre105"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.5 – Network subnet details for a GCE</p>
<p class="calibre3">VPC Flow Logs are subnet-specific; therefore, it is essential to note that when enabling VPC Flow Logs, you must make changes to the VPC subnet and allow the flow logs to be collected. If the GCE has more than one VPC connected to the instance, you must verify and enable each VPC subnet to<a id="_idIndexMarker433" class="pcalibre1 pcalibre2 pcalibre"/> collect flow logs. In the following figure, we look at the sample customized VPC we created named <strong class="source-inline">test-lab1</strong> with a VPC subnet <span>named </span><span><strong class="source-inline">subnet-lab1</strong></span><span>:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer100"><img alt="Figure 6.6 – VPC subnet information" src="../images/00104.jpeg" class="calibre106"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.6 – VPC subnet information</p>
<p class="calibre3">Click and edit the subnet name and select the option for turning <strong class="bold">FLOW LOGS</strong> on or off. Once enabled, specify the frequency of aggregation of network packets. Remember that VPC Flow Logs only collect header information, not full packet details. As a result, it is essential to weigh the aggregation frequency and identify the most suitable time interval for aggregation. Packet aggregation can occur at 5-second, 30-second, 1-minute, 5-minute, 10-minute, and <span>15-minute intervals.</span></p>
<p class="calibre3">Suppose GCP resources produce a lot of network traffic throughout the day; in that case, a higher frequency flow log aggregation can be set to allow granular network traffic visibility. Low-frequency<a id="_idIndexMarker434" class="pcalibre1 pcalibre2 pcalibre"/> flow log aggregation is suitable for those who do not have a lot of network traffic activity. The following figure demonstrates the option for setting <span>flow logs:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer101"><img alt="Figure 6.7 – Enabling VPC Flow Logs under a VPC subnet" src="../images/00127.jpeg" class="calibre107"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.7 – Enabling VPC Flow Logs under a VPC subnet</p>
<p class="calibre3">While setting up the flow logs, select the sample rate of the packets that will be aggregated into the flow logs and reported to Logs Explorer, ideally at 100%. This means that 100% of observed traffic is sent to Logs Explorer and not downsized to a specific percentage of traffic activity. The following figure demonstrates the subnet configuration with a sample rate of 100% of the observed network traffic with an aggregation interval of <span>5 seconds:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer102"><img alt="Figure 6.8 – Flow log network aggregation configuration" src="../images/00147.jpeg" class="calibre108"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.8 – Flow log network aggregation configuration</p>
<p class="calibre3">Once the VPC is configured, flow logs are automatically sent to Logs Explorer, where investigators can begin threat hunting. The following section will demonstrate an example use case<a id="_idIndexMarker435" class="pcalibre1 pcalibre2 pcalibre"/> for using Logs Explorer and hunting VPC Flow Logs for <span>malicious activities.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h2 id="_idParaDest-110" class="calibre10"><a id="_idTextAnchor121" class="pcalibre1 pcalibre2 pcalibre"/>Hunting VPC Flow Logs for malicious activities</h2>
<p class="calibre3">In this scenario, we have a GCP Cloud Storage bucket named <strong class="source-inline">app-data1</strong> with a few backups critical for the organization. The<a id="_idIndexMarker436" class="pcalibre1 pcalibre2 pcalibre"/> infrastructure setup is such that any internal GCP resource or application can access GCP Cloud Storage but is not publicly available to users or on the internet. The following figure indicates a list of Cloud Storage objects stored within the <span><strong class="source-inline">app-data1</strong></span><span> bucket:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer103"><img alt="Figure 6.9 – Cloud Storage view" src="../images/00164.jpeg" class="calibre109"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.9 – Cloud Storage view</p>
<p class="calibre3">We have a threat actor who is using a GCE VM, <strong class="source-inline">cf1-ta-vm,</strong> (with an internal IP address of <strong class="source-inline">10.0.0.15</strong> and an external IP of <strong class="source-inline">34.152.3.1</strong>) to grab these files from Cloud Storage and ultimately <a id="_idIndexMarker437" class="pcalibre1 pcalibre2 pcalibre"/>exfiltrate the data to a threat actor-controlled remote server <span>at </span><span><strong class="source-inline">3.98.136.11</strong></span><span>.</span></p>
<p class="calibre3">We will now look into using Logs Explorer to hunt for threat actor activity concerning this <span>GCE resource:</span></p>

<ol class="calibre14">
<li class="calibre13">As a first step, we begin by selecting appropriate event times within the Logs Explorer dashboard to capture the most <span>relevant events.</span></li>
<li class="calibre13">We then look for the associated log entry when this file was uploaded to the GCS bucket. Investigators must pay attention to the <strong class="source-inline">methodName</strong> attribute with the <strong class="source-inline">storage.objects.create</strong> value, indicating that the object was created within a specific bucket. The following figure illustrates the log record created when uploaded to the bucket and the full file path identified within the <span><strong class="source-inline">resourceName</strong></span><span> attribute:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer104"><img alt="Figure 6.10 – Log entry for object uploaded to GCS bucket" src="../images/00183.jpeg" class="calibre110"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.10 – Log entry for object uploaded to GCS bucket</p>

<ol class="calibre14">
<li value="3" class="calibre13">The next step is to look for any GCE VMs accessing this resource. Using the log fields pane (as described in <span><em class="italic">Figure 6</em></span><em class="italic">.4</em>), we will filter the logs relevant to the purpose of the investigation. As logs are filtered, the <strong class="bold">Query</strong> pane is automatically updated. Using the result query within the <strong class="bold">Query results</strong> pane, tag the JSON formatted<a id="_idIndexMarker438" class="pcalibre1 pcalibre2 pcalibre"/> results for <strong class="source-inline">src_ip</strong> (source IP), <strong class="source-inline">dest_ip</strong> (destination IP), and <strong class="source-inline">bytes_sent</strong> (bytes sent) to be visualized within the log entry summaries. Right-click and access these options for tagging fields. Notice that the following figure demonstrates tagging key fields for easier visualization <span>and investigation:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer105"><img alt="Figure 6.11 – Logs Explorer field filters" src="../images/00002.jpeg" class="calibre111"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.11 – Logs Explorer field filters</p>

<ol class="calibre14">
<li value="4" class="calibre13">Once relevant filters are applied to support the investigation, we can review the log entries within Logs Explorer and identify threat actor activities. From the Logs Explorer view, we can see that the threat actor first copied the files from GCS to the GCE VM with the <strong class="source-inline">cf1-ta-vm</strong> hostname and associated IP address (<strong class="source-inline">10.0.0.15</strong>) as the destination IP. Given that the transfer is within GCP’s infrastructure, the transfers<a id="_idIndexMarker439" class="pcalibre1 pcalibre2 pcalibre"/> occur through GCP’s backend network infrastructure. Notice the bytes sent size within the following snippet with the order of tags as <strong class="source-inline">src_ip</strong> followed by <strong class="source-inline">dest_ip</strong> <span>and </span><span><strong class="source-inline">bytes_sent</strong></span><span>:</span></li>
</ol>
<div class="calibre2">
<div class="img---figure" id="_idContainer106"><img alt="Figure 6.12 – Query result for GCS data transfer to GCE" src="../images/00019.jpeg" class="calibre112"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.12 – Query result for GCS data transfer to GCE</p>

<ol class="calibre14">
<li value="5" class="calibre13">Putting the pieces together, we have determined that GCS storage objects were copied to a local GCE host. We now flip the destination IP and identify whether that GCE host was<a id="_idIndexMarker440" class="pcalibre1 pcalibre2 pcalibre"/> responsible for outbound connections. We apply filters on the source IP address as <strong class="source-inline">10.0.0.15</strong> and immediately see the outbound connection to a remote server along with the <strong class="source-inline">bytes_sent</strong> values, which we attribute to a threat <span>actor-controlled server.</span></li>
</ol>
<p class="calibre3"> </p>
<div class="calibre2">
<div class="img---figure" id="_idContainer107"><img alt="Figure 6.13 – Logs Explorer hunting for outbound connections" src="../images/00037.jpeg" class="calibre113"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.13 – Logs Explorer hunting for outbound connections</p>
<p class="calibre3">As we can see through the sequence of steps illustrated, investigators can extract relevant event logs attributed to threat actor activities through interactive filtering capabilities and click-through filters to the log fields. There is always the option of extracting all the logs, performing<a id="_idIndexMarker441" class="pcalibre1 pcalibre2 pcalibre"/> an offline analysis, and slicing-and-dicing them further to determine specific actions the threat actor performs. There are various ways, however, for command-line entries to be extracted. Investigation teams can use this information to obtain a complete snapshot of the GCE. We will explore this mechanism in <a href="part0030_split_000.html#_idTextAnchor199" class="pcalibre1 pcalibre2 pcalibre"><span><em class="italic">Chapter 10</em></span></a><span>.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">Logs Explorer has limitations on recording commands entered within the GCE; any commands entered by the user or the threat actor are not recorded within <span>Logs Explorer.</span></p>
<p class="calibre3">Expanding on network monitoring capabilities, let us delve into GCP’s Packet Mirroring feature, which complements the insights provided by VPC <span>Flow Logs.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h1 id="_idParaDest-111" class="calibre5"><a id="_idTextAnchor122" class="pcalibre1 pcalibre2 pcalibre"/>Packet Mirroring</h1>
<p class="calibre3">GCP’s Packet Mirroring feature <a id="_idIndexMarker442" class="pcalibre1 pcalibre2 pcalibre"/>allows security teams to collect network packets from VMs and identify security threats or activities associated with the VMs. GCP’s Packet Mirroring only mirrors traffic between VMs and external interfaces and does not mirror traffic between cluster nodes such as GKE. We will learn more about containers, including <strong class="bold">Docker</strong> and <strong class="bold">Kubernetes</strong>, in <a href="part0031_split_000.html#_idTextAnchor217" class="pcalibre1 pcalibre2 pcalibre"><span><em class="italic">Chapter 11</em></span></a><span>.</span></p>
<p class="calibre3">To mirror packets, ensure the principals are attached with the <strong class="source-inline">compute.packetMirrorUser</strong> and <span><strong class="source-inline">compute.packetMirroringAdmin</strong></span><span> roles.</span></p>
<p class="calibre3">An internal load balancer must be deployed with <strong class="bold">network passthrough</strong> capabilities that pass the traffic to the <strong class="bold">collector</strong> instances to enable packet mirroring. The load balancer must be pointed to a <strong class="bold">managed instance group</strong> in the backend with pre-configured instance templates, allowing GCP to <a id="_idIndexMarker443" class="pcalibre1 pcalibre2 pcalibre"/>create collector instances automatically. The collector instance can be a VM with tools for capturing and receiving network packets via the internal <span>load balancer.</span></p>
<p class="calibre3">When setting up an internal load balancer, ensure that it is created within the same region as the instance being mirrored, <strong class="bold">Session affinity</strong> is set to <strong class="bold">None</strong><strong class="source-inline">,</strong> and <strong class="bold">backend subsetting</strong> is not enabled. Also, ensure that packet forwarding rules are created on the load balancers to forward all the<a id="_idIndexMarker444" class="pcalibre1 pcalibre2 pcalibre"/> mirrored packets while configuring the load balancer. This setting cannot be changed <span>once configured.</span></p>
<p class="calibre3">When creating an internal load balancer, a managed instance group must be created and assigned VMs within that group. GCP will then determine this VM as part of the collector instance for packet mirroring <span>and capture.</span></p>
<p class="calibre3">The following figure demonstrates a simple configuration for an internal network load balancer. We created a sample load balancer, <strong class="source-inline">lb2</strong>, and configured it on <strong class="source-inline">subnet-lab1</strong> under the <strong class="source-inline">test-lab1</strong> VPC. We also created a managed instance group, <strong class="source-inline">instance-group1</strong>, that automatically makes the collector VMs for receiving <span>network packets:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer108"><img alt="Figure 6.14 – Internal load balancer configuration" src="../images/00054.jpeg" class="calibre114"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.14 – Internal load balancer configuration</p>
<p class="calibre3">Once a load balancer is <a id="_idIndexMarker445" class="pcalibre1 pcalibre2 pcalibre"/>created, configure the <strong class="bold">packet mirroring policy</strong> and specify the target VPC and subnet for the source of packet capture. Alternatively, select a suspect GCE from where the <a id="_idIndexMarker446" class="pcalibre1 pcalibre2 pcalibre"/>network packets will be collected. Note that the target VPC and collector instance must be created within the same network region for successfully <span>mirroring packets.</span></p>
<p class="calibre3">In the following screenshot, we configure the packet mirroring policy (<strong class="source-inline">pkt-mirror1</strong>) that defines the collector VM or VPC network (in this case, <strong class="source-inline">test-lab1</strong>) and the load balancers (specified in the form of a forwarding rule, <strong class="source-inline">lb2-forwarding-rule</strong>) the policy will be attached to. <strong class="bold">Policy enforcement</strong> must be turned on to enable <span>packet mirroring.</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer109"><img alt="Figure 6.15 – Packet mirroring policy" src="../images/00072.jpeg" class="calibre115"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.15 – Packet mirroring policy</p>
<p class="calibre3">The packet mirroring policy is also configured to forward and mirror packets associated with the <strong class="source-inline">test-lab1</strong> VPC, with <a id="_idIndexMarker447" class="pcalibre1 pcalibre2 pcalibre"/>the suspect VM attached <span>to </span><span><strong class="source-inline">subnet-lab1</strong></span><span>.</span></p>
<p class="calibre3">Now, in the collector VM, we begin collecting network packets by running <strong class="source-inline">tcpdump</strong>. Note the IP address of the suspect VM before initiating network <span>packet capture:</span></p>
<pre class="console">$ sudo tcpdump -i INTERFACE_NAME -f "host IP_ADDRESS" -w dump.pcap</pre>
<p class="calibre3">The following parameters are supplied when <span>running</span> <span><strong class="source-inline">tcpdump</strong></span><span>:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="source-inline">-i INTERFACE_NAME</strong>: Collector instance network interface name that will listen to network packets (<strong class="source-inline">ens33</strong>, <span><strong class="source-inline">enp03</strong></span><span>, etc.)</span></li>
<li class="calibre13"><strong class="source-inline">-f "IP_ADDRESS"</strong>: Filter flag to apply a packet capture based on a specific IP address of the <span>suspect VM</span></li>
</ul>
<p class="calibre3">Outputs from <strong class="source-inline">tcpdump</strong> can also be written to a file. In the example, we dump the packets using the <strong class="source-inline">-w</strong> flag and provide the <span>file location.</span></p>
<p class="calibre3">Investigators prefer to capture full packets recording all threat actor activities across multiple VMs via the VPC network before focusing on specific GCP services <span>for investigation.</span></p>
<p class="calibre3">Once the packets are written to<a id="_idIndexMarker448" class="pcalibre1 pcalibre2 pcalibre"/> the disk, the following GCP command-line options can be used to access GCP storage and <span>upload artifacts:</span></p>
<pre class="console">$ gcloud auth login</pre>
<p class="calibre3">It is assumed that the investigation team will have its own identities and associated roles attached to those identities (principals). First, you must log in by entering the preceding command and following the <span>on-screen instructions.</span></p>
<p class="calibre3">Once completed, you can access Google Cloud Storage and copy the artifacts using the <span>following command:</span></p>
<pre class="console">$ gsutil cp [SOURCE_FILE] gs://[BUCKET_NAME]/[DESTINATION_PATH]</pre>
<p class="calibre3">The following are the key parameters that are required to upload <span>artifacts successfully:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="source-inline">SOURCE_FILE</strong>: The source artifacts that the team would like <span>to investigate</span></li>
<li class="calibre13"><strong class="source-inline">BUCKET_NAME</strong>: The Google Cloud Storage <span>bucket name</span></li>
<li class="calibre13"><strong class="source-inline">DESTINATION_PATH</strong>: The destination folder path within the <span>storage bucket</span></li>
</ul>
<p class="calibre3">As we can see, the VPC Flow Logs offered by GCP present substantial data related to network traffic patterns, which can significantly enhance security and troubleshooting efforts. Packet mirroring amplifies the potential for monitoring and analyzing network traffic but also enables the identification of potential security threats in <span>real time.</span></p>
<p class="calibre3">The following section will examine more granular GCE logs, offering profound insights into activities and enabling correlation capabilities via <span>Logs Explorer.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h1 id="_idParaDest-112" class="calibre5"><a id="_idTextAnchor123" class="pcalibre1 pcalibre2 pcalibre"/>Compute Engine logs</h1>
<p class="calibre3">GCE is a service offered by GCP that allows users to create VMs within GCP’s infrastructure. These VMs can be hosted across any part of the world where GCP operates. It provides flexibility and scalability options, making various preconfigured VM instances available. It <a id="_idIndexMarker449" class="pcalibre1 pcalibre2 pcalibre"/>can create on demand or resize a VM based on requirements. Users can create a VM instance or a group of VMs<a id="_idIndexMarker450" class="pcalibre1 pcalibre2 pcalibre"/> through <strong class="bold">GCE Instance Group Manager</strong>, which manages the deployment and configuration <span>of VMs.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h2 id="_idParaDest-113" class="calibre10"><a id="_idTextAnchor124" class="pcalibre1 pcalibre2 pcalibre"/>GCP’s logging platform</h2>
<p class="calibre3">GCP’s Cloud Logging platform automatically collects and aggregates logs from various GCP resources via Logs Explorer. It offers a single-pane view of all the logs and filters, allowing investigators to hunt for <a id="_idIndexMarker451" class="pcalibre1 pcalibre2 pcalibre"/>specific alerts or threats and use them for monitoring. Some of the types of logs it collects are <span>as follows:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Platform logs</strong>: Generated through GCP’s services, these logs are used for debugging and troubleshooting. Examples of platform logs include VPC <span>Flow Logs.</span></li>
<li class="calibre13"><strong class="bold">Component logs</strong>: Similar to platform logs, these are generated by GCP’s software-based components, such as Kubernetes clusters. GKE logs are classified as <span>component logs.</span></li>
<li class="calibre13"><strong class="bold">Security logs</strong>: Two forms of security logs are collected within GCP; the first is <strong class="bold">Cloud Audit logs</strong>, which provide administrative information and activities performed by the administrator, supporting cloud audit and compliance requirements. Secondly, <strong class="bold">Access Transparency logs</strong> log any actions performed by Google’s staff directly on a Google Cloud tenant to allow for transparency <span>and compliance.</span></li>
<li class="calibre13"><strong class="bold">User-written logs</strong>: As the name suggests, they log any custom application logging, which can be sent to Cloud Logging through the OpsAgent, Logging Agent, Cloud Logging API, and other libraries. We will learn about the OpsAgent in a later part of <span>this chapter.</span></li>
<li class="calibre13"><strong class="bold">Multi-cloud and hybrid logs</strong>: These include logs from other cloud providers such as Microsoft Azure and on-premises infrastructure. They can be collected alongside GCP logs; however, there<a id="_idIndexMarker452" class="pcalibre1 pcalibre2 pcalibre"/> may be cost implications based on the number <span>of logs.</span></li>
</ul>
</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h2 id="_idParaDest-114" class="calibre10"><a id="_idTextAnchor125" class="pcalibre1 pcalibre2 pcalibre"/>GCP’s default logging</h2>
<p class="calibre3">Every VM within GCP is preconfigured to<a id="_idIndexMarker453" class="pcalibre1 pcalibre2 pcalibre"/> send default logs to the <strong class="bold">Cloud Logging platform</strong>. These include CPU utilization, memory utilization, network bandwidth consumption, and so on. While the telemetry collected is rudimentary, it is vital in determining whether any abnormal activities are detected within the monitoring console for <span>deep-dive investigation.</span></p>
<p class="calibre3">Specifically speaking of logging agents, Google primarily relies on the <strong class="bold">OpsAgent</strong>, legacy agents, and custom <span>logging packages.</span></p>

<h3 class="calibre11">OpsAgent</h3>
<p class="calibre3">GCP uses OpsAgent as the primary source for monitoring and collecting telemetric data from Windows and Linux-based systems. The OpsAgent is based on FluentBit, a third-party but lightweight logging and <a id="_idIndexMarker454" class="pcalibre1 pcalibre2 pcalibre"/>telemetry data provider that allows metrics collection in the <strong class="bold">Prometheus</strong> format. FluentBit (<strong class="bold">fluentd</strong>) handles automatic tagging and metrics parsing before sending it to the <span>logging platform.</span></p>
<p class="calibre3">Google also relies on <strong class="bold">OpenTelemetry Collector</strong>, another open source service, for <span>specific metrics.</span></p>
<p class="calibre3">GCP users can also configure their fluentd configuration for specific application-level logging that will be automatically sent to Google’s Cloud <span>Logging platform.</span></p>
<p class="calibre3">By using the OpsAgent and deploying custom configuration files (fluentd configurations), investigators can collect metrics and logs from various third-party applications such as Microsoft Active Directory, Apache Tomcat, <strong class="bold">Internet Information Services</strong> (<strong class="bold">IIS</strong>), MySQL, MariaDB, and many more. The OpsAgent also allows log collections <span>from GKE.</span></p>
<p class="calibre3">The following are some of the log sources that the OpsAgent collects <span>by default:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Files</strong>: Logs written to disk, such as <strong class="source-inline">/var/log/syslog</strong> and <strong class="source-inline">/var/log/messages</strong> <span>in Linux</span></li>
<li class="calibre13"><strong class="bold">Journald</strong> daemon and <span><strong class="bold">Systemd</strong></span><span> logs</span></li>
<li class="calibre13"><strong class="bold">TCP port</strong>: Listen to a TCP port and <span>collect logs</span></li>
<li class="calibre13"><strong class="bold">Windows event logs</strong>: Logs from Windows <span>operating systems</span></li>
<li class="calibre13"><strong class="bold">Fluentd Forward</strong>: Logs collected via Fluentd Forward <span>over TCP</span></li>
</ul>
<p class="calibre3">The following metrics are reported by the OpsAgent by default without any additional configuration on the host VM. These metrics help identify deviations from the baseline and, if a breach occurs, allow the <a id="_idIndexMarker455" class="pcalibre1 pcalibre2 pcalibre"/>security team to <span>respond immediately:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">CPU metrics</strong>: CPU states (idle, interrupt, system, and user), CPU load, CPU usage time, and <span>CPU utilization</span></li>
<li class="calibre13"><strong class="bold">Disk metrics</strong>: Disk used (bytes), disk I/O time, disk operations, disk pending operations, disk utilization (percent), disk bytes read, and disk <span>bytes written</span></li>
<li class="calibre13"><strong class="bold">IIS metrics (Windows)</strong>: IIS open connections, IIS transferred bytes, IIS connections, and <span>IIS requests</span></li>
<li class="calibre13"><strong class="bold">Network interface metrics</strong>: Network errors, packets, and <span>traffic (bytes)</span></li>
<li class="calibre13"><strong class="bold">Memory metrics</strong>: Memory usage, memory states (buffered, cached, free, slab, and used), and memory <span>utilization (percent)</span></li>
<li class="calibre13"><strong class="bold">MSSQL metrics</strong>: SQL server open connections, SQL server transaction rate, and SQL server write <span>transaction rate</span></li>
<li class="calibre13"><strong class="bold">Swap metrics (Linux only)</strong>: Swap usage, swap I/O operations, and swap <span>utilization (percent)</span></li>
<li class="calibre13"><strong class="bold">Network metrics</strong>: <span>TCP connections</span></li>
<li class="calibre13"><strong class="bold">Process metrics</strong>: Process count by states (running, sleeping, and zombie), process CPU time, process disk read I/O, process disk writes I/O, fork count, process resident memory (allocations), and process virtual <span>memory (usage)</span></li>
<li class="calibre13"><strong class="bold">Agent self metrics</strong>: Agent API request count, agent log entry count, agent memory usage, agent<a id="_idIndexMarker456" class="pcalibre1 pcalibre2 pcalibre"/> metric point count, agent enabled receiver count, and <span>agent uptime</span></li>
</ul>
<h3 class="calibre11">Legacy logging agent</h3>
<p class="calibre3">Google has currently deprecated<a id="_idIndexMarker457" class="pcalibre1 pcalibre2 pcalibre"/> the legacy logging agent. However, there are still VMs that require legacy agents, so they continue to be supported by Google. While fluentd is still being used here, the application utilizes older methodologies for collecting the metrics and routing them to <span>Logs Explorer.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h1 id="_idParaDest-115" class="calibre5"><a id="_idTextAnchor126" class="pcalibre1 pcalibre2 pcalibre"/>Logging Dataflow pipelines</h1>
<p class="calibre3">Dataflow pipelines provide a stream of data or batch processing capabilities at scale. GCP’s Dataflow pipeline is <a id="_idIndexMarker458" class="pcalibre1 pcalibre2 pcalibre"/>based on <strong class="bold">Apache Beam</strong>. Logs can be streamed at variable volumes in near real time using <span>Dataflow applications.</span></p>
<p class="calibre3">Any actions performed on GCP Dataflow are recorded by default in Logs Explorer. Through Logs Explorer, investigators can detect any changes to the Dataflow parameters or whether unauthorized users altered <span>the pipeline.</span></p>
<p class="calibre3">Note that a Docker instance forms the <a id="_idIndexMarker459" class="pcalibre1 pcalibre2 pcalibre"/>base of any Dataflow pipeline’s operations. Therefore, investigators must also investigate the logs emitted by the GKE cluster and GCE Instance Group Manager. GCP relies on Instance Group Manager to create multiple managed VMs that run the containers (GKE) to handle instance resourcing and deploying <span>VMs automatically.</span></p>
<p class="calibre3">The following figure outlines some sample resources required for successful Dataflow pipeline execution. Like <strong class="bold">Syslog</strong>, Dataflow events<a id="_idIndexMarker460" class="pcalibre1 pcalibre2 pcalibre"/> are tagged with a severity rating; it also generates the exact name of the job that emitted the log entry. Using the filters within Logs Explorer, relevant logs can be specifically targeted and investigated in a Dataflow job <span>or pipeline:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer110"><img alt="Figure 6.16 – Resource types for Dataflow pipeline execution" src="../images/00092.jpeg" class="calibre116"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.16 – Resource types for Dataflow pipeline execution</p>
<p class="calibre3">The following figure is a snippet <a id="_idIndexMarker461" class="pcalibre1 pcalibre2 pcalibre"/>of a log stream that outlines the sequence and flow of the logs emitted by the Dataflow service that triggers other resources such as Kubernetes, GCE Instance Group Manager, and <span>so on:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer111"><img alt="Figure 6.17 – Log streams emitted by GCP Dataflow" src="../images/00112.jpeg" class="calibre117"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.17 – Log streams emitted by GCP Dataflow</p>
<p class="calibre3">To summarize, monitoring and investigating Dataflow logs is no different from analyzing any other activity logs emitted by relevant GCP resources. It is essential to understand that when a resource is accessed, GCP in<a id="_idIndexMarker462" class="pcalibre1 pcalibre2 pcalibre"/> the backend may access other associated resources or dependencies to deliver the service, impacting the number of logs or the logs emitted by relevant <span>dependent services.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h1 id="_idParaDest-116" class="calibre5"><a id="_idTextAnchor127" class="pcalibre1 pcalibre2 pcalibre"/>GCP storage logs</h1>
<p class="calibre3">Like AWS’s S3 buckets, GCP<a id="_idIndexMarker463" class="pcalibre1 pcalibre2 pcalibre"/> Storage also refers to storage containers as buckets. Each bucket can <a id="_idIndexMarker464" class="pcalibre1 pcalibre2 pcalibre"/>contain any file format, referred to as an <strong class="bold">object</strong>. Principals can be assigned granular permissions and access to each bucket or object. Storage buckets can also be made publicly accessible on the internet, depending on the use case. Storage metadata is recorded in the key/value pair format at the bucket level to manage the object life cycle. Values assigned to keys can be a bucket name string or an array of object life cycle <span>management configurations.</span></p>
<p class="calibre3">Once a storage bucket is created, you cannot change the bucket name, the location (where the bucket is hosted), the project associated with the storage bucket, or the metadata generation number, uniquely identifying the <span>bucket state.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h2 id="_idParaDest-117" class="calibre10"><a id="_idTextAnchor128" class="pcalibre1 pcalibre2 pcalibre"/>Storage permissions</h2>
<p class="calibre3">Similar to IAM permissions, specific<a id="_idIndexMarker465" class="pcalibre1 pcalibre2 pcalibre"/> permissions are required for accessing objects by a resource or a principal. In GCP’s IAM realm, permissions are assigned to roles and roles are attached <span>to principals.</span></p>
<p class="calibre3">The following table outlines the list of permissions required for accessing <span>storage objects:</span></p>

<table class="t---table" id="table001-2">
<colgroup class="calibre22">
<col class="calibre23"/>
<col class="calibre23"/>
</colgroup>
<tbody class="calibre25">
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3"><span><strong class="bold">Permission name</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3"><span><strong class="bold">Description</strong></span></p>

</td>
</tr>
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">storage.buckets.create</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3">Creates a storage bucket within <span>a project</span></p>

</td>
</tr>
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">storage.buckets.delete</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3">Deletes a storage bucket from <span>a project</span></p>

</td>
</tr>
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">storage.buckets.get</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3">Reads metadata associated with the bucket, including <span>bucket configurations</span></p>

</td>
</tr>
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">storage.buckets.list</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3">Lists buckets in <span>a project</span></p>

</td>
</tr>
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">storage.buckets.update</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3">Updates metadata associated with the bucket and configuration of <span>the bucket</span></p>

</td>
</tr>
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">storage.buckets.getObjectInsights</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3">Reads metadata associated with the object within <span>the bucket</span></p>

</td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US">Table 6.1 – Minimum IAM permissions required to create and manage buckets</p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h2 id="_idParaDest-118" class="calibre10"><a id="_idTextAnchor129" class="pcalibre1 pcalibre2 pcalibre"/>Storage object logging</h2>
<p class="calibre3">Like all the resources within GCP, activities on storage buckets emit logs and are recorded within Logs<a id="_idIndexMarker466" class="pcalibre1 pcalibre2 pcalibre"/> Explorer; storage logs or access logs associated with the objects are also recorded within Logs Explorer. Investigators should, therefore, consider reviewing storage-related logs to determine evidence of data exfiltration and any threats against GCP’s <span>storage buckets.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h2 id="_idParaDest-119" class="calibre10"><a id="_idTextAnchor130" class="pcalibre1 pcalibre2 pcalibre"/>Investigating GCP Cloud storage logs</h2>
<p class="calibre3">When setting up GCP<a id="_idIndexMarker467" class="pcalibre1 pcalibre2 pcalibre"/> Cloud Storage, ensure that it has appropriate permissions set. This also includes public access prevention policies that must be turned on or off, depending on the <span>use case.</span></p>
<p class="calibre3">The following example will examine the logs to determine privilege escalation attempts to GCP’s Cloud Storage. For this purpose, we created a temporary storage folder, <strong class="source-inline">test_cf1_test1</strong>, and set it for non-public access to the folder; we have not enabled any fine-grained access control for <span>this purpose:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer112"><img alt="Figure 6.18 – GCP Cloud Storage configuration summary example" src="../images/00027.jpeg" class="calibre118"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.18 – GCP Cloud Storage configuration summary example</p>
<p class="calibre3">We will examine the storage<a id="_idIndexMarker468" class="pcalibre1 pcalibre2 pcalibre"/> logs within Logs Explorer. We evaluate the IAM policies <a id="_idIndexMarker469" class="pcalibre1 pcalibre2 pcalibre"/>configured using GCP’s <strong class="bold">command-line interface</strong> (<strong class="bold">CLI</strong>) in the following figure, using the <strong class="source-inline">gsutil iam get gs://test_cf1_test1</strong> command and requesting IAM policies configured for this bucket. This is equivalent to making a <strong class="source-inline">GET</strong> request to <strong class="source-inline">https://storage.googleapis.com/storage/v1/b/&lt;bucket&gt;/iam</strong>, but as an <span>authenticated user:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer113"><img alt="Figure 6.19 – IAM policies on a Cloud Storage folder example" src="../images/00170.jpeg" class="calibre119"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.19 – IAM policies on a Cloud Storage folder example</p>
<p class="calibre3">Note that the following primary roles are configured for the storage folder. GCP automatically applies legacy<a id="_idIndexMarker470" class="pcalibre1 pcalibre2 pcalibre"/> roles to buckets when owners create a <strong class="bold">uniform bucket-level access</strong> (meaning all <a id="_idIndexMarker471" class="pcalibre1 pcalibre2 pcalibre"/>objects within the bucket have similar access <span>permissions enabled):</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="source-inline">roles/storage.legacyBucketOwner</strong>: Principals with <strong class="source-inline">roles/editor</strong> or <strong class="source-inline">roles/owner</strong> are granted <span>this access</span></li>
<li class="calibre13"><strong class="source-inline">roles/storage.legacyBucketReader</strong>: Principals with <strong class="source-inline">roles/viewer</strong> are granted <span>this access</span></li>
<li class="calibre13"><strong class="source-inline">roles/storage.legacyObjectOwner</strong>: Principals with <strong class="source-inline">roles/editor</strong> or <strong class="source-inline">roles/owner</strong> are granted <span>this access</span></li>
<li class="calibre13"><strong class="source-inline">roles/storage.legacyObjectReader</strong>: Principals with <strong class="source-inline">roles/viewer</strong> are granted <span>this access</span></li>
</ul>
<p class="calibre3">Now we know that access to this folder is only limited to those users or principals with <strong class="source-inline">roles/editor</strong> access or <strong class="source-inline">roles/owner</strong> access. In summary, any other principals or general public access are not allowed for <span>this folder.</span></p>
<p class="calibre3">We will review Logs Explorer to determine the access requests made when an authenticated user or principal attempts to access the bucket using non-standard methods, such as accessing Cloud Storage buckets through a <span>Python program.</span></p>
<p class="calibre3">We will look at a log entry for an authenticated user attempting to access the bucket. Within the <strong class="source-inline">authorizationInfo</strong> section, we look specifically at the highlighted areas: <strong class="source-inline">CallerIP</strong>, which refers to the user’s IP address that is<a id="_idIndexMarker472" class="pcalibre1 pcalibre2 pcalibre"/> trying to access the bucket, and <strong class="source-inline">callerSuppliedUserAgent</strong> (<strong class="bold">user-agent</strong> string), which is reflective of the browser and operating system variant that the user is using to attempt to access the <a id="_idIndexMarker473" class="pcalibre1 pcalibre2 pcalibre"/>storage. Finally, we also look at what resource is being requested along with the assigned permission tagged to this bucket and object, and whether IAM granted <span>this access:</span></p>
<pre class="source-code">{
  [...]
    "requestMetadata": {
<strong class="bold">      "callerIp": "184.147.94.133",</strong>
<strong class="bold">      "callerSuppliedUserAgent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36,gzip(gfe),gzip(gfe)",</strong>
     [...]
     [...]
      {
<strong class="bold">        "resource": "projects/_/buckets/test_cf1_test1",</strong>
<strong class="bold">        "permission": "storage.buckets.getIamPolicy",</strong>
<strong class="bold">        "granted": true, }</strong></pre>
<p class="calibre3">Let us look at a situation where an unauthenticated user tries to gain access to GCP’s Cloud Storage buckets and objects outside of GCP’s Cloud console. Similar to the previous example, we’ll look at a similar form of log entry and look for the <strong class="source-inline">authorizationInfo</strong> section. The request is for accessing the <strong class="source-inline">test_cf1_test1</strong> bucket. In this case, note the user-agent string and IP address. Given that the user attempted to authenticate as the owner/principal, and since the access attempt was via a Python command-line application<a id="_idIndexMarker474" class="pcalibre1 pcalibre2 pcalibre"/> instead of a browser accessing the bucket, this permission was denied as there is no public access to the folder outside of the GCP console, GCP CLI, or <span>GCP API:</span></p>
<pre class="source-code">{
  [...]
    "status": {
<strong class="bold">      "code": 7,</strong>
<strong class="bold">      "message": "PERMISSION_DENIED"</strong>
    },
   [...]
    "requestMetadata": {
      "callerIp": "12.47.194.133",
<strong class="bold">      "callerSuppliedUserAgent": "python-requests/2.25.1,gzip(gfe)"}</strong>
      [...]
    "authorizationInfo": [
      {
<strong class="bold">        "resource": "projects/_/buckets/test_cf1_test1",</strong>
<strong class="bold">        "permission": "storage.buckets.get",</strong>
        [...]
<strong class="bold">  "severity": "ERROR",</strong>
  [...]
    }</pre>
<p class="calibre3">The following figure outlines the series of attempts while allowing access to GCP <span>API tools:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer114"><img alt="Figure 6.20 – Multiple denied access attempts to non-GCP applications while only allowing API access" src="../images/00068.jpeg" class="calibre120"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.20 – Multiple denied access attempts to non-GCP applications while only allowing API access</p>
<p class="calibre3">As we can see, Logs Explorer forms the basis of most of the investigative insights into activities performed by the user <a id="_idIndexMarker475" class="pcalibre1 pcalibre2 pcalibre"/>or <span>external resources.</span></p>
<p class="calibre3">Next, we will look into some of GCP’s dashboards that offer insight into the security status of the resources configured <span>within GCP.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h1 id="_idParaDest-120" class="calibre5"><a id="_idTextAnchor131" class="pcalibre1 pcalibre2 pcalibre"/>Cloud Security Command Center (Cloud SCC)</h1>
<p class="calibre3">Cloud SCC is like a dashboard for notifying organizations and security teams about possible threats or vulnerabilities. Cloud SCC is only available when a GCP account is set up as an organization. Individual GCP users do not have access to Cloud SCC. When<a id="_idIndexMarker476" class="pcalibre1 pcalibre2 pcalibre"/> an anomaly is identified, it creates a report of a particular threat or misconfiguration in GCP’s realm, called a <strong class="bold">finding</strong>. Cloud SCC <a id="_idIndexMarker477" class="pcalibre1 pcalibre2 pcalibre"/>provides a consolidated view of all the findings and anomalies detected within a cloud service, such as <span>a GCE.</span></p>
<p class="calibre3">Note that there are two activation levels; by default, organizations, when they sign up, are assigned the <strong class="bold">Standard service tier</strong>, which<a id="_idIndexMarker478" class="pcalibre1 pcalibre2 pcalibre"/> has limited functionality and includes looking at the general security health of GCEs and their configurations. It also includes features such as error reporting, continuous exports to Pub/Sub, and access to other integration points, including Cloud Data Loss Prevention, Cloud Armor, and <span>so on.</span></p>
<p class="calibre3">Google also offers a <strong class="bold">Premium service tier</strong>, which<a id="_idIndexMarker479" class="pcalibre1 pcalibre2 pcalibre"/> comes at a price that includes additional capabilities, as outlined in the following screenshot, such as <strong class="bold">Event Threat Detection</strong>, <strong class="bold">Web Security Scanner</strong>, <strong class="bold">Container Threat Detection</strong>, <strong class="bold">Virtual Machine Threat Detection</strong>, <strong class="bold">Security Health Analytics</strong>, and <strong class="bold">Rapid </strong><span><strong class="bold">vulnerability detection</strong></span><span>:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer115"><img alt="Figure 6.21 – Cloud SCC Premium subscriptions" src="../images/00113.jpeg" class="calibre121"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.21 – Cloud SCC Premium subscriptions</p>
<p class="calibre3">The following sections will <a id="_idIndexMarker480" class="pcalibre1 pcalibre2 pcalibre"/>examine some of the Cloud SCC capabilities in <span>more depth.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h2 id="_idParaDest-121" class="calibre10"><a id="_idTextAnchor132" class="pcalibre1 pcalibre2 pcalibre"/>IAM roles</h2>
<p class="calibre3">Now that we know GCP uses IAM roles to assign access to principals, it is vital to understand the various access privileges<a id="_idIndexMarker481" class="pcalibre1 pcalibre2 pcalibre"/> required for teams to have access to Cloud SCC dashboards and <span>other details.</span></p>
<p class="calibre3">From a DFIR perspective, the following roles are required for accessing the Cloud <span>SCC console:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="source-inline">roles/resourcemanager.organizationAdmin</strong>: Provides admin access at the organization level. An organization can have <span>multiple projects.</span></li>
<li class="calibre13"><strong class="source-inline">roles/securitycenter.admin</strong>: Administrative or superuser access to Cloud SCC and other resources within Cloud SCC. It provides access to <span>project-level detections.</span></li>
<li class="calibre13"><strong class="source-inline">roles/securitycenter.adminViewer</strong>: Admin read-only access to the security center. Users can view scan results and see threat detections. No changes are allowed. It provides access to <span>project-level detections.</span></li>
<li class="calibre13"><strong class="source-inline">roles/securitycenter.findingsViewer</strong>: Provides restrictive access to view only the findings generated within Cloud SCC for a <span>specific project.</span></li>
<li class="calibre13"><strong class="source-inline">roles/cloudsecurityscanner.editor</strong>: Provides project-level access, with administrative <a id="_idIndexMarker482" class="pcalibre1 pcalibre2 pcalibre"/>controls (read-write controls) to run cloud web scanning. Access to all the resources within the web scanner module <span>is provided.</span></li>
</ul>
</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h2 id="_idParaDest-122" class="calibre10"><a id="_idTextAnchor133" class="pcalibre1 pcalibre2 pcalibre"/>Threats and Findings dashboards</h2>
<p class="calibre3">The GCP <strong class="bold">Threats</strong> and <strong class="bold">Findings</strong> dashboards provide visibility into potential threats and security incidents, allowing organizations to <a id="_idIndexMarker483" class="pcalibre1 pcalibre2 pcalibre"/>manage security threats and findings within their GCP environment. They are a<a id="_idIndexMarker484" class="pcalibre1 pcalibre2 pcalibre"/> central hub for monitoring and analyzing security events and proactively detecting and responding to threats by aggregating data from various services and tools <span>within GCP.</span></p>
<p class="calibre3">The <strong class="bold">Threats</strong> dashboard displays threats per VM instance and threats identified within the overall GCP environment. This includes any potential misconfigurations and features that, as a result, introduced a vulnerability within the GCP environment. The following figure is a sample dashboard with <span>identified threats:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer116"><img alt="Figure 6.22 – Threats dashboard" src="../images/00135.jpeg" class="calibre122"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.22 – Threats dashboard</p>
<p class="calibre3">Details of identified threats are documented on the <strong class="bold">Findings</strong> page. Findings provide detailed information on the threat, severity, event detection time (event time), event reporting time (create time), GCP resource, GCP project, and resource type. Findings also allow investigators to <a id="_idIndexMarker485" class="pcalibre1 pcalibre2 pcalibre"/>utilize filters to investigate the identified findings further and gain an understanding of<a id="_idIndexMarker486" class="pcalibre1 pcalibre2 pcalibre"/> the threat. The following is the drill-down screenshot of an identified threat within the <span><strong class="bold">Findings</strong></span><span> section:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer117"><img alt="Figure 6.23 – Findings dashboard" src="../images/00086.jpeg" class="calibre123"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.23 – Findings dashboard</p>
<p class="calibre3">Note that findings are classified into <strong class="bold">Threat</strong>, <strong class="bold">Misconfiguration</strong>, or <strong class="bold">Vulnerability</strong>. By default, if investigators <a id="_idIndexMarker487" class="pcalibre1 pcalibre2 pcalibre"/>navigate to the <strong class="bold">Findings</strong> page, it will display all the findings that are not muted and have been active for the previous <span>seven days.</span></p>
<p class="calibre3">On the <strong class="bold">Findings</strong> page, within <a id="_idIndexMarker488" class="pcalibre1 pcalibre2 pcalibre"/>the <strong class="bold">Quick filters</strong> pane, investigators can quickly filter down the types of findings that they are interested in and are relevant to <span>the investigation:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer118"><img alt="Figure 6.24 – Findings quick filters" src="../images/00105.jpeg" class="calibre124"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.24 – Findings quick filters</p>
<p class="calibre3">Once filters are applied, the <a id="_idIndexMarker489" class="pcalibre1 pcalibre2 pcalibre"/>findings are available for review and investigators can determine more information. In the following screenshot, we have filtered down <strong class="bold">Open RDP port</strong> and identified <a id="_idIndexMarker490" class="pcalibre1 pcalibre2 pcalibre"/>two findings concerning the exposed RDP port. GCP has classified this detection as a <span>high-severity finding:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer119"><img alt="Figure 6.25 – Findings based on quick filters" src="../images/00196.jpeg" class="calibre125"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.25 – Findings based on quick filters</p>
<p class="calibre3">Each finding provides a link to get more details about the results that indicate what was detected, including <strong class="bold">Artificial Intelligence (AI) Generated Summary</strong>, <strong class="bold">Description</strong>, <strong class="bold">Affected Resource</strong>, <strong class="bold">Security Marks</strong>, suggested next steps, and related links to various standards and detection services. It also allows investigators to mute this detection to ensure that findings do not report on <span>similar exposures.</span></p>
<p class="calibre3">As we delve into the intricacies of Cloud SCC Assets, we will explore how this feature empowers investigators and security<a id="_idIndexMarker491" class="pcalibre1 pcalibre2 pcalibre"/> teams with a detailed inventory of GCP resources, identifying vulnerabilities, misconfigurations, and potential threats. This visibility lays the foundation for practical risk assessment and proactive security measures, ultimately fostering a more resilient and <a id="_idIndexMarker492" class="pcalibre1 pcalibre2 pcalibre"/>secure cloud infrastructure. Let us now navigate the key functionalities that Cloud SCC Assets brings to the cloud <span>security journey.</span></p>

<h3 class="calibre11">Cloud SCC Assets</h3>
<p class="calibre3">Investigators always appreciate seeing<a id="_idIndexMarker493" class="pcalibre1 pcalibre2 pcalibre"/> all the assets and knowing what is configured within an environment. Similarly, GCP’s Cloud SCC offers something called Cloud SCC Assets that <a id="_idIndexMarker494" class="pcalibre1 pcalibre2 pcalibre"/>provides a high-level view of all the categories of assets, their details, and the configurational information set for these assets. Getting the lay of the land is vital when investigating a complex case. Investigators can use this asset management page to obtain relevant information and potentially identify the next steps in <span>their investigation.</span></p>
<p class="calibre3">The following figure outlines the asset summary configured within our sample GCP instance and the relevant <span>resource types:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer120"><img alt="Figure 6.26 – Cloud SCC Assets view" src="../images/00184.jpeg" class="calibre126"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.26 – Cloud SCC Assets view</p>
<p class="calibre3">Only assets associated with the <a id="_idIndexMarker495" class="pcalibre1 pcalibre2 pcalibre"/>current project or resources are visible in the asset view. More information is presented within each asset under the <strong class="source-inline">resourceProperties.name</strong> field. For example, we can select the <strong class="source-inline">compute</strong>. <strong class="source-inline">Instance</strong> resource type in the filters, then click on the first item. The following figure summarizes what kind of resource is configured and its various configurational elements (or attributes). It also presents resource properties in the JSON format and includes any additional metadata for this asset. Finally, this page also provides any findings about this <span>particular asset:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer121"><img alt="Figure 6.27 – Asset detail view" src="../images/00121.jpeg" class="calibre127"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.27 – Asset detail view</p>

<h3 class="calibre11">Configurational vulnerabilities</h3>
<p class="calibre3"><strong class="bold">Platform configurational vulnerabilities</strong> is a GCP feature that natively scans the configurations of various GCP services and GCP VMs and identifies vulnerabilities within the infrastructure. Although very simplistic, this <a id="_idIndexMarker496" class="pcalibre1 pcalibre2 pcalibre"/>dashboard provides detailed findings for each configurational vulnerability. GCP deems something a vulnerability or a threat if it sees a deviation from acceptable standards. Since each organization differs, some variations would be permissible for <span>the business.</span></p>
<p class="calibre3">From an investigation point of view, the vulnerability findings feature offers historical insights into when GCP observed the vulnerability or the deviation, the severity of the associated findings, and the number of services or endpoints impacted, and provides a mapping to various commonly accepted <span>security standards.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">GCP’s vulnerability findings can be used to determine potential root causes and, through digital forensics, confirm whether the threat actor exploited any of <span>these vulnerabilities.</span></p>
<p class="calibre3">The following figure illustrates the list of vulnerabilities, including third-party application vulnerabilities. Each finding will also provide detailed descriptions of where this deviation <span>was identified:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer122"><img alt="Figure 6.28 – List of vulnerabilities" src="../images/00106.jpeg" class="calibre128"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.28 – List of vulnerabilities</p>
<p class="calibre3">From a digital forensics standpoint, configurational vulnerabilities can provide investigators with clues about potential gaps within an infrastructure and indicate whether any of the gaps could have been the root cause of <span>an incident.</span></p>
<p class="calibre3">In the next section, we <a id="_idIndexMarker497" class="pcalibre1 pcalibre2 pcalibre"/>venture into the command-line environment, which allows access to various GCP resources. GCP Cloud Shell is helpful for incident responders who are very comfortable with command-line tools. It can be useful for quick access and investigative insights into a <span>GCP resource.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h1 id="_idParaDest-123" class="calibre5"><a id="_idTextAnchor134" class="pcalibre1 pcalibre2 pcalibre"/>GCP Cloud Shell</h1>
<p class="calibre3"><strong class="bold">Cloud Shell</strong> is GCP’s native command-line tool that allows access to various GCP services over a command-line interface. GCP Cloud Shell, a browser-based shell environment, can be used to investigate <a id="_idIndexMarker498" class="pcalibre1 pcalibre2 pcalibre"/>and identify potential security incidents for threat-hunting activities. Investigators can also use Cloud Shell to turn a service such as packet mirroring on or off. It also has an interactive code editor for users or investigators who want to import custom code, enabling Cloud Shell to perform certain activities. GCP’s Cloud Shell can also be accessed locally through the Google Cloud SDK or an <span>in-browser session.</span></p>
<p class="calibre3">GCP offers essential command-line tools, specifically <strong class="source-inline">gcloud</strong> and <strong class="source-inline">gsutil</strong>. <strong class="source-inline">gcloud</strong> provides access to general GCP services such as <strong class="bold">GCE</strong>, <strong class="bold">BigQuery</strong>, and so on. In comparison, <strong class="source-inline">gsutil</strong> is a specific utility tool to access <span>storage buckets.</span></p>
<p class="calibre3">Through <strong class="source-inline">gcloud</strong>, investigators can access Logs Explorer and collect all the associated logs for offline analysis. Investigators can also list the services a user has subscribed to or all <span>VPC policies:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer123"><img alt="Figure 6.29 – GCP Cloud Shell" src="../images/00080.jpeg" class="calibre129"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 6.29 – GCP Cloud Shell</p>
<p class="calibre3">GCP Cloud Shell offers<a id="_idIndexMarker499" class="pcalibre1 pcalibre2 pcalibre"/> investigators a browser-based command-line interface for investigating incidents. It allows access to GCP resources for tasks such as log analysis, memory examination, and malware assessment. Cloud Shell aids in artifact preservation, collaboration, and automation, enabling efficient, scalable, and secure digital forensics and incident <span>response operations.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h1 id="_idParaDest-124" class="calibre5"><a id="_idTextAnchor135" class="pcalibre1 pcalibre2 pcalibre"/>Summary</h1>
<p class="calibre3">After diving deep into GCP, we know the GCP infrastructure is very similar to other popular cloud providers. We highlighted the importance of understanding the varying verbosity of logs emitted by GCP services, emphasizing the need for investigators to seek corroborating evidence to confirm events. GCP’s centralized logging system, which flows into Logs Explorer, is a powerful tool for administrators to troubleshoot routine issues and for investigators to delve into event correlations across the <span>GCP ecosystem.</span></p>
<p class="calibre3">We learned about similarities between how GCP organizes its buckets and objects, which is conceptually similar to AWS. Cloud SCC offers a dashboard or a security scorecard on infrastructure for administrators. At the same time, for investigators, it is a goldmine of findings, with detailed information on where to look when kicking off an investigation. Cloud SCC offers unique insights into vulnerabilities without deploying specific agents within the hosts. Finally, we looked at Cloud Shell, which provides more freedom for investigators to perform investigative activities from the <span>command line.</span></p>
<p class="calibre3">In the next chapter, we will dive deep into email workspaces, especially Microsoft 365 and Google Workspaces, and identify methodologies for investigating cloud <span>email workspaces.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer124" class="calibre2">
<h1 id="_idParaDest-125" class="calibre5"><a id="_idTextAnchor136" class="pcalibre1 pcalibre2 pcalibre"/>Further reading</h1>
<ul class="calibre12">
<li class="calibre13">Google Access Transparency <span>policy: </span><a href="https://cloud.google.com/privacy" class="pcalibre1 pcalibre2 pcalibre"><span>https://cloud.google.com/privacy</span></a></li>
<li class="calibre13">Cloud Audit Logs <span>overview: </span><a href="https://cloud.google.com/logging/docs/audit#system-event" class="pcalibre1 pcalibre2 pcalibre"><span>https://cloud.google.com/logging/docs/audit#system-event</span></a></li>
<li class="calibre13">Enabling <span>logging: </span><a href="https://cloud.google.com/logging/docs/audit/configure-data-access" class="pcalibre1 pcalibre2 pcalibre"><span>https://cloud.google.com/logging/docs/audit/configure-data-access</span></a></li>
<li class="calibre13">Cloud SCC IAM, access control with <span>IAM: </span><a href="https://cloud.google.com/security-command-center/docs/access-control" class="pcalibre1 pcalibre2 pcalibre"><span>https://cloud.google.com/security-command-center/docs/access-control</span></a></li>
<li class="calibre13">IAM for organization-level <span>activations: </span><a href="https://cloud.google.com/security-command-center/docs/access-control-org" class="pcalibre1 pcalibre2 pcalibre"><span>https://cloud.google.com/security-command-center/docs/access-control-org</span></a></li>
<li class="calibre13">Exporting Security Command Center <span>data: </span><a href="https://cloud.google.com/security-command-center/docs/how-to-export-data?authuser=2" class="pcalibre1 pcalibre2 pcalibre"><span>https://cloud.google.com/security-command-center/docs/how-to-export-data?authuser=2</span></a></li>
<li class="calibre13">Investigating and responding to <span>threats: </span><a href="https://cloud.google.com/security-command-center/docs/how-to-investigate-threats#defense_evasion_breakglass_workload_deployment" class="pcalibre1 pcalibre2 pcalibre"><span>https://cloud.google.com/security-command-center/docs/how-to-investigate-threats#defense_evasion_breakglass_workload_deployment</span></a></li>
<li class="calibre13">Using event threat <span>detection: </span><a href="https://cloud.google.com/security-command-center/docs/how-to-use-event-threat-detection" class="pcalibre1 pcalibre2 pcalibre"><span>https://cloud.google.com/security-command-center/docs/how-to-use-event-threat-detection</span></a></li>
<li class="calibre13">How Security Command Center helps you detect and stop cyber <span>attacks: </span><a href="https://cloud.google.com/security-command-center/docs/concepts-how-scc-determines-env-under-attack" class="pcalibre1 pcalibre2 pcalibre"><span>https://cloud.google.com/security-command-center/docs/concepts-how-scc-determines-env-under-attack</span></a></li>
<li class="calibre13">Compute Engine IAM roles and <span>permissions: </span><a href="https://cloud.google.com/compute/docs/access/iam" class="pcalibre1 pcalibre2 pcalibre"><span>https://cloud.google.com/compute/docs/access/iam</span></a></li>
<li class="calibre13"><span>FluentBit: </span><a href="https://github.com/fluent/fluent-bit" class="pcalibre1 pcalibre2 pcalibre"><span>https://github.com/fluent/fluent-bit</span></a></li>
<li class="calibre13">Install Google <span>CLI: </span><a href="https://cloud.google.com/sdk/docs/install#linux" class="pcalibre1 pcalibre2 pcalibre"><span>https://cloud.google.com/sdk/docs/install#linux</span></a></li>
<li class="calibre13">Live forensics to analyze a <span>cyber-attack: </span><a href="https://cloud.google.com/blog/products/identity-security/how-to-use-live-forensics-to-analyze-a-cyberattack" class="pcalibre1 pcalibre2 pcalibre"><span>https://cloud.google.com/blog/products/identity-security/how-to-use-live-forensics-to-analyze-a-cyberattack</span></a></li>
</ul></div>
</div>
</body></html>