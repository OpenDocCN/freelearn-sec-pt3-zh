- en: '7'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Denial of Service and Rate-Limiting Testing
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'Continuing from basic API attacks, it’s now time for us to understand more
    about **denial-of-service** (**DoS**) and **distributed denial-of-service** (**DDoS**)
    threats and answer some questions, such as the following: Why are they so important?
    How impactful they could be for API endpoints? What can we leverage to successfully
    manage the triggering of these sorts of attacks? You will learn that DoS, especially
    the distributed form of it, is a global problem affecting pretty much any publicly
    exposed endpoint or application. Additionally, software that is only privately
    accessible is not immune to them. Although sometimes rarer, insider threats are
    present and can disrupt internal applications.'
  prefs: []
  type: TYPE_NORMAL
- en: '**Rate limiting** is a key defense mechanism against DoS attacks, designed
    to control the amount of traffic an API can handle from a particular user or IP
    address over a specific period. It prevents users from making too many requests
    in a short amount of time, which can be an indicator of an attack. Proper rate
    limiting can help maintain service availability even during an attack by allowing
    only a manageable number of requests.'
  prefs: []
  type: TYPE_NORMAL
- en: When conducting penetration testing, it’s important to identify the API’s rate-limiting
    mechanisms and test their effectiveness. It involves assessing the thresholds
    set for users and attempting to circumvent them to check the robustness of these
    controls. This phase of testing may also involve checking the API’s response to
    different attack vectors that could lead to service disruption.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we’re going to cover the following main topics:'
  prefs: []
  type: TYPE_NORMAL
- en: Testing for DoS vulnerabilities
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Identifying rate-limiting mechanisms
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Circumventing rate limitations
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Technical requirements
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As it happened with previous chapters, we’ll leverage the same environment as
    the one pointed out in previous chapters, such as an Ubuntu distribution. Some
    other new relevant utilities will be mentioned in the corresponding sections.
  prefs: []
  type: TYPE_NORMAL
- en: Testing for DoS vulnerabilities
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'There were notable recent incidents that are worth mentioning to illustrate
    the power and reach of such kinds of attacks. They are listed by traffic volume,
    and the references are in the *Further reading* section at the end of the chapter:'
  prefs: []
  type: TYPE_NORMAL
- en: The attack against Google Cloud reached 2.54 Tbps in 2017, but it was only disclosed
    to the public three years later in 2020\. The attacks sent forged packets to web
    servers pretending they were being sent by Google servers. All the responses to
    such packets were sent to Google, which caused this volume.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In February 2020, one AWS customer’s infrastructure was the target of a 2.3
    Tbps DDoS attack. The specialized company service, AWS Shield, managed to absorb
    the “tsunami,” which protected the customer’s assets. By leveraging **Connectionless
    Directory Access Protocol** (**CLDAP**), the criminals dispatched huge amounts
    of packets toward publicly available **Lightweight Directory Access Protocol**
    (**LDAP**) servers.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: GitHub occupies the third place on our list. In 2018, making use of a well-known
    vulnerability in Memcached, a popular in-memory database, attackers could abuse
    public Memcached servers on the internet. The root cause was like the one that
    hit Google. By spoofing GitHub’s IP addresses, criminals sent packets that got
    amplified by such servers and sent back to GitHub.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We will use our old friend Ubuntu to make the lab for this chapter. However,
    we will install a couple of additional tools because we need to send reasonable
    amounts of traffic and tweak some options to simulate what we are doing from different
    sources. For that sake, we will make use of **Mockoon**, an open-source solution
    to create mocked APIs. We’ve been using crAPI and our own Python application since
    then. It’s now time to test with some other software.
  prefs: []
  type: TYPE_NORMAL
- en: Getting to know Mockoon
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: The installation is as simple as using Snap to accomplish it (on Linux at least).
    The product is also available for Windows and macOS. Keep in mind that, at least
    when this book was being written, there was no version for ARM64\. So, unfortunately,
    you have to have an Intel system to use it.
  prefs: []
  type: TYPE_NORMAL
- en: Load the application. The first load might take some time. The opening screen
    is shown in the following screenshot. I recommend you go through the initial tour.
    It’s not too big and quite straightforward. It is important to say that Mockoon
    calls the endpoints **routes**. This is common throughout the literature and among
    some other products.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.1 – Mockoon’s splash screen](img/B19657_figure_07.01.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.1 – Mockoon’s splash screen
  prefs: []
  type: TYPE_NORMAL
- en: 'You’ll realize that Mockoon already starts a pre-configured API (called **DemoAPI**)
    and some routes as soon as you finish the tour or simply cancel it. You need to
    push the *play* icon button to put the API to start listening to requests. On
    the **Settings** tab, you can choose the IP address, port, and optional prefix
    that will be used. It’s also possible to enable TLS. The product comes with a
    self-signed certificate, but you can optionally provide your own certificate file,
    the CA certificate file, and the relevant keys. When this option is enabled, a
    lock icon shows up just below the API name and you must restart the API if it’s
    already running. Simply click on the yellow circled arrow or follow this menu
    sequence: **Run** | **Start** | **Stop** | **Reload** **current environment**:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.2 – Restarting the Mockoon API after enabling TLS](img/B19657_figure_07.02.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.2 – Restarting the Mockoon API after enabling TLS
  prefs: []
  type: TYPE_NORMAL
- en: 'Take some time to navigate through the interface. All the routes (endpoints)
    are listed under the **Routes** tab. The DemoAPI has a total of seven of them.
    The data served as the response for **create, read, update, and delete** (**CRUD**)
    is a script using a type of language. It generates 50 random usernames and their
    IDs:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs: []
  type: TYPE_PRE
- en: Interacting with Mockoon’s endpoints
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'The CRUD route is listening on `/users`. Observe what happens when you do this:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs: []
  type: TYPE_PRE
- en: 'The accepted headers are on the tab with the same name. By default, only the
    well-known `Content-Type: application/json` is there. Logs can be accessed on
    the eponymous tab. Let’s do a first test with this dummy API that Mockoon gives
    us. For that matter, we’ll make use of another famous tool: `ab`. This is the
    acronym for **ApacheBench**, and it’s a utility that developers and sysadmins
    usually apply when they need to do load tests on their applications. It’s also
    straightforward to install.'
  prefs: []
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: From now on, I’ll interchangeably use *endpoint* and *route*. Just bear in mind
    that they have the same meaning in this context.
  prefs: []
  type: TYPE_NORMAL
- en: 'We will target the `/users` route to see how our API behaves when receiving
    a reasonable number of requests. Let’s begin with 100 requests (the `-n` command
    option), with 10 (the `-c` command option) of them being simultaneous. Type the
    following command and observe the results:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs: []
  type: TYPE_PRE
- en: 'The first point we realize is that `ab` is somehow chatty. That’s expected
    since the main purpose is to load-test your application, right? Nevertheless,
    you can control its output with the `-q` and `-v` options. The main page explains
    all its switches. Mockoon seems to have behaved as expected (on my regular laptop
    and running on top of an Ubuntu VM). Pay special attention to the last section
    of the preceding output. It shows the percentiles of requests being served in
    specific periods. It should be interpreted like this:'
  prefs: []
  type: TYPE_NORMAL
- en: 50% of the requests were served in 1 ms or less.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Up to 95% of the requests were served in 10 ms or less.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The longest request took 23 ms to be served.
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: All requests were logged and none of them suffered big delays to be served.
    It’s however curious that Mockoon did not provide any data (not even HTML) when
    answering these requests. This can be perceived by the preceding `Document Length`,
    `Total transferred` and `HTML transferred` lines. This may reveal misconfiguration
    on the API side, unexpected errors, or that Mockoon skipped providing some answer
    to `ab`. This can happen sometimes since Mockoon is just a fake/mock API server.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, let’s see how our dear API will behave when the numbers are multiplied
    by 10\. Some output was purposefully omitted for simplicity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs: []
  type: TYPE_PRE
- en: 'Ha! Now, we are seeing data coming. That’s what I’m talking about, dude! Icebreakers
    apart, observe that the response time substantially increased when compared to
    the previous test. If you repeat this command, but through HTTPS, you will receive
    slightly longer times. I did a final test with 10,000 requests being 1,000 simultaneous,
    and Mockoon was not fully responsive this time:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE4]'
  prefs: []
  type: TYPE_PRE
- en: This had nothing to do with the VM’s memory footprint. I was watching it the
    whole time and my system had around 2.5 GB of free RAM. I even restarted Mockoon
    to give it a clean memory area, but this didn’t suffice. Only 50 requests were
    logged this time (this is the maximum number of log entries the API shows by default).
  prefs: []
  type: TYPE_NORMAL
- en: Leveraging Scapy to attack Mockoon
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'It’s been a while since the last time we used Wireshark, huh? For the next
    tests, it will be more enlightening if we have it running. If you don’t have it
    on your system yet, install it and load it. Put it to listen to the loopback adapter.
    You may need to execute it as the root to accomplish this. For the next test,
    we will make use of `pip` and run the following small code. Observe its output:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE5]'
  prefs: []
  type: TYPE_PRE
- en: 'This code sends 5,000 packets to TCP port `3000` on localhost, with the `3000`
    is where Mockoon is listening to requests. Observe they are not HTTP packets,
    but just regular **Transmission Control Protocol** (**TCP**) packets. The point
    here is not to watch if the API itself will behave as expected, but if the infrastructure
    hosting it will deal with this unusual activity. If you don’t know much about
    TCP/IP networking, packets with such a flag are used to signal to the receiving
    peer that the connection should be terminated. Let’s see how Mockoon deals with
    this weird communication. You will receive something like the following:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE6]'
  prefs: []
  type: TYPE_PRE
- en: What has Wireshark captured? Switch to it and you will find lots of red lines
    corresponding to the packets (*Figure 7**.3*).
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.3 – Wireshark capturing the Scapy packets with the RST flag set](img/B19657_figure_07.03.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.3 – Wireshark capturing the Scapy packets with the RST flag set
  prefs: []
  type: TYPE_NORMAL
- en: The code didn’t return any error, which means Mockoon likely received (and probably
    ignored) all of them. If you are uncertain about the number of dots printed as
    part of the output, simply run the script on the command line and append `|` `wc
    -c`.
  prefs: []
  type: TYPE_NORMAL
- en: When a web server or API gateway is not configured to foresee this type of weird
    behavior, it can simply crash and eventually leak some internal data, such as
    details about the infrastructure. In our case, Mockoon didn’t throw any error
    messages or even crash. Maybe it leverages some backend server with support for
    such a thing. Or, maybe this happened because the packets were sent in a single
    sequence, one after the other.
  prefs: []
  type: TYPE_NORMAL
- en: So far, we have tested from the same source IP address. This is good for simple
    tests, but not enough to check how the endpoints can handle connections from multiple
    addresses at the same time. This is the core of DDoS attacks. It may be difficult
    for API endpoints and their environments to distinguish between legitimate traffic
    and pure attacks.
  prefs: []
  type: TYPE_NORMAL
- en: Mockoon with hping3 – initial tests
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To help us with this, let’s invoke another tool: `hping3`. In the case of our
    lab, we can use `apt` to install it. There are at least five different ways you
    can leverage `hping3` to test your routes. First, we are going to send a couple
    of **Synchronize** (**SYN**) packets, pretending we are trying to establish TCP
    connections and see what happens:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE7]'
  prefs: []
  type: TYPE_PRE
- en: 'The output looks like the `ping` command we are used to. That’s the point.
    The tool boosts the possibilities given by its parent though. Observe how Wireshark
    recorded it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.4 – hping3 sending SYN packets and resetting the connections](img/B19657_figure_07.04.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.4 – hping3 sending SYN packets and resetting the connections
  prefs: []
  type: TYPE_NORMAL
- en: '`hping3` sends each SYN packet, receives the corresponding `Nmap`, too). The
    command is as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE8]'
  prefs: []
  type: TYPE_PRE
- en: 'You can inform multiple ports by separating them with commas or dashes (for
    ranges). We sent three packets, but Mockoon didn’t answer them. By checking on
    Wireshark, we can see the packets did hit Mockoon, but no reply was sent back
    whatsoever. Mockoon is possibly ignoring them since they’re just probe packets,
    not fully HTTP/HTTPS packets, and they don’t carry the expected headers or payloads:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.5 – Packets sent against Mockoon to scan ports](img/B19657_figure_07.05.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.5 – Packets sent against Mockoon to scan ports
  prefs: []
  type: TYPE_NORMAL
- en: Sending random data with hping3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s move forward. Now, we will send something completely random and nonsense.
    We’ve done this before in another context. This time, we will leverage `hping3`
    for it. Generate a 1 MB file and then send it to Mockoon with the following command.
    Observe the outcomes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE9]'
  prefs: []
  type: TYPE_PRE
- en: 'In summary, we told `hping3` to do the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Send packets to port TCP `3000` (`-``p 3000`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Dispatch a total of 3 packets (`-``c 3`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use the just-created file as the data payload (`--``file random.bin`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Define the packet size as 32768 bytes (`-``d 32768`)
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Use `localhost` as the destination
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'If you are still running Wireshark, you will capture something like this:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.6 – Wireshark packet capture when hping3 sent a file to Mockoon](img/B19657_figure_07.06.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.6 – Wireshark packet capture when hping3 sent a file to Mockoon
  prefs: []
  type: TYPE_NORMAL
- en: Observe that the connection attempts were all reset. That’s because no previously
    established connection could sustain the file transmission. The TCP/IP stack simply
    discarded all the attempts, sending packets with the RST flag on. I’m not sure
    if you realized this too, but `hping3` uses a different source port for every
    single packet it sends. Also, `sudo` was necessary this time. This is because
    the tool needs to make a syscall to the kernel’s network driver and that’s only
    allowed to the root operator or after some privilege elevation, which we can obtain
    with `sudo`.
  prefs: []
  type: TYPE_NORMAL
- en: Sending fragmented packets with hping3
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'On the next test, we will send fragmented packets to our target. Fragmented
    packets can disrupt an API endpoint due to the way they interact with the network
    infrastructure and the end service. When a large packet is sent over the internet,
    it often exceeds the `-``f` switch):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE10]'
  prefs: []
  type: TYPE_PRE
- en: 'Packet fragmentation is something that worries network administrators. This
    kind of attack can cause problems for the target, such as the following:'
  prefs: []
  type: TYPE_NORMAL
- en: Resource exhaustion, because of increased CPU usage or memory overhead
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Reassembly failures, due to reassembly timeout or overlapping fragments
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The packet capture demonstrates the fragments flowing through the network.
    You will see many more than just three packets because we are forcing them to
    be fragmented:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.7 – The fragmented packets going to Mockoon](img/B19657_figure_07.07.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.7 – The fragmented packets going to Mockoon
  prefs: []
  type: TYPE_NORMAL
- en: Flooding Mockoon with hping3 packets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'So far, we’ve used `hping3` by asking it to send a small number of packets
    to our target API server. Now, we’ll go a step further. We’ll send a bigger number
    of packets to try to flood the target (the `--flood` switch), and we’ll verify
    whether Mockoon is smart enough to handle them. We will also randomize the source
    IP address to simulate a true DDoS attack. The following command accomplishes
    this task:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE11]'
  prefs: []
  type: TYPE_PRE
- en: 'You can see that I did not specify the number of packets. So, `hping3` will
    forever flood the target. Also, you can see that no packet was received, indicating
    there was a 100% loss. This caused two interesting behaviors in my system:'
  prefs: []
  type: TYPE_NORMAL
- en: 'First, the free memory drastically reduced in a matter of a few seconds and
    did not recover even after stopping `hping3`:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 7.8 – The system’s RAM rapidly reducing because of the DDoS attack
    processing](img/B19657_figure_07.08.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.8 – The system’s RAM rapidly reducing because of the DDoS attack processing
  prefs: []
  type: TYPE_NORMAL
- en: 'Secondly, and possibly because of that lack of free memory, Wireshark often
    stopped responding, asking me to either wait for it or to stop it:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 7.9 – Wireshark failing to be available while capturing network packets](img/B19657_figure_07.09.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.9 – Wireshark failing to be available while capturing network packets
  prefs: []
  type: TYPE_NORMAL
- en: 'When Wireshark finally decided to work at least for a while again, I could
    take a screenshot to show you the anatomy of the packets sent by `hping3`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.10 – Packets that were part of the hping3’s flooding attack](img/B19657_figure_07.10.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.10 – Packets that were part of the hping3’s flooding attack
  prefs: []
  type: TYPE_NORMAL
- en: You can easily verify they were very small packets (54 bytes in size) coming
    from virtually endless different IP address sources. This was successfully exhausted
    by the system’s memory and caused not only Mockoon to stop working, but all other
    applications as well. I could no longer even use `curl` to send simple requests
    to the API. This happened because the operating system received more packets than
    it could process in a feasible amount of time and the buffers were all opened
    at the same time in memory, pretty much fully occupying it. Only a full restart
    was recovered by the system to the previous state.
  prefs: []
  type: TYPE_NORMAL
- en: Making the attack more interesting – the “fast” switch
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'At this point, you can ask me this question: Is there a way to turn this into
    something even worse? Guess what? The answer is a big *YES!* `hping3` has a `--fast`
    switch, where it can send around 10 packets per second, absolutely filling all
    possible packet buffers that a regular system can usually apply to handle the
    receiving of packets. Type the following command and observe the results. Your
    whole system might hang again, just as it happened with mine. The explanation
    is quite like the previous test:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE12]'
  prefs: []
  type: TYPE_PRE
- en: 'The `--syn` switch tells `hping3` to send TCP packets with the SYN flag on.
    I didn’t let it hang my system this time, though. I also didn’t choose to randomize
    the source IP addresses. Even with these restrictions, Mockoon occupied the top
    of the processes using more memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.11 – Output of the top command showing processes using more memory](img/B19657_figure_07.11.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.11 – Output of the top command showing processes using more memory
  prefs: []
  type: TYPE_NORMAL
- en: 'The packet capture is also interesting, showing Mockoon trying to reset the
    packets as they arrive, which was a noble yet not enough task:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.12 – Packet capture with hping3’s --fast switch](img/B19657_figure_07.12.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.12 – Packet capture with hping3’s --fast switch
  prefs: []
  type: TYPE_NORMAL
- en: Even though not having been generated by different source IP addresses, this
    traffic was still massive and can surely cause some damage to unprepared API endpoints
    and their backends when they are not protected against DoS attacks. It’s all about
    how strong and smart the system is to deal with so many packet handles. In the
    next section, we are going to investigate how we can detect rate-limiting controls.
    They are quite useful to block against simple and sometimes complex attacks such
    as the ones we just learned.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying rate-limiting mechanisms
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You just learned several ways to trigger DoS attacks against an API endpoint.
    We even sent a trivial but powerful DDoS wave of packets that made our target
    unable to handle them feasibly. The first option to protect against such types
    of threats is rate-limiting the traffic, also called **throttling**. For more
    information, see the link in the *Further* *reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: Identifying rate-limiting mechanisms within an API is an essential aspect of
    both security and usability assessments. Rate limiting is designed to prevent
    abuse by limiting the number of requests a user can make in each period. It helps
    mitigate various attacks, such as brute force or DDoS, by capping the action frequency.
    This is achieved by applying a policy. This policy ensures that servers are not
    overwhelmed by too many requests at once, which could degrade service for others
    or lead to server failure. Rate limiting can be based on several factors, including
    IP addresses, user accounts, API tokens, or sessions. It typically involves setting
    a maximum number of allowable requests and a time window for these requests. For
    example, an API might allow 100 requests per minute per user. This mechanism helps
    to maintain the quality of service, prevent abuse, and manage server resources
    more effectively.
  prefs: []
  type: TYPE_NORMAL
- en: There are various ways to implement rate limiting, such as fixed window counters,
    rolling window logs, and leaky buckets, each with its advantages and use cases.
    A fixed window counter resets the count at fixed intervals, potentially allowing
    bursts of traffic at the interval edges. Rolling windows track the count in a
    continuously moving window, which can prevent bursts but requires more complex
    tracking. Leaky buckets allow requests at a steady pace, smoothing outbursts.
    Choosing the right algorithm depends on the specific requirements and behavior
    of the API you’re protecting. Let’s understand a bit more about each one of them.
  prefs: []
  type: TYPE_NORMAL
- en: Fixed window counters
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This is an important concept in the world of rate-limiting requests. They are
    simply counters that record the number of requests arriving during a specific
    amount of time. With this window, an API can check at any time what the current
    number of requests is and reduce or increase them, accordingly, depending on the
    threshold. If the traffic is assessed to be legitimate and the API needs to serve
    more requests (for example, after a new product release), the threshold is increased.
    On the other hand, when nothing justifies having a specific volume of traffic,
    it can be capped.
  prefs: []
  type: TYPE_NORMAL
- en: During a pentest, you can leverage fixed window counters to your advantage.
    By strategically sending bursts of requests within the defined window timeframe,
    you can attempt to identify the rate limit itself. Observing server responses
    after exceeding the limit is key. Look for changes in response times, the appearance
    of specific error codes (such as 429 Too Many Requests), or the presence of headers
    revealing rate-limiting information. This information helps pentesters understand
    the API’s tolerance for request volume and the consequences of exceeding the limit.
  prefs: []
  type: TYPE_NORMAL
- en: There are limitations, though. Window counters are not bulletproof against what
    is called bursting. With this technique, you send a consistent wave of requests
    just before the window time is going to be refreshed (the previous window ends,
    the next window starts). This can exploit the gap between the counter reaching
    its limit and the window resetting, allowing a temporary bypass of the rate limit.
    As a pentester, identifying an API that relies solely on fixed window counters
    highlights a potential vulnerability that could be exploited in a real-world attack
    scenario.
  prefs: []
  type: TYPE_NORMAL
- en: Rolling window logs
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'While fixed window counters offer a basic level of rate-limiting, pentesters
    often encounter APIs that employ a more sophisticated approach: rolling window
    logs. Unlike fixed counters, rolling window logs maintain a chronological record
    of timestamps associated with incoming requests. This record is constantly updated,
    with older timestamps falling out of the window as new requests arrive. The API
    calculates the rate limit by analyzing the number of requests within this dynamic
    window.'
  prefs: []
  type: TYPE_NORMAL
- en: This dynamic nature offers several advantages compared to fixed window counters.
    Bursting does not have the same level of success with it. The window is frequently
    being adjusted, which reduces the chances of attackers exploiting the window reset
    timers. Also, rolling window logs provide a more realistic representation of patterns
    for real-time requests. They can account for sudden surges in legitimate traffic
    that might be incorrectly flagged by a fixed window counter. This allows for a
    more nuanced approach to rate limiting, potentially avoiding unnecessary blocking
    of legitimate users during periods of high activity.
  prefs: []
  type: TYPE_NORMAL
- en: However, they present a different set of challenges for a pentester. It can
    be more difficult to identify the specific window size and rate limit when compared
    to fixed counters. You might need to employ more sophisticated techniques such
    as sending requests with varying intervals to analyze server responses and infer
    the underlying logic of the rolling window. Additionally, certain implementations
    of rolling window logs might not provide clear feedback through error codes or
    headers, making it slightly more challenging to pinpoint the exact rate limit
    settings.
  prefs: []
  type: TYPE_NORMAL
- en: Leaky buckets
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: This concept is somehow unique in the world of rate-limiting for API routes.
    Imagine a bucket with a small hole at the bottom, constantly leaking out a controlled
    amount of water. The arriving requests can be compared to water being put into
    this bucket. The maximum number of requests that can be processed during a specific
    amount of time corresponds to the bucket’s capacity (like a real one with liters
    or gallons). If the bucket starts spilling out *water* (too many requests arriving
    at the endpoint), subsequent ones are rejected because of the lack of capacity,
    and new requests are only accepted once the bucket has some room to accommodate
    them.
  prefs: []
  type: TYPE_NORMAL
- en: This analogy translates to a dynamic rate-limiting mechanism for APIs. The bucket’s
    capacity represents the maximum allowed request volume within a timeframe, and
    the leak rate defines how quickly requests are *processed* and considered permissible.
    This approach offers several advantages for pentesting APIs. Leaky buckets work
    better than fixed window counters with respect to bursts of requests. Even if
    a surge of requests arrives, the bucket can accommodate them to a certain extent,
    preventing unnecessary blocking of legitimate users. Also, as happens with **quality
    of service** (**QoS**) mechanisms, leaky buckets can prioritize certain types
    of packets, processing them even when they don’t have the capacity to accommodate
    more. By adjusting the leak rate for different request types, the API can ensure
    critical requests are processed even during periods of high traffic, enhancing
    overall system responsiveness.
  prefs: []
  type: TYPE_NORMAL
- en: Nonetheless, for pentesters, leaky buckets present a different testing challenge.
    Unlike fixed windows or rolling window logs with their focus on request counts,
    leaky buckets involve analyzing both capacity and leak rate. Pentesters might
    need to send a series of requests with varying intervals and observe how the server
    responds. By monitoring for changes in response times or the appearance of error
    codes such as 429 Too Many Requests, testers can attempt to infer the bucket’s
    capacity and leak rate. This information can reveal potential weaknesses in the
    leaky bucket implementation.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we are going to implement a rate-limiting mechanism to
    protect the API we created with Mockoon and check whether we can detect its presence.
    Mockoon itself already comes with some protection controls that you can play with,
    but you can also leverage some external tools for this purpose, which will be
    our case.
  prefs: []
  type: TYPE_NORMAL
- en: A rate-limiting detection lab
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'To implement this lab, we will leverage NGINX. We could have done this in the
    form of a Docker container, but since Mockoon is directly running on top of our
    VM, we will take the secondary path: install NGINX on our Linux box. Just follow
    your operating system’s documentation on how to install the software. On Ubuntu,
    it’s a matter of a couple of `apt` commands. As soon as you finish it, NGINX will
    be listening on port `80`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.13 – NGINX default page](img/B19657_figure_07.13.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.13 – NGINX default page
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, we need a proper `nginx.conf` file to tell NGINX to work as a reverse
    proxy, forwarding all requests to Mockoon and rate-limiting them. Replace the
    contents of the default `/etc/nginx/nginx.conf` file with the following contents:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE13]'
  prefs: []
  type: TYPE_PRE
- en: 'Each option or directive has its own purpose:'
  prefs: []
  type: TYPE_NORMAL
- en: '`worker_connections`: This directive tells NGINX how many concurrent connections
    each worker process can handle, which is vital for handling multiple requests
    simultaneously.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`limit_req_zone $binary_remote_addr zone=limitlab:10m rate=1r/s`: This directive
    is used to define a rate-limiting property that limits the rate of requests that
    a client can make to a server. The `$binary_remote_addr` portion represents the
    client’s IP address in compact binary format. This applies the same rule for every
    single IP address that hits NGINX. We are allocating 10 MB of RAM for the `limitlab`
    shared memory zone we created and specifying a rate of one request per second.
    Further options are configured on the `limit_req` portion.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`include mime.types` and `default_type application/json` ensure that NGINX
    handles MIME types appropriately.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`limit_req zone=limitlab burst=5`: On the previously created `limitlab` zone,
    establish that a burst of up to five requests is processed without limiting, helping
    to accommodate scenarios where a client might occasionally make several requests
    in quick succession.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`proxy_pass http://localhost:3000` and `proxy_http_version 1.1`: Define the
    HTTP version to use and the backend’s address. In our case, the Mockoon API server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`proxy_set_header Upgrade $http_upgrade`: This header is crucial for supporting
    WebSocket connections. The `Upgrade` header in HTTP requests is used to ask the
    server to switch protocols (e.g., from `HTTP/1.1` to `WebSocket`). It’s here for
    educational purposes only. Not applicable to our case.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`proxy_set_header Connection ''upgrade''`: This header is used to control whether
    the network connection stays open after the current transaction finishes. Setting
    this to `''upgrade''` complements the `Upgrade` header and is used primarily for
    WebSocket or other protocol upgrades. Educational only.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`proxy_set_header Host $host`: This header sets the `Host` header of the forwarded
    request to the value of the host of the incoming request to the NGINX server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`proxy_set_header X-Real-IP $remote_addr`: This custom header is commonly used
    to pass the original client’s IP address to the backend server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for`: This header
    is used to append the client’s IP address to any existing `X-Forwarded-For` header
    received by NGINX. If there is no such header, NGINX will create it.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`proxy_set_header X-Forwarded-Proto $scheme`: This header is used to inform
    the backend server about the protocol the client used to connect to the proxy.
    `$scheme` will contain `http` or `https`, depending on the protocol.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`proxy_cache_bypass $http_upgrade`: This directive is used to bypass the cache
    if the `Upgrade` header is present in the client’s request. This is typically
    used in scenarios where caching responses may not be desirable, such as when initiating
    WebSocket connections. This is for educational purposes only too.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'I put a link in the *Further reading* section with more information about how
    to configure NGINX to work as a remote proxy. Restart the service if it is already
    running. By default, all accesses are logged to `/var/log/nginx/access.log`, and
    all errors are recorded on `/var/log/nginx/error.log`. Launch Wireshark too so
    you can inspect whether something different goes on. We’ll start with our friend,
    `ab`. We’ll suppress the `:3000` portion since we are now sending requests to
    NGINX, not directly to Mockoon. Parts of the output were omitted for brevity:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE14]'
  prefs: []
  type: TYPE_PRE
- en: 'Very interesting! Compare this with the previous results we obtained when sending
    packets directly to Mockoon. Observe that 94 out of 100 packets failed to be received!
    This means that 94% of the traffic was filtered by NGINX. Considering that we
    allowed a burst of five requests per second, this signifies that `ab` successfully
    received one of its bursts and one packet that was sent all alone. When you go
    to Wireshark to inspect the traffic, we will find some packets being sent with
    a 503 error code:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.14 – NGINX filtering the excessive requests that would go to Mockoon](img/B19657_figure_07.14.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.14 – NGINX filtering the excessive requests that would go to Mockoon
  prefs: []
  type: TYPE_NORMAL
- en: 'This happened with our basic test of 100 connections, with 10 of them simultaneously.
    In parallel, I was also monitoring the amount of allocated RAM and CPU occupation.
    There was no harm to any of them. Let’s repeat the most aggressive test that we
    ran with `ab` to see whether something changes:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE15]'
  prefs: []
  type: TYPE_PRE
- en: 'There is the same number of blocked connections. Also, we notice a huge increase
    in the processing time for most of the requests (from 1 ms to around 60 ms on
    average). An analog output can be verified on Wireshark as well. Check `/var/log/nginx/error.log`
    and you’ll find some lines like this one:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE16]'
  prefs: []
  type: TYPE_PRE
- en: Well, we can attest that our rate-limiting mechanism is doing its job. Let’s
    see how we can discover this when such a thing is in place. For this, we apply
    Burp Suite. Before starting it, double-check that you don’t have any other service
    running on its proxy service port (by default, `8080`). With Burp on, switch to
    the **Proxy** tab and then to the **Proxy Settings** sub-tab to confirm it’s on.
    Then, go to the **Intruder** tab and click on the **Intercept is on** button to
    turn it off. We don’t want to have to click on **Intercept** for every single
    request we will send.
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, on the `http://localhost/users` on this internal browser. You will receive
    the expected JSON structure with random usernames and IDs. You are good to close
    this browser. Now, back to Burp’s main screen, go to the **Proxy** tab, and click
    on the **HTTP history** sub-tab. You will see the request there:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.15 – Burp capturing the request sent to Mockoon and its response](img/B19657_figure_07.15.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.15 – Burp capturing the request sent to Mockoon and its response
  prefs: []
  type: TYPE_NORMAL
- en: 'Right-click on this request and select **Send to Intruder**. You’ll see that
    the **Intruder** tab will become orange. Click there. The first screen that shows
    up is named **Positions**. We won’t use it since we don’t need to change anything
    on the request. We are not fuzzing anything this time. We just need Burp to repeat
    it:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.16 – The original request captured by Burp’s Intruder](img/B19657_figure_07.16.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.16 – The original request captured by Burp’s Intruder
  prefs: []
  type: TYPE_NORMAL
- en: You are good to use any attack type, although, for this test, either the Sniper
    or Battering ram attack would suffice. With multiple payloads, the Pitchfork or
    Cluster Bomb methods would be more appropriate.
  prefs: []
  type: TYPE_NORMAL
- en: Next, switch to the `30` in the **Generate payloads** textbox. In the following
    figure, you can see the parameters changed in the **Payloads** section.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.17 – Configuring Intruder to send 30 equal packets](img/B19657_figure_07.17.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.17 – Configuring Intruder to send 30 equal packets
  prefs: []
  type: TYPE_NORMAL
- en: 'Now, navigate to the `10`:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.18 – Creating a resource pool and defining the number of concurrent
    requests](img/B19657_figure_07.18.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.18 – Creating a resource pool and defining the number of concurrent
    requests
  prefs: []
  type: TYPE_NORMAL
- en: Finally, click on the **Start attack** button. This will open the attack window
    (*Figure 7**.19*). This will make Intruder send repeated requests to NGINX. You
    will be watching them pop up on this window until request number 30\. Some requests
    might arrive earlier than others, outside of the original order. That’s expected
    since NGINX is imposing limitations on them. As a side note, the delay while receiving
    packets is one variable we need to consider. This may mean a rate-limiting control
    is in place. You can see one of the successful requests in *Figure 7**.19*. Pay
    attention to the date.
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.19 – A successful request captured by Intruder](img/B19657_figure_07.19.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.19 – A successful request captured by Intruder
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s compare it with the request right after it (*Figure 7**.20*), which failed
    (a 503 response code). You can see that the failed request was sent four seconds
    before the successful one, showing that a possible rate-limiting mechanism is
    activated:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 7.20 – A failed request that was received before the successful one](img/B19657_figure_07.20.jpg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 7.20 – A failed request that was received before the successful one
  prefs: []
  type: TYPE_NORMAL
- en: Other indications that such types of controls are protecting the API are the
    presence of response codes such as 429, which means “too many requests” or the
    presence of the `Retry-After` header on the responses. Now that we have identified
    the possibility of being throttled while sending requests to API endpoints, we
    need to learn how we can bypass such protection mechanisms. That’s exactly what
    we will cover in the next section.
  prefs: []
  type: TYPE_NORMAL
- en: Circumventing rate limitations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: When NGINX acts as a vigilant guard, rate limiting becomes the key security
    measure controlling traffic flow and preventing malicious activities. NGINX has
    a set of rate-limiting configurations to restrict the number of requests an API
    client can send within a specific amount of time. To navigate these restrictions
    effectively, we must first become familiar with the specific rate-limiting mechanisms
    employed. This involves deciphering server responses, looking for clues such as
    `Retry-After` headers or specific error codes (e.g., 429 Too Many Requests) that
    signal the presence and details of rate limiting as we covered before.
  prefs: []
  type: TYPE_NORMAL
- en: The first step to bypassing rate limitations is uncovering what triggers them.
    Common culprits include the client’s IP address, user session, or API key. By
    strategically varying these factors, we can pinpoint how the rate limit is applied.
    Tools such as Burp Suite become our allies, allowing us to manipulate request
    headers and simulate requests originating from different IPs or user sessions.
    Analyzing how the server’s response changes with different inputs can offer valuable
    hints about the underlying rate-limiting logic. In our case, we know NGINX is
    imposing a rate based on the source IP addresses.
  prefs: []
  type: TYPE_NORMAL
- en: To bypass such a restriction, we commonly apply a rotation of the source IP
    address. By constantly changing the IP address used to send requests, we can evade
    restrictions tied to a specific IP. Tools such as VPNs, public proxy servers,
    or anonymizing networks such as Tor can be employed for this purpose. Furthermore,
    automated scripts or specialized tools can be used to dynamically route requests
    through a pool of different IP addresses, further complicating detection. That’s
    exactly what we’re going to do here.
  prefs: []
  type: TYPE_NORMAL
- en: If the rate limit hinges on session identifiers or specific user-agent strings,
    altering these elements can potentially reset the rate limit counters. Burp Suite
    empowers us to manipulate cookies (which might store session data) and the `User-Agent`
    header within requests. Scripting custom headers for each request or leveraging
    browser automation tools that randomize user-agent strings can effectively bypass
    restrictions associated with user sessions or device types.
  prefs: []
  type: TYPE_NORMAL
- en: Another way to successfully perpetrate rate-limiting bypassing is by splitting
    the requests among multiple servers or devices. If NGINX tracks the number of
    requests per IP address, utilizing multiple servers, each with a unique IP, to
    send requests can help distribute the load and lessen the risk of hitting rate
    limits. While this strategy involves complex coordination, it can be highly effective,
    especially when combined with IP rotation techniques. In real-world attacks, **botnets**
    are usually applied for this purpose. It’s a matter of sending a command to them
    and then the attack starts at the same time from multiple different geographic
    locations. If you don’t know much about botnets, I shared a reference in the *Further
    reading* section. Look when you can. It’s unmissable.
  prefs: []
  type: TYPE_NORMAL
- en: Carefully examining how NGINX responds to requests exceeding rate limits can
    provide valuable insights into potential circumvention strategies. For instance,
    if the response headers suggest NGINX utilizes a fixed window counter for rate
    limiting, strategically sending requests just after the window resets can maximize
    request capacity. Automated tools can be used to monitor the timing and patterns
    of rate limits, adjusting request timing accordingly to exploit this window.
  prefs: []
  type: TYPE_NORMAL
- en: 'Time for action! Consider the following code. By switching the source IP address,
    we are sending different delayed requests to the `/``users` route:'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE17]'
  prefs: []
  type: TYPE_PRE
- en: 'This code simulates five different users. There’s a 1-second delay between
    each request and, when it fails, we add a 60-second (a.k.a. 1 minute) delay. We
    can adjust both timers, so they stay at the edge of the NGINX’s control. You can
    see that we are dispatching a total of 50 (10 times 5) requests in total, which
    would hit NGINX’s protection 9 times (remember that it allows a maximum burst
    of 5 requests). The key point here is the delay we are putting between every request.
    After running this code, you will receive successful outputs for all the requests
    (part of the output omitted for brevity):'
  prefs: []
  type: TYPE_NORMAL
- en: '[PRE18]'
  prefs: []
  type: TYPE_PRE
- en: NGINX’s error log has no new lines since all requests were sent and received.
    We can confirm that by checking Mockoon’s logs as well. Hence, we can conclude
    that by sourcing the requests from different IP addresses with small delays between
    them and bypassing the rate-limiting imposed by NGINX. As a future exercise for
    your environment, tweak the timers and the `nginx.conf` file to see the behavior
    with different values. Don’t forget to restart the service to apply the changes.
  prefs: []
  type: TYPE_NORMAL
- en: If an API provides multiple endpoints that can achieve similar results, alternating
    between them can help avoid exceeding rate limits on any single endpoint. This
    strategy depends on the API’s design, but it can be effective if rate limits are
    configured on a per-endpoint basis.
  prefs: []
  type: TYPE_NORMAL
- en: Sometimes, simply modifying how requests are made can be enough to evade rate
    limiting. This could involve batching several operations into a single request
    or spreading out requests that typically occur in rapid succession over a longer
    duration. APIs that offer endpoints capable of fetching or updating numerous resources
    in a single request can be particularly beneficial in such scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: In this more practical chapter, we had good coverage on DoS and DDoS, which
    can be used to discover vulnerabilities on target API endpoints. We then moved
    forward and learned how we detect when rate-limiting controls are in place (they
    can filter DoS attacks). We finished the chapter by crafting some Python code
    that, by imposing delays between requests and changing the source IP addresses,
    successfully bypassed the rate-limiting mechanism that was previously blocking
    them.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will start a new part where we will discover advanced
    topics on pentesting APIs. We begin by understanding how successful invasions
    can cause data exposure and sensitive information leakage.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The attack against Google services: [https://cloud.google.com/blog/products/identity-security/identifying-and-protecting-against-the-largest-ddos-attacks](https://cloud.google.com/blog/products/identity-security/identifying-and-protecting-against-the-largest-ddos-attacks)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'AWS suffering a giant DDoS attack: [https://aws-shield-tlr.s3.amazonaws.com/2020-Q1_AWS_Shield_TLR.pdf](https://aws-shield-tlr.s3.amazonaws.com/2020-Q1_AWS_Shield_TLR.pdf)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Memcached vulnerability that affected GitHub with DDoS: [https://github.blog/2018-03-01-ddos-incident-report/](https://github.blog/2018-03-01-ddos-incident-report/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Create Mock APIs with Mockoon: [https://mockoon.com/](https://mockoon.com/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'ApacheBench, a website/API performance tool: [https://httpd.apache.org/docs/current/programs/ab.html](https://httpd.apache.org/docs/current/programs/ab.html)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The Scapy Python library: [https://pypi.org/project/scapy/](https://pypi.org/project/scapy/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`hping3`: [https://linux.die.net/man/8/hping3](https://linux.die.net/man/8/hping3)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*What is API* *Throttling?*: [https://www.tibco.com/glossary/what-is-api-throttling](https://www.tibco.com/glossary/what-is-api-throttling)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'NGINX as a reverse proxy: [https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy/](https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Envoy, another open-source proxy offering: [https://www.envoyproxy.io/](https://www.envoyproxy.io/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Study of Botnets and their Threats to Internet* *Security*: [https://www.researchgate.net/publication/227859109_Study_of_Botnets_and_their_threats_to_Internet_Security](https://www.researchgate.net/publication/227859109_Study_of_Botnets_and_their_threats_to_Internet_Security)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'More information on DoS and DDoS attacks: [https://subscription.packtpub.com/book/programming/9781838645649/8/ch08lvl1sec02/denial-of-service-dos-and-distributed-denial-of-service-ddos-attacks](https://subscription.packtpub.com/book/programming/9781838645649/8/ch08lvl1sec02/denial-of-service-dos-and-distributed-denial-of-service-ddos-attacks)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Building RESTful Python web services, which various good tips on creating APIs,
    including imposing throttling to requests: [https://www.packtpub.com/en-th/product/building-restful-python-web-services-9781786462251](https://www.packtpub.com/en-th/product/building-restful-python-web-services-9781786462251)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Part 4: API Advanced Topics'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: You can achieve good attack rates with the topics covered in *Part 3*. They
    are foundational but still very effective. However, there are some situations
    in which you have to make use of something more sophisticated. We are talking
    about advanced attack techniques, which are covered in this part. You will be
    presented with ways in which to detect data exposure and leakage. You will also
    learn what API business logic is and how you can leverage bad implementations
    of it to gain unauthorized access and do unauthorized actions. As was the case
    with *Part 3*, you will be presented with some recommendations on how to avoid
    problems with this critical part of any API.
  prefs: []
  type: TYPE_NORMAL
- en: 'This section contains the following chapters:'
  prefs: []
  type: TYPE_NORMAL
- en: '[*Chapter 8*](B19657_08.xhtml#_idTextAnchor131), *Data Exposure and Sensitive
    Information Leakage*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[*Chapter 9*](B19657_09.xhtml#_idTextAnchor141), *API Abuse and Business Logic
    Testing*'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
