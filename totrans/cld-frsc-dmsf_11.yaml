- en: '8'
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: The Digital Forensics and Incident Response Process
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: So far, we have mostly looked at cloud-native tools for investigators to review
    logs and perform analysis. In the subsequent chapters, we will be looking at some
    of the third-party tools that complement cloud-native tools – tools that can aid
    in collecting and analyzing forensic artifacts, marrying cloud-native and third-party
    toolsets every investigator should be familiar with before embarking upon a cloud
    forensic case. Specifically, this chapter will revisit the basics of digital forensics
    and the incident response process. We will also identify some core concepts and
    introduce tools we have typically used in cloud forensic cases.
  prefs: []
  type: TYPE_NORMAL
- en: 'In this chapter, we will learn about the following:'
  prefs: []
  type: TYPE_NORMAL
- en: The basics of the incident response process
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Commonly used tools and techniques for host and memory forensics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Options to conduct live forensics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Network forensics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: A refresher on malware analysis
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Traditional forensics versus cloud forensics
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: This chapter assumes you are familiar with most of these topics; this is just
    a refresher on commonly accepted incident response techniques and tools utilized
    in cases.
  prefs: []
  type: TYPE_NORMAL
- en: The basics of the incident response process
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: 'The incident response process is an overarching process that allows investigators
    to approach incident response cases in a structured manner. The seven stages within
    the incident response process enable investigators to understand the actions required
    to satisfy the conditions in each stage. The following diagram outlines the critical
    steps of the incident response process:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.1 – The incident response process](img/00165.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.1 – The incident response process
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are the key stages:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Preparation**: This is the pre-incident stage, where organizations work with
    the incident response teams to document and plan activities in the event of an
    incident. Typically, organizations will establish their objectives for handling
    an incident and how to address critical cybersecurity issues arising from incidents
    in the form of an **incident** **response plan**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: The incident response plan will typically include the roles and responsibilities
    of various actions during an incident, key stakeholders who are notified, and
    so on. The incident response plan will also include organizations’ objectives
    for handling multiple incidents. Once the plans have been documented, organizations
    conduct periodic exercises to train, test, and update their plans regularly.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Detection**: This phase refers explicitly to the process where security teams
    are armed with tools to identify an incident. Typically, this will be the organization’s
    **security incident and event monitoring** (**SIEM**) tool or their **endpoint
    detection and response** (**EDR**) tool. These tools are monitored by a dedicated
    group of teams who provide an early warning about an incident occurring. Organizations
    set up routine security monitoring and alerting to identify breaches or incidents
    immediately. This is also the stage where security teams must triage the incident
    as soon as they are notified. **Triage** is a concept where **Digital Forensic
    and Incident Response** (**DFIR**) teams evaluate the breach, the scope of the
    breach, and the impact as a result of this breach and decide if further investigation
    is necessary. This is the step where the security team identifies the breach as
    an **incident**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Note
  prefs: []
  type: TYPE_NORMAL
- en: Security teams need to scope the incident correctly, identify how many systems
    are impacted, how big or small the spread of the breach is, and so on; otherwise,
    key elements can be missing from investigations.
  prefs: []
  type: TYPE_NORMAL
- en: '**Containment**: Right after the security teams call an incident and regroup
    various security teams, the typical first step is to contain the incident. Imagine
    an example of a burst pipeline with water gushing out; your first action would
    be to stop the leak before you can fix it. In similar teams in a cyber incident
    situation, the first action is, in this case, always about stopping the leak or
    a breach, then determining what has happened, how this incident occurred, and
    so on. Security teams can deploy specific security tools to contain the incident
    or use what is already deployed within an organization’s IT environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Examples include disconnecting the host from the network, network quarantining
    the host using an EDR tool, and shutting certain services down (not allowing access
    to users). This stage is also where security teams must preserve any evidence
    before they are eliminated. We learned about evidence preservation in [*Chapter
    2*](part0020_split_000.html#_idTextAnchor027) and its importance in investigations
    and potential legal actions. In most situations, organizations that do not have
    the skills or capabilities to preserve evidence usually rely on third-party professionals
    who offer DFIR services.
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '**Eradication and recovery**: In our view, the eradication and recovery and
    investigation and analysis phases occur in parallel, provided necessary forensic
    evidence is preserved. In the eradication and recovery stage, incident response
    teams work with other security teams within the organizations or authorized third
    parties to remediate the incident. This can include configurational changes, patching,
    or a complete system rebuild from backup or scratch. Once remediation is completed,
    these systems are restored to normal operations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Investigation and analysis**: Once you have stopped the incident from escalating
    further, investigation teams take over the case. Investigation teams are responsible
    for analyzing what happened; this includes a review of logs and forensic artifacts
    and understanding how the incident occurred, what data was impacted, the extent
    of the damage, and so on. This stage also provides input to the detection, eradication,
    and recovery stages to detect any associated incidents and apply additional remediations
    or security hardening that are required for recovery activities. Often, this is
    the stage where investigation teams identify the incident’s root cause. In incident
    response jargon, we call it **patient zero**. The investigation team will leverage
    threat intelligence to identify the threat actor, their motives, and potential
    **indicators of compromise** (**IoCs**) that may locate any additional investigative
    avenues.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Reporting**: Once the investigation has been wrapped up, key facts have been
    determined, and the root cause has been identified, the investigation team moves
    to the reporting stage. Ideally, the incident report will include all the aspects
    of the incidents, artifacts reviewed, a timeline of the incident’s occurrence,
    actions performed, and so on. Once the report has been developed, it is circulated
    to various relevant stakeholders. Depending on the nature and severity of the
    incident, the incident reports may only be shared with a limited group, including,
    in some cases, a breach coach (external legal counsel) to support and prepare
    the organizations for any potential litigation risks resulting from the incident.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Post-incident reviews**: Once everything has been wrapped up and the organization
    has moved back to the business-as-usual phase, organizations and security teams
    typically conduct a debrief, or what is known as a post-incident review. Security
    teams review documentation and investigative notes that were prepared during and
    after the incident and identify procedural gaps on how to improve in detecting
    or mitigating this incident from reoccurring. Security teams update their incident
    response plan using the knowledge they’ve gained from handling this incident.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Having established the fundamental aspects of the incident response process,
    let’s jump into the practical tools and techniques that are utilized in digital
    forensics investigations. These tools play a critical role in uncovering digital
    evidence, analyzing volatile memory, dissecting filesystems, and piecing together
    timelines of events.
  prefs: []
  type: TYPE_NORMAL
- en: Tools and techniques for digital forensic investigations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: One of the challenges in any incident investigation is acquiring artifacts quickly
    and in a forensically sound manner. In some cases, investigators may collect artifacts
    to investigate the incident further and identify the root cause. Moving swiftly
    to collect artifacts and evidence is crucial to investigations. This section will
    explore some valuable host and memory artifacts for investigations.
  prefs: []
  type: TYPE_NORMAL
- en: Prerequisites
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Before investigators can begin collecting their logs from the cloud console,
    we can utilize some of the prerequisites that were explored in previous chapters
    (enabling logs, audit trails, and so on), along with the ones listed here. These
    prerequisites will help investigators conduct their incident response activities
    much more smoothly:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Instance protection**: Some CSPs will allow instance protection once an incident
    is declared. For example, in AWS, you can configure your instance to prevent it
    from termination. This will ensure you are not terminating or deleting the instance
    once it shuts down and that all the artifacts and associated volumes are preserved
    for investigation. Investigators can even apply tags as a visual marker for security
    administrators not to change or update their configuration.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Decommission**: Deregister and decommission the instance from auto-scaling
    groups where possible.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Isolate instance**: Wherever possible, and if necessary, investigators should
    update the host firewall (the CSP’s firewall) to limit traffic to external IPs
    and ports. Investigators can access the instance from the cloud console and not
    connect from the internet.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Inventory-associated volumes**: When an incident is declared, and investigators
    have identified the instance, inventory the volumes attached to the host as snapshots
    may be required for all the connected volumes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Recreate in an isolated lab**: If the situation warrants, based on the investigative
    leads, then investigators should consider making a copy or snapshot of the instance
    and then using that to re-launch in a dedicated and isolated forensics lab hosted
    on the cloud to capture the necessary artifacts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Cloud host forensics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Host forensics or digital forensics involves collecting, processing, analyzing,
    and preserving digital host-based evidence. It requires discovering artifacts,
    traces, and information not generally available to security tools and often hidden
    from general users. Host forensics plays a crucial role in cybersecurity and law
    enforcement investigations, providing insights into some of the actions taken
    by attackers or users, a timeline of activities, and so on. It is helpful in cases
    of intellectual property theft, data breaches, malware infections, and insider
    threats, and it is commonly used in ransomware cases.
  prefs: []
  type: TYPE_NORMAL
- en: Recognizing that this book is intended for DFIR professionals, we will look
    at various forensic elements that investigators can perform at a high level. We
    will also spend time identifying key artifact sources that can be useful in the
    event of investigations. Collecting artifacts from cloud instances is similar;
    the artifacts and event logs are consistent across the deployment model. So, there
    is no difference between a physical host deployed in a data center versus a host
    running on the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Key artifact sources
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: We want to learn about key sources of artifacts that can sometimes be referred
    to for investigation. These sources often provide evidence that pinpoints what
    activity a user or threat actor (subject of the investigation) could have done
    in a system. By querying these artifact repositories, you will learn about threat
    actors and the vast depth of information operating systems generally retain when
    a user operates a computing system.
  prefs: []
  type: TYPE_NORMAL
- en: However, note that with every iteration of Windows, Linux, or any other operating
    system, the information that’s collected by the artifact or the artifact repository
    itself could change or may no longer be available. It is essential to note the
    version of the operating system, including major and minor versions, to prepare
    investigators on what artifacts would be available for a given version.
  prefs: []
  type: TYPE_NORMAL
- en: In the next subsection, we’ll look at two prominent and commonly used operating
    systems that are deployed for servers and IT infrastructural environments. You
    will also see similar deployments in the cloud (irrespective of the cloud provider).
  prefs: []
  type: TYPE_NORMAL
- en: Windows operating system
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'One of the most popular operating systems is Windows; it collects tons of artifacts
    that can be very helpful for investigations. The following is a list of artifact
    repositories that Windows typically records. However, as indicated earlier, depending
    on the operating system’s major and minor versions, some artifacts may be available
    in a different folder path or no longer available. Note that the following logs
    are not an exhaustive list, and third-party tools may collect additional records
    and artifacts that can be crucial for investigation:'
  prefs: []
  type: TYPE_NORMAL
- en: '`C:\Windows\System32\Tasks\*`: Contains XML files associated with Task Scheduler
    and contains information such as task definitions, task author, trigger criteria,
    and any task customizations. These are automated processes that trigger under
    specific conditions or at certain times. Threat actors use Task Scheduler to hide
    and evade detection while maintaining persistence. You may also see files associated
    with Task Scheduler created under `C:\Windows\Tasks\*` for some legacy systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`C:\Windows\Prefetch\*`: Prefetch is a Windows feature that allows the application
    to optimize loading times by preloading data files and libraries that it frequently
    uses. It provides forensic evidence or proof that an application was executed,
    including if any code or script was injected within an application (for example,
    code execution via PowerShell). When an application is executed for the first
    time, it creates a prefetch file that documents all the files and libraries that
    can be pre-loaded into memory from the disk before execution. Prefetch includes
    information such as executable name, execution times, and count.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`C:\Windows\System32\winevt\Logs\*`: Windows Event Logs are the most critical
    log sources every investigator will want to look into. Various categories of logs
    have dedicated log files that record associated events. Some of the important
    ones to look for are as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Security.evtx`: Login/logouts, destination hostname and IP address, alternate
    username, logon session ID, and logon type.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`System.evtx`: Windows system startup/shutdown time, service installs, driver
    failure/installations, hardware changes, and any system-related activities.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Windows PowerShell.evtx`: PowerShell script executions and cmdlet invocation,
    often corroborated with `Microsoft-Windows-WinRM%4Operational.evtx` for information
    on remote session authentication and session information and `Microsoft-Windows-PowerShell%4Operational.evtx`
    for script block logs.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Microsoft-Windows-PowerShell%4Operational.evtx`: Records details of PowerShell
    executions, including script blocks, module loads, and script policies.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Microsoft-Windows-TerminalServices-RDPClient%4Operational.evtx`: `Security.evtx`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Microsoft-Windows-TerminalServices-RemoteConnectionManager%4Operational.evtx`:
    Evidence of the RDP source IP address and username (evidence of where lateral
    movement occurred). This can be corroborated with `Microsoft-Windows-Terminal
    Services-LocalSessionManager%4Operational.evtx`, `Microsoft-Windows-RemoteDesktopServices-RdpCoreTS%4Operational.evtx`,
    and `Security.evtx`.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Microsoft-Windows-TaskScheduler%4Operational.evtx`: Information about scheduled
    task execution, creation, and registration and corroborated with `Security.evtx`
    for evidence of administrator privilege usage.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`Microsoft-Windows-WMI-Activity%4Operational.evtx`: `Microsoft-Windows-WinRM%4Operational.evtx`:
    `C:\Windows\System32\Logfiles\W3SVC1\*`: Contains information about `C:\Windows\appcompat\Programs\Amcache.hve`:
    `Amcache.hve` records application installations and executions. It includes full
    application metadata and the SHA1 hash of the executable file.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`C:\Windows\System32\config\SAM`: The Windows `SAM` database and any local
    accounts created within the host machine. Access to the `SAM` database requires
    elevated privileges, and threat actors often try to attack the `SAM` database
    to compromise credentials and use it to perform other forms of attack.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`C:\Windows\System32\config\SOFTWARE`: This is one of the critical registry
    hives that collects information about the system state, installed software, and
    various other configurational elements of Windows. Investigators can use the `SOFTWARE`
    registry hive to investigate if unauthorized software was installed, modified,
    or deleted. Investigators can also identify if any core elements were modified,
    such as startup programs (for maintaining persistence), system configurations
    (to lower defenses), and more.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`C:\Windows\System32\config\SECURITY`: The `SECURITY` registry hive is responsible
    for recording all the configurations related to the operating system’s security.
    This includes user accounts, associated account groups, password hashes, permissions
    in registry entries, and security policies. Investigators can analyze this registry
    hive to reconstruct threat actors, unauthorized user activity, and security policy
    violations. Like the `SAM` database, the `SECURITY` hive is also protected by
    the Windows operating system kernel and requires elevated privileges to modify.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`C:\Windows\System32\config\*.LOG1`: The `LOG1` file is a transaction log file
    that ensures the integrity of relevant registry hives (including `SOFTWARE`, `SAM`,
    and `SECURITY`). When changes are made to system configurations, changes are written
    to the relevant transaction log `LOG1` file, and when the changes are committed
    to the hive, the transaction log is marked as complete.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '`C:\Users\*\AppData\Roaming\Microsoft\Windows\PowerShell\PSReadline\ConsoleHost_history.txt`:
    Provides command history for PowerShell console executions by a user.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`C:\Users\*\NTUser.DAT`: For every user, an `NTUSser.DAT` file is created automatically
    by Windows that contains information about user-specific configurations or preferences,
    user interactions with various applications, actions taken, and most recently
    accessed resources.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`C:\Users\*\NTUser.DAT.LOG1`: Similar to registry hives, this transaction log
    file records all the transactions (changes) before committing the changes within
    the `NTUser.DAT` file. Investigators can use this for further correlation of user
    activities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`%SYSTEMDRIVE%\$Recycle.Bin\**`: `%SYSTEMDRIVE%` refers to the root drive partition
    nomenclature, which contains the `RecycleBin` folder. This folder, in turn, contains
    all the files and subfolders that are tagged for deletion. Investigators can use
    this to identify if any files were attempted to be deleted by the user or the
    threat actor.*   `%SYSTEMDRIVE%\$LogFile`: `$LogFile` is a special Windows file
    associated with the filesystem, specifically the `$LogFile` records metadata and
    directory and file creations, modifications, and deletions. Investigators can
    parse `$LogFile` to identify system changes over time and obtain information that
    allows information to be recovered from file storage that’s relevant to the investigation.*   `%SYSTEMDRIVE%\$MFT`:
    This refers to the **Master File Table** (**MFT**) of the NTFS filesystem. It
    provides metadata associated with files and directories, including timestamps,
    file sizes, and directory-to-file relationships. Investigators can use MFT to
    reconstruct the sequence of events concerning filesystem changes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Linux operating systems
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Given that most of the Linux ecosystem is open sourced and used in various
    industry sectors, including its application in the cloud, Linux provides investigators
    with much forensic value. When collecting forensic artifacts from Linux or performing
    live forensics, you should prioritize the following artifacts:'
  prefs: []
  type: TYPE_NORMAL
- en: '`/etc/passwd`: A plaintext file that contains information such as the **username**,
    **User ID** (**UID**), **Group ID** (**GID**), **home path**, and **default**
    **shell** application.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/etc/group`: Similar to the `/etc/passwd` file, it stores information related
    to user groups on the system.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/etc/crontab`: Cron is a job scheduler that automates the execution of commands
    or scripts per a predefined schedule. Threat actors can use cron jobs to maintain
    persistence within an environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/etc/fstab`: Contains information about the filesystem, drives, and partitions,
    including how devices are mounted at startup.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/etc/rc.d/**`: Contains startup and shutdown scripts for services. Threat
    actors can use this directory to maintain persistence and evade detection.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/etc/init.d/**`: Similar to `/etc/rc.d/**`, this directory contains **init**
    **scripts** or initialization scripts for system services. Threat actors can use
    this directory to inject malicious scripts during system initialization.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/etc/systemd.d/**`: Contains additional configurations for init scripts. It
    also allows you to override or extend script scope and services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/var/log/**`: This directory contains valuable event logs stored in files
    generated by system processes and applications.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/home/<username>/*`: The home directory is the user’s directory (defined within
    `/etc/passwd`), allowing the user to store files, configurations, and user-specific
    data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/home/*/.ssh/known_hosts`: Contains a list of public keys for remote servers
    that the user has previously used. It provides evidence of attempts of SSH-based
    connection to these remote servers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`/home/*/.ssh/autorized_keys`: It contains a list of public keys allowed to
    authenticate as the user for remote access. When a user wants to log into a remote
    server using SSH key-based authentication, their public key is added to the `authorized_keys`
    file on the server.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Other artifacts/metadata
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Once we have collected host-specific artifacts, investigators investigating
    the cloud instance should also collect **instance metadata**, including instance
    configuration, IP address allocations, VPC Subnet assignments, policy configurations,
    and more.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, host forensics involves meticulously examining a computer or
    device’s storage, operating system, and files to identify and gather critical
    digital evidence. This process uncovers artifacts such as log files, user profiles,
    registry entries, and system logs, aiding in reconstructing events, user activities,
    and potential security breaches.
  prefs: []
  type: TYPE_NORMAL
- en: Shifting our focus from host forensics, let’s jump into memory forensics. Memory
    forensics uncovers vital insights by examining the volatile memory of a system,
    providing a deeper understanding of ongoing processes, active applications, and
    potentially concealed artifacts.
  prefs: []
  type: TYPE_NORMAL
- en: Fast forensic collection tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Fast forensics refers to using streamlined and efficient methodologies and tools
    in digital forensics investigations. Traditional forensic processes can be time-consuming,
    leading to delays in investigations. Fast forensics aims to address this issue
    by prioritizing speed without compromising the integrity of the investigation.
    Investigators should consider fast forensics approaches to enhance their response
    times, allowing them to identify and mitigate cyber threats quickly, respond to
    incidents promptly, and minimize the impact of the incident.
  prefs: []
  type: TYPE_NORMAL
- en: 'Several tools have been developed to support fast forensics. Fast forensics
    is typically practical when dealing with a large organization with endpoints spread
    geographically. Some of the notable fast forensic tools are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**CyLR**: CyLR is a live response tool that collects artifacts from various
    sources and creates a package that can be utilized in offline analysis. CyLR packages
    can be analyzed using Magnet Axiom or Sleutkit Autopsy tools. CyLR can be deployed
    via EDR or popular script deployment techniques for automated collections. It
    can be used to collect from Windows and Linux operating systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**KAPE**: Developed by Eric Zimmerman, **Kroll Artifact Parser and Extractor**
    (**KAPE**) is known for its modular and extensible framework, making it highly
    adaptable to various digital forensic scenarios. The tool is particularly valued
    for its ability to collect artifacts from various sources within an operating
    system, helping investigators efficiently extract crucial evidence. KAPE utilizes
    a configuration file to define specific artifacts and locations of interest, allowing
    forensic practitioners to customize their data collection based on the requirements
    of a particular investigation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**PowerForensics**: PowerForensics, on the other hand, is a specific PowerShell
    module focused on forensics. It provides a set of cmdlets that enable users to
    interact with the NTFS filesystem, allowing for valuable forensic information
    to be extracted from Windows machines. PowerForensics can be used to analyze artifacts
    such as file metadata, file content, and other filesystem structures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Kansa**: Kansa is an open source incident response and threat-hunting framework
    written in PowerShell. It facilitates collecting and analyzing artifacts from
    Windows systems to aid in security investigations. Kansa provides a set of PowerShell
    scripts and modules that can automate various aspects of the incident response
    process. The framework allows security professionals and incident responders to
    run predefined or custom PowerShell scripts across multiple endpoints in a network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: We have included more details in the *Further* *reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: Memory forensics
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Memory forensics is an advanced digital investigation technique that analyzes
    a computer or device’s volatile memory (**random access memory** – **RAM**). Unlike
    traditional host forensics, which examines storage and files, memory forensics
    dives into the live state of a system, revealing active processes, running applications,
    and hidden artifacts that can provide valuable insights into cyberattacks, malicious
    activities, and volatile data that might not be stored on disk. Everything that’s
    executed within the operating system of the host has to go through the host’s
    memory. This approach offers a unique perspective on the digital landscape, enabling
    investigators to uncover crucial evidence that might otherwise remain concealed.
  prefs: []
  type: TYPE_NORMAL
- en: Memory forensics captures information such as running processes and threads,
    malware or rootkits, open file handles, caches and clipboard contents, encryption
    keys, hardware and software configuration, registry keys, websites visited, and
    commands entered on the console.
  prefs: []
  type: TYPE_NORMAL
- en: Memory forensics in cloud environments presents a unique set of challenges and
    opportunities. As organizations increasingly migrate their systems to cloud platforms,
    understanding and analyzing volatile memory becomes crucial for detecting security
    breaches, insider threats, and unauthorized access.
  prefs: []
  type: TYPE_NORMAL
- en: Especially in the cloud, memory forensics faces challenges due to the shared
    nature of resources, dynamic provisioning, and limited access to physical hardware.
    Virtualization and containerization add layers of complexity, making it essential
    to adapt traditional memory forensics methodologies. However, the cloud also offers
    advantages such as centralization of logs, ease of scalability, and the potential
    to capture memory snapshots across various instances simultaneously. This can
    aid in identifying sophisticated attacks that might target multiple instances
    or users within the cloud environment.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s look at some primary artifacts investigators should typically collect
    and analyze. These artifacts resemble the Windows operating system running in
    the cloud or on a server. Given that memory forensics is worthy of a separate
    book, we assume you are familiar with the basics of computer memory and its various
    elements and functionalities.
  prefs: []
  type: TYPE_NORMAL
- en: Memory acquisition tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In the context of cloud forensics, there are a few options for investigators:
    collect and analyze the memory images of a live system or collect and analyze
    the memory artifacts written to the disk in an offline host. The following figure
    illustrates the distinction between live and dead systems and the tools available
    for collecting memory images from them:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.2 – Memory acquisition sources/tools](img/00003.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.2 – Memory acquisition sources/tools
  prefs: []
  type: TYPE_NORMAL
- en: 'Let’s look at some of the toolsets that can acquire memory in a live system
    while looking at memory remnants of a dead system that can be collected for forensic
    investigations:'
  prefs: []
  type: TYPE_NORMAL
- en: '`dd` is a command that’s commonly used on Linux/Unix platforms for low-level
    copying and conversion of data. In the context of digital forensics, `dd` is used
    in Linux/Unix systems for acquiring a copy of the memory or RAM. Note that it’s
    not typically recommended due to the potential risks and challenges involved.
    Improper use of `dd` for memory acquisition can result in inaccurate or incomplete
    memory captures and disrupt the target system’s operation.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`pagefile.sys`) is a virtual memory extension, allowing the memory to use this
    storage to store data temporarily. In older Windows versions, this file is known
    as `swapfile.sys`. Typically, this is performed when physical RAM space is at
    capacity and applications are queued for execution; Windows will automatically
    offload memory pages into disk via `pagefile.sys`. From a forensic perspective,
    `pagefile.sys` can contain remnants of sensitive or valuable information, including
    fragments of files, registry data, and even passwords. These remnants might not
    be present in the main memory or traditional disk storage, making the page file
    a potential source of evidence. Note that the page file is volatile, meaning its
    contents are not retained after a system shutdown or reboot. However, if a system
    is hibernated, the contents of the page file can persist in the hibernation file
    (`hiberfil.sys`) for potential recovery. It’s a good practice to capture page
    files during memory acquisition.*   `MEMORY.DMP` in the `%SystemRoot%` folder
    of your Windows operating system. Based on the size of the dump file, investigators
    can identify if it’s a complete memory dump (also known as **Kernal Memory Dump**)
    or a snapshot of a memory page that was dumped during a crash (**Active Memory
    Dump**). In any case, existing memory analysis tools should allow investigators
    to parse and analyze these crash dumps. Note that in Linux systems, memory pages
    written to disk are known as **swap files** and are only utilized when the allocated
    memory is insufficient. Investigators can only collect the swap files. Swap files
    are not retained on the disk when rebooting a Linux system. Note that investigators
    may see swap files on disk if a Linux system is hibernated. However, this is rare;
    Linux systems are not commonly hibernated.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While there are plenty of options for collecting memory images (live or dead
    systems), it is essential to note that from a cloud forensics standpoint, it is
    no different from collecting memory swap files or pages from the disk as that
    of a dead box system. Investigators must collect the correct disk copies associated
    with the respective cloud instances. Now that we have a memory snapshot or an
    image, let’s explore the tools to analyze them.
  prefs: []
  type: TYPE_NORMAL
- en: Memory analysis tools
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'In this section, we’ll look at some of the tools that are commonly used during
    an investigation, especially for analyzing system memory artifacts. Once memory
    images have been collected, there are special tools that carve information off
    memory:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Volatility**: Volatility is one of the most popular open source memory forensics
    frameworks and a preferred choice by investigators for memory analysis. Written
    entirely in Python, it allows you to analyze memory snapshots and supports various
    operating systems. It provides multiple plugins for extracting information about
    running processes, network activity, registry data, and more. Volatility supports
    multiple memory dump formats and is extensively used by professionals in the field.
    Volatility can also natively analyze older Windows versions of **hiberfil.sys**
    and **pagefile.sys**. However, various other specific tools are developed to address
    challenges and handle changes to hibernate files with changes to Windows operating
    systems in a much better way.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Velociraptor**: Velociraptor is an open source endpoint monitoring and digital
    forensics platform designed to provide high-fidelity data collection and analysis
    capabilities across a network of endpoints. One of the critical features of Velociraptor
    is its ability to perform live memory analysis on endpoints to uncover insights,
    detect anomalies, and gather evidence for incident response and forensic investigations.
    Analysts can tailor memory analysis tasks to their specific investigation needs
    with support for customizable queries and plugins. Beyond memory analysis, Velociraptor
    facilitates proactive threat detection through predefined indicators and patterns.
    Its centralized management, workflow automation, scalability, and active user
    community contribute to its effectiveness in various environments (physical, virtual,
    and the cloud).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Rekall**: Rekall is a fork on Volatility and enhanced it by enabling live
    memory forensics. Like Volatility, Rekall includes most of the features of Volatility
    and can analyze **hiberfil.sys**, **pagefile.sys**, and swap files in different
    operating systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**GRR**: GRR is another open source incident response platform that is agent-based.
    Investigators must deploy an agent to capture telemetry or perform live memory
    forensics. Although more powerful memory analysis tools are available, such as
    Velociraptor and Volatility, GRR remains a valuable tool in any organization’s
    DFIR arsenal due to its unique strengths and capabilities. GRR is designed explicitly
    for collecting endpoint data, including real-time analysis of memory files, making
    it a versatile tool for any cybersecurity team.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Magnet AXIOM**: Designed to assist law enforcement agencies, corporate investigators,
    and DFIR professionals, Magnet AXIOM is a license-based commercial tool developed
    by Magnet Forensics that focuses on efficiently collecting, analyzing, and presenting
    digital evidence from various sources. It supports data acquisition from diverse
    sources such as computers, smartphones, and cloud services. Magnet AXIOM also
    supports the analysis of artifacts such as files, emails, and chat messages. It
    supports memory images captured from various operating systems, including **hiberfil.sys**,
    **pagefile.sys**, and swap files. It can also parse quick forensics packages collected
    through multiple third-party tools. Magnet AXIOM supports timeline analysis and
    reconstructs events from digital evidence. It also supports keyword searches,
    data carving, and advanced filtering to help investigators quickly pinpoint relevant
    information. Finally, it streamlines report generation, supports collaboration,
    and specializes in mobile device analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In conclusion, host and memory forensics are indispensable pillars in digital
    investigations. The analysis of artifacts on operating systems, coupled with the
    extraction of volatile memory data, allows digital forensic investigators to reconstruct
    digital trails, uncover hidden evidence, and decipher the story behind cyber incidents.
    Host forensics comprehensively explains a system’s history and user activities.
  prefs: []
  type: TYPE_NORMAL
- en: In contrast, memory forensics enables real-time snapshots to be captured, exposing
    the inner workings of processes and potential threats. Intertwined with advanced
    tools and methodologies, these disciplines collectively contribute to the pursuit
    of truth and justice in the dynamic landscape of digital forensics. We will learn
    how to acquire disk and memory images from the cloud in [*Chapter 10*](part0030_split_000.html#_idTextAnchor199).
    The following section focuses on techniques to perform live forensic analysis
    using various tools, as well as perform threat hunting, given that threat actors
    have evolved and use sophisticated techniques to hide malware in plain sight.
  prefs: []
  type: TYPE_NORMAL
- en: Live forensic analysis and threat hunting
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Digital forensic investigators operate on the principle that malware must always
    run on memory; there is nowhere they can hide. However, in recent times, technology
    has evolved to make memory massive and less volatile, giving rise to fileless
    malware – that is, malware that does not touch the disk – which maintains this
    hidden nature until execution time. The following sections will cover some of
    the tools that modern corporate investigators utilize to identify malware and
    conduct threat hunting, helping you understand common persistence mechanisms that
    malware uses.
  prefs: []
  type: TYPE_NORMAL
- en: EDR-based threat hunting
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Advancements in computational technologies, cloud infrastructure, and support
    for massive disk and memory sizes have made it necessary for a new set of tools
    that can continuously monitor a host and collect live telemetry data on disk and
    memory, capture every footprint of an application, spot malware, and stop the
    attack before it can get worse. This technology, known as **EDR**, is a new class
    of security tools (commercial tools) that collects advanced telemetry and uses
    various techniques beyond standard signature-based detection to identify and detect
    malware and respond to the threat tactically. We typically refer to EDRs as antiviruses
    on steroids as they can do much more than a simple antivirus, which threat actors
    can easily turn off or evade in terms of being detected.
  prefs: []
  type: TYPE_NORMAL
- en: EDRs generally operate at the operating system kernel level and can identify
    various activities on disk and memory beyond what a user can see. EDRs can track
    process calls, information regarding child processes, Windows **application programing
    interface** (**API**) usage, the command line passed to each process, network
    connections, process thread information, **Dynamic Link Libraries** (**DLLs**),
    file handles, registry handles, and more.
  prefs: []
  type: TYPE_NORMAL
- en: Note that EDRs are not forensic tools. However, they do enhance forensic investigation
    by providing high-fidelity telemetry that would otherwise be missed if EDRs were
    not deployed within an organization. Most popular EDRs also offer forensic teams
    the ability to perform live queries on the host. You can query the host system
    using preset command-line parameters and perhaps even run a custom-built script
    to collect additional information or artifacts. Forensic investigators typically
    use live querying to download artifacts, logs, or even quick forensic packages
    for offline analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Diving deep with EDR hunting
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Let’s assume that, as investigators, an EDR tool was deployed as part of the
    breach response. We are using the **SentinelOne Singularity platform** (used with
    permission) to demonstrate hunting using this method.
  prefs: []
  type: TYPE_NORMAL
- en: 'Once the SentinelOne agent has been installed on the infected system, it typically
    scans the system and starts breach containment, meaning any detected malware is
    contained. An alert is raised on the central Singularity console. This becomes
    the starting point for investigating or hunting, and investigators can continue
    to pursue their investigation via this EDR tool. In the following screenshot,
    notice that there’s additional information under the **Threats** dashboard while
    providing options for kick-starting threat hunting. The **SHA1** hash also allows
    investigators to look at other threat intelligence sources, such as VirusTotal:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.3 – Sample alert on SentinelOne EDR (produced with permission)](img/00020.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.3 – Sample alert on SentinelOne EDR (produced with permission)
  prefs: []
  type: TYPE_NORMAL
- en: 'Once investigators can obtain enough information about the circumstances of
    the threat, they can begin to perform their threat hunting. SentinelOne offers
    multiple ways to hunt for threats. One of the easiest ways is through their Singularity
    `tgt.file.sha1 = "41e8db9bb005fce152e08c20e6392e0a5d44bb6e"` SHA1 entry:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.4 – SHA1 hash-based hunting in the SentinelOne Singularity XDR module](img/00185.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.4 – SHA1 hash-based hunting in the SentinelOne Singularity XDR module
  prefs: []
  type: TYPE_NORMAL
- en: Notice that each result has a checkbox that provides more information regarding
    the data collected. This includes information regarding the event itself, the
    account it was executed under, the SentinelOne agent’s name and endpoint makeup,
    and details of the detection, including process information and command-line parameters
    supplied. Each entry can further be used to hunt deeper, which is especially useful
    for complex threat scenarios.
  prefs: []
  type: TYPE_NORMAL
- en: 'SentinelOne Singularity XDR natively presents a collection of all the fields
    in the telemetry data. The **FIELDS** view allows investigators to quickly jump
    in and investigate without spending time identifying their way around it. Here
    is an example of the field list that’s part of the navigation options. It also
    provides aggregated field results for investigators to identify any anomalies.
    Each result can be clicked through to apply relevant search filters for hunts:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.5 – SentinelOne Singularity XDR’s fields](img/00114.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.5 – SentinelOne Singularity XDR’s fields
  prefs: []
  type: TYPE_NORMAL
- en: Once initial hunts have been performed using the Singularity XDR module, based
    on the results, investigators can quickly pivot to obtain more information regarding
    the activities around the detected threat. Through telemetric data, we know that
    the threat actor used PowerShell to attempt to access and execute the malware.
    The sample screenshot shows the event data identifying this threat actor’s action,
    allowing investigators to pivot further to obtain more situational information
    about the event.
  prefs: []
  type: TYPE_NORMAL
- en: 'Investigators can use the **Event Details** tab when a relevant event entry
    is accessed (see *Figure 8**.3*). **Event Details** provides more information
    about the event, including the commands for invoking the malware:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.6 – Event Details based on the SigularityXDR search result](img/00153.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.6 – Event Details based on the SigularityXDR search result
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, EDR enhances the process of detecting and preventing malware
    from being executed. In the context of cloud forensics, having an EDR/XDR tool
    to investigate a cloud endpoint combined with the logs generated on the cloud
    console enhances the investigator’s ability to analyze and identify how the threat
    occurred. Furthermore, from a legal standpoint, this allows investigators to corroborate
    the events from various sources, ensuring the identified investigations are forensically
    sound and legally acceptable.
  prefs: []
  type: TYPE_NORMAL
- en: Hunting for malware
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Hunting for malware is a proactive approach to uncovering malicious applications/software
    within a host. This technique goes beyond traditional security measures by actively
    seeking signs of compromise, identifying root causes, and preventing future incidents.
    Incident responders analyze system behavior, employ threat intelligence, and leverage
    memory analysis to uncover signs of compromise. By scrutinizing logs, conducting
    sandboxing, and utilizing automated tools, they detect anomalies and patterns
    associated with malware. Here are some of the ways malware will commonly try to
    evade detection:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Service hijacking**: Service hijacking involves malicious actors gaining
    control over system services, enabling them to execute arbitrary code within the
    context of legitimate processes. By compromising trusted services, attackers can
    execute malicious commands or payloads, evading detection. One real-life example
    is the **Zeus** banking Trojan, which exploited the WMI service to execute malicious
    code and maintain persistence on infected systems.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Process injection**: Process injection is a technique that malware uses to
    insert its code into a legitimate process, effectively hiding its presence within
    a trusted application’s memory space. Common injection methods include DLL injection,
    reflective DLL injection, and process hollowing. Detecting process injection involves
    monitoring memory regions for unexpected modifications, analyzing process memory
    for code inconsistencies, and examining API calls to identify signs of injected
    code execution. The **TrickBot** malware used process injection techniques such
    as reflective DLL injection to inject malicious code into legitimate processes,
    evading detection by security solutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Alternate Data Streams** (**ADS**): ADS provides a way to hide data within
    a legitimate file by attaching additional data streams. Malware can use ADS to
    store its code or configuration, making detection challenging. Hunting for ADS
    involves analyzing file metadata, checking for multiple data streams within files,
    and monitoring unusual data stream associations.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Web shells**: Web shells are malicious scripts or code snippets embedded
    within web applications or servers, allowing attackers to gain remote access and
    control. The **Shellshock** vulnerability allowed attackers to inject malicious
    code into web server environments, effectively deploying web shells to gain unauthorized
    access.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Packing**: Packing involves compressing or encrypting malware files to obfuscate
    their contents and prevent straightforward analysis. Malware typically unpacks
    in memory during runtime, making it difficult for investigators to sample it and
    identify its true nature. Detecting packing involves identifying packed executable
    headers, analyzing file entropy levels, and employing unpacking tools or techniques
    to reveal the original code. One of the most common application packers that legitimate
    applications and malware use is **UPX**.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Code signing**: Malware authors might sign their code with stolen or fraudulently
    obtained digital certificates to appear legitimate and avoid detection by security
    software. Detecting code signed with valid certificates involves checking the
    certificate’s authenticity, examining the certificate chain, and monitoring for
    revoked certificates or anomalies in the certificate’s usage. There have been
    multiple examples in recent history where attackers stole an organization’s code
    signing certificate to sign malware and use it for downstream supply chain attacks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Fileless malware**: Fileless malware operates in memory without leaving traces
    on disk, making detection difficult. This technique often involves leveraging
    scripting languages or exploiting system tools. Detecting these techniques requires
    collecting specific logs, such as PowerShell, and obtaining a memory image. EDRs
    are a great way to detect these attacks since they monitor and track filesystem
    changes and memory activities. Popular fileless malware methods use PowerShell’s
    **IEX** cradle to download an application or additional scripts in memory and
    execute it at runtime without ever touching the disk. Recently, threat actors
    have been spotted using PowerShell Empire, a framework that allows fileless malware
    delivery techniques.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: As we can see, threat actors can hide and evade detection on a host in various
    ways. While we discussed the most common and obvious ones, advanced threat actor
    groups use innovative techniques. To some extent, malware running in a cloud infrastructure
    may make an investigator’s life easier because CSPs have integrated various security
    tools to identify and spot malicious activities.
  prefs: []
  type: TYPE_NORMAL
- en: Moreover, most CSPs partner with multiple security vendors that provide tooling
    and visibility into these hosts, thus helping investigators identify malware more
    quickly than traditional investigative methods. For example, AWS GuardDuty can
    scan the VMs directly without any agent installation and provide visibility into
    the malware detection capability. At the same time, GCP’s CloudSCC and Azure’s
    Security Center have similar features that monitor the VMs and notify the administrator
    of malicious programs. In either case, these detections are provided by CSP’s
    partners yet available for investigators in the respective CSP security consoles.
    We’ll cover these tools in *Chapters* *4*, *5*, and *6*.
  prefs: []
  type: TYPE_NORMAL
- en: Common persistence mechanisms
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'We will now look at common persistence mechanisms that malware can typically
    employ. It is no different in the context of the cloud since malware will run
    irrespective of the underlying infrastructure:'
  prefs: []
  type: TYPE_NORMAL
- en: '`Run` key of the Windows Registry start applications or scripts during every
    user login, allowing user-specific applications to launch automatically. Some
    of the common Registry keys to scan for are as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE0]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Startup folders**: Applications placed in the user’s or system’s startup
    folders are automatically launched when a user logs in, enabling user-specific
    customization of startup behavior. One of the most common folders that’s used
    by threat actors to maintain persistence is as follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '[PRE1]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: '**Scheduled tasks**: Scheduled tasks configured to run at system startup or
    user login times are managed by Windows Task Scheduler and can perform various
    actions, such as updates or maintenance tasks.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Group Policy Objects** (**GPOs**): GPOs are one of the most common ways threat
    actors maintain persistence within an organization. They do this by creating a
    malicious GPO with the company’s domain controller to prepare and dispatch malware
    copies for persistence and execution. Moreover, threat actors can tweak the GPO
    to control how malware is deployed across the enterprise centrally. Threat actors
    can also create a scheduled task when a condition is met and can either download
    scripts or trigger malware execution. Most ransomware operators use GPOs to centrally
    control and deploy ransomware across the organization, leaving no time for security
    administrators to stop the attack.*   **DLL hijacking**: DLL hijacking is a technique
    that’s exploited by attackers to achieve malware persistence by manipulating how
    Windows loads DLLs. During DLL loading, Windows follows a specific order to locate
    the required DLLs, including standard directories such as the application’s folder
    and system directories. Attackers identify a vulnerable application and place
    a malicious DLL with the same name as the needed one in a guide the application
    searches. When the application starts, the malicious DLL is loaded instead of
    the legitimate one, executing the attacker’s code within the application’s context.
    This allows the attacker to establish persistence, run arbitrary code, and potentially
    gain control over the compromised system. Due to the regular use of the targeted
    application, the malicious code executes consistently, ensuring persistence even
    after the system reboots.*   **WMI event consumers**: Malware persistence through
    WMI event consumers involves leveraging WMI’s capabilities to execute malicious
    actions at specific trigger events. Here are the steps attackers might take to
    achieve this form of persistence. These steps are ultimately stored in a **Managed
    Object Format** (**MOF)** file, which is used to register new classes within the
    WMI repository:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Create a malicious event consumer**: Attackers create a WMI event consumer,
    a script or executable designed to execute when a specific WMI event occurs. System
    events such as startup, login, or other custom triggers could trigger this event.
    The malicious event consumer contains instructions to execute the attacker’s payload.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Event filter and binding**: Attackers create an event filter that defines
    the conditions under which the malicious event consumer should execute. This filter
    is associated with a specific trigger event. They then bind the event filter to
    the malicious event consumer, establishing a link between the filter and the payload
    containing the script or executable.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: '**Trigger event execution**: When the defined trigger event occurs, the associated
    event filter evaluates whether the conditions are met. If the conditions are satisfied,
    the WMI event consumer executes the payload, which could be malware, a script,
    or an executable. This payload runs in the context of the WMI service, allowing
    attackers to establish persistence, execute arbitrary code, and potentially gain
    control over the compromised system.'
  prefs:
  - PREF_IND
  - PREF_OL
  type: TYPE_NORMAL
- en: 'Investigators should refer to the following commands to query the WMI repository
    and determine malicious WMI:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '[PRE2]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: In summary, the convergence of live forensics, EDR solutions, proactive malware
    hunting, and advanced persistence mechanisms underscore a comprehensive approach
    to modern cybersecurity. Live forensics, powered by cutting-edge tools and techniques,
    provides real-time insights into ongoing threats, enabling swift incident response.
  prefs: []
  type: TYPE_NORMAL
- en: We are now transitioning to the realm of network forensics. Network forensics
    is pivotal in uncovering cyber threats as it allows us to examine network activities,
    traffic patterns, and communication behavior. By delving into the intricacies
    of network data, we will gain invaluable insights into potential breaches, malicious
    activities, and the broader tactics employed by adversaries. This is highly vital
    in the context of cloud forensics.
  prefs: []
  type: TYPE_NORMAL
- en: Network forensics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As this section’s title suggests, network forensics is an approach to forensically
    analyzing network protocols, packets, and any artifacts on the wire. Network forensics
    in the context of cloud environments involves analyzing network traffic, communication
    patterns, and data flows between CSP services and external users to uncover potential
    security breaches, data exfiltration, and unauthorized access. By examining network
    data within the cloud infrastructure, we can create a comprehensive picture of
    events, identify anomalies, and detect the traces left behind by cyber threats.
    Fundamentally, investigators must have access to network data to conduct this
    analysis. This deeper scrutiny allows us to respond to incidents effectively,
    mitigate risks, and maintain a resilient cloud security posture.
  prefs: []
  type: TYPE_NORMAL
- en: Basic networking concepts
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'In network forensics, investigators must always remember that any network communication
    is broken down into the layers outlined by the network communication model, which
    can be **Open Systems Interconnection** (**OSI**) or **Transmission Control Protocol/Internet
    Protocol** (**TCP/IP**). These models provide a clear picture to investigators
    of how a threat actor accessed a host and what protocols were used by the threat
    actor. Let’s look at these two models in more detail. Note that we assume you
    are familiar with this area; this is only a refresher:'
  prefs: []
  type: TYPE_NORMAL
- en: '**OSI model**: This model is a framework that standardizes the functions and
    interactions of various networking protocols, serving as a guide for designing
    and understanding how different networking technologies communicate. The model
    is divided into seven layers, each responsible for specific tasks and functions.
    The following figure outlines the seven layers and associated protocols that operate
    within each of those layers. In the context of the cloud, lower-level layers are
    managed by CSPs. This includes the **physical layer** and **data link layer**.
    In contrast, the **network layer** is a shared responsibility between cloud customers
    and CSPs since this layer allows customers to create their VPCs. To some extent,
    the **transport layer** is a shared responsibility if a specific IPsec needs to
    be configured, for example. On the other hand, the **session**, **presentation**,
    and **application layers** are the responsibility of cloud customers. While CSPs
    act as enablers, cloud customers are responsible for configuring and securing
    them:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.7 – OSI model and cloud responsibilities](img/00171.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.7 – OSI model and cloud responsibilities
  prefs: []
  type: TYPE_NORMAL
- en: '**TCP/IP reference model**: This model is a widely used framework for understanding
    and describing the functionalities of networking protocols that power the internet
    and many other networks. Unlike the seven-layer OSI model, the TCP/IP model consists
    of four layers, each with its own set of protocols and responsibilities; however,
    it closely aligns with the OSI model. The following figure shows a breakdown of
    the TCP/IP reference model’s layers and supported protocols. In the context of
    the cloud, the reference models’ lower layers, the **link layer** and the **CSPs**,
    typically handle the **internet layer**. In contrast, the customer and CSPs share
    responsibility for the **transport layer**, allowing customers to create their
    VPC subnets. Typically, it’s the customer’s responsibility to manage the **application
    layer**:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.8 – TCP/IP reference model and cloud responsibilities](img/00136.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.8 – TCP/IP reference model and cloud responsibilities
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will explore log sources that are vital for investigative
    purposes, and we will also explore some tools for easier network analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Cloud network forensics – log sources and tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Let’s look at some of the network artifacts that can be leveraged from CSPs
    and cloud instances:'
  prefs: []
  type: TYPE_NORMAL
- en: '**VPC flow logs**: In the previous chapters ([*Chapter 4*](part0022_split_000.html#_idTextAnchor065),
    [*Chapter 5*](part0024_split_000.html#_idTextAnchor095), and [*Chapter 6*](part0025_split_000.html#_idTextAnchor108)),
    we looked at how to turn on and enable VPC flow logs. These are the most essential
    logs an investigator can access for network investigation. While VPC flow logs
    do not capture entire network traffic packets, analyzing and determining the source
    and destination nodes for malicious activities is vital.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**tcpdump outputs**: In situations where VPC flow logs are not helpful, such
    as when examining data exfiltration and uncovering what data was exported by the
    threat actor, investigators need an entire packet dump. tcpdump is a widely popular
    network capture framework for collecting complete network packets and is vital
    for identifying threat actor activities on the network. With tcpdump outputs,
    investigators can trace the threat actor activities and sessions, determine transferred
    files or malware, and even reconstruct the files or malware from the packet capture
    for further analysis. With full packets, investigators can also replay and identify
    vulnerabilities exploited in the environment.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logs from cloud-based firewalls and web application firewalls** (**WAFs**):
    Most cloud-based organizations may also deploy a cloud-based firewall, which is
    a virtual firewall instance, or use CSP’s native firewalling capabilities (with
    its limited features). Cloud-based firewalls generate logs that detail network
    traffic, including allowed and denied connections, while WAFs focus on web application-related
    traffic, filtering out malicious requests. Analyzing these logs can identify patterns
    of unauthorized access, attacks, and potential breaches. Investigators can reconstruct
    events, pinpoint vulnerabilities, and understand attackers’ tactics by correlating
    firewall and WAF logs with other forensic data, such as system logs and packet
    captures. These logs serve as a crucial source of evidence in cloud network forensics,
    facilitating swift and accurate incident detection, response, and mitigation measures.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Now that we have an idea of the tools we can use to capture network traffic
    information, let’s look at an example of using one of the popular network investigation
    tools available for investigators.
  prefs: []
  type: TYPE_NORMAL
- en: Network investigation tools
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: Network investigation tools in DFIR are essential resources that allow investigators
    to delve deep into network activities, analyze traffic patterns, and uncover potential
    security breaches. For example, investigators can tap the network to identify
    data exfiltration or use malicious code on a cloud instance. These tools provide
    the means to scrutinize network data, identify anomalies, trace the origins of
    threats, and reconstruct the sequence of events leading up to and during a security
    incident without accessing the host directly in the middle of an incident.
  prefs: []
  type: TYPE_NORMAL
- en: Not only do network investigations allow for a deeper dive, but they also provide
    essential IoCs that investigators can correlate with multiple sources, such as
    by using the IP address of the threat-actor-controlled remote server for data
    exfiltration, which can then be tracked within the SIEM tools to determine if
    there is any other evidence of exfiltration across the environment. Let’s explore
    the diverse network investigation tools and techniques that are integral to modern
    DFIR practices.
  prefs: []
  type: TYPE_NORMAL
- en: Arkime
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: Arkime, formerly known as Moloch, is a powerful open source network investigation
    tool designed to capture, store, and analyze large volumes of network traffic
    data. Arkime provides investigators and incident responders with a comprehensive
    platform to investigate and understand network activities, detect anomalies, and
    uncover potential security threats. With its focus on scalability and flexibility,
    Arkime is particularly suited for analyzing vast network traffic in both on-premises
    and cloud environments.
  prefs: []
  type: TYPE_NORMAL
- en: 'Arkime offers several key features that make it a valuable tool in network
    investigation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Packet capture and storage**: Arkime captures and stores network packets
    in a scalable and efficient manner, allowing for the retention of extensive historical
    traffic data for analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Search and analysis**: The tool provides advanced search and filtering capabilities,
    enabling users to query and analyze network data based on various attributes,
    such as IP addresses, ports, protocols, and time ranges.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Session reconstruction**: Arkime can reconstruct network sessions from captured
    data, providing a holistic view of conversations and interactions between network
    nodes and understanding the context of communication.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Metadata extraction**: Arkime extracts metadata from network traffic and
    packet data, providing a higher-level overview of communications and facilitating
    efficient data analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Visualization and reporting**: The tool visualizes network traffic patterns,
    helping analysts identify trends and anomalies. It also supports customizable
    reporting for documenting findings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Customization and extensibility**: Arkime allows users to develop custom
    plugins and parsers to accommodate specific network protocols or applications,
    enhancing flexibility and adaptability.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Integration with other tools**: Arkime can integrate with other network and
    security tools, enabling seamless information sharing and enhanced analysis capabilities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Arkime’s ability to handle large-scale data analysis and its focus on aiding
    network investigations make it an indispensable tool in the DFIR toolkit. By leveraging
    its features, investigators can effectively detect, respond to, and mitigate network-related
    threats, ultimately bolstering their organization’s cybersecurity posture. Let’s
    look at an example of ingesting and analyzing a sample full packet capture from
    a cloud instance using Arkime.
  prefs: []
  type: TYPE_NORMAL
- en: Working with Arkime
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Working with Arkime is easy; it has an intuitive `http://<Arkime.ipAddress>:8005`:'
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure represents the binary file that’s shipped with Arkime,
    which is created explicitly for offline PCAP ingestion – `capture`:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.9 – Arkime “capture” for processing PCAPs offline](img/00087.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.9 – Arkime “capture” for processing PCAPs offline
  prefs: []
  type: TYPE_NORMAL
- en: 'Based on the options available, we will use the following command-line parameters
    to upload PCAP files to Arkime for further processing:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '[PRE3]'
  prefs:
  - PREF_IND
  type: TYPE_PRE
- en: 'Once uploaded to Arkime, we can jump onto the web browser to perform investigations.
    The following figure shows a real-life example of a ransomware attack captured
    on a cloud instance. The organization captured network traffic packets by mirroring
    their host network traffic and sending them to another host to record traffic.
    The following figure provides an overview of the UI and general feature sets.
    We can see activity spikes per session; you can slice the entries per time and
    perform additional searches. For each entry in the lower half of the page, there
    is a **+** option, which allows you to dig deeper into the particular TCP session.
    It also provides an entire conversation of the TCP stream (provided the TCP traffic
    was in clear text and not over SSL traffic):'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.10 – Arkime main screen – post-PCAP ingestion and processing](img/00128.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.10 – Arkime main screen – post-PCAP ingestion and processing
  prefs: []
  type: TYPE_NORMAL
- en: 'As shown in the following screenshot, investigators also have the option of
    parsing the packets, depending on the requirements or nature of the traffic itself.
    It also provides the opportunity to decode packets:'
  prefs:
  - PREF_OL
  type: TYPE_NORMAL
- en: '![Figure 8.11 – Arkime TCP session details (conversation)](img/00148.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.11 – Arkime TCP session details (conversation)
  prefs: []
  type: TYPE_NORMAL
- en: As we can see from a session’s detailed view, investigators can often view the
    individual packets that make up the session. This includes information about the
    packet size, timestamp, and packet payload, and this level of detail can be crucial
    for security analysts investigating network activities. Now, let’s switch to session
    awareness and filtering capabilities in Arkime.
  prefs: []
  type: TYPE_NORMAL
- en: Session awareness – filtering
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'In this section, we’ll look at the session awareness and filtering capabilities.
    Arkime has a **Session and Protocol Information** (**SPI**) view. This view is
    a critical component of Arkime’s web-based interface and allows users to analyze
    and dissect network sessions and their associated protocols. Here are some of
    the use cases that investigators can leverage using SPI:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Session list**: The SPI view provides a list of network sessions that have
    been captured and indexed by Arkime. A session represents a sequence of network
    packets between a source and destination IP address and port.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Session detail**: Clicking on a specific session from the list will allow
    you to view detailed information about that session. This can include source and
    destination IP addresses, source and destination ports, protocol used, packet
    capture details, and more.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Protocol analysis**: Arkime’s SPI view often provides protocol-specific information.
    This means you can analyze network sessions based on their protocols, including
    HTTP, DNS, and FTP. This can help in identifying suspicious or malicious activities.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Filters and searches**: Just like in other views of Arkime, the SPI view
    allows you to apply filters and search criteria to narrow down the sessions you’re
    interested in. This can be helpful when you’re dealing with large amounts of captured
    network data. With the SPI view and list of IP addresses, investigators can export
    the breakdown of the attributes and perform threat intelligence searches on each
    indicator to obtain more information. Some of the filtering capabilities are as
    follows:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Simple filters**: You can filter sessions based on simple attributes such
    as IP addresses, ports, protocols, and timestamp ranges. For example, you can
    filter for all sessions involving a specific IP address or sessions that occurred
    within a specific time frame.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Combining filters**: Moloch’s query language allows you to combine multiple
    conditions using logical operators (AND, OR, NOT) to create more complex filters.
    This helps you narrow down your focus to specific scenarios.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Regular expressions**: You can use regular expressions to match patterns
    within session attributes. For instance, you might want to filter sessions with
    URLs containing a specific keyword.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Custom fields**: Arkime allows you to define and use custom fields, which
    can be extracted from session data or added during ingestion. You can then filter
    sessions based on these custom fields.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Saved queries**: Once you’ve constructed a useful filter, you can save it
    as a named query for easy reuse in the future.'
  prefs:
  - PREF_IND
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Session graphs**: Depending on the capabilities of the SPI view, you might
    also have access to visual representations of session data, such as graphs illustrating
    communication flows between hosts.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Threat detection**: Security analysts often use Arkime’s SPI view to detect
    potential threats or anomalies within network traffic. Unusual patterns, unexpected
    protocols, or suspicious payloads can indicate malicious activity.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following screenshot shows an example PCAP file. Here, Arkime will break
    down the sessions and protocols and provide a deeper dive into each packet. As
    we can see, the SPI view breaks down destination IPs and other protocols. Each
    result can be clicked, and further analysis can be performed:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.12 – Arkime’s SPI view for session and protocol analysis](img/00107.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.12 – Arkime’s SPI view for session and protocol analysis
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, Arkime is a powerful tool that allows you to break network traffic
    down for investigators to consume. It also has powerful enrichment capabilities.
    For example, Arkime can integrate an IP geolocation database to determine the
    location of origin IPs. Arkime also allows integration with other threat intelligence
    sources. Another feature is that it provides content extraction, meaning you can
    download files from Arkime for further manual analysis.
  prefs: []
  type: TYPE_NORMAL
- en: Wireshark/tcpdump
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: tcpdump and Wireshark are powerful tools that are commonly used in DFIR to capture
    and analyze network traffic. Both tools serve similar purposes but have distinct
    characteristics and use cases. Often, these tools are used to reverse engineer
    network protocols from a network investigation point of view.
  prefs: []
  type: TYPE_NORMAL
- en: tcpdump
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: tcpdump is a command-line packet analyzer that captures network packets in real
    time or from a previously captured file. It operates at the lower level of the
    network stack, allowing it to capture packets at a very granular level, including
    Ethernet frames, IP packets, TCP/UDP segments, and more. It’s often used for network
    monitoring, troubleshooting, and security analysis. In DFIR, tcpdump is particularly
    useful for live packet capture during incident response, capturing network traffic
    for later analysis.
  prefs: []
  type: TYPE_NORMAL
- en: From a network investigation point of view, sometimes, investigators do not
    have full cloud access to set up a packet mirroring service that mirrors all the
    packets from the infected cloud instance to another instance under the organization’s
    tenant. Knowledge of these tools certainly helps with preparing and initiating
    a network capture if access to the configuration elements is limited.
  prefs: []
  type: TYPE_NORMAL
- en: 'Investigators can initiate a full packet dump using the `sudo tcpdump` command
    (you will need administrator access). *Figure 8**.13* shows the sample output
    of a tcpdump dump without any filters; it displays the following fields:'
  prefs: []
  type: TYPE_NORMAL
- en: '`HH:MM:SS.microseconds`.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`t2.lan.ssh` is the source IP/port sending data to `dfirlab.lan.27018`, and
    `dfirlab.lan.27018` is the source IP sending data to `t2.lan.ssh` as a response.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`[P.]` indicates that the packet carries application data (PUSH flag set),
    while `[.]` indicates a regular acknowledgment (ACK flag set).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`seq 188:440` indicates that the sequence numbers of the data in the packet
    range from `188` to `440`. This is used to keep track of the order of the data
    packets. `seq 6000:6256` indicates a subsequent sequence range.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`ack 1` indicates the acknowledgment number of the next expected byte. `ack
    1148` are acknowledgments of the received data.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`win 4097` and `win 501` indicate the receiver window size, which is the amount
    of data the receiver can buffer.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`length 252` indicates the packet’s data payload length.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Note that you will have to explicitly indicate a filename to capture the packets
    to a file on the disk in a PCAP format for offline analysis:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.13 – tcpdump in action](img/00038.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.13 – tcpdump in action
  prefs: []
  type: TYPE_NORMAL
- en: '**TCP dump filters**: Investigators should familiarize themselves with tcpdump
    filters. When applied during capture, these filters will only collect network
    packets that match the conditions specified in the filter. In the case of tcpdump,
    it uses **Berkeley Packet Filter** (**BPF**), which allows for low-level filtering
    and specifies requirements for capturing particular packets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following figure shows an example of using a BPF filter for capturing specific
    network packets – that is, `sudo tcpdump -i <interface_name> proto 17`. In this
    example, we filter packets based on protocol number 17, which refers to UDP traffic:'
  prefs:
  - PREF_IND
  type: TYPE_NORMAL
- en: '![Figure 8.14 – tcpdump with BPF filter](img/00073.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.14 – tcpdump with BPF filter
  prefs: []
  type: TYPE_NORMAL
- en: Let’s jump over to a more intuitive version of packet capture software – Wireshark.
    It has very similar functionality; however, you can do real-time analysis as packets
    are captured.
  prefs: []
  type: TYPE_NORMAL
- en: Wireshark
  prefs:
  - PREF_H4
  type: TYPE_NORMAL
- en: 'Wireshark, on the other hand, is a user-friendly graphical network protocol
    analyzer. It provides a detailed, visually rich interface for examining captured
    packets. Wireshark can open and analyze tcpdump capture files and packets directly
    from network interfaces. It operates at a higher level of abstraction than tcpdump,
    presenting dissected and decoded network protocols in a more human-readable format.
    Investigators widely use Wireshark to analyze network traffic for evidence of
    malicious activity, network anomalies, and data exfiltration. The following figure
    shows a simplistic view of the Wireshark user interface:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.15 – Wireshark user interface](img/00093.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.15 – Wireshark user interface
  prefs: []
  type: TYPE_NORMAL
- en: Wireshark offers many capabilities to filter packets and parse them through
    their UI and has clearly defined information on how to handle and filter packet
    information. Some of the cheat sheets have been referenced in the *Further reading*
    section of this chapter.
  prefs: []
  type: TYPE_NORMAL
- en: CyberChef
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: 'CyberChef is a powerful web-based tool for various data manipulation tasks
    that’s often used in cybersecurity and digital forensics. It provides a user-friendly
    interface and recipes for encoding, decoding, transforming, and analyzing data
    in various formats. CyberChef can be incredibly useful for processing and analyzing
    network-related data in the context of network investigation. Here’s how CyberChef
    can be used in network investigation:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Data transformation**: Network investigators often encounter encoded or obfuscated
    data in network traffic. CyberChef provides various data transformation operations,
    such as base64 encoding/decoding, URL encoding/decoding, XOR operations, and more.
    These transformations can help investigators unveil hidden information in network
    packets.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '`grep` function can search for specific patterns, headers, or keywords within
    the traffic. This can help with identifying crucial details such as IP addresses,
    domain names, or file paths.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Hashing and encryption**: CyberChef supports various hashing and encryption/decryption
    techniques. Investigators can hash strings or files to check for matches with
    known malicious hashes. Additionally, they can attempt to decrypt encrypted data
    if they can access the necessary keys.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Parsing and decoding protocols**: CyberChef’s capabilities can be extended
    using custom recipes. Investigators can create recipes that parse and decode network
    protocols such as HTTP, DNS, and SMTP. This can help in extracting meaningful
    information from protocol headers and payloads.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**File carving**: CyberChef can be used to retrieve and reconstruct files from
    the captured data if network traffic contains file transfers. This is particularly
    useful when investigating potential data exfiltration or malware distribution.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data visualization**: CyberChef can help visualize data transformations and
    conversions, making it easier to understand how data changes during its journey
    across the network. Visualizing data can assist in identifying anomalies or suspicious
    patterns.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Automating workflows**: CyberChef allows you to create and save recipes,
    enabling the automation of repetitive data manipulation tasks. This can significantly
    speed up the investigation process and ensure consistency in data processing.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Collaboration and sharing**: CyberChef recipes can be shared among investigators,
    allowing for collaboration and knowledge sharing within the investigative team.
    This can help less experienced team members benefit from the expertise of others.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Quick analysis**: For quick analysis of small pieces of data, CyberChef’s
    easy-to-use interface can provide immediate insights without the need for complex
    scripting or coding.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'The following figure demonstrates an example of CyberChef in use. As indicated
    earlier, it comes with predefined recipes (algorithms) to parse a given dataset.
    It is a helpful tool for network investigators and digital forensic investigators.
    In this example, we’re taking a log export from AWS and parsing it in CyberChef.
    The log export was in JSON format; reading through it can be tricky if the export
    needs to be formatted correctly. Once the recipe has been defined, investigators
    can drag and drop the artifacts and review the output:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.16 – CyberChef in use](img/00055.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.16 – CyberChef in use
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, CyberChef is an enabler that extends an investigator’s capabilities
    and creativity in solving an investigative challenge. Predefined recipes come
    with CyberChef, while other investigators have published a combination of recipes
    that can be applied to address a challenging forensic situation. We have included
    the cheat sheet in the *Further reading* section of this chapter for reference.
  prefs: []
  type: TYPE_NORMAL
- en: In the next section, we will switch gears and look at malware investigations.
    While a whole book could be written about this topic, the next section aims to
    provide a quick refresher on malware investigation concepts and how to explore
    some artifacts once you have captured them through host or network forensic investigation.
    We will look into setting up your lab environment and some essential tools that
    can be useful during an investigation.
  prefs: []
  type: TYPE_NORMAL
- en: Malware investigations
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Malware investigations are a critical component of any incident response and
    involve the systematic process of identifying, analyzing, and responding to malicious
    software in an environment. The primary objective of a malware investigation is
    to understand the nature of the malware, its potential impact, and the extent
    of its infiltration. This information is essential for making informed decisions
    about containment, eradication, and recovery.
  prefs: []
  type: TYPE_NORMAL
- en: Malware analysts conduct in-depth analysis, dissecting the malware’s code and
    behavior to reveal its capabilities, communication methods, and potential vulnerabilities
    that can be exploited. This information guides the understanding of the extent
    of compromise and aids in formulating appropriate countermeasures. An impact assessment
    evaluates the damage inflicted by the malware, including compromised data and
    affected systems, to prioritize response actions.
  prefs: []
  type: TYPE_NORMAL
- en: Eradication follows, which involves removing the malware using tailored antivirus
    signatures, removing files, and patching vulnerabilities. Post-eradication, recovery
    efforts commence, accompanied by an assessment of the incident response process
    and the integration of lessons learned into future strategies. For instances requiring
    legal action or a more profound understanding, forensic analysis preserves evidence,
    documents attack details, and facilitates potential collaboration with law enforcement.
    This comprehensive process ensures a thorough and effective response to malware
    incidents, safeguarding organizational integrity and security.
  prefs: []
  type: TYPE_NORMAL
- en: In the context of cloud environments, malware analysis introduces unique challenges
    and considerations due to the distributed and dynamic nature of cloud computing.
    Cloud-based malware analysis examines malicious software within virtualized or
    containerized environments hosted on cloud platforms.
  prefs: []
  type: TYPE_NORMAL
- en: As we can see, malware analysis closely follows the incident response process,
    providing critical indicators that are vital for containing and eradicating threats.
  prefs: []
  type: TYPE_NORMAL
- en: However, to perform malware analysis, you need a specialized set of tools and
    a completely isolated setup so that investigators do not detonate the malware
    on their devices and compromise the working papers of investigative information.
    For this reason, malware analysis is always performed in a lab environment.
  prefs: []
  type: TYPE_NORMAL
- en: Setting up your malware analysis lab
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: In this section, we will look at the basic architecture of setting up a malware
    analysis lab. For an on-premises lab, malware analysts typically use virtual infrastructure
    so that it is easier to tear it down and bring it back up as a fresh setup. Once
    malware is detonated in the lab, it leaves traces or artifacts that must be carefully
    studied. Similarly, investigators can set up a malware lab in the cloud. However,
    if you are detonating malware in the cloud, care must be taken that it does not
    compromise any other tenants and ensure that the malware lab is locked down.
  prefs: []
  type: TYPE_NORMAL
- en: 'The following figure illustrates an example of setting up a malware analysis
    lab and some key components. As indicated earlier, investigators must take utmost
    care while handling malware and associated artifacts. They are live and can also
    infect or compromise the investigator’s computers. For this reason, most of the
    investigators will operate the malware in a lab. This is similar to handling an
    explosive and ensuring it does not cause damage. In the following figure, every
    connection is secured by a firewall and does not allow direct access to the detonation
    VM. This is where reverse engineers can explore malware and understand its capabilities:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.17 – Malware analysis lab architecture](img/00129.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.17 – Malware analysis lab architecture
  prefs: []
  type: TYPE_NORMAL
- en: 'Some of the critical components of the lab are as follows:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Firewalls**: Any firewall, physical or virtual, should be good. All the network
    connections to the malware-hosting VMs are secured and filtered. In our example,
    we use pfSense, a popular firewall appliance also available for virtual deployments.
    You can deploy a similar one if you plan to set up a lab in the cloud. In this
    example, the firewall and its subnet ensure that the malware lab is only accessible
    via specific port forwarding and not widely accessible on the internal network.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Malware repository**: A dedicated application with a database where malware
    can securely reside. We use a Python-based Viper framework application, which
    allows file and static malware analysis. It also has a database that stores malware
    and helps organize malware and exploit samples.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Detonation VMs**: These are dedicated VMs hosted on a separate and isolated
    subnet for detonating malware or enabling reverse engineers to explore the internal
    workings of the malware. It is important to note that investigators must securely
    configure the malware VMs, and all the network connections are carefully allowed.
    For example, for detonating malware, if it needs to connect to the internet, care
    must be taken when allowing internet access to the malware. Detonation VMs can
    come pre-built; you can use any freely available open source-based malware analysis
    VMs, such as Linux-based **Remnux** or **SANS SIFT workstation**, or you can build
    one based on your tools. You can also build on Windows, such as **Flare VM** from
    Mandiant, which offers scripts to set up the necessary software and harden the
    VM. You can also download a limited-time version of Windows 10 or Windows 11 directly
    from Microsoft at no cost; this provides a 90-day license and enables you to reinstall
    after the license’s expiry date. This ensures that your Windows and malware analysis
    toolkits are up to date.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Apache Guacamole**: Apache Guacamole is an open source remote desktop gateway
    that provides web-based access to remote desktops and applications. It allows
    users to access their desktop environments and applications through a web browser
    session without requiring additional software installation on the client side.
    Guacamole supports various remote desktop protocols such as VNC, RDP, and SSH.
    The most crucial benefit of utilizing Apache Guacamole is enforcing additional
    controls, such as restrictions on copy-paste and limitations on the accessibility
    of network drives and printers. This is crucial as you do not want malware to
    spread or jump out of the VM’s secure network zone.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Malware Analyst VM**: This is purely for securely accessing the malware network
    via Apache Guacamole over a web browser session. When accessing the malware lab,
    it is always recommended that a dedicated workstation is used to access this lab
    environment and for no other purposes.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: Investigators can also choose to deploy similar architecture in the cloud by
    utilizing free and open source tools for malware analysis. Various renditions
    of malware analysis architecture can also be deployed if there is a requirement
    to set up a more oversized malware analysis workbench. One example is Japan’s
    JPCERT group, which developed an architecture to deploy a lab in the cloud for
    memory forensics and analysis. A link to JPCERT’s memory forensic lab is available
    in the *Further* *reading* section.
  prefs: []
  type: TYPE_NORMAL
- en: Let’s dive deeper into some common malware traits that investigators often end
    up encountering with packed malware and multiple versions of the same malware.
  prefs: []
  type: TYPE_NORMAL
- en: Working with packed malware
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'One of the top challenges that malware reverse engineers encounter is packed
    malware. Packers are tools that enterprises, as well as threat actors, use to
    compress and encrypt any code. In the context of threats, malware code is packed
    and deployed in an environment that makes it harder for reverse engineers to analyze.
    Note that we indicated *harder* and not *impossible*. Threat actors aim to make
    it harder to detect and research so that investigators cannot create detection
    packages before the threat severely impacts organizations. These packers help
    obfuscate the code, making it challenging to understand malware functionality.
    Historically, some of the packers are commonly observed by investigators as preferred
    choices by threat actors:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Ultimate Packer for eXecutables** (**UPX**): This is a very popular and well-known
    tool for packing executable files. UPX is an open source tool that can protect
    executable packages. Unpacking a UPX-packed executable is relatively easy as well.
    Any commonly used **Portable Executable** (**PE**) file analyzer would provide
    results if a given executable is packed. The following figure shows a side-by-side
    example of real-world malware caught in the wild; the one on the left is UPX-packed,
    while the one on the right is unpacked or uncompressed. Note the size of each
    of the sections. Remember that UPX compresses the malware binary; therefore, the
    size and memory address locations of the unpacked binary differ when unpacked.
    While this is a simplistic version, sophisticated threat actors can make it more
    complex by applying multiple packing levels or numerous forms of packers:'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '![Figure 8.18 – UPX packed versus unpacked malware](img/00004.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.18 – UPX packed versus unpacked malware
  prefs: []
  type: TYPE_NORMAL
- en: '**Armadillo**: Armadillo is a commercial packer and employs code encryption,
    virtualization, anti-debugging measures, and dynamic unpacking to shield executable
    code from reverse engineering and analysis. Although intended for legitimate purposes,
    threat actors have exploited its features to obfuscate malware, making research
    and detection more challenging for security researchers.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Themida**: Themida is a commercial software protection tool that’s commonly
    utilized by software developers to safeguard their applications against reverse
    engineering and unauthorized access. Like Armadillo, it employs sophisticated
    techniques such as code obfuscation, encryption, and anti-debugging measures to
    make it difficult for researchers to decipher the packed code’s functionality.
    Additionally, Themida offers anti-tampering mechanisms and virtualization to fortify
    the protection further. While initially intended for legitimate purposes, we have
    seen threat actors repurposing Themida to cloak malware and complicate detection
    by security solutions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: While dealing with malware packers can be tricky, investigators must remember
    that whatever is executed in memory, at some point, the packed code must be unpacked
    and decoded before running in memory. Irrespective of the choice of packers used
    by threat actors, reverse engineers may choose a difficult road by manually debugging
    the packed malware to reveal unpacked code under it and adjust other associated
    parameters so that further analysis of the malware is possible.
  prefs: []
  type: TYPE_NORMAL
- en: Another challenging situation that investigators often encounter is multiple
    versions of the same binary. This raises concerns about the number of versions
    the threat actor may have deployed to evade detection; dealing with various versions
    of the same binary adds additional complexities to the investigation.
  prefs: []
  type: TYPE_NORMAL
- en: Binary comparison
  prefs:
  - PREF_H2
  type: TYPE_NORMAL
- en: 'Binary comparison is a process that’s used in computer science and software
    engineering to determine the differences between two binary files, which are files
    containing compiled code or machine-readable data. This comparison involves analyzing
    the individual bytes or bits of the files to identify variations in content, structure,
    and code sequences or by evaluating the **Control Flow Graph** (**CFG**). Binary
    comparison is commonly employed in tasks such as version control, software debugging,
    malware analysis, and digital forensics. By identifying differences between binary
    files, developers, analysts, and researchers can understand code changes, track
    modifications, detect tampering, and uncover potential changes to the malware
    capabilities. The following screenshot shows an example of a Windows program represented
    in CFG format that demonstrates various decision trees, jump points, network access,
    and complexities of a program. We’re using a free, open source tool known as **ProcDot**
    for this purpose. The following screenshot is just for illustration to demonstrate
    the code complexities:'
  prefs: []
  type: TYPE_NORMAL
- en: '![Figure 8.19 – Compressed view of an application CFG with read/write paths](img/00137.jpeg)'
  prefs: []
  type: TYPE_IMG
- en: Figure 8.19 – Compressed view of an application CFG with read/write paths
  prefs: []
  type: TYPE_NORMAL
- en: CFG is a graphical representation that’s used in computer science and software
    engineering to visualize control flow within a program or software application.
    It illustrates the various paths that a program’s execution can take by depicting
    its basic blocks (individual segments of code with a single entry point and a
    single exit point) and the connections between them. Each basic block typically
    corresponds to a sequence of instructions executed sequentially without branching.
    CFGs use nodes to represent basic blocks and edges to represent the flow of control
    between them, indicating where the program can branch or jump to different sections
    of code based on conditions or loop constructs. CFGs are particularly useful for
    understanding program behavior, analyzing code paths, and detecting potential
    bugs or vulnerabilities, and especially useful when comparing similar versions
    of the executable files. They are commonly used in program analysis, optimization,
    debugging, and security research. Let’s look at some of the specialized tools
    that are used to compare binaries.
  prefs: []
  type: TYPE_NORMAL
- en: BinDiff
  prefs:
  - PREF_H3
  type: TYPE_NORMAL
- en: '**BinDiff** is a software comparison tool developed by **Zynamics**, a company
    acquired by Google. BinDiff is primarily used for analyzing and comparing binary
    files, such as executables, libraries, and other compiled code. It’s widely employed
    in reverse engineering and malware analysis to identify similarities and differences
    between software versions or find common code patterns among different binaries.'
  prefs: []
  type: TYPE_NORMAL
- en: To summarize, while we reflected upon some of the basic tools that are out there
    for malware investigations, researchers develop various tools that investigators
    must be prepared to stay up to date with so that they can leverage them when they
    notice complex malware that requires specialized tools. Knowing that there is
    a tool out there is more important than the knowledge of the tool itself. Given
    threat actors create malware differently all the time to make it difficult for
    us, it’s important to stay on top of the technologies, techniques, and concepts
    utilized by malware developers. In the next section, we will compare traditional
    and cloud forensics, debunking a few myths.
  prefs: []
  type: TYPE_NORMAL
- en: Traditional forensics versus cloud forensics
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: Traditional and cloud forensics play critical roles in incident response but
    differ in focus and methodologies due to the distinct environments they address.
  prefs: []
  type: TYPE_NORMAL
- en: 'Here are their similarities:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Evidence collection**: Both traditional and cloud forensics involve collecting
    and preserving digital evidence to reconstruct events leading to an incident.
    This may include collecting memory dumps, log files, network traffic, and filesystem
    artifacts. Investigators often use cloud storage to store large volumes of artifacts,
    irrespective of the underlying CSP, as most breaches affect a cloud tenant at
    a CSP. In scenarios where the underlying CSP is believed to be compromised, it
    is recommended that investigators save all the necessary artifacts in a different
    CSP storage or offline for analysis.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Analysis techniques**: Both domains employ similar techniques for analyzing
    digital evidence, such as examining file structures, metadata, timestamps, and
    memory contents to understand the timeline and scope of an incident.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Chain of custody**: Maintaining the chain of custody is crucial in both scenarios
    to ensure the integrity and admissibility of evidence in legal proceedings.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: 'Here are their differences:'
  prefs: []
  type: TYPE_NORMAL
- en: '**Environment**: Traditional forensics involves physical devices such as computers,
    servers, and mobile devices. In contrast, cloud forensics focuses on virtualized
    and distributed environments, including **Infrastructure-as-a-Service** (**IaaS**),
    **Platform-as-a-Service** (**PaaS**), and **Software-as-a-Service** (**SaaS**).'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Evidence location**: In traditional forensics, evidence is often stored locally
    on physical devices. In cloud forensics, evidence might be distributed across
    multiple virtual instances and storage services, requiring different collection
    and preservation techniques.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data ownership**: Data ownership and control can be complex due to shared
    resources in the cloud. Identifying which party is responsible for maintaining
    and providing access to evidence can be more challenging.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Data residency**: Data might be stored in various geographic locations in
    the cloud, potentially affecting legal and regulatory considerations in different
    jurisdictions.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Network traffic**: In traditional forensics, capturing network traffic is
    relatively straightforward. Network traffic might be harder to access in cloud
    environments due to virtualized networks and third-party services.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Logs and auditing**: Cloud environments often offer extensive logging and
    auditing capabilities, providing more detailed activity information. However,
    accessing and interpreting these logs can be complex.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Resource sharing**: In cloud environments, multiple tenants might share the
    same physical hardware, impacting the isolation and preservation of evidence.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Incident response tools**: Traditional incident response tools may not fully
    translate to cloud environments due to architectural differences and the need
    for specialized tools tailored to cloud forensics.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '**Legal and compliance**: Cloud forensics can involve additional legal and
    compliance challenges due to jurisdictional issues, cross-border data transfers,
    and varying cloud service provider terms.'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: In summary, while traditional and cloud forensics share common principles regarding
    evidence collection and analysis, cloud forensics introduces complexities related
    to cloud environments’ virtualized and distributed nature (such as containerization
    and serverless architectures), shared resources, and legal considerations specific
    to the cloud. Incident responders and digital forensics experts must adapt their
    practices to effectively handle incidents in traditional and cloud-based systems.
  prefs: []
  type: TYPE_NORMAL
- en: Summary
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: As we’ve seen through this chapter, the basics of the incident response process
    and threat hunting largely remain the same, focusing on finding evil within the
    environment. Depending on the operating systems, investigators can customize what
    logs and artifacts should be collected and what must be investigated. We also
    saw how EDR deployments speed up the breach containment and incident response
    process. Remember, the incident response process is a discipline that investigators
    closely follow to ensure that all the investigative steps are performed. At the
    same time, the breach is contained, and there is no further risk to the organization
    and the endpoint under investigation. While this chapter aimed to introduce various
    elements of the breach investigation, it is undoubtedly encouraged that investigators
    stay up to date with the latest investigative tools and techniques.
  prefs: []
  type: TYPE_NORMAL
- en: In the next chapter, we will look at collecting these artifacts from the cloud
    environment. Recognizing that collecting necessary artifacts from the cloud environment
    is difficult, we will look at various cloud service providers and their support
    for collecting forensic packages. We will also look at the options for exporting
    full disk images versus quick forensic collections in the cloud.
  prefs: []
  type: TYPE_NORMAL
- en: Further reading
  prefs:
  - PREF_H1
  type: TYPE_NORMAL
- en: '*PE* *block*: [https://archive.org/details/windowsntfilesys00naga/page/129](https://archive.org/details/windowsntfilesys00naga/page/129)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Overview of memory dump file options for* *Windows*: [https://learn.microsoft.com/en-us/troubleshoot/windows-server/performance/memory-dump-file-options](https://learn.microsoft.com/en-us/troubleshoot/windows-server/performance/memory-dump-file-options)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Varieties of Kernel-Mode Dump Files*: [Varieties of Kernel-Mode Dump Files
    - Windows drivers](https://blog.cloudflare.com/bpf-the-forgotten-bytecode/) |
    [Microsoft Learn](https://andreaskaris.github.io/blog/networking/bpf-and-tcpdump/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Awesome Threat* *Hunting*: [https://github.com/0x4D31/awesome-threat-detection/tree/master](https://github.com/0x4D31/awesome-threat-detection/tree/master)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*BPF – the forgotten* *bytecode*: [https://blog.cloudflare.com/bpf-the-forgotten-bytecode/](https://blog.cloudflare.com/bpf-the-forgotten-bytecode/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*BPF and* *tcpdump*: [https://andreaskaris.github.io/blog/networking/bpf-and-tcpdump/](https://andreaskaris.github.io/blog/networking/bpf-and-tcpdump/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Transmission Control* *Protocol*: [https://datatracker.ietf.org/doc/html/rfc793](https://datatracker.ietf.org/doc/html/rfc793)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Wireshark Cheat* *Sheet*: [https://cdn.comparitech.com/wp-content/uploads/2019/06/Wireshark-Cheat-Sheet-1.jpg.webp](https://cdn.comparitech.com/wp-content/uploads/2019/06/Wireshark-Cheat-Sheet-1.jpg.webp)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*CyberChef*: [https://gchq.github.io/CyberChef/](https://gchq.github.io/CyberChef/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*CyberChef* *Recipes*: [https://github.com/mattnotmax/cyberchef-recipes](https://github.com/mattnotmax/cyberchef-recipes)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Flare* *VM*: [https://github.com/mandiant/flare-vm](https://github.com/mandiant/flare-vm)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*REMnux: A Linux Toolkit for Malware* *Analysis*: [https://remnux.org/](https://remnux.org/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*SIFT* *Workstation*: [https://www.sans.org/tools/sift-workstation/](https://www.sans.org/tools/sift-workstation/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*JPCERT Coordination Center-Memory* *Forensics*: [https://github.com/JPCERTCC/MemoryForensic-on-Cloud](https://github.com/JPCERTCC/MemoryForensic-on-Cloud)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Building a Custom Malware Analysis Lab* *Environment*: [https://www.sentinelone.com/labs/building-a-custom-malware-analysis-lab-environment/](https://www.sentinelone.com/labs/building-a-custom-malware-analysis-lab-environment/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Get a Windows 11 development* *environment*: [https://developer.microsoft.com/en-us/windows/downloads/virtual-machines/](https://developer.microsoft.com/en-us/windows/downloads/virtual-machines/)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Leveraging Microsoft Graph API for memory* *forensics*: [https://medium.com/comae/leveraging-microsoft-graph-api-for-memory-forensics-7ab7f9ea4d06](https://medium.com/comae/leveraging-microsoft-graph-api-for-memory-forensics-7ab7f9ea4d06)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Digital Forensic – Most Commonly used* *Tools*: [https://medium.com/@KhalilAfridii/digital-forensic-most-commonly-used-tools-4a9dbb98f926](mailto:https://medium.com/@KhalilAfridii/digital-forensic-most-commonly-used-tools-4a9dbb98f926)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*CyLR*: [https://github.com/orlikoski/CyLR](https://github.com/orlikoski/CyLR)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*Kansa*: [https://github.com/davehull/Kansa](https://github.com/davehull/Kansa)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PSHunt*: [https://github.com/Infocyte/PSHunt](https://github.com/Infocyte/PSHunt)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
- en: '*PowerForensics*: [https://github.com/Invoke-IR/PowerForensics](https://github.com/Invoke-IR/PowerForensics)'
  prefs:
  - PREF_UL
  type: TYPE_NORMAL
