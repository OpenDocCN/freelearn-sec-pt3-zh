["```\n>>> import hashlib\n>>> m = hashlib.md5()\n>>> m.update('This will be hashed!')\n>>> m.hexdigest()\n'0fc0cfd05cc543be3a2f7e7ed2fe51ea'\n>>> hashlib.md5('This will be hashed!').hexdigest()\n'0fc0cfd05cc543be3a2f7e7ed2fe51ea'\n>>> hashlib.sha1('This will be hashed!').hexdigest()\n'5166bd094f3f27762b81a7562d299d887dbd76e3'\n>>> hashlib.sha256('This will be hashed!').hexdigest()\n'03bb6968581a6d6beb9d1d863b418bfdb9374a6ee23d077ef37df006142fd595' \n```", "```\n>>> output_file = open('output_file.txt', 'w')\n>>> output_file.write('TmV2ZXIgR29ubmEgR2l2ZSBZb3UgVXA=')\n>>> output_file.close()\n>>> input_file = open('output_file.txt', 'r')\n>>> buffer = input_file.read()\n>>> hashlib.sha1(buffer).hexdigest()\n'aa30b352231e2384888e9c78df1af47a9073c8dc'\n>>> hashlib.md5(buffer).hexdigest()\n'1b49a6fb562870e916ae0c040ea52811'\n>>> hashlib.sha256(buffer).hexdigest()\n'89446e08f985a9c201fa969163429de3dbc206bd7c7bb93e490631c308c653d7' \n```", "```\n001 \"\"\"Sample script to hash large files effiently.\"\"\"\n002 import argparse\n003 import hashlib\n...\n033 HASH_LIBS = ['md5', 'sha1', 'sha256', 'sha512']\n034 BUFFER_SIZE = 1024**3\n```", "```\n036 parser = argparse.ArgumentParser()\n037 parser.add_argument(\"FILE\", help=\"File to hash\")\n038 parser.add_argument(\"-a\", \"--algorithm\",\n039     help=\"Hash algorithm to use\", choices=HASH_LIBS,\n040     default=\"sha512\")\n041 args = parser.parse_args()\n```", "```\n043 alg = getattr(hashlib, args.algorithm)()\n```", "```\n045 with open(args.FILE, 'rb') as input_file:\n046 \n047     buffer_data = input_file.read(BUFFER_SIZE)\n048     while buffer_data:\n049         alg.update(buffer_data)\n050         buffer_data = input_file.read(BUFFER_SIZE)\n051 \n052 print(alg.hexdigest())\n```", "```\nabcdefghijklmnopqrstuvwxyz01\n```", "```\n001 \"\"\"Spamsum hash generator.\"\"\"\n002 import argparse\n003 import logging\n004 import json\n005 import os\n006 import sys\n007\n008 \"\"\" The original spamsum algorithm carries the following license:\n009 Copyright (C) 2002 Andrew Tridgell <tridge@samba.org>\n010 \n011 This program is free software; you can redistribute it and/or\n012 modify it under the terms of the GNU General Public License\n013 as published by the Free Software Foundation; either version 2\n014 of the License, or (at your option) any later version.\n015 \n016 This program is distributed in the hope that it will be useful,\n017 but WITHOUT ANY WARRANTY; without even the implied warranty of\n018 MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the\n019 GNU General Public License for more details.\n020 \n021 You should have received a copy of the GNU General Public License\n022 along with this program; if not, write to the Free Software\n023 Foundation, Inc.,\n024 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301, USA.\n025 \n026 CHANGELOG:\n027 Implemented in Python as shown below by Chapin Bryce &\n028 Preston Miller\n029 \"\"\"\n030\n031 __authors__ = [\"Chapin Bryce\", \"Preston Miller\"]\n032 __date__ = 20181027\n033 __description__ = '''Generate file signatures using\n034     the spamsum algorithm.'''\n035 \n036 # Base64 Alphabet\n037 ALPHABET = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n038 ALPHABET += 'abcdefghijklmnopqrstuvwxyz0123456789+/'\n039 \n040 # Constants for use with signature calculation\n041 CONTEXT_WINDOW = 7\n042 FNV_PRIME = 0x01000193\n043 HASH_INIT = 0x28021967\n044 SIGNATURE_LEN = 64\n045 \n046 # Argument handling constants\n047 OUTPUT_OPTS = ['txt', 'json', 'csv']\n048 logger = logging.getLogger(__file__)\n```", "```\n051 def main(file_path, output_type):\n...\n087 def fuzz_file(file_path):\n...\n188 def output(sigval, filename, output_type='txt'):\n```", "```\n204 if __name__ == '__main__':\n205     parser = argparse.ArgumentParser(\n206         description=__description__,\n207         epilog='Built by {}. Version {}'.format(\n208             \", \".join(__authors__), __date__),\n209         formatter_class=argparse.ArgumentDefaultsHelpFormatter\n210     )\n211     parser.add_argument('PATH',\n212         help='Path to file or folder to generate hashes for. '\n213              'Will run recursively.')\n214     parser.add_argument('-o', '--output-type',\n215         help='Format of output.', choices=OUTPUT_OPTS,\n216         default=\"txt\")\n217     parser.add_argument('-l', help='specify log file path',\n218         default=\"./\")\n219 \n220     args = parser.parse_args()\n221 \n222     if args.l:\n223         if not os.path.exists(args.l):\n224             os.makedirs(args.l) # create log directory path\n225             log_path = os.path.join(args.l, 'fuzzy_hasher.log')\n226     else:\n227         log_path = 'fuzzy_hasher.log'\n228 \n229     logger.setLevel(logging.DEBUG)\n230     msg_fmt = logging.Formatter(\"%(asctime)-15s %(funcName)-20s\"\n231         \"%(levelname)-8s %(message)s\")\n232     strhndl = logging.StreamHandler(sys.stderr) # Set to stderr\n233     strhndl.setFormatter(fmt=msg_fmt)\n234     fhndl = logging.FileHandler(log_path, mode='a')\n235     fhndl.setFormatter(fmt=msg_fmt)\n236     logger.addHandler(strhndl)\n237     logger.addHandler(fhndl)\n238 \n239     logger.info('Starting Fuzzy Hasher v. {}'.format(__date__))\n240     logger.debug('System ' + sys.platform)\n241     logger.debug('Version ' + sys.version.replace(\"\\n\", \" \"))\n242 \n243     logger.info('Script Starting')\n244     main(args.PATH, args.output_type)\n245     logger.info('Script Completed')\n```", "```\n051 def main(file_path, output_type):\n052     \"\"\"\n053     The main function handles the main operations of the script\n054     :param file_path: path to generate signatures for\n055     :param output_type: type of output to provide\n056     :return: None\n057     \"\"\"\n058 \n059     # Check output formats\n060     if output_type not in OUTPUT_OPTS:\n061         logger.error(\n062             \"Unsupported output format '{}' selected. Please \"\n063             \"use one of {}\".format(\n064                 output_type, \", \".join(OUTPUT_OPTS)))\n065         sys.exit(2)\n```", "```\n067     # Check provided file path\n068     file_path = os.path.abspath(file_path)\n069     if os.path.isdir(file_path):\n070         # Process files in folders\n071         for root, _, files in os.walk(file_path):\n072             for f in files:\n073                 file_entry = os.path.join(root, f)\n074                 sigval = fuzz_file(file_entry)\n075                 output(sigval, file_entry, output_type)\n```", "```\n076     elif os.path.isfile(file_path):\n077         # Process a single file\n078         sigval = fuzz_file(file_path)\n079         output(sigval, file_path, output_type)\n080     else:\n081         # Handle an error\n082         logger.error(\"Error - path {} not found\".format(\n083             file_path))\n084         sys.exit(1)\n```", "```\n087 def fuzz_file(file_path):\n088     \"\"\"\n089     The fuzz_file function creates a fuzzy hash of a file\n090     :param file_path (str): file to read.\n091     :return (str): spamsum hash\n092     \"\"\"\n```", "```\n095     def update_rolling_hash(nb, rh):\n096         \"\"\"\n097         Update the rolling hash value with the new byte\n098         :param nb (int): new_byte as read from file\n099         :param rh (dict): rolling hash tracking dictionary\n100         :return: computed hash value to compare to reset_point\n101         \"\"\"\n```", "```\n102         # Calculate R2\n103         rh['r2'] -= rh['r1']\n104         rh['r2'] += (CONTEXT_WINDOW * nb)\n105 \n106         # Calculate R1\n107         rh['r1'] += nb\n108         rh['r1'] -= rh['rw'][rh['rn'] % CONTEXT_WINDOW]\n109 \n110         # Update RW and RN\n111         rh['rw'][rh['rn'] % CONTEXT_WINDOW] = nb\n112         rh['rn'] += 1\n113 \n114         # Calculate R3\n115         rh['r3'] = (rh['r3'] << 5) & 0xFFFFFFFF\n116         rh['r3'] = rh['r3'] ^ nb\n117 \n118         # Return the sum of R1 + R2 + R3\n119         return rh['r1'] + rh['r2'] + rh['r3']\n```", "```\n122     fsize = os.stat(file_path).st_size\n123     if fsize == 0:\n124         logger.warning(\"File is 0-bytes. Skipping...\")\n125         return \"\"\n126     open_file = open(file_path, 'rb')\n```", "```\n129     reset_point = 3\n130     while reset_point * 64 < fsize:\n131         reset_point *= 2\n```", "```\n134     complete_file = bytearray(open_file.read())\n135     done = False\n136     while not done:\n```", "```\n138         rolling_hash = {\n139             'r1': 0,\n140             'r2': 0,\n141             'r3': 0,\n142             'rn': 0,\n143             'rw': [0 for _ in range(CONTEXT_WINDOW)]\n144         }\n145         trad_hash1 = HASH_INIT\n146         trad_hash2 = HASH_INIT\n147         sig1 = \"\"\n148         sig2 = \"\"\n```", "```\n151         for new_byte in complete_file:\n152             # Calculate our rolling hash\n153             rh = update_rolling_hash(new_byte, rolling_hash)\n```", "```\n156             trad_hash1 = (trad_hash1 * FNV_PRIME) ^ new_byte\n157             trad_hash2 = (trad_hash2 * FNV_PRIME) ^ new_byte\n```", "```\n159             # Check if our rolling hash reaches a reset point\n160             # If so, update sig and reset trad_hash\n161            if (rh % reset_point == reset_point - 1\n162                     and len(sig1) < SIGNATURE_LEN - 1):\n163                 sig1 += ALPHABET[trad_hash1 % 64]\n164                 trad_hash1 = HASH_INIT\n165             if (rh % (reset_point * 2) == (reset_point * 2) - 1\n166                     and len(sig2) < (SIGNATURE_LEN / 2) - 1):\n167                 sig2 += ALPHABET[trad_hash2 % 64]\n168                 trad_hash2 = HASH_INIT\n```", "```\n170         # If sig1 is too short, change block size and recalculate\n171         if len(sig1) < SIGNATURE_LEN / 2 and reset_point > 3:\n172             reset_point = reset_point // 2\n173             logger.debug(\"Shortening block size to {}\".format(\n174                 reset_point))\n175         else:\n176             done = True\n```", "```\n178     # Add any values from the tail to our hash\n179     if rh != 0:\n180         sig1 += ALPHABET[trad_hash1 % 64]\n181         sig2 += ALPHABET[trad_hash2 % 64]\n182 \n183     # Close the file and return our new signature\n184     open_file.close()\n185     return \"{}:{}:{}\".format(reset_point, sig1, sig2)\n```", "```\n188 def output(sigval, filename, output_type='txt'):\n189     \"\"\"Write the output of the script in the specified format\n190     :param sigval (str): Calculated hash\n191     :param filename (str): name of the file processed\n192     :param output_type (str): Formatter to use for output\n193     \"\"\"\n194     if output_type == 'txt':\n195         print(\"{} {}\".format(sigval, filename))\n196     elif output_type == 'json':\n197         print(json.dumps({\"sig\": sigval, \"file\": filename}))\n198     elif output_type == 'csv':\n199         print(\"{},\\\"{}\\\"\".format(sigval, filename))\n200     else:\n201         raise NotImplementedError(\n202             \"Unsupported output type: {}\".format(output_type))\n```", "```\n001 \"\"\"Example script that uses the ssdeep python bindings.\"\"\"\n002 import argparse\n003 import logging\n004 import os\n005 import sys\n006 \n007 import ssdeep\n```", "```\n047 def main():\n...\n104 def output(): \n```", "```\n134 if __name__ == '__main__':\n135     parser = argparse.ArgumentParser(\n136         description=__description__,\n137         epilog='Built by {}. Version {}'.format(\n138             \", \".join(__authors__), __date__),\n139         formatter_class=argparse.ArgumentDefaultsHelpFormatter\n140     )\n141     parser.add_argument('KNOWN',\n142         help='Path to known file to use to compare')\n143     parser.add_argument('COMPARISON',\n144         help='Path to file or directory to compare to known. '\n145         'Will recurse through all sub directories')\n```", "```\n047 def main(known_file, comparison, output_type):\n048     \"\"\"\n049     The main function handles the main operations of the script\n050     :param known_file: path to known file\n051     :param comparison: path to look for similar files\n052     :param output_type: type of output to provide\n053     :return: None\n054     \"\"\"\n055 \n056     # Check output formats\n057     if output_type not in OUTPUT_OPTS:\n058         logger.error(\n059             \"Unsupported output format '{}' selected. Please \"\n060             \"use one of {}\".format(\n061                 output_type, \", \".join(OUTPUT_OPTS)))\n062         sys.exit(2)\n063     elif output_type == 'csv':\n064         # Special handling for CSV headers\n065         print('\"similarity\",\"known_file\",\"known_hash\",'\n066               '\"comp_file\",\"comp_hash\"')\n```", "```\n068     # Check provided file paths\n069     known_file = os.path.abspath(known_file)\n070     comparison = os.path.abspath(comparison)\n071\n072     # Generate ssdeep signature for known file\n073     if not os.path.exists(known_file):\n074         logger.error(\"Error - path {} not found\".format(\n075             comparison))\n076         sys.exit(1)\n077\n078     known_hash = ssdeep.hash_from_file(known_file)\n```", "```\n080     # Generate and test ssdeep signature for comparison file(s)\n081     if os.path.isdir(comparison):\n082         # Process files in folders\n083         for root, _, files in os.walk(comparison):\n084             for f in files:\n085                 file_entry = os.path.join(root, f)\n086                 comp_hash = ssdeep.hash_from_file(file_entry)\n087                 comp_val = ssdeep.compare(known_hash, comp_hash)\n088                 output(known_file, known_hash,\n089                        file_entry, comp_hash,\n090                        comp_val, output_type)\n```", "```\n\n092     elif os.path.isfile(comparison):\n093         # Process a single file\n094         comp_hash = ssdeep.hash_from_file(comparison)\n095         comp_val = ssdeep.compare(known_hash, comp_hash)\n096         output(known_file, known_hash, file_entry, comp_hash,\n097                comp_val, output_type)\n098     else:\n099         logger.error(\"Error - path {} not found\".format(\n100             comparison))\n101         sys.exit(1)\n```", "```\n104 def output(known_file, known_hash, comp_file, comp_hash, comp_val,\n105            output_type='txt'):\n106     \"\"\"Write the output of the script in the specified format\n107     :param sigval (str): Calculated hash\n108     :param filename (str): name of the file processed\n109     :param output_type (str): Formatter to use for output\n110     \"\"\"\n```", "```\n111     comp_val = str(comp_val)\n112     if output_type == 'txt':\n113         msg = \"{similarity} - {known_file} {known_hash} | \"\n114         msg += \"{comp_file} {comp_hash}\"\n```", "```\n115     elif output_type == 'json':\n116         msg = '{{\"similarity\": {similarity}, \"known_file\": '\n117         msg += '\"{known_file}\", \"known_hash\": \"{known_hash}\", '\n118         msg += '\"comparison_file\": \"{comp_file}\", '\n119         msg += '\"comparison_hash\": \"{comp_hash}\"}}'\n```", "```\n120     elif output_type == 'csv':\n121         msg = '\"{similarity}\",\"{known_file}\",\"{known_hash}\"'\n122         msg += '\"{comp_file}\",\"{comp_hash}\"'\n```", "```\n123     else:\n124         raise NotImplementedError(\n125             \"Unsupported output type: {}\".format(output_type))\n```", "```\n127     print(msg.format(\n128         similarity=comp_val,\n129         known_file=known_file,\n130         known_hash=known_hash,\n131         comp_file=comp_file,\n132         comp_hash=comp_hash))\n```"]