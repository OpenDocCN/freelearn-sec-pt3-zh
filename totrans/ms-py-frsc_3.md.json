["```\n#!/usr/bin/env python\nimport mmap\nimport contextlib\nimport argparse\n\nfrom Evtx.Evtx import FileHeader\nfrom Evtx.Views import evtx_file_xml_view\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Dump a binary EVTX file into XML.\")\n    parser.add_argument(\"--cleanup\", action=\"store_true\", help=\"Cleanup unused XML entities (slower)\"),\n    parser.add_argument(\"evtx\", type=str, help=\"Path to the Windows EVTX event log file\")\n    args = parser.parse_args()\n\n    with open(args.evtx, 'r') as f:\n        with contextlib.closing(mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)) as buf:\n\n            fh = FileHeader(buf, 0x0)\n            print \"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\" standalone=\\\"yes\\\" ?>\"\n            print \"<Events>\"\n            for xml, record in evtx_file_xml_view(fh):\n                print xml\n            print \"</Events>\"\n\nif __name__ == \"__main__\":\n    main()\n```", "```\n<Event ><System><Provider Name=\"Microsoft-Windows-Security-Auditing\" Guid=\"54849625-5478-4994-a5ba-3e3b0328c30d\"></Provider>\n<EventID Qualifiers=\"\">4724</EventID>\n<Version>0</Version>\n<Level>0</Level>\n<Task>13824</Task>\n<Opcode>0</Opcode>\n<Keywords>0x8020000000000000</Keywords>\n<TimeCreated SystemTime=\"2013-11-21 10:40:51.552799\"></TimeCreated>\n<EventRecordID>115</EventRecordID>\n<Correlation ActivityID=\"\" RelatedActivityID=\"\"></Correlation>\n<Execution ProcessID=\"452\" ThreadID=\"1776\"></Execution>\n<Channel>Security</Channel>\n<Computer>windows</Computer>\n<Security UserID=\"\"></Security>\n</System>\n<EventData><Data Name=\"TargetUserName\">mspreitz</Data>\n<Data Name=\"TargetDomainName\">windows</Data>\n<Data Name=\"TargetSid\">S-1-5-21-3147386740-1191307685-1965871575-1000</Data>\n<Data Name=\"SubjectUserSid\">S-1-5-18</Data>\n<Data Name=\"SubjectUserName\">WIN-PC9VCSAQB0H$</Data>\n<Data Name=\"SubjectDomainName\">WORKGROUP</Data>\n<Data Name=\"SubjectLogonId\">0x00000000000003e7</Data>\n</EventData>\n</Event>\n```", "```\n#!/usr/bin/env python\nimport mmap\nimport contextlib\nimport argparse\nfrom xml.dom import minidom\n\nfrom Evtx.Evtx import FileHeader\nfrom Evtx.Views import evtx_file_xml_view\n\ndef main():\n    parser = argparse.ArgumentParser(description=\"Dump specific event ids from a binary EVTX file into XML.\")\n    parser.add_argument(\"--cleanup\", action=\"store_true\", help=\"Cleanup unused XML entities (slower)\"),\n    parser.add_argument(\"evtx\", type=str, help=\"Path to the Windows EVTX event log file\")\n    parser.add_argument(\"out\", type=str, help=\"Path and name of the output file\")\n    parser.add_argument(\"--eventID\", type=int, help=\"Event id that should be extracted\")\n    args = parser.parse_args()\n\n    outFile = open(args.out, 'a+')\n    with open(args.evtx, 'r') as f:\n        with contextlib.closing(mmap.mmap(f.fileno(), 0, access=mmap.ACCESS_READ)) as buf:\n            fh = FileHeader(buf, 0x0)\n            outFile.write(\"<?xml version=\\\"1.0\\\" encoding=\\\"utf-8\\\" standalone=\\\"yes\\\" ?>\")\n            outFile.write(\"<Events>\")\n            for xml, record in evtx_file_xml_view(fh):\n                xmldoc = minidom.parseString(xml)\n                event_id = xmldoc.getElementsByTagName('EventID')[0].childNodes[0].nodeValue\n                if event_id == str(args.eventID):\n                    outFile.write(xml)\n                else:\n                    continue\n            outFile.write(\"</Events>\")\n\nif __name__ == \"__main__\":\n    main()\n```", "```\nuser@lab:~$ ./evtxdump.py security.evtx logon_events.xml –eventID 4724\n\n```", "```\nuser@lab:~$ ./plasm.py tag --tagfile=tag_windows.txt storage_file\n\n```", "```\nuser@lab:~$ ./psort.py storage_file \"tag contains 'Session logon succeeded'\"\n\n```", "```\nC:\\tools\\mandiant> python ShimCacheParser.py –l –o out.csv\n\n[+] Dumping Shim Cache data from the current system...\n[+] Found 64bit Windows 7/2k8-R2 Shim Cache data...\n[+] Found 64bit Windows 7/2k8-R2 Shim Cache data...\n[+] Found 64bit Windows 7/2k8-R2 Shim Cache data...\n[+] Writing output to out.csv...\n\n```", "```\nLast Modified,Last Update,Path,File Size,Exec Flag\n05/04/11 05:19:28,N/A,C:\\Windows\\system32\\SearchFilterHost.exe,N/A,True\n05/24/15 16:44:45,N/A,C:\\Program Files (x86)\\Avira\\AntiVir Desktop\\avwsc.exe,N/A,True\n11/21/10 03:24:15,N/A,C:\\Windows\\system32\\wbem\\wmiprvse.exe,N/A,True\n05/30/14 08:07:49,N/A,C:\\Windows\\TEMP\\40F00A21-D2E7-47A3-AE16-0AFB8E6C1F87\\dismhost.exe,N/A,True\n07/14/09 01:39:02,N/A,C:\\Windows\\system32\\DeviceDisplayObjectProvider.exe,N/A,True\n07/26/13 02:24:56,N/A,C:\\Windows\\System32\\shdocvw.dll,N/A,False\n05/24/15 16:46:22,N/A,C:\\Program Files (x86)\\Google\\Update\\1.3.27.5\\GoogleCrashHandler.exe,N/A,True\n05/07/15 21:42:59,N/A,C:\\Windows\\system32\\GWX\\GWX.exe,N/A,True\n03/26/15 20:57:08,N/A,C:\\Program Files (x86)\\Parallels\\Parallels Tools\\prl_cc.exe,N/A,True\n10/07/14 16:29:54,N/A,C:\\Program Files (x86)\\KeePass Password Safe 2\\KeePass.exe,N/A,True\n10/07/14 16:44:13,N/A,C:\\ProgramData\\Avira\\Antivirus\\TEMP\\SELFUPDATE\\updrgui.exe,N/A,True\n04/17/15 21:03:48,N/A,C:\\Program Files (x86)\\Avira\\AntiVir Desktop\\avwebg7.exe,N/A,True\n\n```", "```\n    $id$salt$encrypted\n\n    ```", "```\ndef read_passwd(filename):\n    \"\"\"Reads entries from shadow or passwd files and\n       returns the content as list of entries.\n       Every entry is a list of fields.\"\"\"\n\n    content = []\n    with open(filename, 'r') as f:\n        for line in f:\n            entry = line.strip().split(':')\n            content.append(entry)\n\n    return content\n```", "```\ndef detect_aliases(passwd):\n    \"\"\"Prints users who share a user id on the console\n\n       Arguments:\n       passwd -- contents of /etc/passwd as read by read_passwd\"\"\"\n\n    id2user = {}\n    for entry in passwd:\n        username = entry[0]\n        uid = entry[2]\n        if uid in id2user:\n            print 'User \"%s\" is an alias for \"%s\" with uid=%s' % (username, id2user[uid], uid)\n        else:\n            id2user[uid] = username\n```", "```\ndef detect_missing_users(passwd, shadow):\n    \"\"\"Prints users of /etc/passwd missing in /etc/shadow\n       and vice versa.\n\n       Arguments:\n       passwd -- contents of /etc/passwd as read by read_passwd\n       shadow -- contents of /etc/shadow as read by read_passwd\"\"\"\n\n    passwd_users = set([e[0] for e in passwd])\n    shadow_users = set([e[0] for e in shadow])\n\n    missing_in_passwd = shadow_users - passwd_users\n    if len(missing_in_passwd) > 0:\n        print 'Users missing in passwd: %s' % ', '.join(missing_in_passwd)\n\n    missing_in_shadow = passwd_users - shadow_users\n    if len(missing_in_shadow) > 0:\n        print 'Users missing in shadow: %s' % ', '.join(missing_in_shadow)\n```", "```\ndef detect_unshadowed(passwd, shadow):\n    \"\"\"Prints users who are not using shadowing or have no password set\n\n       Arguments:\n       passwd -- contents of /etc/passwd as read by read_passwd\n       shadow -- contents of /etc/shadow as read by read_passwd\"\"\"\n\n    nopass = [e[0] for e in passwd if e[1]=='']\n    nopass.extend([e[0] for e in shadow if e[1]==''])\n    if len(nopass) > 0:\n        print 'Users without password: %s' % ', '.join(nopass)\n\n    unshadowed = [e[0] for e in passwd if e[1] != 'x' and e[1] != '']\n    if len(unshadowed) > 0:\n        print 'Users not using password-shadowing: %s' % \\\n              ', '.join(unshadowed)\n```", "```\nimport re\ndef detect_deviating_hashing(shadow):\n    \"\"\"Prints users with non-standard hash methods for passwords\n\n       Arguments:\n       shadow -- contents of /etc/shadow as read by read_passwd\"\"\"\n\n    noalgo = set()\n    salt2user = {}\n    algorithms = set()\n    for entry in shadow:\n        pwhash = entry[1]\n        if len(pwhash) < 3:\n            continue\n\n        m = re.search(r'^\\$([^$]{1,2})\\$([^$]+)\\$', pwhash)\n        if not m:\n            noalgo.add(entry[0])\n            continue\n\n        algo = m.group(1)\n        salt = m.group(2)\n\n        if salt in salt2user:\n            print 'Users \"%s\" and \"%s\" share same password salt \"%s\"' % \\\n                  (salt2user[salt], entry[0], salt)\n        else:\n            salt2user[salt] = entry[0]\n\n        algorithms.add(algo)\n\n    if len(algorithms) > 1:\n        print 'Multiple hashing algorithms found: %s' % ', '.join(algorithms)\n\n    if len(noalgo) > 0:\n        print 'Users without hash algorithm spec. found: %s' % \\\n              ', '.join(noalgo)\n```", "```\nfrom datetime import datetime as dt\nfrom os import lstat\n\nstat_info = lstat('/etc/passwd')\n\natime = dt.utcfromtimestamp(stat_info.st_atime)\nmtime = dt.utcfromtimestamp(stat_info.st_mtime)\nctime = dt.utcfromtimestamp(stat_info.st_ctime)\n\nprint 'File mode bits:      %s' % oct(stat_info.st_mode)\nprint 'Inode number:        %d' % stat_info.st_ino\nprint '# of hard links:     %d' % stat_info.st_nlink\nprint 'Owner UID:           %d' % stat_info.st_uid\nprint 'Group GID:           %d' % stat_info.st_gid\nprint 'File size (bytes)    %d' % stat_info.st_size\nprint 'Last read (atime)    %s' % atime.isoformat(' ')\nprint 'Last write (mtime)   %s' % mtime.isoformat(' ')\nprint 'Inode change (ctime) %s' % ctime.isoformat(' ')\n```", "```\nFile mode bits:      0100644\nInode number:        1054080\n# of hard links:     1\nOwner UID:           0\nGroup GID:           0\nFile size (bytes)    2272\nLast read (atime)    2015-05-15 09:25:15.991190\nLast write (mtime)   2014-09-20 10:40:46.389162\nInode change (ctime) 2014-09-20 10:40:46.393162\n\n```", "```\nimport stat\n\nif stat.S_ISUID & stat_info.st_mode:\n    print 'SUID mode set!'\n\nif stat.S_ISGID & stat_info.st_mode:\n    print 'SGID mode set!'\n\nif stat.S_ISVTX & stat_info.st_mode:\n    print 'Sticky mode set!'\n```", "```\nfrom os import readlink,lstat\nimport stat\n\npath = '/etc/rc5.d/S99rc.local'\n\nstat_info = lstat(path)\n\nif stat.S_ISREG(stat_info.st_mode):\n    print 'File type: regular file'\n\nif stat.S_ISDIR(stat_info.st_mode):\n    print 'File type: directory'\n\nif stat.S_ISLNK(stat_info.st_mode):\n    print 'File type: symbolic link pointing to ',\n    print readlink(path)\n```", "```\nuser@lab:~$ touch /tmp/mytest\nuser@lab:~$ getfacl /tmp/mytest\ngetfacl: Removing leading '/' from absolute path names\n# file: tmp/mytest\n# owner: user\n# group: user\nuser::rw-\ngroup::r--\nother::r--\n\n```", "```\nuser@lab:~$ setfacl -m o::0 -m u:games:rw /tmp/mytest\nuser@lab:~$ getfacl /tmp/mytest\ngetfacl: Removing leading '/' from absolute path names\n# file: tmp/mytest\n# owner: user\n# group: user\nuser::rw-\nuser:games:rw-\ngroup::r--\nmask::rw-\nother::---\nuser@lab:~$ ls -l /tmp/mytest\n-rw-rw----+ 1 user user 0 May 16 16:59 /tmp/mytest\n\n```", "```\n#!/usr/bin/env python\n\nimport os\nfrom os.path import join\nimport posix1e\nimport re\nimport stat\nimport sys\n\ndef acls_from_file(filename, include_standard = False):\n    \"\"\"Returns the extended ACL entries from the given\n       file as list of the text representation.\n\n       Arguments:\n       filename -- the file name to get the ACLs from\n       include_standard -- if True, ACL entries representing \n                           standard Linux permissions will be\n                           included\"\"\"\n    result = []\n    try:\n acl = posix1e.ACL(file=filename)\n    except:\n        print 'Error getting ACLs from %s' % filename\n        return []\n\n    text = acl.to_any_text(options=posix1e.TEXT_ABBREVIATE | posix1e.TEXT_NUMERIC_IDS)\n\n    for entry in text.split(\"\\n\"):\n        if not include_standard and \\\n           re.search(r'^[ugo]::', entry) != None:\n            continue\n        result.append(entry)\n\n    return result\n\ndef get_acl_list(basepath, include_standard = False):\n    \"\"\"Collects all POSIX ACL entries of a directory tree.\n\n    Arguments:\n    basepath -- directory to start from\n    include_standard -- if True, ACL entries representing \n                        standard Linux permissions will be\n                        included\"\"\"\n    result = {}\n\n for root, dirs, files in os.walk(basepath):\n        for f in dirs + files:\n            fullname = join(root, f)\n\n            # skip symbolic links (target ACL applies)\n if stat.S_ISLNK(os.lstat(fullname).st_mode):\n                continue\n\n            acls = acls_from_file(fullname, include_standard)\n            if len(acls) > 0:\n                result[fullname] = acls\n\n    return result\n\nif __name__ == '__main__':\n    if len(sys.argv) < 2:\n        print 'Usage %s root_directory' % sys.argv[0]\n        sys.exit(1)\n\n    acl_list = get_acl_list(sys.argv[1], False)\n\n    for filename, acls in acl_list.iteritems():\n        print \"%s: %s\" % (filename, ','.join(acls))\n```", "```\n/tmp/mytest: u:5:rw-,m::rw-\n\n```", "```\n#!/usr/bin/env python\n\nimport ctypes\nimport os\nfrom os.path import join\nimport sys\n\n# load shared library\nlibcap2 = ctypes.cdll.LoadLibrary('libcap.so.2')\n\nclass cap2_smart_char_p(ctypes.c_char_p):\n    \"\"\"Implements a smart pointer to a string allocated\n       by libcap2.so.2\"\"\"\n    def __del__(self):\n        libcap2.cap_free(self)\n\n# note to ctypes: cap_to_text() returns a pointer\n# that needs automatic deallocation\nlibcap2.cap_to_text.restype = cap2_smart_char_p\n\ndef caps_from_file(filename):\n    \"\"\"Returns the capabilities of the given file as text\"\"\"\n\n cap_t = libcap2.cap_get_file(filename)\n    if cap_t == 0:\n        return ''\n    return libcap2.cap_to_text(cap_t, None).value\n\ndef get_caps_list(basepath):\n    \"\"\"Collects file capabilities of a directory tree.\n\n    Arguments:\n    basepath -- directory to start from\"\"\"\n\n    result = {}\n    for root, dirs, files in os.walk(basepath):\n        for f in files:\n            fullname = join(root, f)\n            caps = caps_from_file(fullname)\n            if caps != '':\n                result[fullname] = caps\n\n    return result\n\nif __name__ == '__main__':\n    if len(sys.argv) < 2:\n        print 'Usage %s root_directory' % sys.argv[0]\n        sys.exit(1)\n\n    capabilities = get_caps_list(sys.argv[1])\n\n    for filename, caps in capabilities.iteritems():\n        print \"%s: %s\" % (filename, caps)\n```", "```\nuser@lab:~$ python chap03_capabilities.py /usr\n\n```", "```\n/usr/bin/gnome-keyring-daemon: = cap_ipc_lock+ep\n\n```", "```\nuser@lab:~$ man 7 capabilities\n\n```", "```\n#!/usr/bin/env python\n\nfrom datetime import datetime\nfrom matplotlib.dates import DateFormatter\nimport matplotlib.pyplot as plt\nimport os\nfrom os.path import join\nimport sys\n\n# max. number of bars on the histogram\nNUM_BINS = 200\n\ndef gen_filestats(basepath):\n    \"\"\"Collects metadata about a directory tree.\n\n    Arguments:\n    basepath -- root directory to start from\n\n    Returns:\n    Tuple with list of file names and list of\n    stat results.\"\"\"\n\n    filenames = []\n    filestats = []\n\n    for root, dirs, files in os.walk(basepath):\n        for f in files:\n            fullname = join(root, f)\n            filenames.append(fullname)\n            filestats.append(os.lstat(fullname))\n    return (filenames, filestats)\n\ndef show_date_histogram(times, heading='', block=False):\n    \"\"\"Draws and displays a histogram over the given timestamps.\n\n    Arguments:\n    times -- array of time stamps as seconds since 1970-01-01\n    heading -- heading to write to the drawing\n    block --- if True, the graph window waits for user interaction\"\"\"\n\n    fig, ax = plt.subplots()\n\n times = map(lambda x: datetime.fromtimestamp(x).toordinal(), times)\n\n ax.hist(times, NUM_BINS)\n    plt.xlabel('Date')\n    plt.ylabel('# of files')\n    plt.title(heading)\n\n    ax.autoscale_view()\n\n    ax.xaxis.set_major_formatter(DateFormatter('%Y-%m-%d'))\n    fig.autofmt_xdate()\n\n    fig.show()\n    if block:\n        plt.show()\n\nif __name__ == '__main__':\n    if len(sys.argv) < 2:\n        print 'Usage %s base_directory' % sys.argv[0]\n        sys.exit(1)\n\n    path = sys.argv[1]\n\n    (names, stats) = gen_filestats(path)\n\n    # extract time stamps\n    mtimes = map(lambda x: x.st_mtime, stats)\n    atimes = map(lambda x: x.st_atime, stats)\n\n    show_date_histogram(mtimes, 'mtimes of ' + path)\n    show_date_histogram(atimes, 'atimes of ' + path, True)\n```", "```\nuser@lab:~$ clamscan –i /sbin\n\n```", "```\n#!/usr/bin/python\n\nfrom datetime import date\nimport numpy as np\nimport os\nfrom os.path import join\nfrom sklearn.cluster import DBSCAN\nimport sys\n\ndef gen_filestats(basepath):\n    \"\"\"Collects metadata about a directory tree.\n\n    Arguments:\n    basepath -- root directory to start from\n\n    Returns:\n    Tuple with list of file names and list of\n    stat results.\"\"\"\n\n    filenames = []\n    filestats = []\n\n    for root, dirs, files in os.walk(basepath):\n        for f in files:\n            fullname = join(root, f)\n            filenames.append(fullname)\n            filestats.append(os.lstat(fullname))\n    return (filenames, filestats)\n\ndef _calc_clusters(data, eps, minsamples):\n    samples = np.array(data)\n db = DBSCAN(eps=eps, min_samples=minsamples).fit(samples)\n    return (db.labels_, db.core_sample_indices_)\n\ndef calc_atime_clusters(stats, days=1, mincluster=5):\n    \"\"\"Clusters files regarding to their 'last access' date.\n\n    Arguments:\n    stats -- file metadata as returned as 2nd element by gen_filestats\n    days  -- approx. size of a cluster (default: accessed on same day)\n    mincluster -- min. number of files to make a new cluster\n\n    Returns:\n    Tuple with array denoting cluster membership\n    and indexes of representatives of cluster cores\"\"\"\n\n    atimes = map(lambda x: [x.st_atime], stats)\n    return _calc_clusters(atimes, days * 24 * 3600, mincluster)\n\ndef calc_mtime_clusters(stats, days=1, mincluster=5):\n    \"\"\"Clusters files regarding to their 'last modified' date.\n\n    Arguments:\n    stats -- file metadata as returned as 2nd element by gen_filestats\n    days  -- approx. size of a cluster (default: accessed on same day)\n    mincluster -- min. number of files to make a new cluster\n\n    Returns:\n    Tuple with array denoting cluster membership\n    and indexes of representatives of cluster cores\"\"\"\n\n    mtimes = map(lambda x: [x.st_mtime], stats)\n    return _calc_clusters(mtimes, days * 24 * 3600, mincluster)\n\ndef calc_histogram(labels, core_indexes, timestamps):\n    # reserve space for outliers (label -1), even if there are none\n    num_entries = len(set(labels)) if -1 in labels else len(set(labels))+1\n\n    counters = [0] * num_entries\n    coredates = [0] * num_entries\n\n    for c in core_indexes:\n        i = int(c)\n        coredates[int(labels[i])+1] = timestamps[i]\n\n    for l in labels:\n        counters[int(l)+1] += 1\n\n    return zip(coredates, counters)\n\ndef print_histogram(histogram):\n    # sort histogram by core time stamps\n    sort_histo = sorted(histogram, cmp=lambda x,y: cmp(x[0],y[0]))\n\n    print '[date around] [number of files]'\n    for h in sort_histo:\n        if h[0] == 0:\n            print '<outliers>',\n        else:\n            t = date.fromtimestamp(h[0]).isoformat()\n            print t,\n        print '    %6d' % h[1]\n\nif __name__ == '__main__':\n    if len(sys.argv) < 2:\n        print 'Usage %s base_directory [number of days in one cluster]' % sys.argv[0]\n        sys.exit(1)\n\n    days = 1\n    if len(sys.argv) > 2:\n        days = int(sys.argv[2])\n\n    names, stats = gen_filestats(sys.argv[1])\n\n    print '%d files to analyze...' % len(names)\n\n    atime_labels, atime_cores = calc_atime_clusters(stats, days)\n    mtime_labels, mtime_cores = calc_mtime_clusters(stats, days)\n\n    atimes = map(lambda x: x.st_atime, stats)\n    mtimes = map(lambda x: x.st_mtime, stats)\n\n    ahisto = calc_histogram(atime_labels, atime_cores, atimes)\n    mhisto = calc_histogram(mtime_labels, mtime_cores, mtimes)\n\n    print \"\\n=== Access time histogram ===\"\n    print_histogram(ahisto)\n\n    print \"\\n=== Modification time histogram ===\"\n    print_histogram(mhisto)\n```", "```\nuser@lab:~$ python timecluster.py /sbin\n\n```", "```\n202 files to analyze...\n\n=== Access time histogram ===\n[date around] [number of files]\n<outliers>          0\n2015-05-24        202\n\n=== Modification time histogram ===\n[date around] [number of files]\n<outliers>         64\n2011-11-20          9\n2012-02-09          5\n2012-03-02          6\n2012-03-31         11\n2012-07-26          6\n2012-09-11         10\n2013-01-18         15\n2013-01-26          6\n2013-03-07          8\n2014-06-18         29\n2014-11-20          7\n2015-02-16         19\n2015-05-01          7\n\n```"]