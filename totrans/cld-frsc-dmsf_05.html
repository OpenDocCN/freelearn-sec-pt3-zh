<html><head></head><body>
<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2"><h1 class="chapter-number" id="_idParaDest-60"><a id="_idTextAnchor065" class="pcalibre1 pcalibre2 pcalibre"/>4</h1>

<h3 id="_idParaDest-61" class="calibre6"><a id="_idTextAnchor066" class="pcalibre1 pcalibre2 pcalibre"/>DFIR Investigations – Logs in AWS</h3>
<p class="calibre3">Through <em class="italic">Chapters 1</em> to <em class="italic">3</em>, you may have recognized the importance of the cloud in today’s technological landscape, and with any technological innovation comes threats against it. As organizations use more cloud products and host and store personal or sensitive information, it is prone to unauthorized disclosure, accidentally or by threat actors exploiting a vulnerability in the configuration of the systems. This chapter will focus on how to handle incidents that have occurred within <strong class="bold">Amazon Web Services</strong> (<strong class="bold">AWS</strong>). We will discuss various log sources that are available for investigators and how investigators can make use of these <span>log sources.</span></p>
<p class="calibre3">Before we can begin our investigation, we will need to understand which logs are available by default versus which log sources must be explicitly turned on; something organizations should consider for ensuring breaches can be investigated thoroughly. We will focus on configuring these logs and look at utilizing some of the native features of AWS for investigation. Specifically, we will discuss the following AWS <span>data sources:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Virtual Private Cloud</strong> (<strong class="bold">VPC</strong>) <span>flow logs</span></li>
<li class="calibre13"><strong class="bold">Simple Storage Service</strong> (<strong class="bold">S3</strong>) <span>access logs</span></li>
<li class="calibre13"><span>AWS CloudTrail</span></li>
<li class="calibre13"><span>AWS CloudWatch</span></li>
<li class="calibre13"><span>Amazon GuardDuty</span></li>
<li class="calibre13"><span>Amazon Detective</span></li>
</ul>
</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h1 id="_idParaDest-62" class="calibre5"><a id="_idTextAnchor067" class="pcalibre1 pcalibre2 pcalibre"/>VPC flow logs</h1>
<p class="calibre3">We briefly introduced <a id="_idIndexMarker211" class="pcalibre1 pcalibre2 pcalibre"/>VPC in <a href="part0021_split_000.html#_idTextAnchor042" class="pcalibre1 pcalibre2 pcalibre"><span><em class="italic">Chapter 3</em></span></a>. VPC is the core of the network configuration for every instance within AWS. Each AWS instance (<strong class="bold">Elastic Compute Cloud</strong> (<strong class="bold">EC2</strong>)) is assigned a VPC and uniquely identified using a VPC ID. VPC allows users complete control of the network environment, including defining specific IP addresses (non-public routable IPs), subnets, and security groups. Users can also<a id="_idIndexMarker212" class="pcalibre1 pcalibre2 pcalibre"/> configure a <strong class="bold">virtual private network</strong> (<strong class="bold">VPN</strong>) through their VPC connection. In default configurations, AWS will automatically create a VPC for every new instance of EC2. Users can also connect their EC2 instance to an existing preconfigured <span>VPC instead.</span></p>
<p class="calibre3">All VPCs have a <strong class="bold">VPC identifier</strong> (<strong class="bold">VPC ID</strong>). The VPC ID is the single reference point for all network-related configuration items. For each instance, if you want to configure any network properties within AWS, you must look into each VPC specifically. In the next example, for a specific<a id="_idIndexMarker213" class="pcalibre1 pcalibre2 pcalibre"/> EC2 instance, certain details are captured <span>for VPC.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">Before we dive into details, it is essential to note that VPC flow logs are similar to network flow logs. These logs only capture header information of the network traffic; for example, source IP, destination IP, protocols, port, and if the connection was accepted or rejected (depending upon the inbound and outbound <span>connection rules).</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h2 id="_idParaDest-63" class="calibre10"><a id="_idTextAnchor068" class="pcalibre1 pcalibre2 pcalibre"/>VPC basics</h2>
<p class="calibre3">In the following <a id="_idIndexMarker214" class="pcalibre1 pcalibre2 pcalibre"/>screenshot, you will notice a few configurational information under the <strong class="bold">Networking</strong> tab, which<a id="_idIndexMarker215" class="pcalibre1 pcalibre2 pcalibre"/> is specifically helpful for <strong class="bold">digital forensics and incident response</strong> (<span><strong class="bold">DFIR</strong></span><span>) teams:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer026"><img alt="Figure 4.1 – Default VPC setup" src="../images/00059.jpeg" class="calibre36"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.1 – Default VPC setup</p>
<p class="calibre3">This includes <span>the following:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Public IPv4 address</strong>: The publicly routable IP address scheme for this <span>EC2 instance.</span></li>
<li class="calibre13"><strong class="bold">VPC ID</strong>: A unique<a id="_idIndexMarker216" class="pcalibre1 pcalibre2 pcalibre"/> identifier that connects all network configuration items to this <span>VPC setup.</span></li>
<li class="calibre13"><strong class="bold">Private IP DNS name (IPv4 only)</strong>: Non-publicly routable IP assigned to the EC2 instance on a network interface. AWS typically uses this to provide backend communications or EC2 instance-to-EC2 <span>instance communications.</span></li>
<li class="calibre13"><strong class="bold">Subnet ID</strong>: The IP subnet that the <span>VPC hosts.</span></li>
<li class="calibre13"><strong class="bold">Availability zone</strong>: The AWS region where the VPC is <span>configured initially.</span></li>
</ul>
<p class="calibre3">DFIR teams can use this core information set to filter events and perform their analysis. In the <em class="italic">AWS CloudWatch</em> section of the chapter, we will look into how to tie this all together <span>for investigation.</span></p>
<p class="calibre3">As illustrated in the preceding screenshot, each VPC is provided with one or more subnet(s) responsible for<a id="_idIndexMarker217" class="pcalibre1 pcalibre2 pcalibre"/> assigning IPs and managing the network segment. You may assign multiple subnets under the same VPC to various <span>EC2 instances:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer027"><img alt="Figure 4.2 – A default subnet configuration and network interface" src="../images/00077.jpeg" class="calibre37"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.2 – A default subnet configuration and network interface</p>
<p class="calibre3">Similar to a VPC configuration, the preceding screenshot illustrates some of the default properties of a subnet assigned <a id="_idIndexMarker218" class="pcalibre1 pcalibre2 pcalibre"/>to a VPC. These include <span>the following:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Subnet ID</strong>: A unique identifier to identify the subnet assigned to <span>the VPC.</span></li>
<li class="calibre13"><strong class="bold">Available IPv4 addresses</strong>: Number of IPs assigned under this subnet. While AWS reserves IPs for administrative purposes, the total available IPs under this configuration <span>are </span><span><strong class="source-inline">4089</strong></span><span>.</span></li>
<li class="calibre13"><strong class="bold">Network border group</strong>: An assigned internet edge location. A network border group is a collection of AWS edge locations and <strong class="bold">points of presence</strong> (<strong class="bold">PoPs</strong>) that are <a id="_idIndexMarker219" class="pcalibre1 pcalibre2 pcalibre"/>geographically distributed and designed to provide a secure and reliable connection between a VPC and the <span>public internet.</span></li>
<li class="calibre13"><strong class="bold">Route table</strong>: A unique identifier that points to a specific routing information schema assigned to <span>this subnet.</span></li>
<li class="calibre13"><strong class="bold">Subnet ARN</strong>: A subnet <strong class="bold">Amazon Resource Name</strong> (<strong class="bold">ARN</strong>) is a unique identifier that can reference the<a id="_idIndexMarker220" class="pcalibre1 pcalibre2 pcalibre"/> subnet in various AWS services and APIs, such as AWS CloudFormation templates, AWS <strong class="bold">Identity and Access Management</strong> (<strong class="bold">IAM</strong>) policies, and <a id="_idIndexMarker221" class="pcalibre1 pcalibre2 pcalibre"/>AWS <span>Lambda functions.</span></li>
<li class="calibre13"><strong class="bold">VPC</strong>: The VPC that this subnet is assigned to. Note that this subnet is assigned to the VPC referenced in <span><em class="italic">Figure 4</em></span><span><em class="italic">.1</em></span><span>.</span></li>
<li class="calibre13"><strong class="bold">Owner</strong>: Unique identifier of the account under which the instance, VPC and subnet are assigned. For privacy purposes, this <span>is masked.</span></li>
<li class="calibre13"><strong class="bold">IPv4 CIDR</strong>: A <strong class="bold">Classless Inter-Domain Routing</strong> (<strong class="bold">CIDR</strong>) notation scheme for the IPs assigned under<a id="_idIndexMarker222" class="pcalibre1 pcalibre2 pcalibre"/> this subnet. In <span><em class="italic">Figure 4</em></span><em class="italic">.2</em>, <strong class="source-inline">/20</strong> indicates that the first 20 bits of the IP address are used for the network address, and the remaining 12 bits for the <span>host address.</span></li>
<li class="calibre13"><strong class="bold">Availability Zone ID</strong>: A unique identifier assigned to each availability zone. This EC2 instance and subnet are assigned to Canada (<strong class="source-inline">ca-central</strong>); however, if required, you may place the subnet in another availability zone to provide <strong class="bold">fault tolerance</strong> (<strong class="bold">FT</strong>) <span>and</span><span><a id="_idIndexMarker223" class="pcalibre1 pcalibre2 pcalibre"/></span><span> resilience.</span></li>
<li class="calibre13"><strong class="bold">Network ACL</strong>: Another unique identifier to precisely identify the <strong class="bold">access control lists</strong> (<strong class="bold">ACLs</strong>) configured for this<a id="_idIndexMarker224" class="pcalibre1 pcalibre2 pcalibre"/> subnet. ACLs will enforce what is allowed versus restricted for network resources. This can also include inbound and outbound <span>network filters.</span></li>
<li class="calibre13"><strong class="source-inline">eni-035e09cd5e22e5515</strong>: The network <span>interface ID.</span></li>
</ul>
<p class="calibre3">While the preceding screenshot specifies essential configurational elements, each property can be adjusted per organizational requirements. However, DFIR teams need to note that the <a id="_idIndexMarker225" class="pcalibre1 pcalibre2 pcalibre"/>aforementioned aspects will play a role in your investigation and the nature of the threat you are observing as part of <span>the investigation.</span></p>
<p class="calibre3">For DFIR teams, the following tabs offer additional detailed insights into the <span>network configuration:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Flow logs</strong> indicates how the network is logged. This VPC/subnet is logged in CloudWatch, which allows DFIR teams to query the network logs. We will investigate and query logs in a later part of <span>the chapter:</span></li>
</ul>
<div class="calibre2">
<div class="img---figure" id="_idContainer028"><img alt="Figure 4.3 – VPC flow logs" src="../images/00097.jpeg" class="calibre38"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.3 – VPC flow logs</p>
<p class="callout-heading">Note</p>
<p class="callout">Note that VPC flow logs are not enabled by default and require <span>explicit setup.</span></p>

<ul class="calibre12">
<li class="calibre13">The next screenshot offers a<a id="_idIndexMarker226" class="pcalibre1 pcalibre2 pcalibre"/> deeper insight into <strong class="bold">route tables</strong> configured to connect to the internet. Note the <strong class="bold">Target</strong> internet gateway identifier (unique identifier) this subnet connects to. The route table defines how routing will perform for all instances related to this subnet. In organizations where a custom VPC is set up, this route table may look different or point to another network resource within AWS. It may not expose the instance directly to the internet. DFIR teams need to make a note of the gateway and the route table that the resources are assigned to for <span>the investigation:</span></li>
</ul>
<div class="calibre2">
<div class="img---figure" id="_idContainer029"><img alt="Figure 4.4 – Routing table" src="../images/00118.jpeg" class="calibre39"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.4 – Routing table</p>

<ul class="calibre12">
<li class="calibre13">The following screenshot shows details of inbound and outbound <strong class="bold">network ACL</strong> (<strong class="bold">NACL</strong>) lists that will define the<a id="_idIndexMarker227" class="pcalibre1 pcalibre2 pcalibre"/> network activity expected by the subnet. The ACLs operate <a id="_idIndexMarker228" class="pcalibre1 pcalibre2 pcalibre"/>at Layer 3 of the <strong class="bold">Open Systems Interconnection</strong> (<strong class="bold">OSI</strong>) model and filter traffic. In the next screenshot, you may <a id="_idIndexMarker229" class="pcalibre1 pcalibre2 pcalibre"/>notice two rules. A network rule number determines the order in which rules are enforced. Rule numbers are integers; lower numbers have higher priority, and rules are evaluated in ascending order. Specifically, in <span><em class="italic">Figure 4</em></span><em class="italic">.5</em>, you will notice <strong class="source-inline">*</strong> in the <strong class="bold">Rule number</strong> column, which means this rule will be evaluated last once any rule numbers are assessed. Based on inbound and outbound ACLs, this resource is available online. It can access any part of the internet, presently the least secure setup and a default setup offered <span>by AWS:</span></li>
</ul>
<div class="calibre2">
<div class="img---figure" id="_idContainer030"><img alt="Figure 4.5 – NACLs configured for subnet" src="../images/00141.jpeg" class="calibre40"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.5 – NACLs configured for subnet</p>
<p class="calibre3">Now that we have reviewed various configuration items under the VPC, here is the summary dashboard that <a id="_idIndexMarker230" class="pcalibre1 pcalibre2 pcalibre"/>AWS offers for each of the VPCs, which outlines the VPC configuration properties and assignments along with <span>additional information:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer031"><img alt="Figure 4.6 – VPC summary dashboard" src="../images/00157.jpeg" class="calibre41"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.6 – VPC summary dashboard</p>
<p class="calibre3">The VPC summary dashboard page will also provide additional information regarding the subnets associated with this VPC and the flow logs configured. VPC flow logs are not enabled by default and require specific AWS resource access configured within AWS’s IAM module. We will be looking into how to set up flow logs to enable DFIR teams to investigate network activity on AWS and <span>query them.</span></p>
<p class="calibre3">The following screenshot outlines AWS’s diagrammatic representation or resource map of how the network is configured from an internal AWS perspective connecting to the internet. The resource map displays the connections among the resources in a VPC, outlining the traffic path from<a id="_idIndexMarker231" class="pcalibre1 pcalibre2 pcalibre"/> subnets to <strong class="bold">network address translation</strong> (<strong class="bold">NAT</strong>) gateways, internet gateways, and gateway endpoints. Using the resource map, DFIR teams can comprehend<a id="_idIndexMarker232" class="pcalibre1 pcalibre2 pcalibre"/> the VPC’s design, determine the number of subnets, identify which subnets correspond with route tables, and discern which route tables contain routes to NAT gateways, internet gateways, and <span>gateway endpoints:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer032"><img alt="Figure 4.7 – Resource map for vpc-0183a969 VPC" src="../images/00175.jpeg" class="calibre42"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.7 – Resource map for vpc-0183a969 VPC</p>
<p class="calibre3">Moreover, the resource map can assist you in identifying unsuitable or inaccurate setups, such as private subnets separated from NAT gateways or private subnets with direct routes to the internet gateway. You can select specific resources from the <strong class="bold">Resource map</strong> screen, such as route tables, and modify their settings. This functionality is presently <span>under development.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h2 id="_idParaDest-64" class="calibre10"><a id="_idTextAnchor069" class="pcalibre1 pcalibre2 pcalibre"/>Sample VPC flow log</h2>
<p class="calibre3">Here is a sample VPC flow<a id="_idIndexMarker233" class="pcalibre1 pcalibre2 pcalibre"/> log and the properties captured by the flow log. It is essential to understand the elements captured within each <span>flow log.</span></p>
<p class="calibre3">Flow logs are recorded between time intervals where it aggregates network traffic into <span>a log:</span></p>
<pre class="console">2 65179142xxxx eni-035e09cd5e22e5515 45.79.132.41 172.31.5.217 41340 636 6 1 44 1682678411 1682678469 REJECT OK</pre>
<p class="calibre3">Let us look into the details of each element of the <span>flow log:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="source-inline">2</strong>: This field indicates the version of the VPC flow <span>log’s format.</span></li>
<li class="calibre13"><strong class="source-inline">65179142xxxx</strong>: This is the ID of the AWS account that owns the network interface. This is currently masked for <span>privacy reasons.</span></li>
<li class="calibre13"><strong class="source-inline">eni-035e09cd5e22e5515</strong>: This is the ID<a id="_idIndexMarker234" class="pcalibre1 pcalibre2 pcalibre"/> of the network interface (<strong class="bold">elastic network interface</strong> (<strong class="bold">ENI)</strong>). Notice this log matches the <span><em class="italic">Figure 4</em></span><em class="italic">.2</em> configuration, which reflects the network connection of an <span>EC2 resource.</span></li>
<li class="calibre13"><strong class="source-inline">45.79.132.41</strong>: This is<a id="_idIndexMarker235" class="pcalibre1 pcalibre2 pcalibre"/> the source IP address of <span>the traffic.</span></li>
<li class="calibre13"><strong class="source-inline">172.31.5.217</strong>: This is the destination IP address of <span>the traffic.</span></li>
<li class="calibre13"><strong class="source-inline">41340</strong>: This is the source <span>port number.</span></li>
<li class="calibre13"><strong class="source-inline">636</strong>: This is the destination <span>port number.</span></li>
<li class="calibre13"><strong class="source-inline">6</strong>: This is the protocol number. In this case, it is TCP (<strong class="source-inline">6</strong>). Port <strong class="source-inline">6</strong> is <span>currently unassigned.</span></li>
<li class="calibre13"><strong class="source-inline">1</strong>: This is the number of packets transferred during <span>the flow.</span></li>
<li class="calibre13"><strong class="source-inline">44</strong>: This is the number of bytes transferred during the flow. Note the bytes transferred during this <span>flow session.</span></li>
<li class="calibre13"><strong class="source-inline">1682678411</strong>: This is the start time of the flow in epoch time (seconds since January <span>1, 1970).</span></li>
<li class="calibre13"><strong class="source-inline">1682678469</strong>: This is the end time of the flow in <span>epoch time.</span></li>
<li class="calibre13"><strong class="source-inline">REJECT</strong>: Action taken on traffic by a security group or NACL. Actions include <strong class="source-inline">ACCEPT</strong>/<strong class="source-inline">REJECT</strong>/<strong class="source-inline">NO DATA</strong>/<strong class="source-inline">SKIPDATA</strong>. <strong class="source-inline">NO DATA</strong> and <strong class="source-inline">SKIPDATA</strong> are edge cases where <strong class="source-inline">NO DATA</strong> is recorded to indicate the flow log event is empty. In contrast, <strong class="source-inline">SKIPDATA</strong> is recorded when flow capture cannot capture the log during network aggregation intervals due to capacity limitations. <strong class="source-inline">SKIPDATA</strong> log entry means<a id="_idIndexMarker236" class="pcalibre1 pcalibre2 pcalibre"/> multiple network logs could not be captured due to internal <span>configurational errors.</span></li>
<li class="calibre13"><strong class="source-inline">OK</strong>: This is the status of <span>the action.</span></li>
</ul>
</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h2 id="_idParaDest-65" class="calibre10"><a id="_idTextAnchor070" class="pcalibre1 pcalibre2 pcalibre"/>DFIR use cases for VPC flow logging</h2>
<p class="calibre3">There are several reasons why DFIR teams should utilize VPC flow logs in their incident investigation when<a id="_idIndexMarker237" class="pcalibre1 pcalibre2 pcalibre"/> investigating an AWS resource. Here are some use cases where VPC flow logs can play a crucial role for <span>DFIR teams:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Threat detection and monitoring</strong>: VPC flow logs can be used to detect suspicious or malicious network traffic. DFIR teams can identify traffic patterns that indicate known threats or potential intrusions by analyzing the flow logs. For example, they can use flow logs to detect port scanning, brute-force attacks, command-and-control traffic, and data exfiltration by reviewing flow logs’ <span>activity spikes.</span></li>
<li class="calibre13"><strong class="bold">IR</strong>: DFIR teams can use VPC flow logs to reconstruct an event’s timeline and identify an attack’s source in a security incident. By analyzing the flow logs, they can determine the systems and applications that were affected, the duration of the attack, and the IP addresses and ports used by <span>the attacker.</span></li>
<li class="calibre13"><strong class="bold">Forensic analysis</strong>: VPC flow logs can also be used in digital forensic investigations to identify the source of an attack and trace the path of data access through the network. DFIR teams can use the flow logs to determine the source IP address, the destination IP address, and the protocols used during the network connection. This information can help them identify the source of a data breach or other <span>security incident.</span></li>
<li class="calibre13"><strong class="bold">Compliance monitoring</strong>: VPC flow logs can be utilized to monitor compliance with security policies and regulations. DFIR teams or the <strong class="bold">Security Operations Center</strong> (<strong class="bold">SOC</strong>) can use the flow logs<a id="_idIndexMarker238" class="pcalibre1 pcalibre2 pcalibre"/> to detect unauthorized access to sensitive data and security violations. This information can be used to generate reports for compliance auditors or to support <span>legal investigations.</span></li>
<li class="calibre13"><strong class="bold">Anomaly detection</strong>: Finally, VPC flow logs can be used to detect abnormal network traffic. DFIR teams can<a id="_idIndexMarker239" class="pcalibre1 pcalibre2 pcalibre"/> use <strong class="bold">machine learning</strong> (<strong class="bold">ML</strong>) techniques to identify patterns of traffic that deviate from the expected behavior of the network. This can <a id="_idIndexMarker240" class="pcalibre1 pcalibre2 pcalibre"/>help them detect potential security incidents or system failures before they become <span>more serious.</span></li>
</ul>
</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h1 id="_idParaDest-66" class="calibre5"><a id="_idTextAnchor071" class="pcalibre1 pcalibre2 pcalibre"/>S3 access logs</h1>
<p class="calibre3">Amazon S3 is a very popular cloud storage service that is highly scalable and dependable for data storage and retrieval. S3 <a id="_idIndexMarker241" class="pcalibre1 pcalibre2 pcalibre"/>provides <strong class="bold">high availability</strong> (<strong class="bold">HA</strong>), storage performance, and <a id="_idIndexMarker242" class="pcalibre1 pcalibre2 pcalibre"/>accessibility of any amount of data from around <span>the world.</span></p>
<p class="calibre3">In AWS, S3 operates on <em class="italic">buckets</em>, which contain <em class="italic">objects</em>. Objects are any files, documents, images, and videos. Each object is identified using a unique identifier known as the key that serves within a bucket. A bucket can be visualized as a folder that contains all <span>the objects.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h2 id="_idParaDest-67" class="calibre10"><a id="_idTextAnchor072" class="pcalibre1 pcalibre2 pcalibre"/>Logging options</h2>
<p class="calibre3">Access logs record information<a id="_idIndexMarker243" class="pcalibre1 pcalibre2 pcalibre"/> about the requests made to an Amazon S3 bucket, including details such as request information, specific resource requests, and the time and date of the request. Amazon S3 uses a specific internal account to write server access logs, which requires AWS account owners to configure explicit permission within their IAM modules to allow S3 to log server <span>access requests.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">Note that S3 access logs are not enabled by default and require <span>explicit setup.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h2 id="_idParaDest-68" class="calibre10"><a id="_idTextAnchor073" class="pcalibre1 pcalibre2 pcalibre"/>DFIR use cases for S3 monitoring</h2>
<p class="calibre3">Since S3 storage is used for moving and hosting data, most DFIR use cases revolve around data analysis and movement. Some specific DFIR use <span>cases include:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Data leakage</strong>: Data leakage or data exposure can occur due to misconfiguration of an<a id="_idIndexMarker244" class="pcalibre1 pcalibre2 pcalibre"/> S3 bucket. Through access logs, you can help identify unauthorized access to data stored in S3 buckets. By monitoring bucket access logs and performing anomaly detection, you can identify suspicious activities such as large data transfers, unexpected access patterns, or unauthorized attempts to access <span>specific objects.</span></li>
<li class="calibre13"><strong class="bold">Malware and ransomware detection</strong>: S3 buckets can be targeted by attackers to store and distribute malware or ransomware. DFIR teams can monitor S3 for file integrity changes, unexpected file types, or suspicious behavior that can help identify such<a id="_idIndexMarker245" class="pcalibre1 pcalibre2 pcalibre"/> malicious files. Integration with <strong class="bold">threat intelligence</strong> (<strong class="bold">TI</strong>) can enhance <span>detection capabilities.</span></li>
<li class="calibre13"><strong class="bold">IR and forensic investigation</strong>: S3 monitoring can provide insights during IR and forensic investigations. Through access logs, DFIR teams can help reconstruct events, identify the source of an incident, and understand the scope of the compromise. Monitoring access logs, object metadata, and versioning can aid in analyzing activities leading to a <span>security incident.</span></li>
<li class="calibre13"><strong class="bold">Data exfiltration detection</strong>: Attackers may attempt to exfiltrate sensitive data by copying or downloading it from S3 buckets. Monitoring S3 access logs and performing content analysis can help identify large or unexpected data transfers that may indicate data exfiltration attempts. This can also be done through integrations with CloudTrail and CloudWatch and the development of a log pattern insight that allows DFIR teams to determine deviations in file access and identify <span>exfiltration activities.</span></li>
</ul>
</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h1 id="_idParaDest-69" class="calibre5"><a id="_idTextAnchor074" class="pcalibre1 pcalibre2 pcalibre"/>AWS CloudTrail</h1>
<p class="calibre3">AWS CloudTrail records activities performed on the management console of AWS accessing any AWS resource—for example, an EC2 instance created or terminated, changes to the VPC settings, and<a id="_idIndexMarker246" class="pcalibre1 pcalibre2 pcalibre"/> so on. Any activity on the management console of AWS is recorded as an event <span>within CloudTrail.</span></p>
<p class="calibre3">CloudTrail consolidates detailed action log events in a centralized location and provides a comprehensive and unified view of account’s activity, making it easier to search, analyze, download, and respond to account activity across your AWS infrastructure. It also identifies what actions were performed by which user and any other details that help DFIR teams analyze and respond to an incident <span>in AWS.</span></p>
<p class="calibre3">CloudTrail logs can be integrated into CloudWatch to query activities and perform further analysis. We will discuss CloudWatch in the <span>next section.</span></p>
<p class="calibre3">The following screenshot demonstrates an example of a <span>CloudWatch dashboard:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer033"><img alt="Figure 4.8 – CloudWatch dashboard" src="../images/00192.jpeg" class="calibre43"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.8 – CloudWatch dashboard</p>
<p class="calibre3">At the time of writing, we see that events are recorded under the <strong class="source-inline">mgmt-event</strong> trail. It aggregates all management activities<a id="_idIndexMarker247" class="pcalibre1 pcalibre2 pcalibre"/> performed under each AWS account. Events are recorded in CloudTrail <strong class="bold">JavaScript Object Notation</strong> (<strong class="bold">JSON</strong>) <span>log format.</span></p>
<p class="calibre3">There are three types of events that CloudTrail can record: management events, data events, and CloudTrail data insight events. Let’s take a closer look <span>at these:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Management events</strong>: As the name suggests, these record AWS account management-level activities, including operations performed on the AWS account. AWS refers to <a id="_idIndexMarker248" class="pcalibre1 pcalibre2 pcalibre"/>these as <strong class="bold">control-plane operations</strong>. Examples are <strong class="bold">application programming interface</strong> (<strong class="bold">API</strong>) operations, <strong class="bold">AWS IAM</strong>, creating new EC2<a id="_idIndexMarker249" class="pcalibre1 pcalibre2 pcalibre"/> instances, editing VPC configurations, configuring routing operations, creating subnets, and creating new trails <span>under CloudTrail.</span></li>
<li class="calibre13"><strong class="bold">Data events</strong>: Records information regarding operations performed on the resource. AWS refers to<a id="_idIndexMarker250" class="pcalibre1 pcalibre2 pcalibre"/> these as <strong class="bold">data-plane operations</strong>. Usually, data events are voluminous, and you will have to configure them to ensure that AWS resources can <a id="_idIndexMarker251" class="pcalibre1 pcalibre2 pcalibre"/><span>provide them.</span></li>
</ul>
<p class="callout-heading">Note</p>
<p class="callout">Data event logging is not enabled by default and requires administrators to allow <span>it explicitly.</span></p>
<p class="calibre3">Here is a list of AWS resources that provide these <span>data events:</span></p>

<table class="t---table" id="table001-1">
<colgroup class="calibre22">
<col class="calibre23"/>
<col class="calibre23"/>
<col class="calibre23"/>
</colgroup>
<thead class="calibre24">
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3"><span><strong class="bold">Data Event</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3"><span><strong class="bold">Resources</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3"><span><strong class="bold">Specific Events</strong></span></p>

</td>
</tr>
</thead>
<tbody class="calibre25">
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3"><span>DynamoDB</span></p>

</td>
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">AWS::DynamoDB::Table</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3">API-level activities, including <strong class="source-inline">PutItem</strong>, <strong class="source-inline">DeleteItem</strong>, <span>and </span><span><strong class="source-inline">UpdateItem</strong></span></p>

</td>
</tr>
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3"><span>DynamoDB Streams</span></p>

</td>
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">AWS::DynamoDB::Stream</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3">Dynamo API calls <span>on streams</span></p>

</td>
</tr>
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3"><span>Lambda</span></p>

</td>
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">AWS::Lambda::Function</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3">Lambda function execution activities, including <strong class="source-inline">Invoke</strong> <span>API calls</span></p>

</td>
</tr>
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3"><span>S3</span></p>

</td>
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">AWS::S3:Object</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3">S3 object-level activity, including <strong class="source-inline">GetObject</strong>, <strong class="source-inline">DeleteObject</strong>, and <strong class="source-inline">PutObject</strong> API calls on <span>S3 buckets</span></p>

</td>
</tr>
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3">S3 <span>Access Points</span></p>

</td>
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">AWS::S3::AccessPoint</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3">Amazon S3 API activity on <strong class="bold">access </strong><span><strong class="bold">points</strong></span><span> (</span><span><strong class="bold">APs</strong></span><span>)</span></p>

</td>
</tr>
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3">S3 <span>Object Lambda</span></p>

</td>
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">AWS::S3ObjectLambda::AccessPoint</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3">S3 Object Lambda APs’ API activity, such as calls to <strong class="source-inline">CompleteMultipartUpload</strong> <span>and </span><span><strong class="source-inline">GetObject</strong></span></p>

</td>
</tr>
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3"><span>CloudTrail</span></p>

</td>
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">AWS::CloudTrail::Channel</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3"><strong class="source-inline">PutAuditEvents</strong> on CloudTrail Lake for logging events outside <span>of AWS</span></p>

</td>
</tr>
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3"><span>Cognito</span></p>

</td>
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">AWS::Cognito::IdentityPool</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3">Cognito API activity on <span>identity pools</span></p>

</td>
</tr>
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3">Amazon <strong class="bold">Elastic Block Store </strong>(<strong class="bold">EBS</strong>) <span>direct APIs</span></p>

</td>
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">AWS::EC2::Snapshot</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3">Direct APIs, such as <strong class="source-inline">PutSnapshotBlock</strong>, <strong class="source-inline">GetSnapshotBlock</strong>, and <strong class="source-inline">ListChangedBlocks</strong>, on Amazon <span>EBS snapshots</span></p>

</td>
</tr>
<tr class="t---table1">
<td class="t---table2">
<p class="calibre3"><span>GuardDuty</span></p>

</td>
<td class="t---table2">
<p class="calibre3"><span><strong class="source-inline">AWS::GuardDuty::Detector</strong></span></p>

</td>
<td class="t---table2">
<p class="calibre3"><strong class="source-inline">GuardDuty</strong> API activity for <span>a detector</span></p>

</td>
</tr>
</tbody>
</table>
<p class="img---caption" lang="en-US">Table 4.1 – AWS data event collectors</p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">CloudTrail data insight events</strong>: CloudTrail Insights<a id="_idIndexMarker252" class="pcalibre1 pcalibre2 pcalibre"/> provides insights into abnormal activities such as large volumes or spikes of API calls or high error rates within an <a id="_idIndexMarker253" class="pcalibre1 pcalibre2 pcalibre"/>AWS account. Insights are logged when CloudTrail notices deviations within API usage and error rates within the <span>AWS account.</span></li>
</ul>
</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h2 id="_idParaDest-70" class="calibre10"><a id="_idTextAnchor075" class="pcalibre1 pcalibre2 pcalibre"/>Creating a trail</h2>
<p class="calibre3">CloudTrail is not automatically enabled when an<a id="_idIndexMarker254" class="pcalibre1 pcalibre2 pcalibre"/> account is created within AWS. Security teams must define a trail to collect all the necessary information/activities within the AWS account for audit, compliance, and <span>investigation purposes.</span></p>
<p class="calibre3">You will first have to define a trail and uniquely identify it for it to be integrated with other AWS resources <a id="_idIndexMarker255" class="pcalibre1 pcalibre2 pcalibre"/>such as <strong class="bold">CloudWatch</strong>. As described earlier, a trail is similar to an audit trail that tracks the activities of a user within an AWS account. In the following screenshot, we identify the trail as <strong class="source-inline">mgmt-events</strong> to signify what types of events are collected within this trail. We then select the location where this trail is stored. You can create a new S3<a id="_idIndexMarker256" class="pcalibre1 pcalibre2 pcalibre"/> bucket; however, if your security operations team owns an S3 bucket, you can also place your trail there. We have masked the account number associated with this trail for <span>security reasons:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer034"><img alt="Figure 4.9 – Setting up CloudTrail logging" src="../images/00011.jpeg" class="calibre44"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.9 – Setting up CloudTrail logging</p>
<p class="calibre3">When configuring CloudTrail logs, you can enable it to feed into CloudWatch automatically. We will discuss more about CloudWatch in a later part of the chapter. Essentially, providing CloudTrail logs to CloudWatch allows DFIR teams to focus their investigation and log<a id="_idIndexMarker257" class="pcalibre1 pcalibre2 pcalibre"/> reviews on a single console, giving them a <strong class="bold">single-pane-of-glass</strong> (<strong class="bold">SPOG</strong>) view of<a id="_idIndexMarker258" class="pcalibre1 pcalibre2 pcalibre"/> <span>the logs:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer035"><img alt="Figure 4.10 – AWS CloudWatch for AWS CloudTrail" src="../images/00030.jpeg" class="calibre45"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.10 – AWS CloudWatch for AWS CloudTrail</p>
<p class="calibre3">When defining a CloudTrail log, you should also configure what types of data events are collected within CloudTrail. Earlier in this section, we referred to three types of data events: management events, data events, and data <span>insight events.</span></p>
<p class="calibre3">The following screenshot defines the configurations enabled for the trail to collect records. As you can see in the screenshot, CloudTrail will collect events associated with the management of AWS resources itself, such as accessing/querying, creating, modifying, or deleting resources. For example, an AWS IAM administrator creating another account with privileges triggers a management event recorded under <span>this trail:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer036"><img alt="Figure 4.11 – CloudTrail management events’ configuration" src="../images/00048.jpeg" class="calibre46"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.11 – CloudTrail management events’ configuration</p>
<p class="calibre3">On the other hand, a data event specifically collects events associated with data-level activities within an AWS resource, such as tracking changes to the files stored on an S3 bucket. Monitoring data events allows DFIR teams to confirm if the data was accessed, modified, or deleted <a id="_idIndexMarker259" class="pcalibre1 pcalibre2 pcalibre"/>within these AWS services. The next screenshot indicates the configuration required to enable data events. It reflects the options for DFIR teams to configure and allow appropriate <span>CloudTrail logging:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer037"><img alt="Figure 4.12 – CloudTrail data events’ configuration" src="../images/00065.jpeg" class="calibre47"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.12 – CloudTrail data events’ configuration</p>

<h3 class="calibre11">Log file validations</h3>
<p class="calibre3">When you create a trail, you also <a id="_idIndexMarker260" class="pcalibre1 pcalibre2 pcalibre"/>want to protect its integrity so that there are no unauthorized changes. Hence, we also enable a log file validation checkmark to enforce integrity checks on the trail as it is generated to ensure the course is not altered and is accurate for investigation. Integrity checks results are delivered to the same S3 buckets as digests. DFIR teams can utilize the log file digests to validate the integrity of log files. Each log file is hashed and digitally signed. CloudTrail log data digest files are signed using RSA, where a private key is generated for each region, and SHA-256 data is used to sign using the private key, resulting in a digital signature. The SHA-256 data is<a id="_idIndexMarker261" class="pcalibre1 pcalibre2 pcalibre"/> generated from the <strong class="bold">Universal Time Coordinated</strong> (<strong class="bold">UTC</strong>) timestamp of the log file, S3 path, SHA-256 hash of the current digest file (in hex format), and signature of the previous digest file (in hex format). These elements together form a hashing <a id="_idIndexMarker262" class="pcalibre1 pcalibre2 pcalibre"/>string, which is used to generate a SHA-256 hash of the data, which is <span>then signed.</span></p>
<p class="calibre3">Once a signature is generated, it is further encoded in a hex format. Hexadecimal signatures are then recorded within the <strong class="source-inline">x-amz-met-signature</strong> tag of the digest files stored <span>on S3.</span></p>
<p class="calibre3">DFIR teams can choose to enable log file validation later through the AWS Management Console, API, or AWS <span>command line:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer038"><img alt="Figure 4.13 – Log file validation is enabled" src="../images/00083.jpeg" class="calibre48"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.13 – Log file validation is enabled</p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h2 id="_idParaDest-71" class="calibre10"><a id="_idTextAnchor076" class="pcalibre1 pcalibre2 pcalibre"/>Event data stores</h2>
<p class="calibre3">Since CloudTrail is an auditing tool that documents events/changes within an AWS account, security teams must indicate the data lake where these events are filtered and stored once a trail is<a id="_idIndexMarker263" class="pcalibre1 pcalibre2 pcalibre"/> created. AWS refers to this data lake of events as an <strong class="bold">event store</strong>. You can create <a id="_idIndexMarker264" class="pcalibre1 pcalibre2 pcalibre"/>one or more event stores to store management or data events based on filters across various regions within the AWS account. Event stores offer long-term retention of up to 7 years. Organizations can send these logs to a<a id="_idIndexMarker265" class="pcalibre1 pcalibre2 pcalibre"/> centrally managed <strong class="bold">security information and event management</strong> (<span><strong class="bold">SIEM</strong></span><span>) solution.</span></p>
<p class="calibre3">Once an event store is created, it effectively allows DFIR teams to immediately use it and query the store for associated activities on a specific AWS resource (module/service) and details about <span>the event.</span></p>
<p class="calibre3">The following screenshot demonstrates the steps required to configure an event store and apply a filter. We<a id="_idIndexMarker266" class="pcalibre1 pcalibre2 pcalibre"/> select all management and data events in the same event store in <span>this example:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer039"><img alt="Figure 4.14 – Configuring event stores in AWS CloudTrail" src="../images/00102.jpeg" class="calibre49"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.14 – Configuring event stores in AWS CloudTrail</p>

<h3 class="calibre11">Querying CloudTrail event stores</h3>
<p class="calibre3">CloudTrail allows DFIR teams to query event stores, where all management and data events are stored <a id="_idIndexMarker267" class="pcalibre1 pcalibre2 pcalibre"/>as with any logging tool. In simplistic terms, CloudTrail events can be queried <span>using </span><span><strong class="bold">SQL</strong></span><span>.</span></p>
<p class="calibre3">Note that within CloudTrail, given that the events are immutable, only SQL <strong class="source-inline">SELECT</strong> statements are allowed. You can apply filters using <strong class="source-inline">WHERE</strong> clauses. However, CloudTrail does not allow users to manipulate data within <span>event stores.</span></p>
<p class="calibre3">While event stores can be named, DFIR teams must note the unique event data store ID generated by AWS to run SQL queries. The following screenshot demonstrates a SQL query and associated query results. In this example, we are querying to return entire values stored in the event store. However, once comfortable, DFIR specialists can directly query the event store to obtain the necessary information from <span>the <a id="_idTextAnchor077" class="pcalibre1 pcalibre2 pcalibre"/>store:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer040"><img alt="Figure 4.15 – Simple SQL query and results on AWS CloudTrail" src="../images/00124.jpeg" class="calibre50"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.15 – Simple SQL query and results on AWS Cl<a id="_idTextAnchor078" class="pcalibre1 pcalibre2 pcalibre"/>oudTrail</p>
<p class="calibre3">Another example is where you query event stores to identify the top active users. In DFIR cases, this can be a needle in a haystack, with multiple users and interaction points. However, you are<a id="_idIndexMarker268" class="pcalibre1 pcalibre2 pcalibre"/> looking for one particular outlier where you can start your investigation into <span>this case.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h2 id="_idParaDest-72" class="calibre10"><a id="_idTextAnchor079" class="pcalibre1 pcalibre2 pcalibre"/>Investigating CloudTrail events</h2>
<p class="calibre3">Any DFIR specialist would love<a id="_idIndexMarker269" class="pcalibre1 pcalibre2 pcalibre"/> to access an event store full of logs that provide invaluable information for an investigation. This section will examine some investigative strategies that DFIR specialists can adopt to investigate CloudTrail events. Note that any queries performed on the CloudTrail event store are also recorded <a id="_idIndexMarker270" class="pcalibre1 pcalibre2 pcalibre"/>within the same <span>event store.</span></p>

<h3 class="calibre11">Investigating directly within the event store</h3>
<p class="calibre3">DFIR teams can directly choose to<a id="_idIndexMarker271" class="pcalibre1 pcalibre2 pcalibre"/> investigate the logs available in the event store. For example, we will investigate event stores to identify users who most frequently accessed AWS resources from <span>the console.</span></p>
<p class="calibre3">By default, when you log in to CloudTrail, CloudTrail will automatically provide a summary of events in its dashboard, which includes some recent user activities. It will also record any API calls performed by other AWS resources. It consists of any API calls a resource made internally to another within AWS and user interaction via the AWS <span>web browser.</span></p>
<p class="calibre3">For example, the following screenshot demonstrates some recent events in this demo lab. This dashboard also allows DFIR teams to click and obtain more specific information about a particular event entry. Each entry in the dashboard is reflective of <span>ea<a id="_idTextAnchor080" class="pcalibre1 pcalibre2 pcalibre"/>ch event:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer041"><img alt="Figure 4.16 – Dashboard view of events ordered by time in descending order" src="../images/00145.jpeg" class="calibre51"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.16 – Dashboard view of events ordered by time in descending order</p>
<p class="calibre3">For example, in the first event, the <strong class="source-inline">cf_user1</strong> user interacted with an AWS EC2 resource. We know from <a href="part0021_split_000.html#_idTextAnchor042" class="pcalibre1 pcalibre2 pcalibre"><span><em class="italic">Chapter 3</em></span></a> of this book that each EC2 instance is uniquely identified using an instance ID within AWS. It is, therefore, more accessible for DFIR teams to track back and remember which instance the user interacted with and gather specific configurations. Through the summary view, we can understand that the <strong class="source-inline">cf_user1</strong> user stopped an EC2 instance identified by <strong class="source-inline">i-09c02a7e1ff652c13</strong> on May 10, 2023, 05:55:49 (UTC-04:00). Should DFIR teams need additional information, this can be obtained by <a id="_idIndexMarker272" class="pcalibre1 pcalibre2 pcalibre"/>clicking on the link under the <strong class="bold">Event name</strong> field. The following screenshot shows the details of the <span>captured event:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer042"><img alt="Figure 4.17 – Additional information about the event recorded in CloudTrail" src="../images/00162.jpeg" class="calibre52"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.17 – Additional information about the event recorded in CloudTrail</p>
<p class="calibre3">It is important to note that additional information captures the source IP address, which records the IP address of the threat actor who may have compromised and accessed this AWS account to stop this instance. DFIR teams can further dig into the IP address and identify what other activities were performed by this user or from this source IP address, giving a timeline of events. In the additional information section, DFIR teams also have the opportunity to capture a raw event record in JSON format. AWS refers to this as an <strong class="bold">event payload</strong>. Usually, this<a id="_idIndexMarker273" class="pcalibre1 pcalibre2 pcalibre"/> is available within the dropdown under <strong class="bold">Event history</strong>. An event payload allows DFIR teams to review the raw log and determine more specific actions a user or attacker may have performed on the affected resource. Specifically, it also identifies other metadata that may be useful for further investigation. Here is a raw event log or event payload for stopping an instance, as indicated in the <span>preceding screenshot:</span></p>
<pre class="source-code">{
    "eventVersion": "1.08",
    "userIdentity": {
        "type": "IAMUser",
        "principalId": "AIDAZPQOL4P2OUQxxxxx",
        "arn": "arn:aws:iam::<strong class="bold">xxxxxxxx6548:user/cf_user1",</strong>
        "accountId": "xxxxxxxx6548",
        "accessKeyId": "xxxxxxxxxxxxMBCSD6",
        "userName": "<strong class="bold">cf_user1</strong>",
        "sessionContext": {
            "sessionIssuer": {},
            "webIdFederationData": {},
            "attributes": {
                "creationDate": "<strong class="bold">2023-05-10T09:55:05Z</strong>",
                "mfaAuthenticated": "<strong class="bold">true</strong>"
            }
        }
    },
    "eventTime": "<strong class="bold">2023-05-10T09:55:49Z</strong>",
    "eventSource": "ec2.amazonaws.com",
    "eventName": "StopInstances",
    "awsRegion": "ca-central-1",
    "sourceIPAddress": "<strong class="bold">184.147.70.116</strong>",
    "userAgent": "AWS Internal",
    "requestParameters": {
        "instancesSet": {
            "items": [
                {
                    "instanceId": "i-09c02a7e1ff652c13"
                }
            ]
        },
        "force": false
    },
    "responseElements": {
        "requestId": "1497712b-d47d-462a-a3a0-048d82463a96",
        "instancesSet": {
            "items": [
                {
                    "instanceId": "<strong class="bold">i-09c02a7e1ff652c13</strong>",
                    <strong class="bold">"currentState": {</strong>
                        "code": 64,
                        "name": "stopping"
                    },
                    <strong class="bold">"previousState": {</strong>
                        "code": 16,
                        "name": "running"
                    }
                }
            ]
        }
    },
    "requestID": "1497712b-d47d-462a-a3a0-048d82463a96",
    "eventID": "5ecd20de-1c37-41f1-b200-8660fe5d5eed",
    "readOnly": false,
    "eventType": "AwsApiCall",
    "managementEvent": true,
    "recipientAccountId": "xxxxxxxx6548",
    "eventCategory": "Management",
    "sessionCredentialFromConsole": "true"
}</pre>
<p class="calibre3">In the preceding raw <a id="_idIndexMarker274" class="pcalibre1 pcalibre2 pcalibre"/>event payload, we have highlighted essential elements or attributes of the log that DFIR teams should typically make a <span>note of:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Account used for logging in to the AWS console and type of account </strong>(<strong class="source-inline">{"arn": "arn:aws:iam::xxxxxxxx6548:user/cf_user1"}</strong>): In this instance, we have an IAM regular user logging in to an AWS account with a unique identifier (<strong class="source-inline">xxxxxxxx6548</strong>). We have tokenized the account number for <span>security reasons.</span></li>
<li class="calibre13"><strong class="bold">Username field</strong> (<strong class="source-inline">{userName": "cf_user1"}</strong>: The actual username that was used to authenticate to <span>this session.</span></li>
<li class="calibre13"><strong class="bold">Session creation date and time</strong> (<strong class="source-inline">"attributes": {"creationDate": "2023-05-10T09:55:05Z"</strong>, <strong class="source-inline">"mfaAuthenticated": "true"}</strong>: The time of the session that was created after authenticating the user to an AWS session. This entry demonstrates that the user successfully logged in to the AWS console and verified its two-factor token to complete the <span>authentication process.</span></li>
<li class="calibre13"><strong class="bold">Event time</strong> (<strong class="source-inline">{"eventTime": "2023-05-10T09:55:49Z"}</strong>: The actual date and time of the event that was recorded in <span>UTC time.</span></li>
<li class="calibre13"><strong class="bold">Source IP address</strong> (<strong class="source-inline">{"sourceIPAddress": "184[.]147[.]70[.]116"}</strong>: Source IP address of the user or threat actor who performed this event. For security reasons, IP addresses <span>are defanged.</span></li>
<li class="calibre13"><strong class="bold">Instance information</strong> (<strong class="source-inline">"instanceId": "i-09c02a7e1ff652c13"</strong>, <strong class="source-inline">"currentState": {"code": 64, "name": "stopping"}</strong>, <strong class="source-inline">"previousState": {"code": 16, "name": "running"}</strong>): Specific event entries reflecting current and previous states of the instances that confirm what specific actions were performed. In this example, we have a running instance that the user logged in to and stopped <span>the instance.</span></li>
</ul>
<p class="calibre3">Putting this in the<a id="_idIndexMarker275" class="pcalibre1 pcalibre2 pcalibre"/> perspective of a DFIR investigation, one can deduce and summarize the activities performed in this case and identify the next steps concerning <span>the investigation.</span></p>

<h3 class="calibre11">Downloading and investigating event store results offline</h3>
<p class="calibre3">Since CloudTrail event logs <a id="_idIndexMarker276" class="pcalibre1 pcalibre2 pcalibre"/>are in JSON format and you can query, filter, and extract results accordingly for investigation, we can always query the event store and download the logs for offline review. This is specifically useful where DFIR teams do not have access to AWS. However, investigation into CloudTrail events is imperative from an investigation point <span>of view.</span></p>
<p class="calibre3">Using the source IP address captured in the previous example, we will query the event data store to identify activities from this IP address. For this, we will perform the <span>following query:</span></p>
<pre class="console">SELECT * FROM d4f86c5e-2518-46a4-b751-943e266f3c49 WHERE eventTime &gt; '2023-04-30 00:00:00' AND sourceIPAddress='184.147.70.116'</pre>
<p class="calibre3">Remember—event data stores are uniquely identified using an event data store ID; we filter dates based on our incident investigation, and further filtering is applied to the <span><strong class="source-inline">sourceIPAddress</strong></span><span> attribute.</span></p>
<p class="calibre3">While query results are displayed in a tabulated format, you can copy entire raw records using the <strong class="bold">Copy</strong> option. You do have to select event records or everything you would like <span>to copy:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer043"><img alt="Figure 4.18 – Search query result" src="../images/00181.jpeg" class="calibre53"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.18 – Search query result</p>
<p class="calibre3">Using any third-party <a id="_idIndexMarker277" class="pcalibre1 pcalibre2 pcalibre"/>tools such as CyberChef, you can parse this JSON log for further investigation. Alternatively, you may use any log parsing tool to parse and further investigate <span>the logs.</span></p>
<p class="calibre3">Alternatively, you can download the whole set of logs directly from the associated Amazon S3 bucket. You can find the location for this S3 bucket by simply navigating to the CloudTrail dashboard and selecting the relevant trail name. See the next screenshot for <span>an example:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer044"><img alt="Figure 4.19 – Navigating to CloudTrail S3 bucket" src="../images/00001.jpeg" class="calibre54"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.19 – Navigating to CloudTrail S3 bucket</p>
<p class="calibre3">When you navigate to the S3 bucket, you will notice that CloudTrail details are stored in two different object repositories; one contains the digest (which we discussed in the earlier sections of the<a id="_idIndexMarker278" class="pcalibre1 pcalibre2 pcalibre"/> chapter), which includes information to verify the integrity of the logs, while the other object repository is where actual logs <span>are stored.</span></p>
<p class="calibre3">The logs are further stored per region, based on each AWS region the resources are operating from and sending logs to CloudTrail. DFIR teams need to understand that AWS breaks down the storage of logs per calendar day. When downloading S3 logs, you will need this information before your log collection from S3. Downloading all the data hosted on S3 may be huge and not beneficial from an investigation standpoint. However, it depends upon the circumstances of the investigation. The next screenshot provides an overview of a sample set of logs available for May 1, 2023, located under the <strong class="source-inline">ca-central-1</strong> region, and how AWS stores <span>Clou<a id="_idTextAnchor081" class="pcalibre1 pcalibre2 pcalibre"/>dTrail logs:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer045"><img alt="Figure 4.20 – Obtaining CloudTrail logs from the CA-Canada Central region" src="../images/00018.jpeg" class="calibre55"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.20 – Obtaining CloudTrail logs from the CA-Canada Central region</p>
<p class="calibre3">You may download multiple files simultaneously if you have API access to AWS. However, AWS limits downloads to one file at a time from the web console, which may make <span>it time-consuming.</span></p>
<p class="calibre3">While CloudTrail <a id="_idIndexMarker279" class="pcalibre1 pcalibre2 pcalibre"/>stores its logs in gzip format to preserve storage, AWS will serve you an unzipped log format <span>while downloading.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h2 id="_idParaDest-73" class="calibre10"><a id="_idTextAnchor082" class="pcalibre1 pcalibre2 pcalibre"/>DFIR use cases for CloudTrail logging</h2>
<p class="calibre3">Next are some use cases for enabling CloudTrail <a id="_idIndexMarker280" class="pcalibre1 pcalibre2 pcalibre"/>and how it can support <span>DFIR teams:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Incident investigation</strong>: CloudTrail can support your incident investigations. Some common investigation themes can be looked into, such as AWS account takeovers, where an attacker creates an unauthorized account to create/modify resources within AWS. You can use CloudTrail logs to determine the username, source IP address, and how they authenticated themselves into AWS. CloudTrail logs also provide vital information about whether the attacker performed specific modifications and the configuration previously set. Other investigation areas include <span>the following:</span><ul class="calibre17"><li class="calibre13"><strong class="bold">Looking for malicious or rogue EC2 instances</strong>: Through CloudTrail logs, you can determine if the attacker created an EC2 <strong class="bold">virtual machine</strong> (<strong class="bold">VM</strong>) to access specific production environments. CloudTrail can provide information on the instance type, instance ID – which can be used for further investigative hunting – and the date and time of the creation of such rogue EC2 instances. Because CloudTrail logs activities across multiple regions under the organization, DFIR teams can also use the CloudTrail logs to determine attacker lateral movements across various AWS resources in <span>various regions.</span></li><li class="calibre13"><strong class="bold">Unauthorized API calls</strong>: Since CloudTrail tracks all the API calls made by AWS internally from one resource to another, as well as API calls made by users, CloudTrail logs can be used to determine any unauthorized use of API resources. For <a id="_idIndexMarker281" class="pcalibre1 pcalibre2 pcalibre"/>example, a sudden surge of API calls using a specific access token can allow DFIR teams to quickly determine if the associated account was compromised, allowing unauthorized access to <span>the attackers.</span></li></ul></li>
<li class="calibre13"><strong class="bold">Security and compliance auditing</strong>: Given a large portion of CloudTrail’s purpose is to create an audit trail of all activities, CloudTrail can be used for monitoring compliance with security policies and regulations. For example, in healthcare, where user access must be closely monitored and provided on a least-privileged basis, CloudTrail logs can be valuable for fine-tuning these privileges based on the activities recorded, thus <span>ensuring compliance.</span></li>
<li class="calibre13"><strong class="bold">Infrastructure monitoring and troubleshooting</strong>: Outside of DFIR, CloudTrail can benefit developers and application testers to ensure their applications operate effectively. CloudTrail will allow developers to review API calls and determine the cause of any <span>unintended consequences.</span></li>
</ul>
</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h1 id="_idParaDest-74" class="calibre5"><a id="_idTextAnchor083" class="pcalibre1 pcalibre2 pcalibre"/>AWS CloudWatch</h1>
<p class="calibre3">AWS <strong class="bold">CloudWatch</strong> monitors your AWS resources in near real time. You can collect and monitor resource usage and key metrics in a SPOG view. CloudWatch presents every resource metric on its dashboard for quick view. However, for DFIR teams, CloudWatch can query certain logs to support<a id="_idIndexMarker282" class="pcalibre1 pcalibre2 pcalibre"/> <span>an investigation.</span></p>
<p class="calibre3">From a security perspective, CloudWatch is a log management solution that can centrally collect and monitor logs from systems, applications, and resources. It offers log analytics on top to allow interactive searching and analysis capabilities. Similar to CloudTrail, CloudWatch offers log exports via S3 buckets. Note that logs in CloudWatch never expire and are retained indefinitely. Administrators can change the retention policy and choose between a log retention of a day or up to 10 years. Alternatively, organizations can send CloudWatch logs to an SIEM solution via an API for centralized monitoring and management <span>of logs.</span></p>
<p class="calibre3">CloudWatch is a service that allows you to search and analyze log data interactively. You can monitor logs from Amazon EC2 instances and CloudTrail logged events, create alarms, and receive notifications for specific API activity to perform troubleshooting. Additionally, you can audit and mask sensitive data, adjust log retention, and archive log data. CloudWatch Logs can also log information about DNS queries that Route 53 receives. It uses a purpose-built query language with sample queries, command descriptions, query autocompletion, and log field discovery to help you <span>get started.</span></p>
<p class="calibre3">You can access CloudWatch <a id="_idIndexMarker283" class="pcalibre1 pcalibre2 pcalibre"/>using any of the <span>following methods:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">AWS CloudWatch console</strong>: Direct access to CloudWatch dashboards <span>and logs</span></li>
<li class="calibre13"><strong class="bold">AWS Command Line Interface (CLI)</strong>: Using modules provided by Amazon to connect to AWS via commonly available terminals or command-line consoles within popular <span>operating systems</span></li>
<li class="calibre13"><strong class="bold">CloudWatch APIs</strong>: Using your technologies to publish or monitor AWS CloudWatch logs <span>via APIs</span></li>
<li class="calibre13"><strong class="bold">AWS SDKs</strong>: Build applications that publish logs <span>into CloudWatch</span></li>
</ul>
<p class="callout-heading">Note</p>
<p class="callout">From a DFIR perspective, it is essential to note that CloudWatch logs, when enabled, only record activities performed on an AWS account and do not capture what specific actions were performed within each resource. (For example, CloudWatch will not capture events/records of activities performed by a user/threat actor within an EC2 instance. It will, however, record if the threat actor logged in to the AWS console and made changes, deleted EC2 instances, and <span>so on.)</span></p>
<p class="calibre3">The following diagram <a id="_idIndexMarker284" class="pcalibre1 pcalibre2 pcalibre"/>illustrates a typical configuration of logs that are recoded <span>into CloudWatch:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer046"><img alt="Figure 4.21 – Sample CloudWatch logging architecture of an EC2 instance with a VPC" src="../images/00036.jpeg" class="calibre56"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.21 – Sample CloudWatch logging architecture of an EC2 instance with a VPC</p>
<p class="calibre3">The following sections will review the difference between CloudWatch and CloudTrail and how DFIR teams can set it up for <span>incident investigation.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h2 id="_idParaDest-75" class="calibre10"><a id="_idTextAnchor084" class="pcalibre1 pcalibre2 pcalibre"/>CloudWatch versus CloudTrail</h2>
<p class="calibre3">So, let us look at some key differences between CloudWatch and CloudTrail. DFIR teams need to realize the difference<a id="_idIndexMarker285" class="pcalibre1 pcalibre2 pcalibre"/> in the features and how they can complement an <span>incident investigation:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">CloudWatch is a log management tool</strong>: CloudWatch offers monitoring and observability capabilities, explicitly<a id="_idIndexMarker286" class="pcalibre1 pcalibre2 pcalibre"/> collecting and displaying resource usage and metrics from various AWS products. It provides an <em class="italic">as-it-happens</em> view of <span>the logs.</span></li>
<li class="calibre13"><strong class="bold">CloudTrail records API interactions</strong>: CloudTrail records API interactions between users and internal AWS resources, which makes a record of all activities within an AWS account. Unlike CloudWatch, CloudTrail only records API-related activities and allows specific querying for application troubleshooting or <span>security investigations.</span></li>
</ul>
<p class="calibre3">Since CloudWatch is a log management tool at its core, CloudWatch can ingest CloudTrail events and, therefore, offers a single console view into various log sources. DFIR teams can use the CloudWatch API to pull logs into their local SIEM solution for further monitoring <span>and investigation.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h2 id="_idParaDest-76" class="calibre10"><a id="_idTextAnchor085" class="pcalibre1 pcalibre2 pcalibre"/>Setting up CloudWatch logging</h2>
<p class="calibre3">Once the organization establishes its AWS account, you can turn on CloudWatch logging. However, doing so requires a few steps, including configuring privileges for other AWS resources to <a id="_idIndexMarker287" class="pcalibre1 pcalibre2 pcalibre"/>allow them to send logs to CloudWatch. CloudWatch is regional; therefore, the best approach is to create a CloudWatch setup where most AWS resources are hosted. It is important to note for DFIR teams that enabling CloudWatch speeds up the incident investigation process. So, if an organization does not have CloudWatch, setting up an appropriate policy can allow flow logs to be immediately available, which is crucial <span>for investigations.</span></p>

<h3 class="calibre11">Configuring VPC flow logging</h3>
<p class="calibre3">Every category of logs is <a id="_idIndexMarker288" class="pcalibre1 pcalibre2 pcalibre"/>recorded in CloudWatch as a log group. A log group is a collection of similar types of logs. For example, all VPC flow logs will be under a single log group for CloudWatch; similarly, all CloudTrail events will be under a separate log group. In the next example, two log groups were created, with specific logging enabled for each. Each AWS resource will publish its flow logs within each log group as a log stream. For example, let us say you have five EC2 instances running, and you later create another five EC2 instances. At the end, when you log in to the CloudWatch console, you will see one log group that has multiple log streams <a id="_idIndexMarker289" class="pcalibre1 pcalibre2 pcalibre"/>uniquely identifying each EC2 resource using its network <span>interface ID.</span></p>
<p class="calibre3">Note that a log stream is a stream of network flow logs that only captures specific elements within the stream. We discussed what a flow log contains in an earlier part of this chapter in the <em class="italic">VPC flow logs</em> section. Each log stream contains multiple entries of flow logs associated with the network interface, which can then be queried or analyzed to obtain further insights. The following screenshot describes how CloudWatch groups all flow logs based on categories. In the screenshot, you will see VPC flow logs are grouped under <strong class="source-inline">vpcgrp1</strong>, while CloudTrail logs are grouped <span>under </span><span><strong class="source-inline">aws-cloudtrai<a id="_idTextAnchor086" class="pcalibre1 pcalibre2 pcalibre"/>l-logs-vb77-569383a0</strong></span><span>:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer047"><img alt="Figure 4.22 – CloudWatch log groups" src="../images/00053.jpeg" class="calibre57"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.22 – CloudWatch log groups</p>

<h3 class="calibre11">VPC flow log access requirements</h3>
<p class="calibre3">Since AWS is publishing flow <a id="_idIndexMarker290" class="pcalibre1 pcalibre2 pcalibre"/>logs originating per EC2 instance to be published or sent to another AWS resource, AWS requires the account to have appropriate IAM configurations to allow services to interact. By default, AWS does not automatically enable logs to be published to CloudWatch (given it is a separate subscription). Rights associated with flow logs must have appropriate permissions to allow VPC to post them <span>on CloudWatch.</span></p>
<p class="calibre3">At a high level, the following permissions are <span>typically required:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="source-inline">CreateLogGroup</strong>: Remember, as indicated in <span><em class="italic">Figure 4</em></span><em class="italic">.22</em>, that logs are grouped per category. This allows write permissions to create new log groups with a <span>specific name.</span></li>
<li class="calibre13"><strong class="source-inline">CreateLogStream</strong>: Each EC2 resource will publish its VPC logs within the log group as a log stream. This allows write permission to create a new log stream <span>per resource.</span></li>
<li class="calibre13"><strong class="source-inline">PutLogEvents</strong>: Allows <a id="_idIndexMarker291" class="pcalibre1 pcalibre2 pcalibre"/>permissions to write log events in batches within <span>each stream.</span></li>
<li class="calibre13"><strong class="source-inline">DescribeLogGroups</strong>: Describe or list log groups associated with the <span>AWS account.</span></li>
<li class="calibre13"><strong class="source-inline">DescribeLogStream</strong>: Similar to log groups, this allows listing all log streams within a specific log group associated with <span>the account.</span></li>
<li class="calibre13"><strong class="source-inline">GetLogRecord</strong>: Allows the ability to read all fields within a single <span>log event.</span></li>
<li class="calibre13"><strong class="source-inline">GetQueryResults</strong>: Allows the ability to read/return query results from <span>specific queries.</span></li>
</ul>
<p class="calibre3">There are additional permissions that are assigned to the <span>CloudWatch role:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="source-inline">DescribeQueries</strong>: Allows listing of CloudWatch Logs Insights queries that were <span>recently executed</span></li>
<li class="calibre13"><strong class="source-inline">StopQuery</strong>: Allows permissions to stop a CloudWatch Logs Insights query <span>from execution</span></li>
<li class="calibre13"><strong class="source-inline">DeleteQueryDefinition</strong>: Ability to delete a saved <span>CloudWatch query</span></li>
<li class="calibre13"><strong class="source-inline">PutQueryDefinition</strong>: Ability to create and update <span>a query</span></li>
<li class="calibre13"><strong class="source-inline">GetLogDelivery</strong>: Allows the ability to read log delivery information for <span>specific logs</span></li>
<li class="calibre13"><strong class="source-inline">ListLogDeliveries</strong>: Similar to <strong class="source-inline">GetLogDelivery</strong>, this allows log information to be listed for all log deliveries associated with an <span>AWS account</span></li>
<li class="calibre13"><strong class="source-inline">CreateLogDelivery</strong>: Allows permissions to create a new <span>log delivery</span></li>
<li class="calibre13"><strong class="source-inline">UpdateLogDelivery</strong>: Allows the ability to edit log <span>delivery configurations</span></li>
</ul>
<p class="calibre3">In addition to the IAM permissions, you must configure policies to allow flow logs to assume specific roles within your AWS account. For this case, we explicitly set up a policy to enable VPC flow logs to take roles within the AWS account. Policies group roles and resource assignments along with specific resource access conditions. Policies are how IAM manages permissions by attaching them to specific IAM users or identity profiles. A policy defines its permissions when associated with an identity, a user, or <span>a resource.</span></p>
<p class="calibre3">Next is an example of an IAM<a id="_idIndexMarker292" class="pcalibre1 pcalibre2 pcalibre"/> policy specifically created using a visual tool provided by AWS to allow VPC flow logs to be published and for users to access and query <span>the logs:</span></p>
<pre class="source-code">{
    "Version": "2022-10-17",
    "Statement": [
        {
            "Sid": "VisualEditor0",
            "Effect": "Allow",
            «Action»: [
                "logs:DescribeQueries",
                "logs:GetLogRecord",
                "logs:StopQuery",
                "logs:TestMetricFilter",
                "logs:DeleteQueryDefinition",
                "logs:PutQueryDefinition",
                "logs:GetLogDelivery",
                "logs:ListLogDeliveries",
                "logs:Link",
                "logs:CreateLogDelivery",
                "logs:DeleteResourcePolicy",
                "logs:PutResourcePolicy",
                "logs:DescribeExportTasks",
                "logs:GetQueryResults",
                "logs:UpdateLogDelivery",
                "logs:CancelExportTask",
                "logs:DeleteLogDelivery",
                "logs:DescribeQueryDefinitions",
                "logs:DescribeResourcePolicies",
                "logs:DescribeDestinations"
            ],
            "Resource": "*"
        },
        {
            "Sid": "VisualEditor1",
            "Effect": "Allow",
            "Action": "logs:*",
            "Resource": "arn:aws:logs:*:xxxxxxxx6548:log-group:*"
        },
        {
            "Sid": "VisualEditor2",
            "Effect": "Allow",
            "Action": "logs:*",
            "Resource": [
                "arn:aws:logs:*:xxxxxxxx6548:destination:*",
                "arn:aws:logs:*:xxxxxxxx6548:log-group:*:log-stream:*"
            ]
        }
    ]
}</pre>
<p class="calibre3">At a high level, here is a <a id="_idIndexMarker293" class="pcalibre1 pcalibre2 pcalibre"/>breakdown of the policy. The policy has three statements in the form of <span>array entries:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Statement 1</strong>: A list of CloudWatch Logs actions that are allowed. These actions include various management and data retrieval operations for <span>CloudWatch Logs.</span></li>
<li class="calibre13"><strong class="bold">Statement 2</strong>: Allow <strong class="source-inline">logs:*</strong> instances (CloudWatch Logs actions) within a specific AWS account. This will include all log groups associated with the <span>AWS account.</span></li>
<li class="calibre13"><strong class="bold">Statement 3</strong>: Allow actions on all <strong class="source-inline">logs:*</strong> instances associated with a specific AWS account and all log streams specified within the <span>AWS account.</span></li>
</ul>
<p class="calibre3">Remember—policies allow users to access, edit, or query CloudWatch logs. You will, however, need to set up trust relationships between AWS resources for it to share/publish logs in the first place. This is typically done automatically when you first set up and enable CloudWatch. However, you can make granular trust policies for specific trust relationships between resources. Here is an example of a trust relation configured within the <span>IAM module:</span></p>
<pre class="source-code">{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Principal": {
                "Service": "vpc-flow-logs.amazonaws.com"
            },
            "Action": "sts:AssumeRole"
        }
    ]
}</pre>
<p class="calibre3">The preceding JSON represents an IAM role trust policy that allows the Amazon VPC flow logs service (<strong class="source-inline">vpc-flow-logs.amazonaws.com</strong>) to assume the role. This trust policy is used when establishing a trust relationship between an IAM role and a trusted entity (in this case, the VPC flow logs service). The <strong class="source-inline">AssumeRole</strong> security token allows the relevant AWS resource a temporary set of security credentials that, in this case, the VPC service can use to <a id="_idIndexMarker294" class="pcalibre1 pcalibre2 pcalibre"/>communicate with other AWS services (CloudWatch) to pass the flow logs. <strong class="source-inline">AssumeRole</strong> allows for cross-account access and can be used for making API calls to any <span>AWS service.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h2 id="_idParaDest-77" class="calibre10"><a id="_idTextAnchor087" class="pcalibre1 pcalibre2 pcalibre"/>Querying CloudWatch logs on the AWS console</h2>
<p class="calibre3">For manually querying CloudWatch within AWS, DFIR teams can utilize Logs Insights to construct specific queries for investigation. Logs Insights enables interactive querying capabilities to search and analyze log data. CloudWatch automatically identifies relevant fields from various log sources, including <a id="_idIndexMarker295" class="pcalibre1 pcalibre2 pcalibre"/>any custom logs sent to CloudWatch in JSON format. You can also create visual outputs, including graphs, as part of Logs <span>Insights queries.</span></p>
<p class="calibre3">In the next example, we are looking at VPC flow logs. However, when querying, you may choose all log groups. The following screenshot demonstrates an example of querying within CloudWatch Logs Insights. The query targets the <strong class="source-inline">vpcgrp1</strong> log group to identify the <strong class="bold">timestamp</strong> of the log, <strong class="bold">message</strong> (complete log information), <strong class="source-inline">LogStream</strong> (the source network identifier from where flow logs are generated), and the <strong class="bold">log</strong> (the account and the log group where the log was identified, useful when querying multiple log groups). Select the appropriate time range for CloudWatch to look up <span>the logs:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer048"><img alt="Figure 4.23 – Sample query on CloudWatch" src="../images/00071.jpeg" class="calibre58"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.23 – Sample query on CloudWatch</p>
<p class="calibre3">When you query within Logs Insights, CloudWatch will generate results and a histogram to allow investigators to drag and select timelines based on identified anomalies within the histogram. The<a id="_idIndexMarker296" class="pcalibre1 pcalibre2 pcalibre"/> next screenshot is an example of such a query result, with a histogram that outlines the events based on timestamp and number of records per date and <span>time entries:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer049"><img alt="Figure 4.24 – Sample visualization generated by CloudWatch for VPC traffic" src="../images/00091.jpeg" class="calibre59"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.24 – Sample visualization generated by CloudWatch for VPC traffic</p>
<p class="calibre3">By just utilizing a sample query to determine traffic patterns observed by all VPC logs, you can further begin to filter down for the investigation. You filter on dates (through a selection option) and specific VPC log streams if the subject of investigation is nailed down to an EC2 instance connected with a particular log stream. Each query will also provide you with summary details of the log (as a simple string), along with a visualization, as indicated in <span><em class="italic">Figure 4</em></span><span><em class="italic">.24</em></span><span>.</span></p>
<p class="calibre3">CloudTrail also provides pre-canned queries to get DFIR teams started; they can use these base queries to modify and apply necessary filters to obtain results for <span>their investigation.</span></p>
<p class="calibre3">We used a sample query to<a id="_idIndexMarker297" class="pcalibre1 pcalibre2 pcalibre"/> determine all network traffic that was tagged as <strong class="source-inline">ACCEPT</strong>, meaning allowed by VPC and EC2 (configured via security groups,) and examine the traffic volume of each of <span>those sessions:</span></p>
<pre class="console">filter action="ACCEPT" | filter bytesTransferred &gt; 100 | stats sum(bytes) as bytesTransferred by srcAddr, srcPort, dstAddr, dstPort, action</pre>
<p class="calibre3">The preceding query is run against all VPC log streams; however, AWS will limit the results to 1,000 records if we do not specify the <em class="italic">limit</em> result option. This is to avoid resource constraints to pull <span>the results.</span></p>
<p class="calibre3">The next screenshot outlines the results we obtain once we run the <span>previous query:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer050"><img alt="Figure 4.25 – CloudWatch query results" src="../images/00111.jpeg" class="calibre60"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.25 – CloudWatch query results</p>
<p class="calibre3">Let us look at an example of data exfiltration over SSH. We want to determine the overall network traffic on where there was outbound network traffic from the AWS EC2 instance to a remote threat actor-controlled server. You can use a CloudWatch query to filter to a specific IP address or just the source port (<strong class="source-inline">srcPort</strong>) to identify which other EC2 instance was accessed from this IP address. In the next example, we specifically look at all outbound network connections. If you are interested in inbound network activity on a specific port, you can set the <a id="_idIndexMarker298" class="pcalibre1 pcalibre2 pcalibre"/>destination port (<strong class="source-inline">dstPort</strong>) on <span>the filter:</span></p>
<pre class="console">filter action="ACCEPT" | filter bytesTransferred &gt; 100 | filter srcPort=22 |stats sum(bytes) as bytesTransferred by srcAddr, srcPort, dstAddr, dstPort, action</pre>
<p class="calibre3">We can look into network spikes through the results and associated visualizations provided by CloudWatch. As indicated earlier, since CloudWatch offers interactive querying capabilities, you can click and select specific traffic spikes to filter down the time range associated with those network outbound spikes. In the next screenshot, we drill down into the network spikes identified <span>by CloudWatch:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer051"><img alt="Figure 4.26 – Initial query results" src="../images/00132.jpeg" class="calibre61"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.26 – Initial query results</p>
<p class="calibre3">To continue with the routine investigation, we choose a date/time by interactively selecting the spikes, which provides more granular visualizations. Note that the date/time in the filter is now converted <span>to hours:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer052"><img alt="Figure 4.27 – Granular view of outbound network traffic" src="../images/00150.jpeg" class="calibre62"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.27 – Granular view of outbound network traffic</p>
<p class="calibre3">Through this deep dive, we can boil down the network traffic to three large spikes attributed to outbound network activity. Note that the traffic patterns still indicate multiple IP addresses; some of them can still be legitimate. To nail down potential threat actor IP addresses, at the same time, on the same screen with applicable time filters, we will edit the query to identify IP addresses with the largest to fewest data transfers. In a data exfiltration scenario, threat actors would exfiltrate large volumes of information from the servers. For this <a id="_idIndexMarker299" class="pcalibre1 pcalibre2 pcalibre"/>example, we filter outbound network traffic to anything above 1,000,000 bytes (approximately 1 MB) transferred and sort them in <span>descending order:</span></p>
<pre class="console">filter action="ACCEPT" | filter bytesTransferred &gt; 1000000 | filter srcPort=22 |stats sum(bytes) as bytesTransferred by srcAddr, srcPort, dstAddr, dstPort, action | sort bytesTransferred desc</pre>
<p class="calibre3">As a result, we get about 19 data transfer events across the 3 instances of network spikes that can be potentially attributed to data exfiltration activity. Since we filtered the results down, DFIR teams can now use the destination<a id="_idIndexMarker300" class="pcalibre1 pcalibre2 pcalibre"/> IP address field to perform some form of <strong class="bold">open source intelligence</strong> (<strong class="bold">OSINT</strong>) to determine the legitimacy of the IP addresses to nail down further or apply <span>necessary filters:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer053"><img alt="Figure 4.28 – Query result on data exfiltration of over 1 MB" src="../images/00169.jpeg" class="calibre63"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.28 – Query result on data exfiltration of over 1 MB</p>
<p class="calibre3">As we can see in the descending order of bytes transferred results, we can immediately start looking at those spikes to determine and correlate them with the rest of the investigation. Here is just an example of an IP address filter to identify a network activity to a specific <span>IP address:</span></p>
<pre class="console">filter action="ACCEPT" | filter bytesTransferred &gt; 1000000 | filter srcPort=22  | filter dstAddr="72.137.104.5" |stats sum(bytes) as bytesTransferred by srcAddr, srcPort, dstAddr, dstPort, action | sort bytesTransferred desc</pre>
<p class="calibre3">We see in the next screenshot the results of <span>the query:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer054"><img alt="Figure 4.29 – IP address-based network activity" src="../images/00188.jpeg" class="calibre64"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.29 – IP address-based network activity</p>
<p class="calibre3">As we know, VPC flow logs are similar to<a id="_idIndexMarker301" class="pcalibre1 pcalibre2 pcalibre"/> NetFlow logs; we can use the results we extracted and further query to determine the source of the network traffic—that is, which EC2 instance the traffic originates from. You can do that by correlating the source IP address field (<strong class="source-inline">srcAddr</strong>) and mapping it back to which EC2 instance was assigned this IP during the incident. We edit this query to yield the <span>following fields:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="source-inline">timestamp</strong>: Date and time of <span>the event</span></li>
<li class="calibre13"><strong class="source-inline">message</strong>: A NetFlow summary in <span>message format</span></li>
<li class="calibre13"><strong class="source-inline">logStream</strong>: The VPC log stream responsible for <span>this message</span></li>
</ul>
<p class="calibre3">The next query aims to obtain the exfiltration activity’s entire message and log <span>stream information:</span></p>
<pre class="console">filter action="ACCEPT" | filter srcPort=22 | filter dstAddr="72.137.104.5" | fields @timestamp, @message, @logStream</pre>
<p class="calibre3">Based on the query indicated previously, we can see the details of each event in the screenshot. This allows DFIR teams to obtain specific information about the network flow log and <span>additional metadata:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer055"><img alt="" role="presentation" src="../images/00008.jpeg" class="calibre65"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.30 – Screenshot of the results from the preceding query</p>
<p class="calibre3">The preceding results provide a <a id="_idIndexMarker302" class="pcalibre1 pcalibre2 pcalibre"/>hyperlink to the log information for each row while presenting other critical data. Through the drop-down option against each row, the following additional information is presented for further investigation. In the next screenshot, we expand an example log event to highlight the fields capt<a id="_idTextAnchor088" class="pcalibre1 pcalibre2 pcalibre"/>ured by the VPC <span>flow log:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer056"><img alt="Figure 4.31 – Additional VPC flow log information" src="../images/00023.jpeg" class="calibre66"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.31 – Additional VPC flow log information</p>
<p class="calibre3">You can use pre-canned CloudWatch queries to add extra filters to further your investigation. Through the additional information reflected in the preceding screenshot, we can nail down to which EC2 instance the outbound network traffic originated by correlating the ENI ID to the EC2 instance. In summary, we started from 89,827 records to just 3 with the highest data exfiltration within the applicable time filter. As DFIR teams, you must slice and dice further on other IP addresses; this demonstrates how CloudWatch can contribute to <span>an investigation.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h2 id="_idParaDest-78" class="calibre10"><a id="_idTextAnchor089" class="pcalibre1 pcalibre2 pcalibre"/>DFIR use cases for CloudWatch</h2>
<p class="calibre3">Through this chapter’s sections, we now know why CloudWatch is vital from a DFIR perspective. Next are some use cases on how CloudWatch can be used for forensic investigation and <span>anomaly detection:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Log review</strong>: CloudWatch, as<a id="_idIndexMarker303" class="pcalibre1 pcalibre2 pcalibre"/> we all know, offers a centralized repository for logs, including CloudTrail logs. Therefore, it provides a SPOG where DFIR teams can query all logs quickly and yield investigative results. You can leverage CloudWatch to detect abnormal activity and unauthorized access and correlate events across various log sources ingested <span>into CloudWatch.</span></li>
<li class="calibre13"><strong class="bold">Anomaly detection</strong>: DFIR teams can define thresholds and alarms based on specific metrics (for example, CPU utilization, network traffic, or storage) to identify unusual patterns or deviations from normal behavior. Anomalous metrics can serve as early indicators of security breaches or <span>compromised instances.</span></li>
<li class="calibre13"><strong class="bold">IR automation</strong>: CloudWatch natively integrates with other workflow-based services, including AWS Lambda and AWS Systems Manager Automation, for automatic orchestration of isolation, snapshot creation, and user account changes upon a specific event alert. Workflows are based on triggers that allow automated remediation and <span>containment actions.</span></li>
<li class="calibre13"><strong class="bold">Compliance and auditing</strong>: Since CloudWatch offers centralized logging and monitoring capabilities, this also allows compliance monitoring and supporting audits. DFIR teams can leverage CloudWatch logs and metrics to demonstrate adherence to security policies, track user activity, and generate reports for <span>compliance audits.</span></li>
</ul>
</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h1 id="_idParaDest-79" class="calibre5"><a id="_idTextAnchor090" class="pcalibre1 pcalibre2 pcalibre"/>Amazon GuardDuty</h1>
<p class="calibre3"><strong class="bold">GuardDuty</strong> is a threat detection service designed to help protect AWS resources and workloads by continuously monitoring for malicious activity and unauthorized behavior. Note that this is a detection service and not a response service. It detects and notifies the user of a potential threat within an <a id="_idIndexMarker304" class="pcalibre1 pcalibre2 pcalibre"/>AWS resource. However, integration with automated services such as Lambda will enhance GuardDuty’s capabilities to respond to threats based on established playbooks for each threat detected. GuardDuty uses ML, anomaly detection, and integrated TI to identify potential security threats within your <span>AWS environment.</span></p>
<p class="calibre3">Some DFIR use cases are <span>as follows:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Threat detection</strong>: GuardDuty analyzes CloudTrail logs, VPC flow logs, and DNS logs to detect <strong class="bold">indicators of compromise</strong> (<strong class="bold">IOCs</strong>) and potential threats. It applies ML algorithms to identify patterns<a id="_idIndexMarker305" class="pcalibre1 pcalibre2 pcalibre"/> and anomalies that might indicate malicious activities, such as unauthorized access attempts, reconnaissance, or instances exhibiting behavior associated with malware or botnets. These IOCs are collected through AWS’s TI partners and third-party vendor tools offered to their clients. DFIR teams do not have control or the ability to manage <span>these IOCs.</span></li>
<li class="calibre13"><strong class="bold">TI</strong>: GuardDuty leverages TI feeds from AWS, partner organizations, and OSINT to enhance its threat detection capabilities. It compares network activity within your AWS environment against known malicious IPs, domains, and other indicators to identify potential <span>security risks.</span></li>
<li class="calibre13"><strong class="bold">Centralized security monitoring</strong>: GuardDuty provides a centralized view of security findings across your AWS accounts and regions. It aggregates and prioritizes security alerts, allowing security teams to focus on the most critical threats. The consolidated dashboard and event stream enable quick detection and response to potential <span>security incidents.</span></li>
<li class="calibre13"><strong class="bold">Automated remediation</strong>: GuardDuty integrates with other AWS services, such as AWS Lambda and AWS Systems Manager, to facilitate automated responses to security events. You can orchestrate customized actions or use pre-built response playbooks to automate remediation actions, such as isolating compromised instances, blocking malicious IPs, or updating <span>security groups.</span></li>
<li class="calibre13"><strong class="bold">Security operations and IR</strong>: GuardDuty is crucial in security operations and IR workflows. It provides real-time alerts and findings, enabling security teams to investigate and respond to potential security incidents quickly. Integrating with AWS services such as Amazon CloudWatch and AWS Lambda enables automated IR and<a id="_idIndexMarker306" class="pcalibre1 pcalibre2 pcalibre"/> security teams to take <span>immediate action.</span></li>
</ul>
<h3 class="calibre11">Permissions and trust</h3>
<p class="calibre3">To leverage the capabilities of GuardDuty, DFIR<a id="_idIndexMarker307" class="pcalibre1 pcalibre2 pcalibre"/> teams must ensure that, at a minimum, the following permissions must <span>be allowed:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="source-inline">ec2:DescribeInstances</strong>: Describe <span>EC2 instances</span></li>
<li class="calibre13"><strong class="source-inline">ec2:DescribeImages</strong>: Describe EC2 <span>instances’ images</span></li>
<li class="calibre13"><strong class="source-inline">ec2:DescribeVpcEndpoints</strong>: Identify the VPC <span>endpoint name</span></li>
<li class="calibre13"><strong class="source-inline">ec2:DescribeSubnets</strong>: Identify VPC <span>subnet information</span></li>
<li class="calibre13"><strong class="source-inline">ec2:DescribeVpcPeeringConnections</strong>: Identify and enumerate VPC <span>peering information</span></li>
<li class="calibre13"><strong class="source-inline">ec2:DescribeTransitGatewayAttachments</strong>: Identify VPC transit gateway, <span>if any</span></li>
<li class="calibre13"><strong class="source-inline">organizations:ListAccounts</strong>: List user accounts configured under the AWS <span>account (organization)</span></li>
<li class="calibre13"><strong class="source-inline">organizations:DescribeAccount</strong>: Describe the AWS account <span>type (user/root)</span></li>
<li class="calibre13"><strong class="source-inline">s3:GetBucketPublicAccessBlock</strong>: Check for an S3 public access block on <span>the bucket</span></li>
<li class="calibre13"><strong class="source-inline">s3:GetEncryptionConfiguration</strong>: Obtain S3 data <span>encryption information</span></li>
<li class="calibre13"><strong class="source-inline">s3:GetBucketTagging</strong>: Obtain S3 <span>bucket tags</span></li>
<li class="calibre13"><strong class="source-inline">s3:GetAccountPublicAccessBlock</strong>: Check for an S3 public access block on the <span>AWS account</span></li>
<li class="calibre13"><strong class="source-inline">s3:ListAllMyBuckets</strong>: Enumerate S3 buckets owned by an <span>AWS account</span></li>
<li class="calibre13"><strong class="source-inline">s3:GetBucketAcl</strong>: Enumerate S3 <span>bucket ACLs</span></li>
<li class="calibre13"><strong class="source-inline">s3:GetBucketPolicy</strong>: Enumerate S3 <span>bucket policy</span></li>
<li class="calibre13"><strong class="source-inline">s3:GetBucketPolicyStatus</strong>: Obtain current bucket <span>policy status</span></li>
</ul>
<p class="calibre3">Furthermore, the Amazon GuardDuty service requires it to assume a specific IAM role. The roles can have additional<a id="_idIndexMarker308" class="pcalibre1 pcalibre2 pcalibre"/> policies configured, which may be attached. Amazon GuardDuty typically requires the <strong class="source-inline">sts:AssumeRole</strong> role to delegate access. Allowing GuardDuty to assume this role enables the service to act on behalf of the role and perform authorized actions based on the <span>permissions assigned.</span></p>

<h3 class="calibre11">Amazon GuardDuty malware scan</h3>
<p class="calibre3">Enabling malware scans on EC2 instances and other resources is a great way to begin hunting for malware. GuardDuty<a id="_idIndexMarker309" class="pcalibre1 pcalibre2 pcalibre"/> provides a built-in service for altering or modifying an existing EC2 instance to natively scan the EC2 endpoints for evidence of compromise or malware. It examines data storage such as Amazon EBS volumes and other storage forms attached to a particular EC2 instance. It also provides the ability to obtain snapshots of relevant storage volumes should it detect evidence <span>of malware.</span></p>
<p class="calibre3">Depending upon the AWS account and its operating regions, Amazon GuardDuty offers malware scanning capabilities through the following vendors: Bitdefender, CloudHesive, CrowdStrike, Fortinet, Palo Alto Networks, Rapid7, Sophos, Sysdig, Trellix. For DFIR teams, this means that they do not have to integrate or deploy software on affected AWS resources (such as EC2); instead, they enable GuardDuty on specific AWS accounts and activate malware scans, which offer these solutions automatically and allow scanning of EBS for the presence <span>of malware.</span></p>
<p class="callout-heading">Note</p>
<p class="callout">Amazon GuardDuty is specifically beneficial in cases where the installed antivirus configured within the EC2 instance may have been potentially disabled or tampered with by a threat actor. GuardDuty malware scans on EC2 instances allow insights into any malicious activities or malware downloaded by a threat actor for performing any nefarious actions without any additional security tooling deployments. This is beneficial as threat actors do not typically go after <span>disabling GuardDuty.</span></p>
<p class="calibre3">GuardDuty also integrates with CloudWatch without specific configurations so that DFIR teams can query additional <a id="_idIndexMarker310" class="pcalibre1 pcalibre2 pcalibre"/>telemetry based on the malware scan. The following screenshot demonstrates an example of GuardDuty’s integration with CloudWatch, specifically malware <span>scan events:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer057"><img alt="Figure 4.32 – Example of CloudWatch query for Amazon GuardDuty malware scan" src="../images/00044.jpeg" class="calibre67"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.32 – Example of CloudWatch query for Amazon GuardDuty malware scan</p>
<p class="calibre3">Besides malware scans, GuardDuty offers insights into threats based on TI and detections of activities performed by various resources within the AWS account. Here is a sample set generated by GuardDuty to illustrate different detections. Note that each of the detections is rated by GuardDuty and is tagged as high, medium, <span>or low-risk:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer058"><img alt="Figure 4.33 – Sample threat detections within Amazon GuardDuty" src="../images/00060.jpeg" class="calibre68"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.33 – Sample threat detections within Amazon GuardDuty</p>
<p class="calibre3">Once a malware scan is initiated, GuardDuty generates a unique detector ID to identify each scan uniquely. We started a scan on one of the EC2 instances to determine if there was any evidence of malware. Next <a id="_idIndexMarker311" class="pcalibre1 pcalibre2 pcalibre"/>is the JSON output of the malware scan on one of the EC2 instances, demonstrating an example of an <span>ongoing scan:</span></p>
<pre class="source-code">{
  "DetectorId": "26c440764b66ddeb7ff50f0881fc5e52",
  "AdminDetectorId": "26c440764b66ddeb7ff50f0881fc5e52",
  "ScanId": "b9d0d5771729105b69012dcd71190e81",
  "ScanStatus": "RUNNING",
  "ScanStartTime": "2023-06-03T11:53:24.000Z",
  "TriggerDetails": {},
  "ResourceDetails": {
    "InstanceArn": "arn:aws:ec2:ca-central-1:xxxxxxx6548:instance/i-00229ce2dd123a2e6"
  },
  "ScanResultDetails": {},
  "AccountId": "xxxxxxxx6548",
  "AttachedVolumes": [
    {
      "VolumeArn": "arn:aws:ec2:ca-central-1:xxxxxxxx6548:volume/vol-061392d9abebf9433",
      "VolumeType": "gp2",
      "DeviceName": "/dev/sda1",
      "VolumeSizeInGB": 30,
      "EncryptionType": "UNENCRYPTED"
    },
    {
      "VolumeArn": "arn:aws:ec2:ca-central-1:xxxxxxxx6548:volume/vol-06c47b3cf15b2d6ae",
      "VolumeType": "gp3",
      "DeviceName": "xvdb",
      "VolumeSizeInGB": 30,
      "EncryptionType": "UNENCRYPTED"
    }
  ],
  "ScanType": "ON_DEMAND"
}</pre>
<p class="calibre3">Once the scan is completed, GuardDuty generates a scan report accessible via the <strong class="bold">Malware scans</strong> page, accessing the<a id="_idIndexMarker312" class="pcalibre1 pcalibre2 pcalibre"/> unique GuardDuty malware scanning detection ID. The next screenshot demonstrates that Amazon GuardDuty identified potential malware on the disk (Amazon <span>EBS storage):</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer059"><img alt="Figure 4.34 – Amazon GuardDuty malware scan detections" src="../images/00078.jpeg" class="calibre69"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.34 – Amazon GuardDuty malware scan detections</p>
<p class="calibre3">This allows DFIR teams to confirm the presence of malware and hunt for threats further. Next are examples of the results <a id="_idIndexMarker313" class="pcalibre1 pcalibre2 pcalibre"/>of the detections. We see the scan has picked up eight threats on the disk, and here is a sample detection summary of one of <span>the threats:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer060"><img alt="Figure 4.35 – Amazon GuardDuty malware scan detections" src="../images/00098.jpeg" class="calibre70"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.35 – Amazon GuardDuty malware scan detections</p>
<p class="calibre3">As you can see, the malware scan identifies the name of the sample detected, which is typically assigned by the vendor that scanned this binary. The SHA-256 hash of the file identified on the disk can be handy for DFIR teams for further threat hunting and detection. The file path and name identify the file’s location and allow DFIR teams to manually collect artifacts and AWS volume information on where this file was identified. For AWS purposes, this is recognized as part of AWS resource naming conventions that determine the account owner and information on which volume this detection <span>occurred (</span><span><strong class="source-inline">arn:aws:ec2:ca-central-1:xxxxxxxx6548:volume/vol-061392d9abebf9433</strong></span><span>).</span></p>
<p class="calibre3">DFIR teams can also identify the scanning partner that scanned this instance through the summary page. In our example, Bitdefender scanned <span>this detection:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer061"><img alt="Figure 4.36 – Amazon GuardDuty scanner" src="../images/00119.jpeg" class="calibre71"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.36 – Amazon GuardDuty scanner</p>
<p class="calibre3">Once Amazon GuardDuty<a id="_idIndexMarker314" class="pcalibre1 pcalibre2 pcalibre"/> completes the scans, it allows DFIR teams to also pivot into the Amazon <span>Detective service:</span></p>
<div class="calibre2">
<div class="img---figure" id="_idContainer062"><img alt="Figure 4.37 – Amazon Detective playbook on Amazon GuardDuty detections" src="../images/00142.jpeg" class="calibre72"/></div>
</div>
<p class="img---caption" lang="en-US">Figure 4.37 – Amazon Detective playbook on Amazon GuardDuty detections</p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h1 id="_idParaDest-80" class="calibre5"><a id="_idTextAnchor091" class="pcalibre1 pcalibre2 pcalibre"/>Amazon Detective</h1>
<p class="calibre3">Amazon Detective helps DFIR teams analyze, investigate, and visualize security data from various AWS services. It automatically collects and analyzes log data from AWS CloudTrail, Amazon VPC flow logs, and Amazon GuardDuty to provide insights into potential security vulnerabilities and suspicious <a id="_idIndexMarker315" class="pcalibre1 pcalibre2 pcalibre"/>activities within an AWS environment. Some of the capabilities of Amazon Detective are <span>as follows:</span></p>

<ul class="calibre12">
<li class="calibre13"><strong class="bold">Security graph</strong>: Amazon Detective uses a graph-based approach to visualize and analyze security-related data by creating a graphical representation of AWS resources, accounts, and their relationships, allowing DFIR teams to identify patterns, anomalies, and potential security <span>threats quickly.</span></li>
<li class="calibre13"><strong class="bold">Automated data ingestion</strong>: Amazon Detective automatically collects and ingests data from AWS CloudTrail, Amazon VPC flow logs, and Amazon GuardDuty for aggregating and processing to provide insights <span>and recommendations.</span></li>
<li class="calibre13"><strong class="bold">Threat hunting</strong>: Amazon Detective enables DFIR teams with pre-built queries and analytics to proactively hunt for security threats and anomalies. These queries leverage ML algorithms and statistical models to identify suspicious activities and potential <span>security issues.</span></li>
<li class="calibre13"><strong class="bold">Security findings</strong>: Amazon Detective presents security findings based on its analysis of the collected data. These findings are prioritized and include details about accounts, resources, activities, and potential threats. It also includes supporting evidence and artifacts to allow <span>further investigations.</span></li>
</ul>
<p class="callout-heading">Note</p>
<p class="callout">Note that to enable Amazon Detective, having Amazon GuardDuty is <span>a pre-requisite.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h1 id="_idParaDest-81" class="calibre5"><a id="_idTextAnchor092" class="pcalibre1 pcalibre2 pcalibre"/>Summary</h1>
<p class="calibre3">To summarize, AWS offers integration of API logs and generic event logs and provides a SPOG to determine threat actor activity or an insider threat within an AWS account. With CloudWatch and CloudTrail, DFIR teams can natively investigate AWS using AWS’s tools and identify activities an unauthorized user performs at a granular level. Furthermore, resources such as EC2 and S3 offer additional information concerning the configuration that allows DFIR teams to deduce and obtain further information for investigations. Remember that some security solutions, such as VPC flow logs, are not enabled by default and require the account owner or administrator to allow them explicitly. Integrating CloudTrail logs with CloudWatch and enabling Amazon GuardDuty offers DFIR teams a deep insight into threats within an AWS account and resources without explicitly going through deployments of security tools. Enabling GuardDuty and, subsequently, Amazon Detective allows telemetric information and the ability of the DFIR team to pinpoint the threat and perform additional threat hunting. Organizations and DFIR teams must be aware that enabling any security features is separately priced by AWS and will be reflected in your <span>next bill.</span></p>
<p class="calibre3">In the following few chapters, we will similarly explore native capabilities for investigations on Microsoft Azure and Google Cloud, and we will eventually tie them together with other open source and commercial tools for extracting forensic artifacts from these cloud instances for purposes of offline investigation. Overall, the goal is to ensure DFIR teams have enough information at hand and from multiple sources of logs that validate threat actor activities and enable the teams to confirm unauthorized activities beyond a reasonable doubt using <span>these tools.</span></p>

</div>
</div>


<div id="sbo-rt-content" class="calibre1">
<div id="_idContainer063" class="calibre2">
<h1 id="_idParaDest-82" class="calibre5"><a id="_idTextAnchor093" class="pcalibre1 pcalibre2 pcalibre"/>Further reading</h1>
<ul class="calibre12">
<li class="calibre13"><em class="italic">CIDR/VLSM </em><span><em class="italic">Calculator</em></span><span>: </span><a href="https://www.subnet-calculator.com/cidr.php" class="pcalibre1 pcalibre2 pcalibre"><span>https://www.subnet-calculator.com/cidr.php</span></a></li>
<li class="calibre13">Port number <span>assignments: </span><a href="https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.txt" class="pcalibre1 pcalibre2 pcalibre"><span>https://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.txt</span></a></li>
<li class="calibre13"><em class="italic">CloudTrail </em><span><em class="italic">concepts</em></span><span>: </span><a href="https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-concepts.xhtml#cloudtrail-concepts-data-events" class="pcalibre1 pcalibre2 pcalibre"><span>https://docs.aws.amazon.com/awscloudtrail/latest/userguide/cloudtrail-concepts.xhtml#cloudtrail-concepts-data-events</span></a></li>
<li class="calibre13">The cyber Swiss Army knife – a web app for encryption, encoding, compression, and data <span>analysis: </span><a href="https://gchq.github.io/CyberChef/" class="pcalibre1 pcalibre2 pcalibre"><span>https://gchq.github.io/CyberChef/</span></a></li>
<li class="calibre13">Amazon GuardDuty – malware protection for Amazon EBS <span>volumes: </span><a href="https://aws.amazon.com/blogs/aws/new-for-amazon-guardduty-malware-detection-for-amazon-ebs-volumes/" class="pcalibre1 pcalibre2 pcalibre"><span>https://aws.amazon.com/blogs/aws/new-for-amazon-guardduty-malware-detection-for-amazon-ebs-volumes/</span></a></li>
<li class="calibre13"><em class="italic">Bitdefender and Amazon Web Services Strengthen Cloud </em><span><em class="italic">Security</em></span><span>: </span><a href="https://businessinsights.bitdefender.com/bitdefender-and-amazon-web-services-strengthen-cloud-security" class="pcalibre1 pcalibre2 pcalibre"><span>https://businessinsights.bitdefender.com/bitdefender-and-amazon-web-services-strengthen-cloud-security</span></a></li>
<li class="calibre13">Introduction to GuardDuty malware <span>protection: </span><a href="https://www.cloudhesive.com/blog-posts/new-guardduty-malware-protection/" class="pcalibre1 pcalibre2 pcalibre"><span>https://www.cloudhesive.com/blog-posts/new-guardduty-malware-protection/</span></a></li>
<li class="calibre13"><em class="italic">Prisma Cloud Supports Amazon GuardDuty Malware </em><span><em class="italic">Protection</em></span><span>: </span><a href="https://www.paloaltonetworks.com/blog/prisma-cloud/amazon-guardduty-malware-protection/" class="pcalibre1 pcalibre2 pcalibre"><span>https://www.paloaltonetworks.com/blog/prisma-cloud/amazon-guardduty-malware-protection/</span></a></li>
<li class="calibre13"><em class="italic">Hunting malware with Amazon GuardDuty and </em><span><em class="italic">Sysdig</em></span><span>: </span><a href="https://sysdig.com/blog/hunting-malware-with-amazon-guardduty-and-sysdig/" class="pcalibre1 pcalibre2 pcalibre"><span>https://sysdig.com/blog/hunting-malware-with-amazon-guardduty-and-sysdig/</span></a></li>
<li class="calibre13"><em class="italic">Trellix leverages Amazon GuardDuty Malware Protection for Extended Detection and Response (</em><span><em class="italic">XDR)</em></span><span>: </span><a href="https://www.trellix.com/en-us/about/newsroom/stories/xdr/trellix-leverages-amazon-guardduty-malware-protection.xhtml" class="pcalibre1 pcalibre2 pcalibre"><span>https://www.trellix.com/en-us/about/newsroom/stories/xdr/trellix-leverages-amazon-guardduty-malware-protection.xhtml</span></a></li>
<li class="calibre13"><em class="italic">Unauthorized IAM Credential Use Simulation and </em><span><em class="italic">Detection</em></span><span>: </span><a href="https://catalog.workshops.aws/aws-cirt-unauthorized-iam-credential-use/en-US" class="pcalibre1 pcalibre2 pcalibre"><span>https://catalog.workshops.aws/aws-cirt-unauthorized-iam-credential-use/en-US</span></a></li>
<li class="calibre13"><em class="italic">Ransomware on S3 - Simulation and </em><span><em class="italic">Detection</em></span><span>: </span><a href="https://catalog.workshops.aws/aws-cirt-ransomware-simulation-and-detection/en-US" class="pcalibre1 pcalibre2 pcalibre"><span>https://catalog.workshops.aws/aws-cirt-ransomware-simulation-and-detection/en-US</span></a></li>
<li class="calibre13"><em class="italic">Cryptominer Based Security Events - Simulation and </em><span><em class="italic">Detection</em></span><span>: </span><a href="https://catalog.workshops.aws/aws-cirt-cryptominer-simulation-and-detection/en-US" class="pcalibre1 pcalibre2 pcalibre"><span>https://catalog.workshops.aws/aws-cirt-cryptominer-simulation-and-detection/en-US</span></a></li>
<li class="calibre13"><em class="italic">SSRF on IMDSv1 - Simulation and </em><span><em class="italic">Detection</em></span><span>: </span><a href="https://catalog.workshops.aws/aws-cirt-ssrf-imdsv1-simulation-and-detection/en-US" class="pcalibre1 pcalibre2 pcalibre"><span>https://catalog.workshops.aws/aws-cirt-ssrf-imdsv1-simulation-and-detection/en-US</span></a></li>
<li class="calibre13"><em class="italic">AWS CIRT Toolkit for Incident Response </em><span><em class="italic">Preparedness</em></span><span>: </span><a href="https://catalog.workshops.aws/aws-cirt-toolkit-for-incident-response-preparedness/en-US" class="pcalibre1 pcalibre2 pcalibre"><span>https://catalog.workshops.aws/aws-cirt-toolkit-for-incident-response-preparedness/en-US</span></a></li>
<li class="calibre13"><em class="italic">Logging IP traffic using VPC Flow </em><span><em class="italic">Logs</em></span><span>: </span><a href="https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.xhtml" class="pcalibre1 pcalibre2 pcalibre"><span>https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs.xhtml</span></a></li>
<li class="calibre13"><em class="italic">What is VPC Flow Logs, and how can you publish flow logs to CloudWatch and </em><span><em class="italic">S3?</em></span><span>: </span><a href="https://www.manageengine.com/log-management/amazon-vpc-publishing-flow-logs-to-cloudwatch-and-s3.xhtml" class="pcalibre1 pcalibre2 pcalibre"><span>https://www.manageengine.com/log-management/amazon-vpc-publishing-flow-logs-to-cloudwatch-and-s3.xhtml</span></a></li>
<li class="calibre13"><em class="italic">Publish flow logs to CloudWatch </em><span><em class="italic">Logs</em></span><span>: </span><a href="https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs-cwl.xhtml" class="pcalibre1 pcalibre2 pcalibre"><span>https://docs.aws.amazon.com/vpc/latest/userguide/flow-logs-cwl.xhtml</span></a></li>
<li class="calibre13"><em class="italic">Least-privilege Cloudwatch Logs policy for API </em><span><em class="italic">Gateway</em></span><span>: </span><a href="https://repost.aws/questions/QUUWdk2GyPRKeTadZ9EpO3aQ/least-privilege-cloudwatch-logs-policy-for-api-gateway" class="pcalibre1 pcalibre2 pcalibre"><span>https://repost.aws/questions/QUUWdk2GyPRKeTadZ9EpO3aQ/least-privilege-cloudwatch-logs-policy-for-api-gateway</span></a></li>
<li class="calibre13"><em class="italic">AWS Security Incident Response </em><span><em class="italic">Guide</em></span><span>: </span><a href="https://docs.aws.amazon.com/whitepapers/latest/aws-security-incident-response-guide/aws-security-incident-response-guide.xhtml" class="pcalibre1 pcalibre2 pcalibre"><span>https://docs.aws.amazon.com/whitepapers/latest/aws-security-incident-response-guide/aws-security-incident-response-guide.xhtml</span></a></li>
<li class="calibre13"><em class="italic">Threat Hunting AWS CloudTrail with Sentinel: Part </em><span><em class="italic">1</em></span><span>: </span><a href="https://www.binarydefense.com/resources/blog/threat-hunting-aws-cloudtrail-with-sentinel-part-1/" class="pcalibre1 pcalibre2 pcalibre"><span>https://www.binarydefense.com/resources/blog/threat-hunting-aws-cloudtrail-with-sentinel-part-1/</span></a></li>
<li class="calibre13"><em class="italic">Threat Hunting AWS CloudTrail with Sentinel: Part </em><span><em class="italic">2</em></span><span>: </span><a href="https://www.binarydefense.com/resources/blog/threat-hunting-aws-cloudtrail-with-sentinel-part-2/" class="pcalibre1 pcalibre2 pcalibre"><span>https://www.binarydefense.com/resources/blog/threat-hunting-aws-cloudtrail-with-sentinel-part-2/</span></a></li>
<li class="calibre13">AWS security <span>products: </span><a href="https://aws.amazon.com/products/security/" class="pcalibre1 pcalibre2 pcalibre"><span>https://aws.amazon.com/products/security/</span></a></li>
</ul></div>
</div>
</body></html>