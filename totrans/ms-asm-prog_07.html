<html><head></head><body>
        

                            
                    <h1 class="header-title">Data Structures</h1>
                
            
            
                
<p>As it has been stated more than once in this book, Assembly is about moving and performing certain basic operations on data, and Assembly programming is about knowing what to move where and which operations to apply to it on the way. Until now, we have primarily dedicated all our attention to operations that we are able to perform on different types of data, and it is now time to talk about the data itself.</p>
<p>The least data item that is accessible on Intel architecture-based processors is bit, and the least addressable item is byte (which is 8 bits on Intel architecture). We already know how to work with such data and even words, double words, and single-precision floating-point values. Data, however, may be much more complex than that, and I do not mean quad words and/or double-precision floating points.</p>
<p>In this chapter, we will see how to declare, define, and manipulate simple and complex data structures and how this may make our lives as Assembly developers much easier. Starting with simple data structures, such as arrays, we will proceed to more complex ones containing different types of data and go through linked lists and trees toward more complex and powerful methods of data arrangement. The intention here, given that you as a developer are familiar with different data structures, is to show how easy it may be to work with them in Assembly, especially using FASM with its powerful features as an assembler.</p>
<p>The following are the data structures (data arrangement schemes) covered in this chapter:</p>
<ul>
<li>Arrays</li>
<li>Structures</li>
<li>Arrays of structures</li>
<li>Linked lists and special cases thereof</li>
<li>Binary Search Trees and balancing thereof</li>
<li>Sparse matrices</li>
<li>Graphs</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Arrays</h1>
                
            
            
                
<p>By now, we have come a long way, dealing primarily with basic data types ranging from bytes to quad words, preparing ourselves for more complex data-related concepts. Let's continue by looking into arrays, which may be characterized as the sequential storage of data of the same type. Theoretically, there is no limitation to the size of array members, but practically we are limited to, for example, the size of a register. However, workarounds exist and we will see that later in this chapter.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Simple byte arrays</h1>
                
            
            
                
<p>A good example of a widely used, yet simple, array would be a forward substitution table and/or a reverse substitution table used with the AES algorithm:</p>
<pre>aes_sbox:<br/>db 0x63, 0x7c, 0x77, 0x7b, 0xf2, 0x6b, 0x6f, 0xc5<br/>db 0x30, 0x01, 0x67, 0x2b, 0xfe, 0xd7, 0xab, 0x76<br/>db 0xca, 0x82, 0xc9, 0x7d, 0xfa, 0x59, 0x47, 0xf0<br/>db 0xad, 0xd4, 0xa2, 0xaf, 0x9c, 0xa4, 0x72, 0xc0<br/>db 0xb7, 0xfd, 0x93, 0x26, 0x36, 0x3f, 0xf7, 0xcc<br/>db 0x34, 0xa5, 0xe5, 0xf1, 0x71, 0xd8, 0x31, 0x15<br/>db 0x04, 0xc7, 0x23, 0xc3, 0x18, 0x96, 0x05, 0x9a<br/>db 0x07, 0x12, 0x80, 0xe2, 0xeb, 0x27, 0xb2, 0x75<br/>db 0x09, 0x83, 0x2c, 0x1a, 0x1b, 0x6e, 0x5a, 0xa0<br/>db 0x52, 0x3b, 0xd6, 0xb3, 0x29, 0xe3, 0x2f, 0x84<br/>db 0x53, 0xd1, 0x00, 0xed, 0x20, 0xfc, 0xb1, 0x5b<br/>db 0x6a, 0xcb, 0xbe, 0x39, 0x4a, 0x4c, 0x58, 0xcf<br/>db 0xd0, 0xef, 0xaa, 0xfb, 0x43, 0x4d, 0x33, 0x85<br/>db 0x45, 0xf9, 0x02, 0x7f, 0x50, 0x3c, 0x9f, 0xa8<br/>db 0x51, 0xa3, 0x40, 0x8f, 0x92, 0x9d, 0x38, 0xf5<br/>db 0xbc, 0xb6, 0xda, 0x21, 0x10, 0xff, 0xf3, 0xd2<br/>db 0xcd, 0x0c, 0x13, 0xec, 0x5f, 0x97, 0x44, 0x17<br/>db 0xc4, 0xa7, 0x7e, 0x3d, 0x64, 0x5d, 0x19, 0x73<br/>db 0x60, 0x81, 0x4f, 0xdc, 0x22, 0x2a, 0x90, 0x88<br/>db 0x46, 0xee, 0xb8, 0x14, 0xde, 0x5e, 0x0b, 0xdb<br/>db 0xe0, 0x32, 0x3a, 0x0a, 0x49, 0x06, 0x24, 0x5c<br/>db 0xc2, 0xd3, 0xac, 0x62, 0x91, 0x95, 0xe4, 0x79<br/>db 0xe7, 0xc8, 0x37, 0x6d, 0x8d, 0xd5, 0x4e, 0xa9<br/>db 0x6c, 0x56, 0xf4, 0xea, 0x65, 0x7a, 0xae, 0x08<br/>db 0xba, 0x78, 0x25, 0x2e, 0x1c, 0xa6, 0xb4, 0xc6<br/>db 0xe8, 0xdd, 0x74, 0x1f, 0x4b, 0xbd, 0x8b, 0x8a<br/>db 0x70, 0x3e, 0xb5, 0x66, 0x48, 0x03, 0xf6, 0x0e<br/>db 0x61, 0x35, 0x57, 0xb9, 0x86, 0xc1, 0x1d, 0x9e<br/>db 0xe1, 0xf8, 0x98, 0x11, 0x69, 0xd9, 0x8e, 0x94<br/>db 0x9b, 0x1e, 0x87, 0xe9, 0xce, 0x55, 0x28, 0xdf<br/>db 0x8c, 0xa1, 0x89, 0x0d, 0xbf, 0xe6, 0x42, 0x68<br/>db 0x41, 0x99, 0x2d, 0x0f, 0xb0, 0x54, 0xbb, 0x16</pre>
<p>As we may clearly see, all values have a size of 1 byte and are stored sequentially one after the other. Accessing such arrays is very simple and may even be performed with the XLAT instruction. For example, imagine that we are in the middle of an AES-128 calculation and we have a value in which we need to substitute each byte with a byte from the preceding table. Let the following be the value:</p>
<pre>needs_substitution db 0, 1,  2,  3,  4,  5,  6,  7\<br/>                      8, 9, 10, 11, 12, 13, 14, 15</pre>
<p>The following code would do the substitution:</p>
<pre>   lea  ebx, [aes_sbox]<br/>   lea  esi, [needs_substitution] <em>; Set the source pointer (ESI) and</em><br/>   mov  edi, esi                  <em>; destination pointer (EDI) as we </em><br/><em>                                  ; will be storing substituted</em> <br/>                                  ; byte back<br/>   mov  ecx, 0x10                 <em>; Set the counter</em><br/>@@:<br/>   lodsb                          <em>; Load byte from the value</em><br/>   xlatb                          <em>; Substitute byte from the s-box</em>  <br/>   stosb                          <em>; Store new byte to the value</em><br/>   loop @b                        <em>; Loop while ECX != 1</em></pre>
<p>The first thing we do is load the base address of the table (of the s-box) into the EBX register, as the XLAT instruction uses exactly this register for addressing the substitution/lookup table. Then, we load the address of the array of values requiring<br/>
substitution into the ESI register in order to not bother with index computations, as the ESI register is automatically incremented by the <kbd>lodsb</kbd> instruction. Duplicate the address into the EDI register, as we will be storing data back.</p>
<p>You may as well process the 16 byte value from the last byte to the first by loading ESI and EDI with <kbd>lea esi, [needs_substitution + 0x0f]</kbd>, duplicating the address to EDI and setting the direction flag with the <kbd>std</kbd> instruction. Do not forget to clear the direction flag with the <kbd>cld</kbd> instruction when done.</p>
<p>We then sequentially read each byte of the value, substitute it with a byte form the s-box with the XLAT instruction, and store the result back. As an alternative to the XLAT instruction (which is limited to 256 byte tables and may only operate on byte values depending on the AL register), we can write the following:</p>
<pre>mov al, [aes_sbox + eax] <em>; aes_sbox is the base and EAX is the index</em></pre>
<p>However, we would have needed to set the whole EAX register to 0 prior to entering the loop, while XLAT allows the upper 24 bits of the EAX register to remain unchanged throughout the whole operation.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Arrays of words, double words, and quad words</h1>
                
            
            
                
<p>The previous simple example illustrates a trivial byte array and how we can access its members. The same would apply to arrays of words, double words, or quad words with a few additions:</p>
<ul>
<li>We cannot use XLAT on arrays bigger than 256 bytes, nor if members of an array are bigger than 8 bits</li>
<li>We would need to use SIB addressing (scale index base) in order to access array members bigger than one byte</li>
<li>On 32-bit systems we would not be able to read a quad word into a single register</li>
</ul>
<p>For the sake of a simple example, let's consider using a lookup table for the calculation of the factorial for numbers in the range of 0 to 12 (this code is for 32-bit and factorials of larger numbers would not fit into a double word). Although the algorithm of factorial calculation is rather simple, using a lookup table even for such a short range is much more convenient.</p>
<p>First, put the following into the data section (you may put this into the code section too, as we are not going to change any value here, but let's keep data with the data):</p>
<pre>ftable  dd  1,\           <em>; 0!</em><br/>            1,\           <em>; 1!</em><br/>            2,\           <em>; 2!</em><br/>            6,\           <em>; 3!</em><br/>            24,\          <em>; 4!</em><br/>            120,\         <em>; 5!</em><br/>            720,\         <em>; 6!</em><br/>            5040,\        <em>; 7!</em><br/>            40320,\       <em>; 8!</em><br/>            362880,\      <em>; 9!</em><br/>            3628800,\     <em>; 10!</em><br/>            39916800,\    <em>; 11!</em><br/>            479001600     <em>; 12!</em></pre>
<p>This is our lookup table containing 13 values of factorials for numbers in the range of 0 to 12, where each entry is double word (32 bit). Now, let's write a procedure that would use this table. The procedure will be implemented in accordance with the <kbd>stdcall</kbd> calling convention; it receives a single parameter, the number for which we need a factorial, and returns a factorial for the given number or 0 if the number is not in the allowed range (as 0 cannot be a value of factorial). Put the following code into the code section:</p>
<pre>factorial:<br/>   push  ebp<br/>   mov   ebp, esp<br/>   ;-------------<br/>   virtual at ebp + 8             <em>; Assign a readable name to</em><br/>      arg0  dd ?                  <em>; a location on stack where</em> <br/>   end virtual                    <em>; the parameter is stored</em><br/>   ;-------------<br/>   mov   eax, [arg0]              <em>; Load parameter from the stack</em><br/>   cmp   eax, 0x0c                <em>; Check whether it is in range</em><br/>   ja    .oops                    <em>; Go there if not</em><br/>   mov   eax, [ftable + eax * 4]  <em>; Retrieve factorial from  </em><br/><em>                                  ; the lookup table</em><br/> @@:<br/>   leave<br/>   ret   4<br/><br/> .oops:<br/>   xor   eax, eax                 <em>; Set return value to 0</em><br/>   jmp   @b</pre>
<p>The <kbd>virtual</kbd> directive lets us virtually define data at a specific address. In the preceding example, we defined a variable that points to the place on the stack where the parameter is stored. Everything we define within the <kbd>virtual</kbd> block is treated as a legal label by the assembler. In this case, the <kbd>arg0</kbd> translates to <kbd>ebp + 8</kbd>. If we had two or even more parameters passed to the procedure on stack, we could write the following:<br/>
<kbd>virtual at ebp + 8</kbd><br/>
<kbd>arg0 dd ?</kbd><br/>
<kbd>arg1 dd ?</kbd><br/>
<kbd>; the rest</kbd><br/>
<kbd>end virtual</kbd><br/>
Here, <kbd>arg1</kbd> would be translated to <kbd>ebp+12</kbd>, <kbd>arg2</kbd> (if defined), <kbd>ebp+16</kbd>, and so on.</p>
<p>The procedure is indeed very simple as all it does is this:</p>
<ul>
<li>Checks whether the parameter fits the range</li>
<li>Returns <kbd>0</kbd> if the parameter does not fit the range</li>
<li>Uses the parameter as an index into the lookup table and returns a value referenced by the base address of the tables plus index (our parameter) times size of entries in the table</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Structures</h1>
                
            
            
                
<p>As a developer, I believe you would agree that most of the time we are not working with arrays of uniform data (I am definitely not underestimating the power of a regular array). Since data may be anything, starting with 8-bit numbers and ending with complex structures, we need a way to describe such data for the assembler, and the term <em>structure</em> is the key. Flat Assembler, just as any other assembler, lets us declare structures and treat them as additional types of data (similar to the <kbd>typedef</kbd> struct in C).</p>
<p>Let's declare a simple structure, an entry of a string table, and then see what is what:</p>
<pre>struc strtabentry [s]<br/>{<br/>   .length dw  .pad - .string         <em>; Length of the string</em><br/>   .string db  s, 0                   <em>; Bytes of the string</em><br/>   .pad    rb  30 - (.pad - .string)  <em>; Padding to fill 30 bytes</em><br/>   .size = $ - .length                <em>; Size of the structure (valid  </em><br/><em>                                      ; in compile time only)</em><br/>}</pre>
<p>The dot (<kbd>.</kbd>) preceding the names of members of the struct denotes that they are part of a larger namespace. In this specific case, the name <kbd><em>.length</em></kbd> belongs to <kbd>strtabentry</kbd>.</p>
<p>Such a declaration would be equivalent to the following one in C:</p>
<pre>typedef struct<br/>{<br/>   short         length;<br/>   char          string[30];<br/>}strtabentry;</pre>
<p>However, while in C, we would have to initialize the variable of the type <kbd>strtabentry</kbd>, like this:</p>
<pre><em>/* GCC (C99) */</em><br/>strtabentry my_strtab_entry = {.length = sizeof("Hello!"), .string = {"Hello!"} };  <br/><br/><em>/* MSVC */</em><br/>strtabentry my_strtab_entry = {sizeof("Hello!"), {"Hello!"} };              </pre>
<p>In Assembly, or to be more precise, when using Flat Assembler, we would initialize such a variable in a simpler way:</p>
<pre>my_strtab_entry strtabentry "Hello!"</pre>
<p>Either way, the structure is 32-bytes in size (as the string buffer is statically allocated and is 30 bytes) and has only two members:</p>
<ul>
<li><kbd>length</kbd>: This is the word size integer containing the length of the string, plus 1 for a null terminator</li>
<li><kbd>string</kbd>: This is the actual text</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Addressing structure members</h1>
                
            
            
                
<p>A few words need to be said on how individual members of a structure may be addressed. When statically allocated, we may refer to a structure by its label/name, which is translated into its address. For example, if we have a <kbd>strtabentry</kbd> structure named <kbd>se</kbd> defined in our data section, and we need to read the <em>n</em>th byte from the string, all we have to do would be this:</p>
<pre>mov  al, [se.string + n]   <em>; 0 &lt;= n &lt; 30</em></pre>
<p>If, on the other hand, we cannot use a label (for example, we are in a procedure, and a pointer to a structure is its parameter), then we can use the mighty <kbd>virtual</kbd> directive. As a quick demonstration, here's a procedure that returns the length of the string, not including the terminating zero:</p>
<pre>get_string_length:<br/>   push  ebp<br/>   mov   ebp, esp<br/>   push  ebx<br/>   <em>;=========</em><br/>   virtual at ebp + 8      <em>; Give a name to the parameter on stack</em><br/>      .structPtr dd 0      <em>; The parameter itself is not modified</em><br/>   end virtual<br/>   <em>;---------</em><br/>   virtual at ebx          <em>; Give local name to the structure</em><br/>      .s strtabentry 0     <em>; The structure is not really defined</em><br/>   end virtual             <em>; so the string is not modified</em><br/>   <em>;=========</em><br/>   mov   ebx, [.structPtr] <em>; Load structure pointer to EBX</em><br/>   mov   ax, [.s.length]   <em>; Load AX with the length</em><br/>   movzx eax, ax          <em> ; Upper 16 bits may still contain garbage</em><br/><em>                           ; so we need to clean it</em><br/><em>   dec   eax               ; Exclude null terminator</em><br/>   pop   ebx<br/>   leave<br/>   ret   4</pre>
<p>Just to keep things fresh in memory, let's take another look at the lines where we read the pointer from the stack and where we load AX with the length of the string. The first one is as follows:</p>
<pre>mov   ebx, [.structPtr]</pre>
<p>The preceding code loads the parameter from the stack. As we remember, declaring a virtual label lets us assign a readable name to the memory locations that cannot be named otherwise, and the stack is one of the examples. In this specific case, <kbd>.structPtr</kbd> is translated into <kbd>ebp + 8</kbd>, thus the line itself is equivalent to the following:</p>
<pre>mov   ebx,[ebp + 8]</pre>
<p>Similarly, had there be a second parameter, the virtual declaration would look like this:</p>
<pre>virtual at ebp + 8<br/>   .structPtr   dd 0<br/>   .secondParam dd 0<br/>end virtual</pre>
<p>In that case, reading the second parameter would be done like this:</p>
<pre>mov   ecx, [.secondParam]</pre>
<p>Also, it would translate into the following:</p>
<pre>mov   ecx, [ebp + 12]  <em>; Which is ebp + 8 + sizeof(.structPtr)</em></pre>
<p>Here is the second line we are interested in:</p>
<pre>mov   ax, [.s.length]</pre>
<p>In this specific case, we are accessing the first member of the structure - <kbd>.length</kbd>, which means that the line is translated into this:</p>
<pre>mov   ax, [ebx]</pre>
<p>However, should we need to access the string itself, for example, if we need to load a register with the address of the string, the code would look like this:</p>
<pre>lea   eax, [.s.string]</pre>
<p>This would, in turn, translate into the following:</p>
<pre>lea   eax, [ebx + 2]</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Arrays of structures</h1>
                
            
            
                
<p>By now, we are fine with everything regarding access to structures and members thereof, but what if we have more than one structure of the same type? We would naturally organize them into an array of structures. Looks simple, and partially so, it is.</p>
<p>In order to ease the process of accessing array members, we may use an array of pointers and access each structure in the array through a kind of lookup table. In this scenario, we would simply read a pointer from the lookup table with the following:</p>
<pre>mov  ebx, [lookup_table + ecx * 4] <em>; ECX contains the index into array </em><br/><em>                                   ; of pointers and 4 is the scale (size </em><br/><em>                                   ; of pointer on 32-bit systems)</em></pre>
<p>Having a pointer to the structure of interest, we continue the work as usual.</p>
<p>Our example structure is very convenient due to its size, which is only 32 bytes. Should we arrange many structures of this type into an array, we would be able to painlessly access them in an array of 134,217,727 members (on a 32-bit system), which is 4 GB in terms of occupied memory. While we would hardly need this number of strings with a maximum length of 30 bytes (or such a number of strings at all), the addressing in this specific case is very simple (again, due to the comfortable size of the structure). We still use the index in the array of structures, but, as we cannot use the scale part of SIB addressing to scale the index by 32 bytes, we need to multiply the index itself prior to accessing the array.</p>
<p>Let's define a macro instruction that would create such an array in the first place (building the pointer lookup table for demonstration purposes too):</p>
<pre>macro make_strtab strtabName, [strings]<br/>{<br/>   common<br/>   label strtabName#_ptr dword    <em>; The # operator concatenates strings</em><br/>   local c                        <em>; resulting in strtabName_ptr</em><br/>   c = 0<br/><br/>   forward<br/>   c = c + 1                      <em>; Count number of structures</em><br/><br/>   common<br/>   dd c                           <em>; Prepend the array of pointers with </em><br/><em>                                  ; number of entries</em><br/><br/>   forward                        <em>; Build the pointer table</em><br/>   local a<br/>   dd a<br/><br/>   common                         <em>; Build the array of structures</em><br/>   label strtabName dword<br/><br/>   forward<br/>   a strtabentry strings<br/>}</pre>
<p>The invocation of the preceding macro, with the following parameters, is as follows:</p>
<pre>make_strtab strtabName,\          <em>; Spaces are intentionally appended to</em><br/>            "string 0",\          <em>; strings in order to provide us with</em> <br/>            "string 1 ",\         <em>; different lengths.</em><br/>            "string 2  ",\<br/>            "string 3   "</pre>
<p>This would result in the following arrangement of data in memory:</p>
<div><img class="image-border" height="276" src="img/2f21d06a-2d07-4cd2-9739-100c84f67fae.png" width="732"/></div>
<p>As you can see, the <kbd>strtabName_ptr</kbd> variable contains the number of structures/pointers in the array followed by the array of four pointers. Next, at <kbd>strtabName</kbd>, (we can choose whatever name we want when invoking the macro as long as it fits the naming restrictions), we have the actual array of four structures.</p>
<p>Now, should we need to retrieve the length of a string in the structure at index 2 (indices are zero based), we would modify the <kbd>get_string_length</kbd> procedure so that it would accept two parameters (pointer to structure array and index) in the following way:</p>
<pre>get_string_length:<br/>   push   ebp,<br/>   mov    ebp, esp<br/>   push   ebx ecx<br/><br/>   virtual at ebp + 8<br/>      .structPtr   dd ?      <em>; Assign label to first parameter</em><br/>      .structIdx   dd ?      <em>; Assign label to second parameter</em><br/>   end virtual <br/><br/>   virtual at ebx + ecx<br/>      .s strtabentry ?       <em>; Assign label to structure pointer</em><br/>   end virtual<br/><br/>   mov   ebx, [.structPtr]   <em>; Load pointer to array of structures</em><br/>   mov   ecx, [.structIdx]   <em>; Load index of the structure of interest</em><br/>   shl   ecx, 5              <em>; Multiply index by 32</em><br/>   mov   ax, [.s.length]     <em>; Read the length</em><br/>   movzx eax, ax<br/>   dec   eax<br/>   pop   ecx ebx<br/>   leave<br/>   ret   8</pre>
<p>The procedure call would be as follows:</p>
<pre>push  2                 <em>; push index on stack</em><br/>push  strtabName        <em>; push the address of the array</em><br/>call  get_string_length</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Arrays of pointers to structures</h1>
                
            
            
                
<p>The previous subsection shows us how to approach arrays of uniform structures. As there is no particular reason to have string buffers of fixed size and, therefore, no reason for a fixed size structure, let's first of all make a tiny correction to the structure declaration:</p>
<pre>struc strtabentry [s]<br/>{<br/>   .length dw  .pad - .string         <em>; Length of the string</em><br/>   .string db  s, 0                   <em>; Bytes of the string</em><br/>   .size = $ - .length                <em>; Size of the structure (valid  </em><br/><em>                                      ; in compile time only)</em><br/>}</pre>
<p>We only removed the <kbd>.pad</kbd> member of the <kbd>strtabentry</kbd> structure, thus allowing it to be of variable size. Obviously, we may no longer use the same <kbd>get_string_length</kbd> procedure as we have no constant step to iterate through the array. But you might have definitely noticed the <kbd>strtabName_ptr</kbd> structure in the preceding image. This structure is there to help us solve the problem of lack of a fixed step. Let's rewrite the <kbd>get_string_length</kbd> procedure so that it would accept a pointer to an array of pointers to structures, rather than a pointer to the array itself and an index of the desired structure. The procedure would then look like this:</p>
<pre>get_string_length:<br/>   push   ebp,<br/>   mov    ebp, esp<br/>   push   ebx ecx<br/><br/>   virtual at ebp + 8<br/>      .structPPtr   dd ?     <em>; Assign label to first parameter</em><br/>      .structIdx   dd ?      <em>; Assign label to second parameter</em><br/>   end virtual <br/><br/>   virtual at ebx<br/>      .s strtabentry ?       <em>; Assign label to structure pointer</em><br/>   end virtual<br/><br/>   mov   ebx, [.structPPtr]  <em>; Load pointer to array of structures</em><br/>   mov   ecx, [.structIdx]   <em>; Load index of the structure of interest</em><br/>   shl   ecx, 2              <em>; Multiply index by 4 (size of pointer<br/></em>                             <em>; on a 32-bit platform<br/></em>   cmp   ecx, [.structPPtr]  <em>; Check the index to fit the size of the <br/></em>                             <em>; array of pointers<br/></em>   jae   .idx_too_big        <em>; Return error if </em>index exceeds the bounds<br/>   mov   ebx, [ebx + ecx + 4]<em>; We have to add 4 (the size of int), in <br/></em>                             <em>; order to skip the number of structure<br/></em>                             <em>; pointers in the array</em><br/>   mov   ax, [.s.length]     <em>; Read the length</em><br/>   movzx eax, ax<br/><br/>.return:<br/>   dec   eax<br/>   pop   ecx ebx<br/>   leave<br/>   ret   8<br/><br/>.idx_too_big:<br/>   xor   eax, eax             <em>; The value of EAX would be -1 upon return</em><br/>   jmp   .return</pre>
<p>Voila! We only had to make a few tiny modifications, add a line here and a line there, and now we are able to handle structures of variable sizes.</p>
<p>Nothing complicated thus far, nothing complicated to follow. While there are not too many types of data, there are more ways to arrange it. While the structure may be considered both a data type and a method of arrangement for non-uniform data, we will, for convenience, treat it as a type that we are free to define. By now, we have seen how data may be arranged in static memory when the arrangement thereof is not expected to change, but what if we are dealing with dynamic data when the amount of data is not known at the time of writing the code? In such case we should know how to deal with dynamic data. This leads us to the next stage in data arrangement-linked lists and their types.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Linked lists</h1>
                
            
            
                
<p>Linked lists, as the name suggests, consists, of data items (nodes) that are linked to one another by means of pointers. Basically, there are two types of linked lists:</p>
<ul>
<li><strong>Linked list</strong>: This is where each node has a pointer to the following node</li>
<li><strong>Doubly linked list</strong>: This is where each node has a pointer to the following and previous nodes</li>
</ul>
<p>The following diagram illustrates the difference:</p>
<div><img class="image-border" height="337" src="img/e9b56891-f667-4363-bfa9-0e555b403f5b.png" width="226"/></div>
<p>Linked lists of both types may be addressed in a few ways. Obviously, there is at least a pointer to the first node of the list (called <kbd>top</kbd>), which is optionally accompanied by a pointer to the last node of the list (called <kbd>tail</kbd>). There is, of course, no limit to the amount of auxiliary pointers, should there be a need for such. Pointer fields in the nodes are typically referred to as <kbd>next</kbd> and <kbd>previous</kbd>. As we can see in the diagram, the last node of a linked list and the first and the last nodes of a doubly linked list have <kbd>next</kbd>, <kbd>previous</kbd>, and <kbd>next</kbd> fields that point nowhere-such pointers are considered terminators denoting the end of the list and are typically populated with null values.</p>
<p>Before proceeding to the sample code, let's make a tiny change to the structure we've been using in this chapter and add the <kbd>next</kbd> and <kbd>previous</kbd> pointers. The structure should look like this:</p>
<pre>struc strtabentry [s]<br/>{<br/>   .length   dw   .pad - .string<br/>   .string   db   s, 0<br/>   .pad      rb   30 - (.pad - .string)<br/>   .previous dd   ?         <em>; Pointer to the next node</em><br/>   .next     dd   ?         <em>; Pointer to the previous node</em><br/>   .size = $ - .length<br/>}</pre>
<p>We will leave the <kbd>make_strtab</kbd> macro intact as we still need something to build a set of <kbd>strtabentry</kbd> structures; however, we will not consider it to be an array of structures any more. Also, we will add a variable (of type double word) to store the <kbd>top</kbd> pointer. Let's name it <kbd>list_top</kbd>.</p>
<p>Instead or writing a macro instruction that would link the four structures into a doubly linked list, we will write a procedure for adding new nodes to the list. The procedure requires two parameters--a pointer to the <kbd>list_top</kbd> variable and a pointer to the structure we want to add to the list. If we were writing in C, then the prototype of the corresponding function would be as follows:</p>
<pre>void add_node(strtabentry** top, strtabentry* node);</pre>
<p>However, since we are not writing in C, we will put down the following code:</p>
<pre>add_node:<br/>   push   ebp<br/>   mov    ebp, esp<br/>   push   eax ebx ecx<br/><br/>   virtual at ebp + 8<br/>      .topPtr  dd ?<br/>      .nodePtr dd ?<br/>   end virtual<br/>   virtual at ebx<br/>      .scx strtabentry ?<br/>   end virtual<br/>   virtual at ecx<br/>      .sbx strtabentry ?<br/>   end virtual<br/><br/>   mov    eax, [.topPtr]       <em>; Load pointer to list_top</em><br/>   mov    ebx, [.nodePtr]      <em>; Load pointer to new structure</em><br/>   or     dword [eax], 0       <em>; Check whether list_top == NULL</em><br/>   jz     @f                   <em>; Simply store the structure pointer</em><br/><em>                               ; to list_top if true</em><br/><br/>   mov    ecx, [eax]           <em>; Load ECX with pointer to current top</em><br/>   mov    [.scx.next], ecx      <em>; node-&gt;next = top</em><br/>   mov    [.sbx.previous], ebx  <em>; top-&gt;previous = node</em><br/><br/> @@:<br/>   mov    [eax], ebx           <em>; top = node</em><br/>   pop    ecx ebx eax<br/>   leave<br/>   ret    8</pre>
<p>Now, having the procedure ready, we will call it from our main procedure:</p>
<pre>_start:<br/>   push strtabName + 40    <em>; Let the second structure be the first</em><br/>   push list_top           <em>; in the list</em><br/>   call add_node<br/><br/>   push strtabName + 120   <em>; Then we add fourth structure</em><br/>   push list_top<br/>   call add_node<br/><br/>   push strtabName + 80    <em>; Then third</em><br/>   push list_top<br/>   call add_node<br/><br/>   push strtabName         <em>; And first</em><br/>   push list_top<br/>   call add_node</pre>
<p>The first, second, third, and fourth refers to positions of structures in memory, not to positions of nodes in the doubly linked list. Thus, after the last line of the preceding code is executed, we have a doubly linked list of <kbd>strtabentry</kbd> structures (shown by their position in the linked list) <kbd>{0, 2, 3, 1}</kbd>. Let's take a look at the following screenshot for a demonstration of the result:</p>
<div><img class="image-border" height="356" src="img/9782b7f6-79df-419a-8f6f-20d3ef962d33.png" width="556"/></div>
<p>For the sake of convenience, the structures are named <kbd>struct_0</kbd>, <kbd>struct_1</kbd>, <kbd>struct_2</kbd>, and <kbd>struct_3</kbd> in accordance with the order of their appearance in memory. The last line is the <kbd>top</kbd> pointer <kbd>list_top</kbd>. As we can see, it points to <kbd>struct_0</kbd>, which was the last we added to the list, and <kbd>struct_0</kbd>, in turn, only has a pointer to the next structure, while its <kbd>previous</kbd> pointer has a <kbd>NULL</kbd> value. The <kbd>struct_0</kbd> structure's <kbd>next</kbd> pointer points to <kbd>struct_2</kbd>, <kbd>struct_2</kbd> structure's <kbd>next</kbd> points to <kbd>struct_3</kbd>, and the previous pointers lead us back in the reverse order.</p>
<p>Obviously, linked lists (those with a single, either forward or backward), link are a bit simpler than doubly linked lists as we only have to take care of a single pointer member of a node. It may be a good idea to implement a separate structure that describes a linked list node (whether simple or doubly linked) and have a set of procedures for the creation/population of linked lists, search of a node, and removal of a node. The following structure would suffice:</p>
<pre><em>; Structure for a simple linked list node</em><br/>struc list_node32<br/>{<br/>   .next     dd ?    <em>; Pointer to the next node</em><br/>   .data     dd ?    <em>; Pointer to data object, which</em><br/><em>                     ; may be anything. In case data fits</em><br/><em>                     ; in 32 bits, the .data member itself</em><br/><em>                     ; may be used for storing the data.</em><br/>}<br/><br/><em>; Structure for a doubly linked list node</em><br/>struc dllist_node32<br/>{<br/>   .next     dd ?<br/>   .previous dd ?    <em>; Pointer to the previous node</em><br/>   .data     dd ?<br/>}</pre>
<p>If, on the other hand, you are writing code for the long mode (64-bit), the only change you need to make is replacing <kbd>dd</kbd> (which stands for a 32-bit double word) with <kbd>dq</kbd> (which stands for a 64-bit quad word) in order to be able to store long mode pointers.</p>
<p>In addition to this, you may also want or need to implement a structure that will describe a linked list, as a whole, having all the required pointers, counters, and so on (in our example, it was the <kbd>list_top</kbd> variable; not quite a structure, but it did its job well enough). However, when it comes to an array of linked lists, it would be much more convenient to utilize an array of pointers to linked lists, as this would provide easier access to members of the array, thus making your code less error prone, simpler, and faster.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Special cases of linked lists</h1>
                
            
            
                
<p>You have, most likely, heard a lot about different types of data structures other than arrays and linked lists in programming lessons, unless you are a self-taught developer, in which case you may still have heard or read about these a lot. By different types of data structures other than arrays and linked lists, I mean stacks, queues, deques, and priority queues. However, being a fan of the principle of Occam's Razor, I believe that we should face the truth and acknowledge that all of these are just special cases of linked lists, unless their implementation is based on arrays (which may sometimes be possible).</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Stack</h1>
                
            
            
                
<p>A stack is a <strong>LIFO</strong> (<strong>Last In First Out</strong>) arrangement of data. The simplest example would be the process/thread stack. Although such an implementation is rather array based, it fairly illustrates the mechanism.</p>
<p>However, most of the time, we would not know the size of the required stack in advance, maybe just a rough estimation. Not to mention the fact that we would hardly need to store only double or quad words; we'll mostly have more complex structures. The most common implementation of a stack would be a singly linked list addressed by a <kbd>top</kbd> pointer only. Ideally, only three operations are permitted on a stack:</p>
<ul>
<li><kbd>push</kbd>: This is used to add a new member to the list</li>
<li><kbd>top</kbd>: This is used to view/read the last added member of the list</li>
<li><kbd>pop</kbd>: This is used to remove the last added member from the list</li>
</ul>
<p>While the <kbd>push</kbd> and <kbd>pop</kbd> operations are equivalent to adding and removing a member from/to a singly linked list, the TOP operation basically means getting the value of the <kbd>top</kbd> pointer and so obtaining access to the topmost (added last) member of the list.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Queue and deque</h1>
                
            
            
                
<p>Queues are, exactly as the name states, queues of elements. A linked list is addressed by two pointers-one for the <kbd>top</kbd> element and one for the <kbd>tail</kbd> element. By nature, queues are a <strong>FIFO</strong> (<strong>First In First Out</strong>) arrangement of data, meaning that the element that was pushed first is to be popped first, too. It is totally up to you to decide where the queue starts and where it ends-whether <kbd>top</kbd> is the beginning or the end of a queue, and the same for <kbd>tail</kbd>. Should we want to convert the example of a linked list we used in this chapter to a queue, we would only need to add a <kbd>list_tail</kbd> pointer.</p>
<p>Deques are double-ended queues, which means that elements may be pushed into the queue either at the <kbd>top</kbd> element or at the <kbd>tail</kbd> element depending on the algorithm. The same is true for popping elements from the queue.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Priority queues</h1>
                
            
            
                
<p>A priority queue is a special case of a regular queue. The only difference is that elements added to it each have a certain priority, which is defined by the algorithm and depends on the needs. The idea is that elements with a higher priority are served first, then the elements with lower priorities. If two elements have the same priority, then the order they are served in is in accordance with their position in the queue, so there are at least two possible ways to implement such an arrangement.</p>
<p>One would be the implementation of a sorting algorithm, which would add new elements according to their priority. This merely converts deque into a sorted list.</p>
<p>The other would be combing a deque for elements with the highest priority and serving them first, which makes a deque not much different from a linked list. The only difference, probably, would be that elements may be added only to the <kbd>top</kbd> element or the <kbd>tail</kbd> element.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Cyclic linked list</h1>
                
            
            
                
<p>A cyclic linked list is probably the easiest to implement following the singly linked list. The only difference between the two is that the last element of the list points to the first element of the list, instead of its <kbd>next</kbd> pointer having a <kbd>NULL</kbd> value.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary for special cases of linked lists</h1>
                
            
            
                
<p>As we can see, the special cases of linked lists shown previously are simply different logical paradigms of the same idea. This is especially true in the case of Assembly, which, unlike higher-level languages (those higher than C), does not have any built-in implementation of the preceding approaches, thus performing the function of Occam's Razor, sweeping away redundant notions and showing how things are in low-level reality.</p>
<p>However, we'll consider what Albert Einstein said:</p>
<p>"Everything should be made as simple as possible, but not simpler."</p>
<p>Having made the topic of linked lists and their special cases as simple as possible, we need to proceed to more complex, more powerful forms of data arrangement. In the next section of this chapter, we will meet trees-a very powerful and useful method to store data.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Trees</h1>
                
            
            
                
<p>Sometimes, the data arrangement schemes we have already covered are not ideal for solving certain problems. For example, when having a set of data that is frequently being searched or modified, while having to maintain a sorted nature, we could place it into an array or a sorted linked list, but the search times could be non-satisfactory. In such a case, it would probably be best to arrange the data in the form of a tree. A binary search tree, for instance, is the best way to minimize the search time when searching dynamic (changing) data. In fact, the same applies to static data as well.</p>
<p>But, first of all, what are trees in computing? When talking about trees, one may imagine a special type of graph (graphs will be briefly covered later in this chapter), consisting of nodes which have a parent node (except the root node, which is called, well, root node) and zero or more child nodes. In Assembly, we would declare a structure for a tree node like this:</p>
<pre>struc tnode dataPtr, leftChild, rightChild<br/>{<br/>   .left  dd  leftChild   <em>; Pointer to left node or 0</em><br/>   .right dd  rightChild  <em>; Pointer to right node or 0</em><br/>   .data  dd  dataPtr     <em>; Pointer to data</em><br/>}</pre>
<p>So, we have a structure which has a pointer to the left child node (traditionally, nodes with a lower value), a pointer to the right child node (traditionally, nodes with a higher value), and a pointer to the data represented by the node. In general, it is not a bad idea to add a pointer to the parent node, which may ease the task of balancing a tree; however, we do not need that for the example that we will examine in this part of the chapter. The preceding node structure is sufficient for building a tree like this:</p>
<div><img class="image-border" height="209" src="img/bed40237-dba5-4b61-b8a1-470acbfb6cce.png" width="416"/></div>
<p>This figure demonstrates an ideal case of a balanced binary search tree. In reality, however, this happens not that often and depends on the balancing method. Unfortunately, methodologies of tree balancing slightly fall out of the scope of this book. The main idea, though, is to keep lower values to the left and higher values to the right, which may well involve a certain amount of rotation applied to subtrees, or even the whole tree.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">A practical example</h1>
                
            
            
                
<p>Enough with dry explanations. Being a developer, you are most likely familiar with tree-like structures and methods of balancing thereof, or you must have at least heard of them. Believing in learning by example as one of the most efficient ways of understanding something, I suggest we take a look at the following example.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Example - trivial cryptographic virtual machine</h1>
                
            
            
                
<p>The idea behind this example is widely used and well known-a simple, not to say primitive, virtual machine. Imagine a situation where we have to implement a virtual machine that performs trivial string encryption with an XOR operation using a single byte key.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Virtual machine architecture</h1>
                
            
            
                
<p>The architecture of the virtual processor is quite simple-it has a few registers that store the current execution state:</p>
<table>
<tbody>
<tr>
<td><strong>Register Name</strong></td>
<td><strong>Register function</strong></td>
</tr>
<tr>
<td><kbd>register_a</kbd></td>
<td>An 8-bit general purpose register. The register is accessible to the VM code.</td>
</tr>
<tr>
<td><kbd>register_b</kbd></td>
<td>An 8-bit general purpose register. The register is accessible to the VM code.</td>
</tr>
<tr>
<td><kbd>register_key</kbd></td>
<td>An 8-bit register. This holds the encryption key byte.</td>
</tr>
<tr>
<td><kbd>register_cnt</kbd></td>
<td>An 8-bit register. This holds the counter for <kbd>vm_loop</kbd> instruction. The register is accessible to VM code.</td>
</tr>
<tr>
<td><kbd>data_base</kbd></td>
<td>A 32-bit (64-bit for the long mode) register. This holds the address of the data to be encrypted.</td>
</tr>
<tr>
<td><kbd>data_length</kbd></td>
<td>A 32-bit register. This holds the length of the data to be encrypted (only 8 bits are used, so the data cannot be longer than 256 bytes).</td>
</tr>
</tbody>
</table>
<p> </p>
<p>The virtual processor has a very limited instruction set, but they are not encoded sequentially:</p>
<table>
<tbody>
<tr>
<td><strong>Opcode</strong></td>
<td><strong>Mnemonic</strong></td>
<td>
<p><strong>Meaning</strong></p>
</td>
</tr>
<tr>
<td>0x00</td>
<td><kbd>vm_load_key</kbd></td>
<td>
<p>This loads the <kbd>key</kbd> parameter of the VM procedure into the <kbd>key</kbd> register of the virtual processor.</p>
</td>
</tr>
<tr>
<td>0x01</td>
<td><kbd>vm_nop</kbd></td>
<td>
<p>This is the NOP instruction. No operation is performed.</p>
</td>
</tr>
<tr>
<td>0x02</td>
<td><kbd>vm_load_data_length</kbd></td>
<td>
<p>This loads the length of the string to be encrypted into the <kbd>data length</kbd> register of the virtual processor.</p>
</td>
</tr>
<tr>
<td>0x10</td>
<td><kbd>vm_loop target</kbd></td>
<td>
<p>This jumps to <kbd>target</kbd> if the <kbd>counter</kbd> register is less than the <kbd>data length</kbd> register.</p>
</td>
</tr>
<tr>
<td>0x11</td>
<td><kbd>vm_jump target</kbd></td>
<td>
<p>This unconditionally jumps to the <kbd>target</kbd> address.</p>
</td>
</tr>
<tr>
<td>0x12</td>
<td><kbd>vm_exit</kbd></td>
<td>
<p>This notifies the virtual processor that it should stop.</p>
</td>
</tr>
<tr>
<td>0x20</td>
<td><kbd>vm_encrypt regId</kbd></td>
<td>
<p>Performs the XOR operation on the content of <kbd>register[regId]</kbd> with the content of the key <kbd>register</kbd>.</p>
</td>
</tr>
<tr>
<td>0x21</td>
<td><kbd>vm_decrement regId</kbd></td>
<td>
<p>This decrements the content of <kbd>register[regId]</kbd>.</p>
</td>
</tr>
<tr>
<td>0x22</td>
<td><kbd>vm_increment regId</kbd></td>
<td>
<p>This increments the content of <kbd>register[regId]</kbd>.</p>
</td>
</tr>
<tr>
<td>0x30</td>
<td><kbd>vm_load_data_byte regId</kbd></td>
<td>
<p>Load byte from <kbd>data_base_address + counter_register</kbd> into <kbd>register[regId]</kbd>.</p>
</td>
</tr>
<tr>
<td>0x31</td>
<td><kbd>vm_store_data_byte regId</kbd></td>
<td>
<p>Store byte from <kbd>register[regId]</kbd> to <kbd>data_base_address + counter_register</kbd>.</p>
</td>
</tr>
</tbody>
</table>


            

            
        
    

        

                            
                    <h1 class="header-title">Adding support for a virtual processor to the Flat Assembler</h1>
                
            
            
                
<p>We will skip the declaration of a separate structure for the processor; instead, its state will be stored on a stack. However, we do need to make some preparations. First of all, we need to make the Flat Assembler understand our mnemonics and create a proper binary output. For this purpose, we will create an additional source file and name it <kbd>vm_code.asm</kbd>. As it will contain declarations of macro instructions and the VM code, which will be treated as data, the inclusion of the file in the main source would be done by adding the following:</p>
<pre>include 'vm_code.asm'</pre>
<p>Add this line somewhere in the data section. The next step-we have to define macro instructions that can be translated into a binary output that our virtual processor can understand. This is a very powerful feature of FASM, as one may add support for almost any architecture with a set of macro instructions (which, by the way, is the exact idea behind the Flat Assembler G):</p>
<pre>macro vm_load_key<br/>{<br/>   db 0x00<br/>}<br/><br/>macro vm_nop<br/>{<br/>   db 0x01<br/>}<br/><br/>macro vm_load_data_length<br/>{<br/>   db 0x02<br/>}<br/><br/>macro vm_loop loopTarget<br/>{<br/>   db 0x10<br/>   dd loopTarget - ($ + 4)<br/>}<br/><br/>macro vm_jump jumpTarget<br/>{<br/>   db 0x11<br/>   dd loopTarget - ($ + 4)<br/>}<br/><br/>macro vm_exit<br/>{<br/>   db 0x12<br/>}<br/><br/>macro vm_encrypt regId<br/>{<br/>   db 0x20<br/>   db regId<br/>}<br/><br/>macro vm_decrement regId<br/>{<br/>   db 0x21<br/>   db regId<br/>}<br/><br/>macro vm_increment regId<br/>{<br/>   db 0x22<br/>   db regId<br/>}<br/><br/>macro vm_load_data_byte regId<br/>{<br/>   db 0x30<br/>   db regId<br/>}<br/><br/>macro vm_store_data_byte regId<br/>{<br/>   db 0x31<br/>   db regId<br/>}<br/><br/><em>; Let's give readable names to registers</em><br/>register_a   = 0<br/>register_b   = 1<br/>register_cnt = 2</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Virtual code</h1>
                
            
            
                
<p>Obviously, we did not write all of the preceding code just for fun; we need to write some code for the virtual processor. Since the architecture is very limited and restricted to a specific task, there are not too many options as to what the code may look like:</p>
<pre><em>; Virtual code                     ; Binary output</em><br/>vm_code_start:<br/>   vm_load_key                     <em>; 0x00</em><br/>   vm_load_data_length             <em>; 0x02</em><br/>   vm_nop                          <em>; 0x01</em><br/> .encryption_loop:    <br/>   vm_load_data_byte register_b    <em>; 0x30 0x01</em><br/>   vm_encrypt register_b           <em>; 0x20 0x01</em><br/>   vm_store_data_byte register_b   <em>; 0x31 0x01</em><br/>   vm_loop .encryption_loop        <em>; 0x10 0xf5 0xff 0xff 0xff</em><br/><br/>   vm_exit                         <em>; 0x12</em></pre>


            

            
        
    

        

                            
                    <h1 class="header-title">The virtual processor</h1>
                
            
            
                
<p>Everything seems to be clear by now, except one thing-what does it all have to do with trees? We are almost there, as we have to implement the virtual processor itself, and that is what we are going to do here.</p>
<p>The easiest and probably the most common implementation of a virtual processor is a <kbd>while()</kbd> loop, which runs by reading instructions from the VM's memory and selects a proper execution path with the <kbd>switch()</kbd> statement implemented as the <strong>indirect jump</strong> and <strong>jump table</strong> (the table of jump target addresses). Although our example would probably run best when implemented this way, and the architecture described below would fit better for a complex instruction set, it was intentionally made simple in order to avoid the need to discuss certain aspects that are clearly unrelated to the topic-trees.</p>
<p>Our operation codes, as shown in the instruction/opcode table, are all 1 byte in size, plus a 1-byte or 4-byte operand (for instructions that require operand), and in range from <kbd>0x00</kbd> to <kbd>0x31</kbd>, with relatively large gaps. However, the amount of operation code allows us to arrange them in an almost perfect binary search tree:</p>
<div><img class="image-border" height="251" src="img/f1b36c80-d801-463f-a74d-05bd9090ed15.png" width="435"/></div>
<p>We say "almost" because if there were two child nodes for each of the nodes denoting opcodes <kbd>0x11</kbd> (<kbd>vm_jump</kbd>) and <kbd>0x20</kbd> (<kbd>vm_encrypt</kbd>), it would be an ideal binary search tree (but who says we cannot add four more instructions?).</p>
<p>Each node on the diagram represents a <kbd>tnode</kbd> structure containing all the necessary pointers, including a pointer to a small structure, which maps the operation code to real Assembly code in the virtual processor's loop:</p>
<pre>struc instruction opcode, target<br/>{<br/>   .opcode dd opcode<br/>   .target dd target<br/>}</pre>
<p>Thus, the first thing we do is build a table that maps all operation codes to Assembly code. The format of the table is rather simple. Each row contains the following:</p>
<ul>
<li>Double word operation code</li>
<li>A pointer to the Assembly code (double word for the 32-bit mode or 64-bit for the long mode).</li>
</ul>
<p>The implementation of the table in code is rather simple:</p>
<pre> i_load_key         instruction 0x00,\<br/>                                run_vm.load_key<br/> i_nop              instruction 0x01,\<br/>                                run_vm.nop<br/> i_load_data_length instruction 0x02,\<br/>                                run_vm.load_data_length<br/> i_loop             instruction 0x10,\<br/>                                run_vm.loop<br/> i_jump             instruction 0x11,\<br/>                                run_vm.jmp<br/> i_exit             instruction 0x12,\<br/>                                run_vm.exit<br/> i_encrypt          instruction 0x20,\<br/>                                run_vm.encrypt<br/> i_decrement        instruction 0x21,\<br/>                                run_vm.decrement<br/> i_increment        instruction 0x22,\<br/>                                run_vm.increment<br/> i_load_data_byte   instruction 0x30,\<br/>                                run_vm.load_data_byte<br/> i_store_data_byte  instruction 0x31,\<br/>                                run_vm.store_data_byte</pre>
<p>At last, we have reached the tree. Let's skip the tree building and balancing procedure, as the tree is statically allocated and as we are interested particularly in the structure itself. In the following code, we in fact create an array of <kbd>tnode</kbd> structures which, however, are not addressed by <kbd>base+index</kbd>, but are linked to a tree. The last line defines a pointer to the root node of the tree, <kbd>tree_root</kbd>, which refers to <kbd>t_exit</kbd>:</p>
<pre> t_load_key         tnode i_load_key,\              ; 0x00 &lt;-\<br/>                          0,\                       ;          |<br/>                          0                         ;          |     <br/> t_nop              tnode i_nop,\                   ; 0x01     | &lt;-\<br/>                          t_load_key,\              ; ---------/   |<br/>                          t_load_data_length        ; ---------\   |<br/> t_load_data_length tnode i_load_data_length,\      ; 0x02   &lt;-/   |<br/>                          0,\                       ;              |<br/>                          0                         ;              |<br/> t_loop             tnode i_loop,\                  ; 0x10         | &lt;-\<br/>                          t_nop,\                   ; -------------/   |<br/>                          t_jmp                     ; --------\        |<br/> t_jmp              tnode i_jump,\                  ; 0x11  &lt;-/        |<br/>                          0,\                       ;                  |<br/>                          0                         ;                  |<br/> t_exit             tnode i_exit,\                  ; 0x12             |<br/>                          t_loop,\                  ; -----------------/<br/>                          t_decrement               ; --------\<br/> t_encrypt          tnode i_encrypt,\               ; 0x20    | &lt;-\  <br/>                          0,\                       ;         |   |<br/>                          0                         ;         |   |<br/> t_decrement        tnode i_decrement,\             ; 0x21  &lt;-/   |<br/>                          t_encrypt,\               ; ------------/<br/>                          t_load_data_byte          ; --------\<br/> t_increment        tnode i_increment,\             ; 0x22    | &lt;-\<br/>                          0,\                       ;         |   |<br/>                          0                         ;         |   |<br/> t_load_data_byte   tnode i_load_data_byte,\        ; 0x30  &lt;-/   |<br/>                          t_increment,\             ; ------------/<br/>                          t_store_data_byte         ; --------\<br/> t_store_data_byte  tnode i_store_data_byte,\       ; 0x31  &lt;-/<br/>                          0,\<br/>                          0 <br/><br/>tree_root dd t_exit</pre>
<p>Once compiled, the data section of the executable would look like this:</p>
<div><img class="image-border" src="img/007e7922-46b3-4932-b871-2bd66506b1b6.png"/></div>


            

            
        
    

        

                            
                    <h1 class="header-title">Searching the tree</h1>
                
            
            
                
<p>We need to take care of a procedure that would extract the correct address of the Assembly implementation of the virtual instruction from the tree prior to beginning the implementation of the virtual processor's loop.</p>
<p>The <kbd>tree_lookup</kbd> procedure requires two parameters:</p>
<ul>
<li>The address of the <kbd>tree_root</kbd> variable</li>
<li>The byte opcode cast to double word</li>
</ul>
<p>When this procedure is called, it "walks" the tree node by node (in accordance with the rule the tree was sorted by) and compares the opcode parameter to the opcode value of the instruction structure referred to by the current node. The procedure returns the address of the Assembly implementation of the operation code, or it returns a zero if no such opcode has been defined:</p>
<pre>tree_lookup:<br/>   push ebp<br/>   mov  ebp, esp<br/>   push ebx ecx<br/><br/>   virtual at ebp + 8<br/>      .treePtr dd ?               <em>; First parameter - pointer to tree_root</em><br/>      .code dd ?                  <em>; Second parameter - opcode value</em><br/>   end virtual<br/>   virtual at ecx<br/>      .node tnode ?,?,?           <em>; Lets us treat ECX as a pointer</em> <br/>                                  <em>; to tnode structure</em><br/>   end virtual<br/>   virtual at eax<br/>      .instr instruction ?, ?     <em>; Lets us treat EAX as a pointer </em><br/><em>                                  ; to instruction structure</em><br/>   end virtual<br/><br/>   mov  ecx, [.treePtr]           <em>; Load the pointer to tree_root</em><br/>   mov  ecx, [ecx]                <em>; Load the pointer to root node</em><br/>   mov  ebx, [.code]              <em>; Read current opcode</em><br/>   movzx ebx, bl                  <em>; Cast to unsigned int</em><br/><br/>@@:<br/>   or   ecx, 0                    <em>; Check whether ECX points to a node</em><br/>   jz   .no_such_thing            <em>; and return zero if not</em><br/><br/>   mov  eax, [.node.data]         <em>; Load pointer to instruction structure</em><br/>   cmp  ebx, [.instr.opcode]      <em>; Compare opcode value</em><br/>   jz   @f<br/>   ja   .go_right                 <em>; If node contains lower opcode, then</em><br/>                                  <em>; continue searching the right subtree</em><br/>   mov  ecx, [.node.left]         <em>; Otherwise continue searching the</em> <br/>   jmp  @b                        <em>; left subtree</em><br/><br/>.go_right:<br/>   mov  ecx, [.node.right]<br/>   jmp  @b<br/><br/>@@:<br/>   mov  eax, [.instr.target]      <em>; Relevant instruction structure has</em><br/>                                  <em>; been found, so return the address</em><br/>                                  <em>; of instruction implementation</em><br/>@@:                    <br/>   pop  ecx ebx                   <em>; We are done</em><br/>   leave<br/>   ret  8<br/><br/>.no_such_thing:                   <em>; Zero out EAX to denote an error</em><br/>   xor  eax, eax<br/>   jmp  @b </pre>


            

            
        
    

        

                            
                    <h1 class="header-title">The loop</h1>
                
            
            
                
<p>The implementation of the loop is a bit long, and we have many more interesting things to fill the space allocated for this chapter, so refer to the accompanying source code for the full version. Here, however, we will examine certain parts of the implementation:</p>
<ul>
<li><strong>Creating a stack frame and parameter markup</strong>: The procedure's prolog code would be just as usual-we allocate some space on the stack and save registers that we want not to be affected by the procedure, and that means all the registers we use in the procedure:</li>
</ul>
<pre>        run_vm:<br/>           push  ebp<br/>           mov   ebp, esp<br/>           sub   esp, 4 * 3           <em>; We only need 12 bytes for storing </em><br/><em>                                      ; the state of virtual cpu</em><br/>           push  eax ebx ecx edx esi  <em>; We will use these registers</em><br/>   <br/>           virtual at ebp + 8         <em>; Assign local labels to parameters</em><br/>              .p_cmd_buffer_ptr  dd ? <em>; Pointer to VM code</em><br/>              .p_data_buffer_ptr dd ? <em>; Pointer to data we want to <br/>                                      ; encrypt</em><br/>              .p_data_length     dd ? <em>; Length of data in bytes</em><br/>              .p_key             dd ? <em>; Key value cast to double word</em><br/>           end virtual<br/><br/>           virtual at ebp - 0x0c      <em>; Assign local labels to stack <br/>                                      ; variables</em><br/>              .register_a        db ? <em>; Register A of virtual processor</em><br/>              .register_b        db ? <em>; Register B of virtual processor</em><br/>              .register_key      db ? <em>; Register to hold the key</em><br/>              .register_cnt      db ? <em>; Counter register</em><br/>              .data_base         dd ? <em>; Pointer to data buffer</em><br/>              .data_length       dd ? <em>; Size of the data buffer in size</em><br/>           end virtual</pre>
<ul>
<li><strong>Preparing a virtual processor loop</strong>: The loop itself begins with reading an opcode from the current position in the virtual code, then calls the <kbd>tree_lookup</kbd> procedure, and either jumps to the address returned by <kbd>tree_lookup</kbd> or to <kbd>.exit</kbd> if the procedure returns an error (zero):</li>
</ul>
<pre>        virtual_loop:<br/>           mov   al, [esi + ebx]  <em>; ESI - points to array of bytes <br/>                                  ; containing </em><br/><em>                                  ; virtual code</em><br/><em>                                  ; EBX - instruction pointer (offset<br/>                                  ; into virtual code)</em><br/>           movzx eax, al          <em>; Cast opcode to double word</em><br/>           push  eax<br/>           push  tree_root<br/>           call  tree_lookup      <em>; Get address of opcode emulation <br/>                                  ; code</em><br/>           or    eax, 0           <em>; Check for error</em><br/>           jz    .exit<br/>           jmp   eax              <em>; Jump to emulation code</em></pre>
<p style="padding-left: 60px">The preceding code is followed by a set of instructions emulating code fragments, as you can see in the accompanying source code.</p>
<p style="padding-left: 60px">The last few lines of the <kbd>run_vm</kbd> procedure are, in fact, the emulation of the <kbd>vm_exit</kbd> opcode:</p>
<pre>        .exit:<br/>           pop   esi edx ecx ebx eax  <em>; Restore saved registers</em><br/>           add   esp, 4 * 3           <em>; Destroy stack frame</em><br/>           leave<br/>           ret   4 * 4</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Tree balancing</h1>
                
            
            
                
<p>Now, when we know what a binary search tree looks like on the Assembly programming level, it would not be correct not to return to the question of binary search tree balancing. There are several approaches to this problem, however, we would only consider one-the Day-Stout-Warren algorithm (included in the accompanying code). The algorithm is simple:</p>
<ol>
<li>Allocate a tree node and make it a "pseudo root" for the tree, making the original root the pseudo root's right child.</li>
<li>Convert the tree into a sorted linked list by means of an in-order traversal (this step also calculates the number of nodes in the original tree). No additional allocations are required, as the step reuses existing pointers in tree nodes.</li>
<li>Convert the list back into a complete binary tree (one in which the bottom layer is populated strictly from left to right).</li>
<li>Make pseudo root's right child the tree's root.</li>
<li>Dispose of the pseudo root node.</li>
</ol>
<p>Applying this algorithm to our opcode tree will result in the following structure:</p>
<div><img class="image-border" height="230" src="img/846f7bb7-b3ac-4b3a-b852-f1220d0b30a5.png" width="419"/></div>
<p>The structure remains almost the same-four levels, including the root node, and four nodes at the bottom-most layer. The order of opcodes has changed a bit, but this is not that important in the case of this particular example. However, should we design a more complex system that expects much more load, we could design the encoding of the operation code in such a way that the most frequently used opcodes would be encoded with values from the upper layers and the least frequently used opcodes, with values from the bottom layers.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Sparse matrices</h1>
                
            
            
                
<p>Sparse matrices are rarely discussed, if at all, due to the relative complexity of implementation and maintenance; however, they may be a very convenient and useful instrument in certain cases. Basically, sparse matrices are conceptually very close to arrays, but they're much more efficient when working with sparse data as they allow memory savings, which in turn allows the processing of much larger amounts of data.</p>
<p>Let's take astrophotography as an example. For those of us not familiar with the subject, amateur astrophotography means plugging your digital camera into a telescope, selecting a region in the night sky, and taking pictures. However, since pictures are taken at night time without a flashlight or any other aid (it would be silly to try to light celestial objects with a flashlight anyway), one has to take dozens of pictures of the same object and then stack the images together using a specific algorithm. In this case, there are two major problems:</p>
<ul>
<li>Noise reduction</li>
<li>Image alignment</li>
</ul>
<p>Lacking professional equipment (meaning not having a huge telescope with a cooled CCD or CMOS matrix), one faces the problem of noise. The longer the exposition, the more noise in the final image. Of course, there are numerous algorithms for noise reduction, but sometimes, a real celestial object may mistakenly be treated as noise and be removed by the noise reduction algorithm. Therefore, it is a good idea to process each image and detect potential celestial objects. If certain "light", which otherwise may be considered as noise, is present in at least 80% of images (it is hard to believe that any noise would have survived for such a long time without any changes, unless we are talking about dead pixels), then its area needs different treatment.</p>
<p>However, in order to process an image, we need to make a decision on how to store the result. We, of course, may use an array of structures describing each and every pixel, but that would be too expensive by means of the memory required for such operation. On the other hand, even if we take a picture of the highly populated area of the night sky, the area occupied by celestial objects would be significantly smaller than the "empty" space. Instead, we may divide an image into smaller areas, analyze certain characteristics of those smaller regions, and only take into consideration those that seem to be populated. The following figure presents the idea:</p>
<div><img class="image-border" height="299" src="img/a3ab2839-e62b-4191-beb4-a390fed31b3f.png" width="353"/></div>
<p>The figure (which shows the Messier 82 object, also known as <em>Cigar Galaxy</em>) is divided into 396 smaller regions (a matrix of 22 x 18 regions, 15 x 15 pixels each). Each region may be described by its luminosity, noise ratio, and many other aspects, including its location on the figure, meaning that it may occupy quite a sensible amount of memory. Having this data stored in a two-dimensional array with more than 30 images simultaneously may result in megabytes, of meaningless data. As the image shows, there are only two regions of interest, which together form about 0.5% (which fits the definition of sparse data more than perfectly), meaning that if we choose to use arrays, we waste 99.5% of the used memory.</p>
<p>Utilizing sparse matrices, we may reduce the usage of memory to the minimum required to store important data. In this particular case, we would have a linked list of 22 column header nodes, 18 row header nodes, and only 2 nodes for data. The following is a very rough example of such an arrangement:</p>
<div><img class="image-border" src="img/e8ede3a0-c7bf-46b3-a72a-79dc92b1b1d8.png"/></div>
<p>The preceding example is very rough; in reality, the implementation would contain a few other links. For example, empty column header nodes would have their <kbd>down</kbd> pointer point to themselves, and empty row headers would have their <kbd>right</kbd> pointers point to themselves, too. The last data node in a row would have its right pointer pointing to the row header node, and the same applies to the last data node in a column having its <kbd>down</kbd> pointer pointing to the column header node.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Graphs</h1>
                
            
            
                
<p>The general definition of a graph states that a graph is a data structure consisting of a set of vertices (V) and edges (E). While the vertex may be anything (anything means any data structure), edge is defined by the two vertices it connects-<em>v</em> and <em>w</em>. Edges have a direction, meaning that the data flows from vertex <em>v</em> to vertex <em>w</em>, and <em>weight</em>, which indicates how difficult the flow is.</p>
<p>The easiest and probably the most common example of a graph structure is a perceptron-an artificial neural network paradigm:</p>
<div><img class="image-border" height="355" src="img/d2bf874b-67e5-47f0-8096-48bfbf6f5d6c.png" width="360"/></div>
<p>Traditionally, perceptrons are drawn from left to right, so we have three layers:</p>
<ul>
<li>The input layer (sensors)</li>
<li>The hidden layer (where most of the processing takes place)</li>
<li>The output layer (forms the output of a perceptron)</li>
</ul>
<p>Although nodes of artificial neural network are called <strong>neurons</strong>, we will refer to them as vertices as we are discussing graphs, not ANNs.</p>
<p>In the preceding graph, we see a typical multilayer perceptron layout for an artificial neural network capable of solving the XOR problem.</p>
<p>An XOR problem in artificial neural networks is the problem of making an ANN implementation receiving two inputs in the range <em>{0, 1}</em> to produce a result, as if two inputs were XOR'ed. A single layer perceptron (where the hidden layer is also the output layer) is not able to find solutions for this problem, therefore an additional layer is added.</p>
<p>The vertices <strong>S0</strong> and <strong>S1</strong> do not perform any computations and serve as sources of data for vertices <strong>N0</strong> and <strong>N1</strong>. As it has been stated, edges have weights, and in this example, the data from <strong>S0</strong> and <strong>S1</strong> is multiplied with the weights of the edges <em>[s0, n0]</em>, <em>[s0, n1]</em>, <em>[s1, n0]</em>, and <em>[s1, n1]</em>. The same applies to data being transferred via <em>[bias, n0]</em>, <em>[bias, n1]</em>, <em>[n0, o]</em>, and <em>[n1, o]</em>.</p>
<p>However, graphs may be of any shape and edges may lead data in any direction (even to the same vertex), depending on the problem they intend to solve.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>In this chapter, we have briefly covered several types of data structures (not to be confused with the Assembly <kbd>struc[tures]</kbd>) and reviewed a few of their possible applications. However, being very vast, the topic of data structures may require a separate chapter for each of the structures briefly described here, and their variations, which, unfortunately, falls out of the scope of this book.</p>
<p>Beginning with the next chapter (<a href="22b2b820-0431-48f6-9ed2-8b9e0cded10a.xhtml" target="_blank">Chapter 8</a>, <em>Mixing Modules Written in Assembly and Those Written in High-Level Languages</em>), we will approach more practical problems and will start applying the knowledge we have gathered thus far in an attempt to find an elegant solution.</p>
<p>In the next chapter, we will see how the Assembly code written for both 32-bit and 64-bit Windows and Linux operating systems may be linked with existing libraries written either in Assembly or in a high-level language. We will even cover the topic of interoperability of .NET and Assembly code (on both Linux and Windows).</p>
<p class="mce-root"/>


            

            
        
    </body></html>