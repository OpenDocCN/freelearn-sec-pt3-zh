<html><head></head><body>
        

                            
                    <h1 class="header-title">Databases in Python</h1>
                
            
            
                
<p>In this chapter, we will leverage databases in our scripts so that we can accomplish meaningful tasks when working with large quantities of data. Using a simple example, we will demonstrate the capabilities and benefits of using a database backend in our Python scripts. We will store file metadata that has been recursively indexed from a given root directory into a database and then query it to generate reports. Although this may seem like a simple feat, the purpose of this chapter is to showcase the ways we can interact with a database in Python by creating an active file listing.</p>
<p>In this chapter, we will delve into the following topics:</p>
<ul>
<li>The basic design and implementation of SQLite3 databases</li>
<li>Working with these databases in Python using built-in and third-party modules</li>
<li>Understanding how to recursively iterate through directories in Python</li>
<li>Understanding filesystem metadata and the methods for accessing it using Python</li>
<li>Crafting CSV and HTML reports for easy review by our end user</li>
</ul>
<p>The code for this chapter was developed and tested using Python 2.7.15 and Python 3.7.1. The <kbd>file_lister.py</kbd> script was developed to work with Python 3.7.1. The <kbd>file_lister_peewee.py</kbd> script was developed and tested using both Python 2.7.15 and Python 3.7.1.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">An overview of databases</h1>
                
            
            
                
<p>Databases provide an efficient means of storing large amounts of data in a structured manner. There are many types of databases, commonly broken into two categories: <strong>SQL</strong> or <strong>NoSQL</strong>. <strong>SQL</strong> (short for <strong>Structured Query Language</strong>) is designed to be a simple language that allows users to manipulate large datasets that are stored in a database. This includes common databases, such as MySQL, SQLite, and PostgreSQL. NoSQL databases are also useful and generally use JSON or XML to store data of varying structures, both of which were discussed as common serialized data types in the previous chapter.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Using SQLite3</h1>
                
            
            
                
<p>SQLite3 is the latest version of SQLite and is one of the most common databases found in application development. This database, unlike others, is stored as a single file and does not require a server instance to be running or installed. For this reason, it is widely used due to its portability and is found in many applications for mobile devices, desktop applications, and web services. SQLite3 uses a slightly modified SQL syntax, though of the many SQL variations that exist, it is one of its simpler implementations. Naturally, there are some limitations to this lightweight database. These limitations include a restriction of one writer being connected to the database at a time, 140 TB of storage, and that it is not client-server based. Because our application will not execute multiple write statements simultaneously, uses less than 140 TB of storage, and does not require a client-server setup for distribution, we will be using SQLite for our example in this chapter.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Using SQL</h1>
                
            
            
                
<p>Before developing our code, let's take a look at the basic SQL statements we will be using. This will help us understand how we can interact with databases even without Python. In SQL, commands are commonly written in uppercase, although they are case-insensitive. For this exercise, we will use uppercase to improve legibility. All SQL statements must end in a semicolon to execute, as it denotes the end of a statement.</p>
<p>If you would like to follow along, install a SQLite management tool, such as the command-line tool sqlite3. This tool can be downloaded from <a href="https://www.sqlite.org/download.html">https://www.sqlite.org/download.html</a>. The output shown in this section has been generated with the sqlite3 command-line tool, though the statements that have been given will generate the same database in most other sqlite3 graphical applications. When in doubt, use the official sqlite3 command-line tool.</p>
<p>To begin, we will create a table, a fundamental component of any database. If we compare a database to an Excel workbook, a table is tantamount to a worksheet. Tables contain named columns, as well as rows of data that are mapped to these columns. Just like how an Excel workbook may contain multiple worksheets, so too can a database contain multiple tables. To create a table, we will use the <kbd>CREATE TABLE</kbd> command, specifying the table name and then wrapping, in parentheses, the column names and their data types as a comma-separated list. Finally, we end the SQL statement with a semicolon:</p>
<pre><strong>&gt;&gt;&gt; CREATE TABLE custodians (id INTEGER PRIMARY KEY, name TEXT);</strong></pre>
<p>As we can see in the <kbd>CREATE TABLE</kbd> statement, we specify the <kbd>id</kbd> and <kbd>name</kbd> columns in the <kbd>custodians</kbd> table. The <kbd>id</kbd> field is an integer and primary key. This designation of <kbd>INTEGER PRIMARY KEY</kbd> in SQLite3 will create an automatic index that sequentially increments for each added row, therefore creating an index of unique row identifiers. The <kbd>name</kbd> column has the data type of <kbd>TEXT</kbd>, which allows any character to be stored as a text string. SQLite supports five data types, two of which we've already introduced:</p>
<ul>
<li><kbd>INTEGER</kbd></li>
<li><kbd>TEXT</kbd></li>
<li><kbd>REAL</kbd></li>
<li><kbd>BLOB</kbd></li>
<li><kbd>NULL</kbd></li>
</ul>
<p>The <kbd>REAL</kbd> data type allows floating point numbers (for example, decimals). The <strong>BLOB</strong> (short for <strong>Binary Large OBject</strong>) data type preserves any input data exactly as is, without casting it as a certain type. The <kbd>NULL</kbd> data type simply stores an empty value.</p>
<p>After creating the table, we can begin to add data to it. As we can see in the following code block, we can use the <kbd>INSERT INTO</kbd> command to insert data into the table. The syntax following this command specifies the table name, the columns to insert the data into, followed by the <kbd>VALUES</kbd> command specifying the values to be inserted. The columns and data must be wrapped in parentheses, as shown in the following code. Using the <kbd>null</kbd> statement as a value, the auto-incrementing feature of SQLite will step in and fill in this value with the next available unique integer. Remember that this auto-incrementing is only true because we designated it as <kbd>INTEGER PRIMARY KEY</kbd>. As a general rule, only one column in a table should have this designation:</p>
<pre><strong>&gt;&gt;&gt; INSERT INTO custodians (id, name) VALUES (null, 'Chell');</strong><br/><strong>&gt;&gt;&gt; INSERT INTO custodians (id, name) VALUES (null, 'GLaDOS');</strong></pre>
<p>We've inserted two custodians, <kbd>Chell</kbd> and <kbd>GLaDOS</kbd>, and we let SQLite assign IDs to each of them. After the data has been inserted, we can select and view this information using the <kbd>SELECT</kbd> command. The basic syntax involves invoking the <kbd>SELECT</kbd> command, followed by the columns to select (or an asterisk <kbd>*</kbd> to designate all columns) and the <kbd>FROM</kbd> statement, indicating the table name following a trailing semicolon. As we can see in the following code, <kbd>SELECT</kbd> will print out a pipe (<kbd>|</kbd>) separated list of the values stored:</p>
<pre><strong>&gt;&gt;&gt; SELECT * FROM custodians;</strong><br/><strong>1|Chell</strong><br/><strong>2|GLaDOS</strong></pre>
<p>In addition to showing only the desired columns from our table, we can also filter data on one or more conditions. The <kbd>WHERE</kbd> statement allows us to filter results and return only responsive items. For the purpose of the script in this chapter, we will stick to a simple <kbd>where</kbd> statement and only use the equals operator to return responsive values. When executed, the <kbd>SELECT-WHERE</kbd> statement returns only the custodian information where the <kbd>id</kbd> value is <kbd>1</kbd>. In addition, note that the order of the columns reflects the order in which they were specified:</p>
<pre><strong>&gt;&gt;&gt; SELECT name,id FROM custodians WHERE id = 1;</strong><br/><strong>Chell|1</strong> </pre>
<p>There are more operations and statements available to interact with SQLite3 databases, although the preceding operations highlight all that we require for our scripts. We invite you to explore additional operations in the SQLite3 documentation, which can be found at <a href="https://sqlite.org">https://sqlite.org</a>.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Designing our script</h1>
                
            
            
                
<p>The first iteration of our script focuses on performing the task at hand with a standard module, sqlite3, in a more manual fashion. This entails writing out each SQL statement and executing them as if you were working with the database itself. Although this is not a very Pythonic manner of handling a database, it demonstrates the methods that are used to interact with a database with Python. Our second iteration employs two third-party libraries: <kbd>peewee</kbd> and <kbd>jinja2</kbd>.</p>
<p>Peewee is an <strong>object-relational mapper</strong> (<strong>ORM</strong>), which is a term that's used to describe a software suite that uses objects to handle database operations. In short, this ORM allows the developer to call functions and define classes in Python that are interpreted as database commands. This layer of abstraction helps to standardize database calls and allows for multiple database backends to be easily interchanged. Peewee is a light ORM, as it is a single Python file that supports PostgreSQL, MySQL, and SQLite3 database connections. If we needed to switch our second script from SQLite3 to PostgreSQL, it would only require that we modify a few lines of code; our first script would require more attention to handle this same conversion. This being said, our first version does not require any dependencies beyond the standard Python installation for SQLite3 support, an attractive feature for tools that are designed to be portable and flexible while in the field.</p>
<p>Our <kbd>file_lister.py</kbd> script is a per-custodian metadata collection and reporting script. This is important in incident response or the discovery phase of an investigation, as it stores information about active files on a system or in a specified directory by custodian name. A custodian assignment system allows for multiple machines, directory paths, or network shares to be indexed and categorized by a single custodian name, regardless of whether the custodian is a user, machine, or device. To implement this system, we need to prompt the user for the custodian name, the path of the database to use, and the input or output information.</p>
<p>By allowing the examiner to add multiple custodians or paths into the same database, they can append to the files that have been found for a single custodian or add in as many custodians as they please. This is helpful in collections as the investigator can preserve as few or as many paths as they need, as we all know how unexpected devices show up once we are in the field. In addition, we can use the same script to create file listing reports, regardless of the number of collected files or custodians, as long as the custodian has at least one collected file.</p>
<p>In our design state, we don't only take into account our script but also the database and the relational model we will use. In our case, we are handling two separate items: custodians and files. These both make for good tables, as they are separate entries that share a common relation. In our scenario, a file has a custodian and a custodian may have one or more files; therefore, we will want to create a foreign key, relating files to a specific custodian. A foreign key is a reference to a primary key in another table. The primary key and the foreign key references are usually a unique value or an index that links the data together.</p>
<p>The following diagram represents the relational model for our database. We have two tables, custodians and files, and a one-to-many relationship between them. As defined earlier, this one-to-many relationship will allow us to assign many files to a single custodian. Using this relationship, we can ensure that our script will properly assign information in a structured and easy-to-manage manner:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-490 image-border" src="img/e9dd4f71-f0f4-4dc7-b9f8-40931f44a576.png" style="width:23.25em;height:20.33em;"/></p>
<p>In this relational model, for example, we could have a custodian named JPriest who owns files located in a folder named <kbd>APB/</kbd>. Under this root folder, there are 40,000 files spread among 300 subdirectories, and we need to assign each of those 40,000 files to JPriest. Because custodian names may be long or complex, we want to assign JPriest an identifier, such as the integer 5, and write that to each row of the data being stored in the <kbd>Files</kbd> table. By doing this, we accomplish three things:</p>
<ul>
<li>We are saving space as we are storing only one character (<kbd>5</kbd>) instead of seven (JPriest) in each of the 40,000 rows</li>
<li>We are maintaining a link between the JPriest user and their files</li>
<li>If we ever needed to rename JPriest, we could change one row in our <kbd>Custodians</kbd> table and therefore update the custodian's name for all associated rows</li>
</ul>


            

            
        
    

        

                            
                    <h1 class="header-title">Manually manipulating databases with Python – file_lister.py</h1>
                
            
            
                
<p>As a note, this script will be designed to work only in Python 3 and was tested with Python 3.7.1. If you'd like the Python 2 version of the code after working through this section, please see <a href="https://github.com/PacktPublishing/Learning-Python-for-Forensics" target="_blank">https://github.com/PacktPublishing/Learning-Python-for-Forensics</a> for the prior iteration.</p>
<p>In the first iteration of the script, we use several standard libraries to complete all of the functionality required for the full operation. Like we did in prior scripts, we are implementing <kbd>argparse</kbd>, <kbd>csv</kbd>, and <kbd>logging</kbd> for their usual purposes, which include argument handling, writing CSV reports, and logging program execution. For logging, we define our log handler, <kbd>logger</kbd>, on line 43. We have imported the <kbd>sqlite3</kbd> module to handle all database operations. Unlike our next iteration, we will only support SQLite databases through this script. The <kbd>os</kbd> module allows us to recursively step through files in a directory and any subdirectories. Finally, the <kbd>sys</kbd> module allows us to gather logging information about the system, and the <kbd>datetime</kbd> module is used to format timestamps as we encounter them on the system. This script does not require any third-party libraries. We have the following code:</p>
<pre>001 """File metadata capture and reporting utility."""<br/>002 import argparse<br/>003 import csv<br/>004 import datetime<br/>005 import logging<br/>006 import os<br/>007 import sqlite3<br/>008 import sys<br/>...<br/>038 __authors__ = ["Chapin Bryce", "Preston Miller"]<br/>039 __date__ = 20181027<br/>040 __description__ = '''This script uses a database to ingest and<br/>041    report meta data information about active entries in<br/>042     directories.'''<br/>043 logger = logging.getLogger(__name__)</pre>
<p>Following our import statements, we have our <kbd>main()</kbd> function, which takes the following user inputs: custodian name, target input directory or output file, and a path to the database to use. The <kbd>main()</kbd> function handles some high-level operations, such as adding and managing custodians, error handling, and logging. It first initializes the database and tables, and then checks whether the custodian is in the database. If it is not, that custodian is added to the database. The function allows us to handle the two possible run options: to recursively ingest the base directory, capturing all subobjects and their metadata, and to read the captured information from the database into a report using our writer functions.</p>
<p>The <kbd>init_db()</kbd> function, which is called by <kbd>main()</kbd>, creates the database and default tables if they do not exist. The <kbd>get_or_add_custodian()</kbd> function, in a similar manner, checks to see whether a custodian exists. If it does, it returns the ID of the custodian, otherwise it creates the custodian table. To ensure that the custodian is in the database, the <kbd>get_or_add_custodian()</kbd> function is run again after a new entry is added.</p>
<p>After the database has been created and the custodian table exists, the code checks whether the source is an input directory. If so, it calls <kbd>ingest_directory()</kbd> to iterate through the specified directory and scan all subdirectories to collect file-related metadata. Captured metadata is stored in the <kbd>Files</kbd> table of the database with a foreign key to the <kbd>Custodians</kbd> table to tie each custodian to their file(s). During the collection of metadata, we call the <kbd>format_timestamp()</kbd> function to cast our collected timestamps into a standard string format.</p>
<p>If the source is an output file, the <kbd>write_output()</kbd> function is called, passing the open database cursor, output file path, and custodian name as arguments. The script then determines whether the custodian has any responsive results in the <kbd>Files</kbd> table and passes them to the <kbd>write_html()</kbd> or <kbd>write_csv()</kbd> function, based on the output file path's extension. If the extension is <kbd>.html</kbd>, then the <kbd>write_html()</kbd> function is called to create an HTML table using Bootstrap CSS, which displays all of the responsive results for the custodian. Otherwise, if the extension is <kbd>.csv</kbd>, then the <kbd>write_csv()</kbd> function is called to write the data to a comma-delimited file. If neither of the extensions is supplied in the output file path, then a report is not generated and an error is raised that the file type could not be interpreted:</p>
<pre>046 def main(custodian, target, db):<br/>...<br/>081 def init_db(db_path):<br/>...<br/>111 def get_or_add_custodian(conn, custodian):<br/>...<br/>132 def get_custodian(conn, custodian):<br/>...<br/>148 def ingest_directory(conn, target, custodian_id):<br/>...<br/>207 def format_timestamp(timestamp):<br/>...<br/>219 def write_output(conn, target, custodian):<br/>...<br/>254 def write_csv(conn, target, custodian_id):<br/>...<br/>280 def write_html(conn, target, custodian_id, custodian_name):</pre>
<p>Now, let's look at the required arguments and the setup for this script. On lines 321 through 339, we build out the <kbd>argparse</kbd> command-line interface with the required positional arguments <kbd>CUSTODIAN</kbd> and <kbd>DB_PATH</kbd>, and the optional arguments <kbd>--input</kbd>, <kbd>--output</kbd>, and <kbd>-l</kbd>:</p>
<pre>320 if __name__ == '__main__':<br/>321     parser = argparse.ArgumentParser(<br/>322     description=__description__,<br/>323     epilog='Built by {}. Version {}'.format(<br/>324         ", ".join(__authors__), __date__),<br/>325     formatter_class=argparse.ArgumentDefaultsHelpFormatter<br/>326     )<br/>327     parser.add_argument(<br/>328         'CUSTODIAN', help='Name of custodian collection is of.')<br/>329     parser.add_argument(<br/>330         'DB_PATH', help='File path and name of database to '<br/>331                         'create or append metadata to.')<br/>332     parser.add_argument(<br/>333         '--input', help='Base directory to scan.')<br/>334     parser.add_argument(<br/>335         '--output', help='Output file to write to. use `.csv` '<br/>336                          'extension for CSV and `.html` for HTML')<br/>337     parser.add_argument(<br/>338         '-l', help='File path and name of log file.')<br/>339     args = parser.parse_args()</pre>
<p>On lines 341 through 347, we check that either the <kbd>--input</kbd> or <kbd>--output</kbd> argument was supplied by the user. We create a variable, <kbd>arg_source</kbd>, which is a tuple containing the mode of operation and the corresponding path specified by the argument. If neither of the mode arguments were supplied, an <kbd>ArgumentError</kbd> is raised and prompts the user for an input or output. This ensures that the user provides the required arguments when there are one or more options:</p>
<pre>341     if args.input:<br/>342         arg_source = ('input', args.input)<br/>343     elif args.output:<br/>344         arg_source = ('output', args.output)<br/>345     else:<br/>346        raise argparse.ArgumentError(<br/>347            'Please specify input or output')</pre>
<p>On lines 349 through 368, we can see the log configuration that we used in previous chapters and check for the <kbd>-l</kbd> argument, making a path to the log if necessary. We also log the script version and the operating system information on lines 366 through 368:</p>
<pre>349     if args.l:<br/>350         if not os.path.exists(args.l):<br/>351             os.makedirs(args.l) # create log directory path<br/>352         log_path = os.path.join(args.l, 'file_lister.log')<br/>353     else:<br/>354         log_path = 'file_lister.log'<br/>355 <br/>356     logger.setLevel(logging.DEBUG)<br/>357     msg_fmt = logging.Formatter("%(asctime)-15s %(funcName)-20s"<br/>358         "%(levelname)-8s %(message)s")<br/>359     strhndl = logging.StreamHandler(sys.stdout)<br/>360     strhndl.setFormatter(fmt=msg_fmt)<br/>361     fhndl = logging.FileHandler(log_path, mode='a')<br/>362     fhndl.setFormatter(fmt=msg_fmt)<br/>363     logger.addHandler(strhndl)<br/>364     logger.addHandler(fhndl)<br/>365 <br/>366     logger.info('Starting File Lister v.' + str(__date__))<br/>367     logger.debug('System ' + sys.platform)<br/>368     logger.debug('Version ' + sys.version)</pre>
<p class="mce-root">With the logging squared away, we can create a dictionary, which defines the arguments passed into the <kbd>main()</kbd> function using kwargs. Kwargs, or keyword arguments, provide a means of passing arguments as dictionary key-value pairs, where the keys match the parameter name and are assigned a corresponding value. To pass a dictionary to a function or class as kwargs instead of a value, we must specify two asterisks preceding the dictionary name, as seen on line 373. If we did not use kwargs, we would have needed to pass the <kbd>args.custodian</kbd>, <kbd>arg_source</kbd>, and <kbd>args.db_path</kbd> arguments as individual positional arguments. There is more advanced functionality with kwargs, and examples of this can be found at <a href="https://docs.python.org/3.7/faq/programming.html#how-can-i-pass-optional-or-keyword-parameters-from-one-function-to-another">https://docs.python.org/3.7/faq/programming.html</a>. We have the following code:</p>
<pre>370     args_dict = {'custodian': args.CUSTODIAN,<br/>371                  'target': arg_source, 'db': args.DB_PATH}<br/>372 <br/>373     main(**args_dict)</pre>
<p>Refer to the following flowchart to understand how each function is linked together:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-491 image-border" src="img/07b28043-e7ad-4163-8fa5-5b1778dbea1b.png" style="width:113.08em;height:41.75em;"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Building the main() function</h1>
                
            
            
                
<p>The <kbd>main()</kbd> function is broken up into two phases: database initialization and input/output (I/O) processing. Database initialization, inclusive of the docstring, occurs on lines 46 through 57, where we define and document the inputs for the function. Note that the input variables match the keys of the <kbd>args_dict</kbd> that is passed as a keyword argument to the function. If <kbd>args_dict</kbd> did not have those exact keys defined, we would receive a <kbd>TypeError</kbd> when calling the function. See the following code:</p>
<pre>046 def main(custodian, target, db):<br/>047     """<br/>048     The main function creates the database or table, logs<br/>049         execution status, and handles errors<br/>050     :param custodian: The name of the custodian<br/>051     :param target: tuple containing the mode 'input' or 'output'<br/>052         as the first elemnet and a file path as the second<br/>053     :param db: The filepath for the database<br/>054     :return: None<br/>055     """</pre>
<p>On line 57, we call the <kbd>init_db()</kbd> function, passing the path to the database and assigning the returned database connection to the <kbd>conn</kbd> variable. The database connection object is handled by the <kbd>sqlite3</kbd> Python library. We use this object to communicate with the database by translating all calls from Python into SQL. With the connection object, we can call the cursor object. A cursor is an object that is used to send and receive data through the connection; we will define it in the functions where we want to interact with the database, since we want to keep cursors limited in scope, whereas we can share the database connection between functions:</p>
<pre>056     logger.info('Initiating SQLite database: ' + db)<br/>057     conn = init_db(db)</pre>
<p>After additional logging, we call <kbd>get_or_add_custodian()</kbd>, passing the connection object and custodian name to the function. By passing the open connection, we allow the function to interact with the database and define its own cursor. If the <kbd>custodian_id</kbd> is found, we move forward and skip the <kbd>while</kbd> loop on line 61; otherwise, we rerun the <kbd>get_or_add_custodian()</kbd> function until we have added the custodian and retrieved a custodian ID:</p>
<pre>058     logger.info('Initialization Successful')<br/>059     logger.info('Retrieving or adding custodian: ' + custodian)<br/>060     custodian_id = get_or_add_custodian(conn, custodian)<br/>061     while not custodian_id:<br/>062         custodian_id = get_or_add_custodian(conn, custodian)<br/>063     logger.info('Custodian Retrieved')</pre>
<p>Once we have a custodian ID to work with, we need to determine whether the source is specified as input or output. If on line 64 the source is an <kbd>input</kbd>, then we run the <kbd>ingest_directory()</kbd> function, which iterates through the provided root directory and gathers associated metadata about any subfiles. Once complete, we commit (save) our changes to the database and log its completion:</p>
<pre>064     if target[0] == 'input':<br/>065         logger.info('Ingesting base input directory: {}'.format(<br/>066             target[1]))<br/>067         ingest_directory(conn, target[1], custodian_id)<br/>068         conn.commit()<br/>069         logger.info('Ingest Complete')</pre>
<p>If the source is an <kbd>output</kbd>, the <kbd>write_output()</kbd> function is called to handle writing the output in the specified format. If the source type cannot be determined, we raise an <kbd>argparse.ArgumentError</kbd> error, stating that the arguments cannot be interpreted. After running the desired mode, we end the function by closing our database connections and log completion of the script, as follows:</p>
<pre>070     elif target[0] == 'output':<br/>071         logger.info('Preparing to write output: ' + target[1])<br/>072         write_output(conn, target[1], custodian)<br/>073     else:<br/>074         raise argparse.ArgumentError(<br/>075             'Could not interpret run time arguments')<br/>076 <br/>077     conn.close()<br/>078     logger.info('Script Completed')</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Initializing the database with the init_db() function</h1>
                
            
            
                
<p>The <kbd>init_db()</kbd> function is called on line 87 of the <kbd>main()</kbd> function to perform the basic tasks of creating the database and the initial structure within it. First, we need to check whether the database already exists, and if it does, connect to it and return the connection object. Regardless of whether a file exists or not, we can use the <kbd>sqlite3</kbd> library's <kbd>connect()</kbd> method to open or create a file as a database. This connection is used to allow communication between Python objects and the database. We also specifically use a cursor object, assigned as <kbd>cur</kbd> on line 94, to keep track of the position we are at among executed statements. This cursor is required to interact with our database:</p>
<pre>081     def init_db(db_path):<br/>082     """<br/>083     The init_db function opens or creates the database<br/>084     :param db_path: The filepath for the database<br/>085     :return: conn, the sqlite3 database connection<br/>086     """<br/>087     if os.path.exists(db_path):<br/>088         logger.info('Found Existing Database')<br/>089         conn = sqlite3.connect(db_path)<br/>090     else:<br/>091         logger.info('Existing database not found. '<br/>092                     'Initializing new database')<br/>093         conn = sqlite3.connect(db_path)<br/>094         cur = conn.cursor()</pre>
<p>If the database does not exist, then we must create a new database, connect to it, and initialize the tables. As mentioned in the SQL section of this chapter, we must create these tables by using the <kbd>CREATE TABLE</kbd> statement, followed by the column names and their data types. In the <kbd>Custodians</kbd> table, we need to create an auto-incrementing <kbd>id</kbd> column to provide an identifier for the <kbd>name</kbd> column, which will hold the custodian's names.</p>
<p>To do this, we must first build our query in the <kbd>sql</kbd> variable on line 96. After assignment, we pass this variable to the <kbd>cur.execute()</kbd> method, which executes our SQL statement through the cursor object. At this point, the cursor talks to the connection object from before, which then communicates with the database. Take a look at the following code:</p>
<pre>096         sql = """CREATE TABLE Custodians (<br/>097                  cust_id INTEGER PRIMARY KEY, name TEXT);"""<br/>098         cur.execute(sql)</pre>
<p>On line 99, we create another SQL query using <kbd>PRAGMA</kbd>, which allows us to modify the database's configuration. By default, in SQLite3, foreign keys are disabled, preventing us from referencing data from one table in another. Using the <kbd>PRAGMA</kbd> statement, we can enable this feature for our database by setting <kbd>foreign_keys</kbd> to <kbd>1</kbd>:</p>
<pre>099         cur.execute('PRAGMA foreign_keys = 1;')</pre>
<p>We repeat the table creation process for the <kbd>Files</kbd> table, adding many more fields to account for the file metadata. On lines 100 through 105, we write out the list of field names and their associated data types. We are able to wrap this string across multiple lines by using triple quotes and have Python interpret it as a single string value. As we've already seen, we need columns to store an ID (in a similar fashion to the <kbd>Custodians</kbd> table), the filename, file path, extension, size, modified time, created time, accessed time, mode, and inode number.</p>
<p>The <kbd>mode</kbd> attribute specifies the permissions of the file and is based on the UNIX permissions standard, whereas the <kbd>inode</kbd> attribute is the unique number that identifies filesystem objects in UNIX-based systems. Both of these elements are further described in the <em>Understanding the ingest_directory() function</em> section, where they are extracted from the files. After creating the two tables and defining their structures, we execute the final SQL statement on line 106 and return the connection object:</p>
<pre>100         sql = """CREATE TABLE Files(id INTEGER PRIMARY KEY,<br/>101             custodian INTEGER NOT NULL, file_name TEXT,<br/>102             file_path TEXT, extension TEXT, file_size INTEGER,<br/>103             mtime TEXT, ctime TEXT, atime TEXT, mode TEXT,<br/>104             inode INTEGER, FOREIGN KEY (custodian)<br/>105             REFERENCES Custodians(cust_id));"""<br/>106         cur.execute(sql)<br/>107         conn.commit()<br/>108     return conn</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Checking for custodians with the get_or_add_custodian() function</h1>
                
            
            
                
<p>At this point, the database is initialized and ready for further interaction. The <kbd>get_or_add_custodian()</kbd> function is called to check for the existence of the custodian and to pass along the ID if it is found. If the custodian does not exist, the function will add the custodian to the <kbd>Custodians</kbd> table. On line 120, we call the <kbd>get_custodian()</kbd> function to check and see whether the custodian exists. On line 122, we use a conditional to check whether <kbd>id</kbd> is not empty, and if so, assign the ID of the custodian to the <kbd>cust_id</kbd> variable. The SQLite library returns tuples for backward compatibility, the first element of which will be our ID of interest:</p>
<pre>111 def get_or_add_custodian(conn, custodian):<br/>112     """<br/>113     The get_or_add_custodian function checks the database for a<br/>114         custodian and returns the ID if present;<br/>115         Or otherwise creates the custodian<br/>116     :param conn: The sqlite3 database connection object<br/>117     :param custodian: The name of the custodian<br/>118     :return: The custodian ID or None<br/>119     """<br/>120     cust_id = get_custodian(conn, custodian)<br/>121     cur = conn.cursor()<br/>122     if cust_id:<br/>123         cust_id = cust_id[0]</pre>
<p>If the custodian is not found, we insert it into the table for future use. In lines 125-126, we craft a SQL statement to insert the custodian into the <kbd>Custodians</kbd> table. Note the <kbd>null</kbd> string in the <kbd>VALUES</kbd> section; this is interpreted by SQLite as a <kbd>NoneType</kbd> object. SQLite converts <kbd>NoneType</kbd> objects in our primary key field to an auto-incrementing integer. Following the <kbd>null</kbd> value is our custodian string. SQLite requires that string values be wrapped in quotes, similar to Python.</p>
<p>We must use double quotes to wrap our query that contains single quotes. This prevents any issues with a string breaking due to an error with the quotes. If you see a syntax error in this section of the code, be sure to check the quotes used on lines 125-126.</p>
<p>Finally, we execute this statement and return the empty <kbd>cust_id</kbd> variable so that the <kbd>main()</kbd> function will have to check for the custodian in the database again and rerun this function. The next pass should detect our inserted value and allow the <kbd>main()</kbd> function to proceed. We have the following code:</p>
<pre>124     else:<br/>125         sql = """INSERT INTO Custodians (cust_id, name) VALUES<br/>126             (null, '{}') ;""".format(custodian)<br/>127         cur.execute(sql)<br/>128         conn.commit()<br/>129     return cust_id</pre>
<p>Although we could call the <kbd>get_custodian()</kbd> function here (or grab the ID after the insert) for validation purposes, we have the <kbd>main()</kbd> function check for the custodian again. Feel free to implement one of these alternative solutions and see in what ways it impacts the performance and stability of the code.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Retrieving custodians with the get_custodian() function</h1>
                
            
            
                
<p>The <kbd>get_custodian()</kbd> function is called to retrieve the custodian ID from the SQLite database. Using a simple <kbd>SELECT</kbd> statement, we select the <kbd>id</kbd> column from the <kbd>Custodian</kbd> table, where we match the name provided by the user to the <kbd>name</kbd> column. We use the string <kbd>format()</kbd> method to insert the custodian name into the SQL statement. Note that we still have to wrap the inserted string in single quotes, as follows:</p>
<pre>132     def get_custodian(conn, custodian):<br/>133     """<br/>134     The get_custodian function checks the database for a<br/>135         custodian and returns the ID if present<br/>136     :param conn: The sqlite3 database connection object<br/>137     :param custodian: The name of the custodian<br/>138     :return: The custodian ID<br/>139     """<br/>140     cur = conn.cursor()<br/>141     sql = "SELECT cust_id FROM Custodians "\<br/>142         "WHERE name='{}';".format(custodian)</pre>
<p>After executing this statement, we use the <kbd>fetchone()</kbd> method on line 144 to return a single result from the statement. This is the first time our script requests data out of the database. To acquire data, we use any of the <kbd>fetchone()</kbd>, <kbd>fetchmany()</kbd>, or <kbd>fetchall()</kbd> functions to gather data from the executed statement. These three methods are only available to the cursor object. The <kbd>fetchone()</kbd> method is the better option here as we anticipate a single custodian to be returned by this statement. This custodian ID is captured and returned in the <kbd>data</kbd> variable:</p>
<pre>143     cur.execute(sql)<br/>144     data = cur.fetchone()<br/>145     return data</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Understanding the ingest_directory() function</h1>
                
            
            
                
<p>The <kbd>ingest_directory()</kbd> function handles the input mode for our script and recursively captures the metadata of files from a user-supplied root directory. On line 158, we set up our database cursor before a <kbd>count</kbd> variable, which will keep count of the number of files stored in the <kbd>Files</kbd> table:</p>
<pre>148     def ingest_directory(conn, target, custodian_id):<br/>149     """<br/>150     The ingest_directory function reads file metadata and stores<br/>151         it in the database<br/>152     :param conn: The sqlite3 database connection object<br/>153     :param target: The path for the root directory to<br/>154         recursively walk<br/>155     :param custodian_id: The custodian ID<br/>156     :return: None<br/>157     """<br/>158     cur = conn.cursor()<br/>159     count = 0</pre>
<p>The most important part of this function is the <kbd>for</kbd> loop on line 160. This loop uses the <kbd>os.walk()</kbd> method to break apart a provided directory path into an iterative array that we can step through. There are three components of the <kbd>os.walk()</kbd> method. They are generally named <kbd>root</kbd>, <kbd>folders</kbd>, and <kbd>files</kbd>. The <kbd>root</kbd> value is a string that represents the path of the base directory we are currently walking during the specific loop iteration. As we traverse through subfolders, they will be appended to the root value. The <kbd>folders</kbd> and <kbd>files</kbd> variables provide lists of folder and filenames within the current root, respectively. Although these variables may be renamed as you see fit, this is a good naming convention to prevent overwriting Python statements, such as <kbd>file</kbd> or <kbd>dir</kbd>, which are already used in Python. In this instance, though, we do not need the <kbd>folders</kbd> list from <kbd>os.walk()</kbd>, so we will name it as a single underscore (<kbd>_</kbd>):</p>
<pre>160     for root, _, files in os.walk(target):</pre>
<p>This is a common practice for assigning a value to a variable that is unused in the code. For this reason, only use a single underscore to represent unused data. Where possible, try to redesign your code to not return unwanted values.</p>
<p>Within the loop, we begin iterating over the <kbd>files</kbd> list to access information about each file. On line 162, we create a file-specific dictionary, <kbd>meta_data</kbd>, to store the collected information, as follows:</p>
<pre>161         for file_name in files:<br/>162             meta_data = dict()</pre>
<p>On line 163, we use a try-except clause to catch any exceptions. We know we said not to do that, but hear us out first. This catch-all is in place so that any error within a discovered file does not cause the script to crash and stop. Instead, the filename and error will be written to the log before skipping that file and continuing execution. This can help an examiner quickly locate and troubleshoot specific files. This is important as some errors may occur on Windows systems due to filesystem flags and naming conventions that cause errors in Python. Different errors will then occur on macOS and Linux/UNIX systems, making it hard to predict all of the instances where the script will crash. This is an excellent example of why logging is important, as we can review errors that have been generated by our script.</p>
<p>Within the try-except clause, we store the different properties of the file's metadata to keys. To begin, we record the filename and full path on lines 163 and 164. Note how the dictionary keys share the name with the columns they belong to in the <kbd>Files</kbd> table. This format will make our lives easier later in the script. The file path is stored using the <kbd>os.path.join()</kbd> method, which combines separate paths into a single one using the operating system's specific path separator.</p>
<p class="mce-root">On line 167, we gather the file extension by using the <kbd>os.path.splitext()</kbd> method to split the extension after the last <kbd>.</kbd> in the filename. Since this function on line 167 creates a list, we select the last element to ensure that we store the extension. In some situations, the file may not have an extension (for example, a <kbd>.DS_Store</kbd> file), in which case the last value in the returned list is an empty string. Be aware that this script does not check file signatures to confirm that the file type matches the extension; the process of checking file signatures can be automated:</p>
<pre>163             try:<br/>164                 meta_data['file_name'] = file_name<br/>165                 meta_data['file_path'] = os.path.join(root,<br/>166                                                       file_name)<br/>167                 meta_data['extension'] = os.path.splitext(<br/>168                     file_name)[-1]</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Exploring the os.stat() method</h1>
                
            
            
                
<p>On line 170, we use <kbd>os.stat()</kbd> to collect our metadata for the file. This method reaches out to the system's <kbd>stat</kbd> library to gather information about the supplied file. By default, this method returns an object with all of the available data gathered about each file. Because this information varies between platforms, we have selected only the most cross-platform properties for our script, as defined in the <kbd>os</kbd> library documentation; more information can be found at <a href="https://docs.python.org/3/library/os.html#os.stat_result">https://docs.python.org/3/library/os.html#os.stat_result</a>. This list includes creation time, modified time, accessed time, file mode, file size, inode number, and mode. SQLite will accept the data types in string format, though we will store them in the script with the correct data types in case we need to modify them or use special characteristics of the specific types.</p>
<p>The file mode is best displayed as an octal integer, so we must use the Python <kbd>oct()</kbd> function to convert it into a readable state, as shown on line 171:</p>
<pre>170                 file_stats = os.stat(meta_data['file_path'])<br/>171                 meta_data['mode'] = str(oct(file_stats.st_mode))</pre>
<p>The file mode is a three-digit integer representing the read, write, and execute permissions of a file object. The permissions are defined in the following table and use the numbers 0-7 to determine the permissions that are assigned. Each digit represents permissions for the file's owner, the group the file is assigned to, and all other users. The number 777, for example, allows full permissions to anyone, and 600 means that only the owner can read and write to the file. Beyond each individual digit, octal representation allows us to assign additional permissions for a file by adding digits. For example, the value 763 grants the owner full permissions (700), read and write permissions to the group (040 + 020), and write and execute permissions to everyone else (002 + 001). You will probably never see 763 as a permission set, though it makes for a fun example here:</p>
<table border="1" style="border-collapse: collapse;width: 80.055%">
<tbody>
<tr>
<td style="width: 13%">
<p class="TableColumnHeadingPACKT"><strong>Permission</strong></p>
</td>
<td style="width: 65.1653%">
<p class="TableColumnHeadingPACKT CDPAlignLeft CDPAlign"><strong>Description</strong></p>
</td>
</tr>
<tr>
<td style="width: 13%">
<p class="TableColumnContentPACKT">700</p>
</td>
<td style="width: 65.1653%">
<p class="TableColumnContentPACKT">Full file owner permissions</p>
</td>
</tr>
<tr>
<td style="width: 13%">
<p class="TableColumnContentPACKT">400</p>
</td>
<td style="width: 65.1653%">
<p class="TableColumnContentPACKT">An owner has read permission</p>
</td>
</tr>
<tr>
<td style="width: 13%">
<p class="TableColumnContentPACKT">200</p>
</td>
<td style="width: 65.1653%">
<p class="TableColumnContentPACKT">An owner has write permission</p>
</td>
</tr>
<tr>
<td style="width: 13%">
<p class="TableColumnContentPACKT">100</p>
</td>
<td style="width: 65.1653%">
<p class="TableColumnContentPACKT">An owner has execute permission</p>
</td>
</tr>
<tr>
<td style="width: 13%">
<p class="TableColumnContentPACKT">070</p>
</td>
<td style="width: 65.1653%">
<p class="TableColumnContentPACKT">Full group permissions</p>
</td>
</tr>
<tr>
<td style="width: 13%">
<p class="TableColumnContentPACKT">040</p>
</td>
<td style="width: 65.1653%">
<p class="TableColumnContentPACKT">A group has read permission</p>
</td>
</tr>
<tr>
<td style="width: 13%">
<p class="TableColumnContentPACKT">020</p>
</td>
<td style="width: 65.1653%">
<p class="TableColumnContentPACKT">A group has write permission</p>
</td>
</tr>
<tr>
<td style="width: 13%">
<p class="TableColumnContentPACKT">010</p>
</td>
<td style="width: 65.1653%">
<p class="TableColumnContentPACKT">A group has execute permission</p>
</td>
</tr>
<tr>
<td style="width: 13%">
<p class="TableColumnContentPACKT">007</p>
</td>
<td style="width: 65.1653%">
<p class="TableColumnContentPACKT">Full permissions for others (not in the group or the owner)</p>
</td>
</tr>
<tr>
<td style="width: 13%">
<p class="TableColumnContentPACKT">004</p>
</td>
<td style="width: 65.1653%">
<p class="TableColumnContentPACKT">Others have read permission</p>
</td>
</tr>
<tr>
<td style="width: 13%">
<p class="TableColumnContentPACKT">002</p>
</td>
<td style="width: 65.1653%">
<p class="TableColumnContentPACKT">Others have write permission</p>
</td>
</tr>
<tr>
<td style="width: 13%">
<p class="TableColumnContentPACKT">001</p>
</td>
<td style="width: 65.1653%">
<p class="TableColumnContentPACKT">Others have execute permission</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>The following table shows additional file type information, which is provided by Python's <kbd>os.stat()</kbd> method. The three-hashes in the table indicate where the file permissions we just discussed are located within the number. The first two rows of the following table are self-explanatory, and symbolic links represent references to other locations in a filesystem. For example, in the following table, the value 100777 represents a regular file, with full permissions for the owner, groups, and anyone else. Although it may take time to get accustomed to this, this system is very useful for identifying the permissions of files and who has access to them:</p>
<table border="1" style="border-collapse: collapse;width: 30.674%">
<tbody>
<tr>
<td style="width: 13%">
<p class="TableColumnHeadingPACKT"><strong>File type</strong></p>
</td>
<td style="width: 15.7163%">
<p class="TableColumnHeadingPACKT"><strong>Description</strong></p>
</td>
</tr>
<tr>
<td style="width: 13%">
<p class="TableColumnContentPACKT">040###</p>
</td>
<td style="width: 15.7163%">
<p class="TableColumnContentPACKT">Directory</p>
</td>
</tr>
<tr>
<td style="width: 13%">
<p class="TableColumnContentPACKT">100###</p>
</td>
<td style="width: 15.7163%">
<p class="TableColumnContentPACKT">Regular file</p>
</td>
</tr>
<tr>
<td style="width: 13%">
<p class="TableColumnContentPACKT">120###</p>
</td>
<td style="width: 15.7163%">
<p class="TableColumnContentPACKT">Symbolic link</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>The <kbd>inode</kbd> value, a unique identifier of filesystem objects, is the next value we will capture on line 172. Although this is a feature that's only found in Linux/UNIX/macOS-based systems, Python converts the record number for NTFS into the same object for uniformity. On line 173, we assign the file size, which is represented by the number of allocated bytes as an integer. On lines 174 through 179, we assign the accessed, modified, and created timestamps to the dictionary, in that order. Each timestamp is converted from a float into a string using our <kbd>format_timestamps()</kbd> function. We have now collected the necessary data to complete a row in our <kbd>Files</kbd> table:</p>
<pre>172                 meta_data['inode'] = int(file_stats.st_ino)<br/>173                 meta_data['file_size'] = int(file_stats.st_size)<br/>174                 meta_data['atime'] = format_timestamp(<br/>175                     file_stats.st_atime)<br/>176                 meta_data['mtime'] = format_timestamp(<br/>177                     file_stats.st_mtime)<br/>178                 meta_data['ctime'] = format_timestamp(<br/>179                     file_stats.st_ctime)</pre>
<p>The exception mentioned earlier in this section is defined on line 180 and logs any errors that are encountered while collecting metadata:</p>
<pre>180             except Exception as e:<br/>181                 logger.error(<br/>182                     'Error processing file: {} {}'.format(<br/>183                         meta_data.get('file_path', None),<br/>184                         e.__str__()))</pre>
<p>Lastly, outside of our try-except clause, we add the <kbd>custodian_id</kbd> to our <kbd>meta_data</kbd> dictionary so that we can store it alongside our record. We can now construct our SQL statement for inserting the new file metadata record. As we saw previously, we will construct an insert statement on line 186 and add placeholders for the column and value names. Using the <kbd>.format()</kbd> method, we will insert our <kbd>meta_data</kbd> key and value data. On line 187, we join the <kbd>meta_data</kbd> keys into a string where each key is separated by double quotes and a comma. On line 188, we join a comma-separated list of commas, inserting one question mark per value as a placeholder for our <kbd>execute()</kbd> call. An example of the generated string in the <kbd>sql</kbd> variable is shown here:</p>
<pre>INSERT INTO Files<br/>    ("custodian","ctime","mtime","extension","inode",<br/>     "file_size","file_name","mode","atime","file_path")<br/>VALUES <br/>    (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)</pre>
<p>This allows us to then provide a list of our values, as seen within the try block on lines 189-190, to the SQLite3 Python library to craft the correct insert statement for the database. We need to convert our dictionary values into a tuple for support with SQLite3, as shown in the call on line 190:</p>
<pre>185             meta_data['custodian'] = custodian_id<br/>186             sql = 'INSERT INTO Files ("{}") VALUES ({})'.format(<br/>187                 '","'.join(meta_data.keys()),<br/>188                 ', '.join('?' for x in meta_data.values()))<br/>189             try:<br/>190                 cur.execute(sql, tuple(meta_data.values()))</pre>
<p>Now, we can close our except clause and provide error handling and logging for SQLite3 library errors on lines 191 through 197. After our error handling, we increment our file processing count by 1 and move to the next file, which can be found in either of our two for loops:</p>
<pre>191             except (sqlite3.OperationalError,<br/>192                     sqlite3.IntegrityError) as e:<br/>193                 logger.error(<br/>194                     "Could not insert statement {}"<br/>195                     " with values: {}".format(<br/>196                         sql, meta_data.values()))<br/>197                 logger.error("Error message: {}".format(e))<br/>198             count += 1</pre>
<p>Once our innermost for loop completes, we use the <kbd>commit()</kbd> method to save the new records in our database. We also run the <kbd>commit()</kbd> method again once our outer for loop finishes, before logging that the directory ingestion is complete and providing the user with a count of files handled:</p>
<pre>199         conn.commit()<br/>200     conn.commit()<br/>201     logger.info('Stored meta data for {} files.'.format(count))</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Developing the format_timestamp() helper function</h1>
                
            
            
                
<p>This comparatively small function interprets integer timestamps as human-readable strings. Because the Python <kbd>os.stat()</kbd> module returns the time as a count of seconds since the epoch, 1/1/1970, we need to use the <kbd>datetime</kbd> library to perform this transformation. Using the <kbd>datetime.datetime.fromtimestamp()</kbd> function, we can parse the float to a <kbd>datetime</kbd> object, which we name <kbd>ts_datetime</kbd> on line 211. With the date as a <kbd>datetime</kbd> object, we can now use the <kbd>strftime()</kbd> method to format the date using our desired format, <kbd>YYYY-MM-DD HH:MM:SS</kbd>, on line 212. With the string ready to be inserted into the database, we return the value to the calling function:</p>
<pre>204 def format_timestamp(timestamp):<br/>205     """<br/>206     The format_timestamp function formats an integer to a string<br/>207     timestamp<br/>208     :param timestamp: An integer timestamp<br/>209     :return: ts_format, a formatted (YYYY-MM-DD HH:MM:SS) string<br/>210     """<br/>211     ts_datetime = datetime.datetime.fromtimestamp(timestamp)<br/>212     ts_format = ts_datetime.strftime('%Y-%m-%d %H:%M:%S')<br/>213     return ts_format</pre>
<p>Short utility functions like this are useful to incorporate into larger scripts. One advantage is that if we wanted to update our date format, we only have to change it in one location, versus finding every use of <kbd>strftime()</kbd>. This smaller function also increases the readability of our code. The <kbd>ingest_directory()</kbd> function is already pretty sizable, and adding this logic three times over could become confusing to the next person to review the code. These functions are useful in string formatting or common conversions, though as you are designing your own script, consider what utility functions you can create to make your life easier.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Configuring the write_output() function</h1>
                
            
            
                
<p>If the output destination is specified by the user, the <kbd>write_output()</kbd> function is called. Once invoked, we select the custodian ID from the database using the <kbd>get_custodian()</kbd> function, which is called on line 225. If found, we need to build a new query to determine the number of files associated with the custodian using the <kbd>COUNT()</kbd> SQL function. If the custodian is not found, an error is logged to alert the user that the custodian was unresponsive, as we can see on lines 234 through 237:</p>
<pre>216 def write_output(conn, target, custodian):<br/>217     """<br/>218     The write_output function handles writing either the CSV or<br/>219     HTML reports<br/>220     :param conn: The sqlite3 database connection object<br/>221     :param target: The output filepath<br/>222     :param custodian: Name of the custodian<br/>223     :return: None<br/>224     """<br/>225     custodian_id = get_custodian(conn, custodian)<br/>226     cur = conn.cursor()<br/>227     if custodian_id:<br/>228         custodian_id = custodian_id[0]<br/>229         sql = "SELECT COUNT(id) FROM Files "\<br/>230               "where custodian = {}".format(<br/>231                   custodian_id)<br/>232         cur.execute(sql)<br/>233         count = cur.fetchone()<br/>234     else:<br/>235         logger.error(<br/>236             'Could not find custodian in database. Please check '<br/>237             'the input of the custodian name and database path')</pre>
<p>If the custodian is found and the number of stored files is greater than zero, we check what type of report to generate. The conditional statements starting on line 239 check the size of <kbd>count</kbd> and the extension of the source. If <kbd>count</kbd> is not greater than zero or does not contain a value, then an error is logged on line 240. Otherwise, we check for the CSV file extension on line 241 and the HTML file extension on line 243, calling the respective function if we find a match. If the source does not end in either of those file extensions, then an error is logged, stating that the file type could not be determined. Finally, if the code reaches the else statement on line 247, we log the fact that an unknown error occurred. We can see all of this in the following code:</p>
<pre>239     if not count or not count[0] &gt; 0:<br/>240         logger.error('Files not found for custodian')<br/>241     elif target.endswith('.csv'):<br/>242         write_csv(conn, target, custodian_id)<br/>243     elif target.endswith('.html'):<br/>244         write_html(conn, target, custodian_id, custodian)<br/>245     elif not (target.endswith('.html')or target.endswith('.csv')):<br/>246         logger.error('Could not determine file type')<br/>247     else:<br/>248         logger.error('Unknown Error Occurred')</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Designing the write_csv() function</h1>
                
            
            
                
<p>If the file extension is CSV, we can start iterating through the entries stored in the Files table. The SQL statement on line 261 uses the <kbd>WHERE</kbd> statement to identify only files related to the specific custodian. The <kbd>cur.description</kbd> value that's returned is a tuple of tuples, with eight elements in each of the nested tuples, representing our column names. The first value in each tuple is the column name, whereas the remaining seven are empty strings that are left in place for backward compatibility purposes. Using list comprehension on line 265, we iterate through these tuples and build the list of column names by selecting only the first element from each item in the returned tuples. This one-line statement allows us to condense a simple for loop into a single statement that generates the desired list:</p>
<pre>251 def write_csv(conn, target, custodian_id):<br/>252     """<br/>253     The write_csv function generates a CSV report from the<br/>254     Files table<br/>255     :param conn: The Sqlite3 database connection object<br/>256     :param target: The output filepath<br/>257     :param custodian_id: The custodian ID<br/>258     :return: None<br/>259     """<br/>260     cur = conn.cursor()<br/>261     sql = "SELECT * FROM Files where custodian = {}".format(<br/>262         custodian_id)<br/>263     cur.execute(sql)<br/>264 <br/>265     cols = [description[0] for description in cur.description]</pre>
<p>A list comprehension is a succinct method for generating a list with a single-line for loop. These are generally used to filter the content of a list or provide some form of transformation. On line 265, we are using it to perform a structural transformation, extracting only the first item from each element of the <kbd>cur.description</kbd> list and storing it as columns. This is because the Python SQLite bindings return the column names as a nested tuple where the first element of each subtuple is the column's name.</p>
<p>With the column names prepared, we log that the CSV report is being written and open the output file in <kbd>wb</kbd> mode on line 267. We then initialize a writer by calling the <kbd>csv.writer()</kbd> method on line 268 and passing the file object. After this file is opened, we write the column rows by calling on the <kbd>csv_writer</kbd> object to <kbd>writerow()</kbd>, which writes a single row.</p>
<p>At this point, we will loop through the results by iterating over the cursor, where it will return a row for each iteration of the loop until exiting when no more rows are responsive to the original query. For each row that's returned, we need to call the <kbd>writerow()</kbd> method again, as shown on line 272. We then flush the new data to the file on line 273 to ensure that the data is written to disk. Finally, we log that the report is complete and stored at the user-specified location. We have the following code:</p>
<pre>266     logger.info('Writing CSV report')<br/>267     with open(target, 'w', newline="") as csv_file:<br/>268         csv_writer = csv.writer(csv_file)<br/>269         csv_writer.writerow(cols)<br/>270 <br/>271         for entry in cur:<br/>272             csv_writer.writerow(entry)<br/>273         csv_file.flush()<br/>274     logger.info('CSV report completed: ' + target)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Composing the write_html() function</h1>
                
            
            
                
<p>If the user specifies an HTML report, the <kbd>write_html()</kbd> function is called to read data from the database, generate the HTML tags for our data, and, using Bootstrap styling, create a table with our file metadata. Because this is HTML, we can customize it to create a professional-looking report that can be converted into a PDF or viewed by anyone with a web browser. If additional HTML elements prove to be useful in your version of the report, they can easily be added to the following strings and customized with logos, highlighting by extension, responsive tables, graphs, and much more, which is possible if you use various web styles and scripts.</p>
<p>Since this book is focused on the design of Python scripts, we won't be diving into detail about HTML, CSS, or other web design languages. Where we use these features, we will describe the basics of why they are used and how to implement them, though we recommend using related resources (such as <a href="http://www.w3schools.com">http://www.w3schools.com</a>) to learn more about those topics if they are of interest to you.</p>
<p class="mce-root"/>
<p>This function begins similarly to <kbd>write_csv()</kbd>: we select the files that belong to the custodian in a SQL statement on line 287. Once executed, we again gather our <kbd>cols</kbd> using list comprehension on line 291. With our column names, we define the <kbd>table_header</kbd> HTML string using the <kbd>join()</kbd> function on our list and separating each value with <kbd>&lt;th&gt;&lt;/th&gt;</kbd> tags on line 292. For all except the first and last element, this will enclose each element in a <kbd>&lt;th&gt;{{ element }}&lt;/th&gt;</kbd> tag. Now, we need to close the first and last element tags to ensure that they form the proper table header. For the beginning of the string, we append the <kbd>&lt;tr&gt;&lt;th&gt;</kbd> tags to define the table row <kbd>&lt;tr&gt;</kbd> for the entire row, and the table header <kbd>&lt;th&gt;</kbd> for the first entry. Likewise, we close the table header and table row tags at the end of the string on line 293, as follows:</p>
<pre>277 def write_html(conn, target, custodian_id, custodian_name):<br/>278     """<br/>279     The write_html function generates an HTML report from the<br/>280         Files table<br/>281     :param conn: The sqlite3 database connection object<br/>282     :param target: The output filepath<br/>283     :param custodian_id: The custodian ID<br/>284     :return: None<br/>285     """<br/>286     cur = conn.cursor()<br/>287     sql = "SELECT * FROM Files where custodian = {}".format(<br/>288         custodian_id)<br/>289     cur.execute(sql)<br/>290 <br/>291     cols = [description[0] for description in cur.description]<br/>292     table_header = '&lt;/th&gt;&lt;th&gt;'.join(cols)<br/>293     table_header = '&lt;tr&gt;&lt;th&gt;' + table_header + '&lt;/th&gt;&lt;/tr&gt;'<br/>294 <br/>295     logger.info('Writing HTML report')</pre>
<p>On line 297, we open our HTML file in <kbd>w</kbd> mode as the <kbd>html_file</kbd> variable. With the file open, we begin to build our HTML code, starting with the <kbd>&lt;html&gt;&lt;body&gt;</kbd> tags that are used to initialize HTML documents on line 298. Next, we connect to the custom style sheet that's hosted online to provide the Bootstrap styles for our table. We do this by using the <kbd>&lt;link&gt;</kbd> tag, with the type and the source of the style sheet, which is located at <a href="https://www.bootstrapcdn.com/">https://www.bootstrapcdn.com/</a>. </p>
<p>Now, let's define the header of our HTML report so that we can ensure it contains the custodian ID and name. We will do this by using the <kbd>&lt;h1&gt;&lt;/h1&gt;</kbd> or heading 1 tags. For our table, we use the table tags on line 302 and the Bootstrap styles (<kbd>table</kbd>, <kbd>table-hover</kbd>, and <kbd>table-striped</kbd>) we would like to implement.</p>
<p>For additional information on Bootstrap, visit <a href="http://getbootstrap.com">http://getbootstrap.com</a>. While this script uses Bootstrap CSS version 3.3.5, explore the more recent updates to Bootstrap and see if you can implement the newer features in your code.</p>
<p>With this header information in the HTML string, we can write it to the file, first writing the HTML header and style sheet information on line 304, followed by the column names for our table on line 305, as follows:</p>
<pre>297     with open(target, 'w') as html_file:<br/>298         html_string = """&lt;html&gt;&lt;body&gt;\n<br/>299             &lt;link rel="stylesheet"<br/>300             href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css"&gt;<br/>301             &lt;h1&gt;File Listing for Custodian ID: {}, {}&lt;/h1&gt;\n<br/>302             &lt;table class='table table-hover table-striped'&gt;\n<br/>303             """.format(custodian_id, custodian_name)<br/>304             html_file.write(html_string)<br/>305             html_file.write(table_header)</pre>
<p>Now, let's iterate over the records in the database and write them to the table as individual rows. We begin by joining each element in the table data tags (<kbd>&lt;td&gt;&lt;/td&gt;</kbd>) that specify the table cell content. We use list comprehension before joining the data on line 308 and converting it to the string value that the <kbd>join()</kbd> method requires:</p>
<pre>307         for entry in cur:<br/>308             row_data = "&lt;/td&gt;&lt;td&gt;".join(<br/>309                 [str(x) for x in entry])</pre>
<p>On line 310, we add a new line character (<kbd>\n</kbd>) followed by a <kbd>&lt;tr&gt;</kbd> table row tag and the initial <kbd>&lt;td&gt;</kbd> tag to open the table data for the first element. The newline character reduces the loading time in some HTML viewers, as it breaks the data into multiple lines. We also have to close the last table data tag and the entire table row, as seen at the end of line 310. The row data is written to the file on line 311. Finally, within the loop for the table rows, we <kbd>.flush()</kbd> the content to the file. With the table data built, we can close the table, body, and the HTML tags on line 313. Once outside of the <kbd>for</kbd> loop, we log the report's status and location on line 315:</p>
<pre>310             html_string = "\n&lt;tr&gt;&lt;td&gt;" + row_data + "&lt;/td&gt;&lt;/tr&gt;"<br/>311             html_file.write(html_string)<br/>312             html_file.flush()<br/>313         html_string = "\n&lt;/table&gt;\n&lt;/body&gt;&lt;/html&gt;"<br/>314         html_file.write(html_string)<br/>315     logger.info('HTML Report completed: ' + target)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Running the script</h1>
                
            
            
                
<p>In this iteration, we have highlighted the process that's required for reading all of the file metadata of a directory recursively, storing it into a database, extracting it out of the database, and generating reports from the data. This iteration uses basic libraries to handle the necessary SQL and HTML operations in a fairly manual fashion. The next iteration focuses on using Python objects to perform this same functionality. Both iterations are final versions of the scripts and are fully functional. The separate iterations demonstrate different methods to accomplish the same task.</p>
<p>To run our script, we need to first supply it with the name of the custodian, the location of the database to create or read from, and the desired mode. In the first example, we specify the input mode and pass the root directory to index. In the second example, we create a CSV report with the output mode and supply an appropriate file path:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-492 image-border" src="img/140d7386-f8f6-47a6-bbc6-8a426c4b6f17.png" style="width:129.83em;height:55.67em;"/></p>
<p>The output of the preceding script can be viewed in the following screenshot. Here, we have simply created a generic CSV report containing the captured metadata of the indexed files for this chapter's custodian:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-493 image-border" src="img/2065652c-8091-4818-aada-4df3ad1c2940.png" style="width:148.83em;height:26.50em;"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Automating databases further – file_lister_peewee.py</h1>
                
            
            
                
<p>In this iteration, we will use third-party Python modules to automate our SQL and HTML setup further. This will introduce extra overhead; however, our script will be simpler to implement and more streamlined, which will allow us to easily develop further functionality. Developing with an eye toward the future helps prevent us from rewriting the entire script for every minor feature request.</p>
<p>We have imported the majority of the standard libraries required in the prior version and added the third-party <kbd>unicodecsv</kbd> module (version 0.14.1). This module wraps around the built-in <kbd>csv</kbd> module and automatically provides Unicode support for the CSV output. To keep things familiar, we can even name it <kbd>csv</kbd> by using the <kbd>import...as...</kbd> statement on line 8. As mentioned previously in this chapter, <kbd>peewee</kbd> (version 2.8.0) and <kbd>jinja2</kbd> (version 2.8) are the two libraries that can handle our SQLite and HTML operations. As these last three imports are third-party libraries, they will need to be installed on the user's machine for our code to run properly and can be done so with <kbd>pip</kbd>:</p>
<pre>001 """File metadata capture and reporting utility."""<br/>002 import argparse<br/>003 import datetime<br/>004 from io import open<br/>005 import logging<br/>006 import os<br/>007 import sys<br/>008 import unicodecsv as csv<br/>009 import peewee<br/>010 import jinja2</pre>
<p>Following the import statements and license, we define our common script metadata and logging handler. On line 46, we add the <kbd>database_proxy</kbd> object, which is used to create the Peewee base model for the <kbd>Custodian</kbd> and <kbd>Files</kbd> class tables. We also add the <kbd>get_template()</kbd> function, which builds a template HTML table using <kbd>jinja2</kbd>. The other functions largely resemble their counterparts in the previous iteration, with minor adjustments here and there. However, we have removed the <kbd>get_custodian()</kbd> function as Peewee has that functionality builtin:</p>
<pre>040 __authors__ = ["Chapin Bryce", "Preston Miller"]<br/>041 __date__ = 20181027<br/>042 __description__ = '''This script uses a database to ingest and<br/>043     report meta data information about active entries in<br/>044     directories.'''<br/>045 logger = logging.getLogger(__name__)<br/>046 database_proxy = peewee.Proxy()<br/>047 <br/>048 class BaseModel(peewee.Model):<br/>...<br/>052 class Custodians(BaseModel):<br/>...<br/>055 class Files(BaseModel):<br/>...<br/>069 def get_template():<br/>...<br/>106 def main(custodian, target, db):<br/>...<br/>138 def init_db(db):<br/>...<br/>150 def get_or_add_custodian(custodian):<br/>...<br/>167 def ingest_directory(source, custodian_model):<br/>...<br/>216 def format_timestamp(ts):<br/>...<br/>226 def write_output(source, custodian_model):<br/>...<br/>253 def write_csv(source, custodian_model):<br/>...<br/>282 def write_html(source, custodian_model):</pre>
<p>The code block under the <kbd>if __name__ == '__main__'</kbd> conditional that defines command-line arguments and sets up logging is identical to the prior iteration. We will not repeat these implementation details here as we can simply copy and paste the section from the previous iteration, saving a few trees. While that section has remained unchanged, the overall flow of our script has seen minor modifications, as shown in the following flow diagram:</p>
<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-494 image-border" src="img/af060217-ae83-40fb-85b9-57a1bf674405.png" style="width:130.50em;height:50.08em;"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Peewee setup</h1>
                
            
            
                
<p>Peewee, the object relational manager library that was described at the beginning of this chapter, is excellent at database management in Python. It uses Python classes to define settings for the database, including table configurations, the location of the database, and how to handle different Python data types. On line 46, we must first create an anonymous database connection using the Peewee <kbd>Proxy()</kbd> class, which allows us to redirect the information into the previously specified format. This variable must be declared before any Peewee operations, as per its documentation (<a href="http://docs.peewee-orm.com/en/3.6.0/">http://docs.peewee-orm.com/en/3.6.0/</a>).</p>
<p>Following the initialization of the proxy, we define our first Python class used in this book, thus creating a <kbd>BaseModel</kbd> class that defines the database to use. As part of the Peewee specification, we must link the <kbd>database_proxy</kbd> to the <kbd>database</kbd> variable within the <kbd>Meta</kbd> class of our <kbd>BaseModel</kbd> object.</p>
<p>While this required configuration may not make the most sense at the moment, continue through the rest of this chapter and revisit this section after completing and running the script, as the purpose of these modules will become clearer. Additionally, the aforementioned documentation does an excellent job at demonstrating the features and the usage of Peewee.</p>
<p>We must include the base model, as defined on lines 48 through 50, as the minimum setup for Peewee to create the database:</p>
<pre>046 database_proxy = peewee.Proxy()<br/>047 <br/>048 class BaseModel(peewee.Model):<br/>049     class Meta:<br/>050         database = database_proxy</pre>
<p>Next, we create the <kbd>Custodians</kbd> table that's defined on line 60. This table inherits the <kbd>BaseModel</kbd> properties and therefore has the <kbd>BaseModel</kbd> class within its parentheses. This is usually used to define arguments that are needed for a function, but with classes, it can also allow us to assign a parent class to inherit data from. In this script, the <kbd>BaseModel</kbd> class is the child of <kbd>peewee.Model</kbd> and the parent to the <kbd>Custodians</kbd> and (soon to be discussed) <kbd>Files</kbd> tables. Keep in mind that Peewee describes tables as class models and that the library will be creating a table named <kbd>Custodians</kbd> for us; more on this in a bit.</p>
<p>After initialization, we add a text field, <kbd>name</kbd>, to the <kbd>Custodians</kbd> table on line 61. The <kbd>unique=True</kbd> keyword creates an auto-incrementing index column in addition to our <kbd>name</kbd> column. This table configuration will be used later to create the table, and then insert data into it and retrieve information out of it:</p>
<pre>052 class Custodians(BaseModel):<br/>053     name = peewee.TextField(unique=True)</pre>
<p>The <kbd>Files</kbd> table has many more fields and several new data types. As we already know, SQLite only manages the text, integers, none, and BLOB data types, and so a few of these types may look out of place. Using the <kbd>DateTimeField</kbd> as an example, Peewee can take any Python <kbd>date</kbd> or <kbd>datetime</kbd> object. Peewee will automatically store it as a text value in the database and can even preserve its original time zone. When the data is called out of the table, Peewee attempts to convert this value back into a <kbd>datetime</kbd> object or into a formatted string. Although the date is still stored as a text value in the database, Peewee transforms the data in transit to provide better support and functionality in Python. Although we could replicate this functionality manually, like we did in our prior script, this is one of the many useful features that are bundled into Peewee.</p>
<p>On lines 56 through 66, we create typed columns, which reflect primary and foreign keys, text, timestamps, and integers. The <kbd>PrimaryKeyField</kbd> specifies unique and primary key attributes and is assigned to the <kbd>id</kbd> column. The <kbd>ForeignKeyField</kbd> has the <kbd>Custodians</kbd> class as the argument, as Peewee uses this to relate it back to the index in the <kbd>Custodians</kbd> class we defined. Following the two special key fields are a series of fields that we described earlier in this chapter:</p>
<pre>055 class Files(BaseModel):<br/>056     id = peewee.PrimaryKeyField(unique=True, primary_key=True)<br/>057     custodian = peewee.ForeignKeyField(Custodians)<br/>058     file_name = peewee.TextField()<br/>059     file_path = peewee.TextField()<br/>060     extension = peewee.TextField()<br/>061     file_size = peewee.IntegerField()<br/>062     atime = peewee.DateTimeField()<br/>063     mtime = peewee.DateTimeField()<br/>064     ctime = peewee.DateTimeField()<br/>065     mode = peewee.TextField()<br/>066     inode = peewee.IntegerField()</pre>
<p>This completes the entire setup for the database we created previously using a SQL query in the first script. Although it is lengthier in comparison, it does prevent us from having to write our own SQL queries and, when working with larger databases, it is even more essential. For example, a larger script with many modules would greatly benefit from using Peewee to define and handle database connections. Not only would it provide uniformity across the modules, it also allows cross-compatibility with different database backends. Later in this chapter, we will showcase how to change the database type between PostgreSQL, MySQL, and SQLite. Although the Peewee setup is verbose, it adds many features and saves us from having to develop our own functions to handle database transactions.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Jinja2 setup</h1>
                
            
            
                
<p>Now, let's discuss the configuration of the other new module. Jinja2 allows us to create powerful text templates using a Pythonic syntax for text expansion and logic evaluation. Templates also allow us to develop a reusable block of text versus needing to build our table rows and columns line by line within our Python script's <kbd>for</kbd> loops. Although the prior script takes a simplistic approach by forming an HTML file from strings, this template is more robust, dynamic, and most importantly, more sustainable.</p>
<p>This function defines one variable, <kbd>html_string</kbd>, which holds our Jinja2 template. This string captures all of the HTML tags and data to be processed by Jinja2. Although we place this information in a single variable, we could also place the text in a file to avoid the extra line count in our code. On lines 76 and 77, we can see identical information to the previous iteration's <kbd>write_html()</kbd> function:</p>
<pre>069 def get_template():<br/>070     """<br/>071     The get_template function returns a basic template for our<br/>072     HTML report<br/>073     :return: Jinja2 Template<br/>074     """<br/>075     html_string = """<br/>076         &lt;html&gt;\n&lt;head&gt;\n&lt;link rel="stylesheet"<br/>077         href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/<br/>css/bootstrap.min.css"&gt;</pre>
<p>On lines 78 through 80, we open the <kbd>&lt;body&gt;</kbd> and <kbd>&lt;h1&gt;</kbd> header tags, followed by a string containing two instances of a Python object wrapped in spaced double curly braces (<kbd>{{ ... }}</kbd>). Jinja2 looks for a provided dictionary key or object name that matches the name of the string inside of the spaced braces. In the case of lines 79 and 80, the <kbd>custodian</kbd> variable is an object with <kbd>id</kbd> and <kbd>name</kbd> attributes. Using the same syntax as in Python, we can call the object's attribute and insert them into the HTML when the template is executed:</p>
<pre>078         &lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;<br/>079         File Listing for Custodian {{ custodian.id }},<br/>080         {{ custodian.name }}&lt;/h1&gt;\n</pre>
<p>The <kbd>&lt;table&gt;</kbd> tag, on line 81, specifies the Bootstrap CSS classes we use to style our table. On line 82, we open the table row <kbd>&lt;tr&gt;</kbd> tag, followed by a newline <kbd>\n</kbd> character and a new template operator. The curly braces surrounding percentage symbols (<kbd>{% ... %}</kbd>) indicate to Jinja2 that the template contains an operation, such as a loop, that it needs to evaluate. In our case, on line 83 we start a for loop, similar in syntax to Python's for loop, though missing the closing colon. Skipping ahead to line 85, we use the same syntax to surround the <kbd>endfor</kbd> statement, notifying Jinja2 that the loop is complete. We must do this because the HTML is not tab or space sensitive and cannot automatically determine the boundary of a loop like Python's indented code.</p>
<p>It is a good practice to include spaces between the Jinja2 template syntax and the value we would like Jinja2 to insert into the configured placeholders. For example, <kbd>{{ Document_Title }}</kbd> reads a lot easier than <kbd>{{Document_Title}}</kbd>.</p>
<p>On line 84, we then wrap the newly defined header variable in the table header <kbd>&lt;th&gt;</kbd> tags. After the loop completes, we close the table row <kbd>&lt;tr&gt;</kbd> tag on line 86. Through this loop, we have generated a table row, <kbd>&lt;tr&gt;</kbd>, containing a list of the table headers, <kbd>&lt;th&gt;</kbd>, as follows:</p>
<pre>081         &lt;table class="table table-hover table-striped"&gt;\n<br/>082         &lt;tr&gt;\n<br/>083         {% for header in table_headers %}<br/>084             &lt;th&gt;{{ header }}&lt;/th&gt;<br/>085         {% endfor %}<br/>086         &lt;/tr&gt;\n</pre>
<p>Next, we open a new loop to iterate over each reported column, creating a new table row <kbd>&lt;tr&gt;</kbd> and wrapping each element in a table data <kbd>&lt;td&gt;</kbd> tag. Because each column of the database is an attribute of the Peewee-returned row object, we can specify the column name using the following format: <kbd>entry.column_name</kbd>. Through this simple for loop, we build a table in an easy-to-read and extensible format:</p>
<pre>087         {% for entry in file_listing %}<br/>088             &lt;tr&gt;<br/>089                 &lt;td&gt;{{ entry.id }}&lt;/td&gt;<br/>090                 &lt;td&gt;{{ entry.custodian.name }}&lt;/td&gt;<br/>091                 &lt;td&gt;{{ entry.file_name }}&lt;/td&gt;&lt;/td&gt;<br/>092                 &lt;td&gt;{{ entry.file_path }}&lt;/td&gt;<br/>093                 &lt;td&gt;{{ entry.extension }}&lt;/td&gt;<br/>094                 &lt;td&gt;{{ entry.file_size }}&lt;/td&gt;<br/>095                 &lt;td&gt;{{ entry.atime }}&lt;/td&gt;<br/>096                 &lt;td&gt;{{ entry.mtime }}&lt;/td&gt;<br/>097                 &lt;td&gt;{{ entry.ctime }}&lt;/td&gt;<br/>098                 &lt;td&gt;{{ entry.mode }}&lt;/td&gt;<br/>099                 &lt;td&gt;{{ entry.inode }}&lt;/td&gt;<br/>100             &lt;/tr&gt;\n<br/>101         {% endfor %}</pre>
<p>After the <kbd>{% endfor %}</kbd> statement, we can complete this HTML template by closing the open HTML tags and closing the multiline string with three double quotes. With the <kbd>html_string</kbd> built, we call the Jinja2 templating engine to interpret the built string. To do so, we call and return the output of the <kbd>jinja2.Template()</kbd> function on line 103. This allows us to use this template whenever we need to generate an HTML report. We could have also supplied Jinja2 with an HTML file using the same markup as the template to load. This is especially helpful when building more complex or multi-page HTML content:</p>
<pre>102         &lt;/table&gt;\n&lt;/body&gt;\n&lt;/html&gt;"""<br/>103     return jinja2.Template(html_string)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Updating the main() function</h1>
                
            
            
                
<p>This function is almost identical to the <kbd>main()</kbd> function we saw in the previous iteration, albeit with a few exceptions. To begin, on line 117 we do not need to catch a returned value from <kbd>init_db()</kbd> as <kbd>peewee</kbd> handles that for us after initialization. We have also removed the <kbd>while</kbd> loop when calling <kbd>get_or_add_custodian</kbd>, as the logic of the function has been supplemented by Peewee, rendering the sanity check unnecessary. We assign the returned custodian table to a variable named <kbd>custodian_model</kbd> since Peewee refers to each table as a model.</p>
<p>In our case, the <kbd>Custodians</kbd> and <kbd>Files</kbd> classes are models in Peewee that represent the <kbd>Custodians</kbd> and <kbd>Files</kbd> tables in SQLite. In Peewee terms, a set of data returned from one model is referred to as a model instance.</p>
<p>The data returned on line 120 is identical in nature to what was returned by the <kbd>SELECT</kbd> statements in the previous instance of the script, though it is a model instance that's handled by Peewee:</p>
<pre>106 def main(custodian, target, db):<br/>107     """<br/>108     The main function creates the database or table, logs<br/>109         execution status, and handles errors<br/>110     :param custodian: The name of the custodian<br/>111     :param target: tuple containing the mode 'input' or 'output'<br/>112         as the first element and its arguments as the second<br/>113     :param db: The file path for the database<br/>114     :return: None<br/>115     """<br/>116     logger.info('Initializing Database')<br/>117     init_db(db)<br/>118     logger.info('Initialization Successful')<br/>119     logger.info('Retrieving or adding custodian: ' + custodian)<br/>120     custodian_model = get_or_add_custodian(custodian)</pre>
<p>The third modification involves modifying how we handle the different modes for our script. Now, we only need to provide the <kbd>target</kbd> and the <kbd>custodian_model</kbd> variables since we can access the database via the <kbd>peewee</kbd> model classes that we have already built. This behavior will be illustrated within each function to demonstrate how to insert and access data in the tables. The remainder of the function remains the same from our prior iteration:</p>
<pre>121     if target[0] == 'input':<br/>122         logger.info('Ingesting base input directory: {}'.format(<br/>123             target[1]))<br/>124         ingest_directory(target[1], custodian_model)<br/>125         logger.info('Ingesting Complete')<br/>126     elif target[0] == 'output':<br/>127         logger.info(<br/>128             'Preparing to write output for custodian: {}'.format(<br/>129                 custodian))<br/>130         write_output(target[1], custodian_model)<br/>131         logger.info('Output Complete')<br/>132     else:<br/>133         logger.error('Could not interpret run time arguments')<br/>134 <br/>135     logger.info('Script Complete')</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Adjusting the init_db() function</h1>
                
            
            
                
<p>The <kbd>init_db()</kbd> function is where we define the database type (for example, PostgreSQL, MySQL, or SQLite). Although we are using SQLite in this example, we could use another database type to call a separate <kbd>peewee</kbd> function on line 144, such as <kbd>PostgresqlDatabase()</kbd> or <kbd>MySQLDatabase()</kbd>. On line 144, we must pass the path to the file we want Peewee to write the database to. If we prefer to only have the database temporarily, we could pass the special string <kbd>:memory:</kbd> to have Peewee host the SQLite database in memory. There are two downsides to the memory option: one is that the database is not persistent after the script exits, and the second is the database's contents must fit in memory, which may not be possible on older machines or with large databases. With our use case, we must write the database to disk as we may wish to rerun the script against the same database to create additional preservations or reports:</p>
<pre>138 def init_db(db):<br/>139     """<br/>140 The init_db function opens or creates the database<br/>141     :param db_path: The file path for the database<br/>142     :return: conn, the sqlite3 database connection<br/>143     """<br/>144     database = peewee.SqliteDatabase(db)</pre>
<p>After creating our database object, we have to initialize the <kbd>database_proxy</kbd> we created on line 46 and update it to reference the newly created SQLite database. This proxy connection tells Peewee how to route the data from the models into our SQLite instance.</p>
<p>We had to create this proxy earlier to allow us to specify the model data before we initiate the database connection. The use of this proxy also allowed us to ask the user where they'd like to store the database, and through a proxy, we can create a placeholder that we can later assign to the SQLite (or other) database handler.<br/>
<br/>
More information about proxy usage is available in the Peewee documentation at <a href="http://docs.peewee-orm.com/en/3.6.0/peewee/database.html?highlight=proxy#dynamically-defining-a-database">http://docs.peewee-orm.com/en/3.6.0/peewee/database.html?highlight=proxy#dynamically-defining-a-database</a>.</p>
<p>Once connected to the proxy, we can create the necessary tables, thus calling the <kbd>create_tables()</kbd> method on our Peewee database object. As you can see, we had to create a list of the models first so that when we called <kbd>create_tables()</kbd>, we could reference the tables (and their schemas) to create.</p>
<p>The <kbd>safe=True</kbd> argument is required here as we want to ignore the table if it exists in the database so that we do not overwrite or lose data. If we were to expand the functionality of the tool or needed another table, we would need to remember to add it to the list on line 146 so that the table would be created. As mentioned in the <kbd>main()</kbd> function, we do not need to return any connection or cursor object here, as the data flows through the <kbd>peewee</kbd> model classes we defined earlier:</p>
<pre>145 database_proxy.initialize(database)<br/>146 table_list = [Custodians, Files] # Update with any new tables<br/>147 database.create_tables(table_list, safe=True)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Modifying the get_or_add_custodian() function</h1>
                
            
            
                
<p>This function is much simpler than the prior iteration. All we must do is call the <kbd>get_or_create()</kbd> method on our <kbd>Custodians</kbd> model and pass the field identifier, <kbd>name</kbd>, and the value it should respond to, <kbd>custodian</kbd>. With this call, we will have an instance from the model and a Boolean value of whether the row was created or not. Using this <kbd>created</kbd> Boolean value, we can add a logging statement to alert the user that a custodian was either added to the database or that an existing custodian was retrieved. On line 164, we return the model instance to the calling function, as follows:</p>
<pre>150 def get_or_add_custodian(custodian):<br/>151     """<br/>152     The get_or_add_custodian function gets the custodian by name<br/>153         or adds it to the table<br/>154     :param custodian: The name of the custodian<br/>155     :return: custodian_model, custodian peewee model instance<br/>156     """<br/>157     custodian_model, created = Custodians.get_or_create(<br/>158         name=custodian)<br/>159     if created:<br/>160         logger.info('Custodian added')<br/>161     else:<br/>162         logger.info('Custodian retrieved')<br/>163 <br/>164     return custodian_model</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Improving the ingest_directory() function</h1>
                
            
            
                
<p>While one of the more complex functions in this script, it is almost identical to the prior iteration, as the method to gather this information has not varied. The new additions here include the initialization on line 177 of a list we will use to collect the dictionaries of file metadata and the assignment of the passed <kbd>custodian_model</kbd> instance instead of an integer value for the custodian. We also generate the <kbd>ddate</kbd> value, set to a default timestamp, to insert into <kbd>peewee</kbd> in the case that the script is unable to retrieve a date value and needs to store a partial record. The default timestamp values will be set to the minimum value for Python's <kbd>datetime</kbd> library to ensure that date encoding and decoding are still functional.</p>
<p>On line 207, we append the <kbd>meta_data</kbd> dictionary to the <kbd>file_data</kbd> list. What's missing, however, is the code to build a complex SQL insert statement and a list of column names and their values. Instead, we iterate over the <kbd>file_data</kbd> list and write the data in a more efficient manner, as described in a moment; for now, we have the following code:</p>
<pre>167 def ingest_directory(source, custodian_model):<br/>168     """<br/>169     The ingest_directory function reads file metadata and stores<br/>170         it in the database<br/>171     :param source: The path for the root directory to<br/>172         recursively walk<br/>173     :param custodian_model: Peewee model instance for the<br/>174         custodian<br/>175     :return: None<br/>176     """<br/>177     file_data = []<br/>178     for root, _, files in os.walk(source):<br/>179         for file_name in files:<br/>180             ddate = datetime.datetime.min<br/>181             meta_data = {<br/>182                 'file_name': None, 'file_path': None,<br/>183                 'extension': None, 'mode': -1, 'inode': -1,<br/>184                 'file_size': -1, 'atime': ddate, 'mtime': ddate,<br/>185                 'ctime': ddate, 'custodian': custodian_model.id}<br/>186             try:<br/>187                 meta_data['file_name'] = os.path.join(file_name)<br/>188                 meta_data['file_path'] = os.path.join(root,<br/>189                     file_name)<br/>190                 meta_data['extension'] = os.path.splitext(<br/>191                     file_name)[-1]<br/>192 <br/>193                 file_stats = os.stat(meta_data['file_path'])<br/>194                 meta_data['mode'] = str(oct(file_stats.st_mode))<br/>195                 meta_data['inode'] = str(file_stats.st_ino)<br/>196                 meta_data['file_size'] = str(file_stats.st_size)<br/>197                 meta_data['atime'] = format_timestamp(<br/>198                     file_stats.st_atime)<br/>199                 meta_data['mtime'] = format_timestamp(<br/>200                     file_stats.st_mtime)<br/>201                 meta_data['ctime'] = format_timestamp(<br/>202                     file_stats.st_ctime)<br/>203             except Exception as e:<br/>204                 logger.error(<br/>205                     'Error processing file: {} {}'.format(<br/>206                         meta_data['file_path'], e.__str__()))<br/>207             file_data.append(meta_data)</pre>
<p>On line 209, we start to insert file metadata into the database. Because we may have several thousands of lines of data in our list, we need to batch the inserts to the database to prevent any resource exhaustion issues. The loop on 209 uses the <kbd>range</kbd> function, starting at <kbd>0</kbd> and continuing through the length of the <kbd>file_data</kbd> list in increments of <kbd>50</kbd>. This means that <kbd>x</kbd> will be an increment of <kbd>50</kbd> until we reach the last element, where it will catch all remaining items.</p>
<p>By doing this, on line 210, we can insert data into <kbd>Files</kbd> using the <kbd>.insert_many()</kbd> method. Within the insert, we access entries from <kbd>x</kbd> through <kbd>x+50</kbd> to insert <kbd>50</kbd> elements of the list at a time. This method is a change of philosophy from the previous iteration where we inserted each line as it was gathered. Here, we are inserting, batches of rows at the same time using a simplified statement to perform the <kbd>INSERT</kbd> actions. Finally, on line 211, we need to execute each task that we have performed to commit the entries to the database. At the end of the function, we log the count of the files that have been inserted, as follows:</p>
<pre>209     for x in range(0, len(file_data), 50):<br/>210         task = Files.insert_many(file_data[x:x+50])<br/>211         task.execute()<br/>212     logger.info('Stored meta data for {} files.'.format(<br/>213         len(file_data)))</pre>
<p>Feel free to adjust the unit of 50 rows to execute as an insert. Tweaking this number on your system may produce improved performance, although this sweet spot tends to vary depending on the available resources.<br/>
You may also want to look into inserting records once our <kbd>file_data</kbd> list gets to a certain length to help with memory management. For example, if the <kbd>file_data</kbd> list exceeds 500 records, pause the collection, insert the whole list (that is, 50 records at a time), clear the list, and then resume the metadata collection. On larger collections, you should notice a significant reduction in memory usage.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">A closer look at the format_timestamp() function</h1>
                
            
            
                
<p>This function serves the same purpose as the prior iteration, but returns a <kbd>datetime</kbd> object instead, since Peewee uses this object to write the data to the cell for <kbd>datetime</kbd> values. As we saw in the previous iteration, by using the <kbd>fromtimestamp()</kbd> method, we can convert the integer date value into a <kbd>datetime</kbd> object with ease. We can return the <kbd>datetime</kbd> object as is because Peewee handles the rest of the string formatting and conversion for us. This is shown in the following code:</p>
<pre>216 def format_timestamp(ts):<br/>217     """<br/>218     The format_timestamp function converts an integer into a<br/>219     datetime object<br/>220     :param ts: An integer timestamp<br/>221     :return: A datetime object<br/>222     """<br/>223     return datetime.datetime.fromtimestamp(ts)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Converting the write_output() function</h1>
                
            
            
                
<p>In this function, we can see how to query a <kbd>peewee</kbd> model instance. On line 235, we need to select a count of files where the custodian is equal to the custodian's <kbd>id</kbd>. We first call <kbd>select()</kbd> on the model to signify we wish to select data, followed by the <kbd>where()</kbd> method to specify the column name, <kbd>Files.custodian</kbd>, and the value, <kbd>custodian_model.id</kbd>, to evaluate. This is followed by the <kbd>count()</kbd> method to provide an integer of the number of responsive results. Note that the <kbd>count</kbd> variable is an integer, not a tuple, like it was in the previous iteration:</p>
<pre>226 def write_output(source, custodian_model):<br/>227     """<br/>228     The write_output function handles writing either the CSV or<br/>229         HTML reports<br/>230     :param source: The output filepath<br/>231     :param custodian_model: Peewee model instance for the<br/>232         custodian<br/>233     :return: None<br/>234     """<br/>235     count = Files.select().where(<br/>236         Files.custodian == custodian_model.id).count()<br/>237 <br/>238     logger.info("{} files found for custodian.".format(count))</pre>
<p>On line 240, we follow the same logic from the prior iteration to check and see whether some lines were responsive, followed by statements to validate the output extension to engage the correct writer or provide the user's accurate error information. Note that, this time, we pass along the custodian model instance versus an <kbd>id</kbd> or name on lines 243 and 247, as Peewee performs operations best on existing model instances:</p>
<pre>240     if not count:<br/>241         logger.error('Files not found for custodian')<br/>242     elif source.endswith('.csv'):<br/>243         write_csv(source, custodian_model)<br/>244     elif source.endswith('.html'):<br/>245         write_html(source, custodian_model)<br/>246     elif not (source.endswith('.html') or \<br/>247         source.endswith('.csv')):<br/>248         logger.error('Could not determine file type')<br/>249     else:<br/>250         logger.error('Unknown Error Occurred')</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Simplifying the write_csv() function</h1>
                
            
            
                
<p>The <kbd>write_csv()</kbd> function uses a new method from the <kbd>peewee</kbd> library, allowing us to retrieve data from the database as dictionaries. Using the familiar <kbd>Files.select().where()</kbd> statement, we append the <kbd>dicts()</kbd> method to convert the result into Python dictionaries. This dictionary format is an excellent input for our reports, as the built-in CSV module has a class named <kbd>DictWriter</kbd>. As its name suggests, this class allows us to pass a dictionary of information to be written as a row of data in a CSV file. Now that we have our query staged, we can log to the user that we are starting to write the CSV report:</p>
<pre>253 def write_csv(source, custodian_model):<br/>254     """<br/>255     The write_csv function generates a CSV report from the Files<br/>256         table<br/>257     :param source: The output filepath<br/>258     :param custodian_model: Peewee model instance for the<br/>259         custodian<br/>260     :return: None<br/>261     """<br/>262     query = Files.select().where(<br/>263         Files.custodian == custodian_model.id).dicts()<br/>264     logger.info('Writing CSV report')</pre>
<p>Next, we define our column names for our CSV writer and open the user-specified output file using the <kbd>with...as...</kbd> statement. To initialize the <kbd>csv.DictWriter</kbd> class, we pass the open file object and column headers that correspond to the table's column names (and therefore the dictionary key names). After initialization, we call the <kbd>writeheader()</kbd> method and write the table's header at the top of the spreadsheet. Finally, to write the row content, we open a <kbd>for</kbd> loop on our query object to iterate over the rows and write them to the file with the <kbd>.writerow()</kbd> method. Using the <kbd>enumerate</kbd> method, we can provide the user with a status update every 10,000 rows to let them know that our code is hard at work for larger file reports. After writing those status updates (and rows, of course), we add some additional log messages for the user and exit the function. Although we are calling the <kbd>csv</kbd> library, remember that it is actually our <kbd>unicodecsv</kbd> import. This means that we will encounter less encoding errors while generating our output versus using the standard <kbd>csv</kbd> library:</p>
<pre>266     cols = [u'id', u'custodian', u'file_name', u'file_path',<br/>267         u'extension', u'file_size', u'ctime', u'mtime',<br/>268         u'atime', u'mode', u'inode']<br/>269 <br/>270     with open(source, 'wb') as csv_file:<br/>271         csv_writer = csv.DictWriter(csv_file, cols)<br/>272         csv_writer.writeheader()<br/>273         for counter, row in enumerate(query):<br/>274             csv_writer.writerow(row)<br/>275             if counter % 10000 == 0:<br/>276                 logger.debug('{:,} lines written'.format(counter))<br/>277         logger.debug('{:,} lines written'.format(counter))<br/>278 <br/>279     logger.info('CSV Report completed: ' + source)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Condensing the write_html() function</h1>
                
            
            
                
<p>We will need the <kbd>get_template()</kbd> function we designed earlier to generate our HTML report. On line 291, we call this pre-built Jinja2 template object and store it in the <kbd>template</kbd> variable. When referencing the template, we need to provide a dictionary with three keys: <kbd>table_headers</kbd>, <kbd>file_listing</kbd>, and <kbd>custodian</kbd>. These three keys are required as they are what we chose as placeholders in our template. On line 292, we build out the table headers as a list of strings, formatted in the order we wish to display them:</p>
<pre>282 def write_html(source, custodian_model):<br/>283     """<br/>284     The write_html function generates an HTML report from the<br/>285         Files table<br/>286     :param source: The output file path<br/>287     :param custodian_model: Peewee model instance for the<br/>288         custodian<br/>289     :return: None<br/>290     """<br/>291     template = get_template()<br/>292     table_headers = [<br/>293         'Id', 'Custodian', 'File Name', 'File Path',<br/>294         'File Extension', 'File Size', 'Created Time',<br/>295         'Modified Time', 'Accessed Time', 'Mode', 'Inode']</pre>
<p>Afterwards, we create our <kbd>file_data</kbd> list for the <kbd>file_listing</kbd> key on line 296 by using a similar <kbd>select</kbd> statement that's found in the CSV function. This list allows us to access the attributes individually within the template, as specified earlier. We could have placed this logic within the template file as well, but we thought it best to place malleable logic in a function versus a template. Take a look at lines 296 and 297:</p>
<pre>296     file_data = Files.select().where(<br/>297         Files.custodian == custodian_model.id)</pre>
<p>With all three of these elements gathered, we create a dictionary with the keys to match the data in our template on line 299. After a log statement, we open the source using a <kbd>with...as...</kbd> statement. To write the template data, we call the <kbd>render()</kbd> method on our <kbd>template</kbd> object, passing our already built dictionary as a <kbd>kwarg</kbd> on line 307. The <kbd>render()</kbd> method evaluates the statements and logic found in the template and places the provided data in the correct location to form an HTML report. This method also returns the raw HTML as a string, so we have encapsulated it in a <kbd>write()</kbd> call to immediately write the data to the file. Once written, we log the path to the source, as well as its successful completion:</p>
<pre>299     template_dict = {<br/>300         'custodian': custodian_model,<br/>301         'table_headers': table_headers,<br/>302         'file_listing': file_data}<br/>303 <br/>304     logger.info('Writing HTML report')<br/>305 <br/>306     with open(source, 'w') as html_file:<br/>307         html_file.write(template.render(**template_dict))<br/>308 <br/>309     logger.info('HTML Report completed: ' + source)</pre>


            

            
        
    

        

                            
                    <h1 class="header-title">Running our new and improved script</h1>
                
            
            
                
<p>This iteration highlights the use of additional Python third-party libraries to handle many of the operations we previously performed in a more manual manner. In this instance, we used Peewee and Jinja2 to further automate database management and HTML reporting. These two libraries are popular methods for handling this type of data and are either bundled into or have ports for other Python suites, such as Flask and Django.</p>
<p>In addition, this iteration closely resembles the first to demonstrate the differences in the two methods in a clearer manner. One of the goals of this book is to introduce as many methods for performing a task in Python as possible. The purpose of this chapter is not to create a better iteration, but to showcase different methods to accomplish the same tasks and add new skills to our toolbox. This is the last chapter where we will be creating multiple iterations of a script; the chapters going forward are focused on more expansive singular scripts as we begin to expand on our forensic coding capabilities.</p>
<p>Note that the way in which we execute our script has not changed. We still need to specify a custodian, a path to a database, and the type of mode. You may notice that this script is considerably slower than our previous script. Sometimes, when using automated solutions, our code can suffer due to additional overhead or the inefficient implementation of the module. Here, we've lost some efficiency by moving away from a more bare-bones and manual process. However, this script is more maintainable and does not require the developer to have in-depth knowledge of SQL.</p>
<p>For this iteration, we opted to generate our Bootstrap-based HTML report. What this report lacks in analytical capacity, it gains in portability and simplicity. This is a professional looking page, thanks to Bootstrap, and can be searched for specific files of interest or printed out for those that prefer the paper-and-pen approach:</p>
<p class="CDPAlignCenter CDPAlign"><img src="img/704f62c0-0c15-4525-84bf-fa7f0564587b.png"/></p>


            

            
        
    

        

                            
                    <h1 class="header-title">Challenge</h1>
                
            
            
                
<p>As always, we challenge you to add new features to this script and extend it using the knowledge and available resources that you have. For this chapter, we first challenge you to hash the indexed files using MD5 or SHA1 and store that information in the database. You can use the built-in <kbd>hashlib</kbd> library to handle hashing operations; more on this and other hashing techniques in <a href="91206072-f125-4a9e-83fe-8de632624d0e.xhtml" target="_blank">Chapter 7</a>, <em>Fuzzy Hashing</em>.</p>
<p>In addition, consider adding user-specified filters for particular file extensions for the collection. These features can be implemented without major renovation to the code, though you may find it easiest and more beneficial to your understanding to start from scratch and build the script with one or more of these new features in mind.</p>
<p>One more extension that we can add to our code is parsing the file's modes into separate columns for ease of querying in our database and reports. While the number we store is compact and the format is generally understood, splitting out the value into separate columns can help non-technical reviewers understand these file's properties and allow easier queries against the database in case we want to identify all files with a specified permission set. We could either perform this operation in our collection module or keep our current database schema and interpret the modes while generating our reports.</p>


            

            
        
    

        

                            
                    <h1 class="header-title">Summary</h1>
                
            
            
                
<p>This chapter focused on the use of databases in script development. We explored how to use and manipulate a SQLite database in Python to store and retrieve information about file listings. We discussed when and how a database is a correct solution to store this information, as it has a fixed data structure and could be a large dataset.</p>
<p>In addition, we discussed multiple methods of interacting with databases, a manual process to show how databases work at a lower level, and a more Pythonic example where a third-party module handles these low-level interactions for us. We also explored a new type of report, using HTML to create a different output that can be viewed without additional software, and manipulating it to add new styles and functionality as we see fit. Overall, this section builds on the underlying goal of demonstrating different ways we can use Python and supporting libraries to solve forensic challenges. The code for this project can be downloaded from GitHub or Packt, as described in the <em>Preface</em>.</p>
<p>In the next chapter, we will learn how to parse binary data and registry hives using third-party libraries. Learning how to parse binary data will become a fundamental skill for the forensic developer and will be performed by many of the libraries that are featured throughout the remainder of this book.</p>


            

            
        
    </body></html>